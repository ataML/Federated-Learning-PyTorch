{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "native-suffering",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MONAI version: 0.5.2+24.g2a4c9e5\n",
      "Numpy version: 1.19.2\n",
      "Pytorch version: 1.8.0a0+52ea372\n",
      "MONAI flags: HAS_EXT = True, USE_COMPILED = False\n",
      "MONAI rev id: 2a4c9e514bbc603191e49120e9d598a9414c0e75\n",
      "\n",
      "Optional dependencies:\n",
      "Pytorch Ignite version: 0.4.4\n",
      "Nibabel version: 3.2.1\n",
      "scikit-image version: 0.15.0\n",
      "Pillow version: 8.2.0\n",
      "Tensorboard version: 1.15.0+nv\n",
      "gdown version: 3.13.0\n",
      "TorchVision version: 0.9.0a0\n",
      "ITK version: 5.1.2\n",
      "tqdm version: 4.53.0\n",
      "lmdb version: 1.1.1\n",
      "psutil version: 5.8.0\n",
      "\n",
      "For details about installing the optional dependencies, please visit:\n",
      "    https://docs.monai.io/en/latest/installation.html#installing-the-recommended-dependencies\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Copyright 2020 MONAI Consortium\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "import tempfile\n",
    "import copy \n",
    "import src.update \n",
    "\n",
    "import tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from monai.apps import DecathlonDataset\n",
    "from monai.config import print_config\n",
    "\n",
    "from monai.losses import DiceLoss\n",
    "from monai.metrics import DiceMetric\n",
    "from monai.networks.nets import UNet\n",
    "\n",
    "from src.update import LocalUpdate\n",
    "from monai.utils import set_determinism\n",
    "from src.utils import get_dataset,average_weights\n",
    "\n",
    "import torch\n",
    "\n",
    "print_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "certain-valuable",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from tensorboardX import SummaryWriter\n",
    "\n",
    "path_project = os.path.abspath('..')\n",
    "#logger = SummaryWriter('../logs')\n",
    "logger=0\n",
    "os.environ[\"MONAI_DATA_DIRECTORY\"]=\"/data\"  \n",
    "root_dir = os.environ.get(\"MONAI_DATA_DIRECTORY\")\n",
    "\n",
    "#args = args_parser()\n",
    "epochs = 80\n",
    "num_users = 1\n",
    "frac = 1 \n",
    "local_ep = 1\n",
    "local_bs = 2\n",
    "lr = 1e-4\n",
    "momentum = 0.5\n",
    "iid=1\n",
    "dataset=\"brats\"\n",
    "#exp_details(args)\n",
    "\n",
    "device = torch.device(\"cuda:0\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "modified-parks",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "print(local_ep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "revised-implementation",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_determinism(seed=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "circular-ladder",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import src.utils\n",
    "importlib.reload(src.utils)\n",
    "from src.utils import get_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "surrounded-sullivan",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Task01_BrainTumour.tar: 0.00B [00:00, ?B/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Task01_BrainTumour.tar: 7.09GB [21:44, 5.83MB/s]                                \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "downloaded file: /data/Task01_BrainTumour.tar.\n",
      "Verified 'Task01_BrainTumour.tar', md5: 240a19d752f0d9e9101544901065d872.\n",
      "Verified 'Task01_BrainTumour.tar', md5: 240a19d752f0d9e9101544901065d872.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading dataset: 100%|██████████| 100/100 [02:12<00:00,  1.32s/it]\n",
      "Loading dataset:   0%|          | 0/96 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verified 'Task01_BrainTumour.tar', md5: 240a19d752f0d9e9101544901065d872.\n",
      "file /data/Task01_BrainTumour.tar exists, skip downloading.\n",
      "extracted file /data/Task01_BrainTumour exists, skip extracting.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading dataset: 100%|██████████| 96/96 [02:01<00:00,  1.26s/it]\n"
     ]
    }
   ],
   "source": [
    "#Load Datasets\n",
    "train_dataset, val_dataset, user_groups_train, user_groups_val = get_dataset(iid, num_users, download_dataset=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "associate-milan",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "smoking-controversy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387}\n",
      "0 {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95}\n"
     ]
    }
   ],
   "source": [
    "for key,value in user_groups_train.items():\n",
    "    print(key,value)\n",
    "for key,value in user_groups_val.items():\n",
    "    print(key,value)\n",
    "#print(len(train_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "going-amateur",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image shape: torch.Size([4, 128, 128, 64])\n",
      "<class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "print(f\"image shape: {train_dataset[2]['image'].shape}\")\n",
    "print(type(train_dataset[2]['image']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "measured-evidence",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Build model\n",
    "global_model = UNet(\n",
    "    dimensions=3,\n",
    "    in_channels=4,\n",
    "    out_channels=3,\n",
    "    channels=(16, 32, 64, 128, 256),\n",
    "    strides=(2, 2, 2, 2),\n",
    "    num_res_units=2,\n",
    ").to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "christian-carol",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "photographic-roommate",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import src.update\n",
    "importlib.reload(src.update)\n",
    "from src.update import LocalUpdate\n",
    "import src.utils\n",
    "importlib.reload(src.utils)\n",
    "from src.utils import average_weights\n",
    "import time "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "associate-myrtle",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "special-yukon",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/80 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " | Global Training Round : 1 |\n",
      "\n",
      "user 0 selected\n",
      "local epoch 1\n",
      "1/194, train_loss: 0.9779\n",
      "2/194, train_loss: 0.9504\n",
      "3/194, train_loss: 0.9455\n",
      "4/194, train_loss: 0.9889\n",
      "5/194, train_loss: 0.9375\n",
      "6/194, train_loss: 0.9605\n",
      "7/194, train_loss: 0.9616\n",
      "8/194, train_loss: 0.9538\n",
      "9/194, train_loss: 0.9743\n",
      "10/194, train_loss: 0.9709\n",
      "11/194, train_loss: 0.9811\n",
      "12/194, train_loss: 0.9662\n",
      "13/194, train_loss: 0.9817\n",
      "14/194, train_loss: 0.9724\n",
      "15/194, train_loss: 0.9849\n",
      "16/194, train_loss: 0.9584\n",
      "17/194, train_loss: 0.9816\n",
      "18/194, train_loss: 0.9616\n",
      "19/194, train_loss: 0.9669\n",
      "20/194, train_loss: 0.9520\n",
      "21/194, train_loss: 0.9627\n",
      "22/194, train_loss: 0.9406\n",
      "23/194, train_loss: 0.9489\n",
      "24/194, train_loss: 0.9588\n",
      "25/194, train_loss: 0.9607\n",
      "26/194, train_loss: 0.9519\n",
      "27/194, train_loss: 0.9555\n",
      "28/194, train_loss: 0.9512\n",
      "29/194, train_loss: 0.9791\n",
      "30/194, train_loss: 0.9600\n",
      "31/194, train_loss: 0.9410\n",
      "32/194, train_loss: 0.9677\n",
      "33/194, train_loss: 0.9656\n",
      "34/194, train_loss: 0.9337\n",
      "35/194, train_loss: 0.9709\n",
      "36/194, train_loss: 0.9815\n",
      "37/194, train_loss: 0.9551\n",
      "38/194, train_loss: 0.9493\n",
      "39/194, train_loss: 0.9276\n",
      "40/194, train_loss: 0.9542\n",
      "41/194, train_loss: 0.9676\n",
      "42/194, train_loss: 0.9547\n",
      "43/194, train_loss: 0.9533\n",
      "44/194, train_loss: 0.9539\n",
      "45/194, train_loss: 0.9426\n",
      "46/194, train_loss: 0.9215\n",
      "47/194, train_loss: 0.9823\n",
      "48/194, train_loss: 0.9468\n",
      "49/194, train_loss: 0.9493\n",
      "50/194, train_loss: 0.9816\n",
      "51/194, train_loss: 0.9657\n",
      "52/194, train_loss: 0.9468\n",
      "53/194, train_loss: 0.9417\n",
      "54/194, train_loss: 0.9638\n",
      "55/194, train_loss: 0.9727\n",
      "56/194, train_loss: 0.9755\n",
      "57/194, train_loss: 0.9366\n",
      "58/194, train_loss: 0.9691\n",
      "59/194, train_loss: 0.9206\n",
      "60/194, train_loss: 0.9350\n",
      "61/194, train_loss: 0.9259\n",
      "62/194, train_loss: 0.9381\n",
      "63/194, train_loss: 0.9073\n",
      "64/194, train_loss: 0.9233\n",
      "65/194, train_loss: 0.9726\n",
      "66/194, train_loss: 0.9581\n",
      "67/194, train_loss: 0.9255\n",
      "68/194, train_loss: 0.9622\n",
      "69/194, train_loss: 0.9566\n",
      "70/194, train_loss: 0.9347\n",
      "71/194, train_loss: 0.9364\n",
      "72/194, train_loss: 0.9527\n",
      "73/194, train_loss: 0.9236\n",
      "74/194, train_loss: 0.9057\n",
      "75/194, train_loss: 0.9407\n",
      "76/194, train_loss: 0.9420\n",
      "77/194, train_loss: 0.9714\n",
      "78/194, train_loss: 0.9535\n",
      "79/194, train_loss: 0.9721\n",
      "80/194, train_loss: 0.9267\n",
      "81/194, train_loss: 0.9564\n",
      "82/194, train_loss: 0.9626\n",
      "83/194, train_loss: 0.9500\n",
      "84/194, train_loss: 0.9163\n",
      "85/194, train_loss: 0.9647\n",
      "86/194, train_loss: 0.9297\n",
      "87/194, train_loss: 0.9425\n",
      "88/194, train_loss: 0.9498\n",
      "89/194, train_loss: 0.9591\n",
      "90/194, train_loss: 0.9638\n",
      "91/194, train_loss: 0.9093\n",
      "92/194, train_loss: 0.9616\n",
      "93/194, train_loss: 0.9479\n",
      "94/194, train_loss: 0.9645\n",
      "95/194, train_loss: 0.8941\n",
      "96/194, train_loss: 0.9150\n",
      "97/194, train_loss: 0.9705\n",
      "98/194, train_loss: 0.9454\n",
      "99/194, train_loss: 0.9207\n",
      "100/194, train_loss: 0.9679\n",
      "101/194, train_loss: 0.9559\n",
      "102/194, train_loss: 0.9420\n",
      "103/194, train_loss: 0.9630\n",
      "104/194, train_loss: 0.9624\n",
      "105/194, train_loss: 0.9379\n",
      "106/194, train_loss: 0.9516\n",
      "107/194, train_loss: 0.9724\n",
      "108/194, train_loss: 0.9547\n",
      "109/194, train_loss: 0.9691\n",
      "110/194, train_loss: 0.9409\n",
      "111/194, train_loss: 0.9457\n",
      "112/194, train_loss: 0.9723\n",
      "113/194, train_loss: 0.9423\n",
      "114/194, train_loss: 0.9655\n",
      "115/194, train_loss: 0.9462\n",
      "116/194, train_loss: 0.9514\n",
      "117/194, train_loss: 0.9416\n",
      "118/194, train_loss: 0.9698\n",
      "119/194, train_loss: 0.9624\n",
      "120/194, train_loss: 0.9707\n",
      "121/194, train_loss: 0.9500\n",
      "122/194, train_loss: 0.9893\n",
      "123/194, train_loss: 0.9852\n",
      "124/194, train_loss: 0.9226\n",
      "125/194, train_loss: 0.9418\n",
      "126/194, train_loss: 0.9753\n",
      "127/194, train_loss: 0.9322\n",
      "128/194, train_loss: 0.9333\n",
      "129/194, train_loss: 0.9676\n",
      "130/194, train_loss: 0.9105\n",
      "131/194, train_loss: 0.9438\n",
      "132/194, train_loss: 0.9358\n",
      "133/194, train_loss: 0.9724\n",
      "134/194, train_loss: 0.9361\n",
      "135/194, train_loss: 0.9422\n",
      "136/194, train_loss: 0.9893\n",
      "137/194, train_loss: 0.9565\n",
      "138/194, train_loss: 0.9376\n",
      "139/194, train_loss: 0.9454\n",
      "140/194, train_loss: 0.9584\n",
      "141/194, train_loss: 0.9324\n",
      "142/194, train_loss: 0.9570\n",
      "143/194, train_loss: 0.9643\n",
      "144/194, train_loss: 0.9335\n",
      "145/194, train_loss: 0.9424\n",
      "146/194, train_loss: 0.9621\n",
      "147/194, train_loss: 0.9781\n",
      "148/194, train_loss: 0.9294\n",
      "149/194, train_loss: 0.9301\n",
      "150/194, train_loss: 0.9762\n",
      "151/194, train_loss: 0.9674\n",
      "152/194, train_loss: 0.9598\n",
      "153/194, train_loss: 0.9205\n",
      "154/194, train_loss: 0.9849\n",
      "155/194, train_loss: 0.9758\n",
      "156/194, train_loss: 0.9251\n",
      "157/194, train_loss: 0.9412\n",
      "158/194, train_loss: 0.9728\n",
      "159/194, train_loss: 0.9887\n",
      "160/194, train_loss: 0.9132\n",
      "161/194, train_loss: 0.9913\n",
      "162/194, train_loss: 0.9670\n",
      "163/194, train_loss: 0.9673\n",
      "164/194, train_loss: 0.9501\n",
      "165/194, train_loss: 0.9857\n",
      "166/194, train_loss: 0.9740\n",
      "167/194, train_loss: 0.9682\n",
      "168/194, train_loss: 0.9345\n",
      "169/194, train_loss: 0.8772\n",
      "170/194, train_loss: 0.9559\n",
      "171/194, train_loss: 0.9268\n",
      "172/194, train_loss: 0.9406\n",
      "173/194, train_loss: 0.9460\n",
      "174/194, train_loss: 0.9609\n",
      "175/194, train_loss: 0.9836\n",
      "176/194, train_loss: 0.9050\n",
      "177/194, train_loss: 0.9042\n",
      "178/194, train_loss: 0.9234\n",
      "179/194, train_loss: 0.9739\n",
      "180/194, train_loss: 0.9131\n",
      "181/194, train_loss: 0.8992\n",
      "182/194, train_loss: 0.8797\n",
      "183/194, train_loss: 0.9566\n",
      "184/194, train_loss: 0.9362\n",
      "185/194, train_loss: 0.9592\n",
      "186/194, train_loss: 0.9387\n",
      "187/194, train_loss: 0.9879\n",
      "188/194, train_loss: 0.9795\n",
      "189/194, train_loss: 0.9639\n",
      "190/194, train_loss: 0.9741\n",
      "191/194, train_loss: 0.9054\n",
      "192/194, train_loss: 0.9310\n",
      "193/194, train_loss: 0.9256\n",
      "194/194, train_loss: 0.9651\n",
      "metric=0.08991515411374469, metric_tc=0.07007136277388781, metric_wt=0.16506222907143334, metric_et=0.03461187309585512\n",
      "metric=0.08991515411374469, metric_tc=0.07007136277388781, metric_wt=0.16506222907143334, metric_et=0.03461187309585512\n",
      "current epoch: 1 current epoch loss: 0.9515\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▏         | 1/80 [13:26<17:41:15, 806.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metric=0.08991515411374469, metric_tc=0.07007136277388781, metric_wt=0.16506222907143334, metric_et=0.03461187309585512\n",
      "0.08991515411374469\n",
      "saved new best metric model\n",
      "current epoch: 1 current mean dice: 0.0899 tc: 0.0701 wt: 0.1651 et: 0.0346\n",
      "best mean dice: 0.0899 at epoch: 1\n",
      "\n",
      " | Global Training Round : 2 |\n",
      "\n",
      "user 0 selected\n",
      "local epoch 1\n",
      "1/194, train_loss: 0.9256\n",
      "2/194, train_loss: 0.9354\n",
      "3/194, train_loss: 0.9702\n",
      "4/194, train_loss: 0.9675\n",
      "5/194, train_loss: 0.9795\n",
      "6/194, train_loss: 0.9369\n",
      "7/194, train_loss: 0.9420\n",
      "8/194, train_loss: 0.9651\n",
      "9/194, train_loss: 0.9777\n",
      "10/194, train_loss: 0.9874\n",
      "11/194, train_loss: 0.9493\n",
      "12/194, train_loss: 0.9676\n",
      "13/194, train_loss: 0.9542\n",
      "14/194, train_loss: 0.9549\n",
      "15/194, train_loss: 0.9580\n",
      "16/194, train_loss: 0.9876\n",
      "17/194, train_loss: 0.9279\n",
      "18/194, train_loss: 0.9753\n",
      "19/194, train_loss: 0.9496\n",
      "20/194, train_loss: 0.9727\n",
      "21/194, train_loss: 0.9091\n",
      "22/194, train_loss: 0.9269\n",
      "23/194, train_loss: 0.9716\n",
      "24/194, train_loss: 0.9650\n",
      "25/194, train_loss: 0.9625\n",
      "26/194, train_loss: 0.9657\n",
      "27/194, train_loss: 0.9656\n",
      "28/194, train_loss: 0.9315\n",
      "29/194, train_loss: 0.9261\n",
      "30/194, train_loss: 0.9241\n",
      "31/194, train_loss: 0.9810\n",
      "32/194, train_loss: 0.9311\n",
      "33/194, train_loss: 0.9446\n",
      "34/194, train_loss: 0.9712\n",
      "35/194, train_loss: 0.9450\n",
      "36/194, train_loss: 0.9338\n",
      "37/194, train_loss: 0.9414\n",
      "38/194, train_loss: 0.8779\n",
      "39/194, train_loss: 0.9521\n",
      "40/194, train_loss: 0.8790\n",
      "41/194, train_loss: 0.9710\n",
      "42/194, train_loss: 0.9514\n",
      "43/194, train_loss: 0.9526\n",
      "44/194, train_loss: 0.9266\n",
      "45/194, train_loss: 0.9040\n",
      "46/194, train_loss: 0.9223\n",
      "47/194, train_loss: 0.9146\n",
      "48/194, train_loss: 0.9143\n",
      "49/194, train_loss: 0.9485\n",
      "50/194, train_loss: 0.9249\n",
      "51/194, train_loss: 0.9340\n",
      "52/194, train_loss: 0.9843\n",
      "53/194, train_loss: 0.9783\n",
      "54/194, train_loss: 0.9685\n",
      "55/194, train_loss: 0.9842\n",
      "56/194, train_loss: 0.9630\n",
      "57/194, train_loss: 0.9454\n",
      "58/194, train_loss: 0.9691\n",
      "59/194, train_loss: 0.9455\n",
      "60/194, train_loss: 0.9496\n",
      "61/194, train_loss: 0.9502\n",
      "62/194, train_loss: 0.9390\n",
      "63/194, train_loss: 0.9420\n",
      "64/194, train_loss: 0.9282\n",
      "65/194, train_loss: 0.9452\n",
      "66/194, train_loss: 0.9501\n",
      "67/194, train_loss: 0.9698\n",
      "68/194, train_loss: 0.9428\n",
      "69/194, train_loss: 0.9034\n",
      "70/194, train_loss: 0.9456\n",
      "71/194, train_loss: 0.9519\n",
      "72/194, train_loss: 0.9085\n",
      "73/194, train_loss: 0.9866\n",
      "74/194, train_loss: 0.9467\n",
      "75/194, train_loss: 0.9518\n",
      "76/194, train_loss: 0.9515\n",
      "77/194, train_loss: 0.9849\n",
      "78/194, train_loss: 0.9413\n",
      "79/194, train_loss: 0.9042\n",
      "80/194, train_loss: 0.9145\n",
      "81/194, train_loss: 0.9382\n",
      "82/194, train_loss: 0.8892\n",
      "83/194, train_loss: 0.9685\n",
      "84/194, train_loss: 0.9627\n",
      "85/194, train_loss: 0.9658\n",
      "86/194, train_loss: 0.9151\n",
      "87/194, train_loss: 0.9902\n",
      "88/194, train_loss: 0.9320\n",
      "89/194, train_loss: 0.9659\n",
      "90/194, train_loss: 0.9195\n",
      "91/194, train_loss: 0.9277\n",
      "92/194, train_loss: 0.9258\n",
      "93/194, train_loss: 0.9222\n",
      "94/194, train_loss: 0.9437\n",
      "95/194, train_loss: 0.9595\n",
      "96/194, train_loss: 0.9622\n",
      "97/194, train_loss: 0.9305\n",
      "98/194, train_loss: 0.8990\n",
      "99/194, train_loss: 0.9576\n",
      "100/194, train_loss: 0.9364\n",
      "101/194, train_loss: 0.8929\n",
      "102/194, train_loss: 0.9482\n",
      "103/194, train_loss: 0.9395\n",
      "104/194, train_loss: 0.9474\n",
      "105/194, train_loss: 0.9300\n",
      "106/194, train_loss: 0.8862\n",
      "107/194, train_loss: 0.8773\n",
      "108/194, train_loss: 0.9584\n",
      "109/194, train_loss: 0.9440\n",
      "110/194, train_loss: 0.9651\n",
      "111/194, train_loss: 0.9654\n",
      "112/194, train_loss: 0.9139\n",
      "113/194, train_loss: 0.9091\n",
      "114/194, train_loss: 0.9387\n",
      "115/194, train_loss: 0.9491\n",
      "116/194, train_loss: 0.9586\n",
      "117/194, train_loss: 0.8747\n",
      "118/194, train_loss: 0.9732\n",
      "119/194, train_loss: 0.9230\n",
      "120/194, train_loss: 0.9217\n",
      "121/194, train_loss: 0.9562\n",
      "122/194, train_loss: 0.9500\n",
      "123/194, train_loss: 0.9922\n",
      "124/194, train_loss: 0.9493\n",
      "125/194, train_loss: 0.9330\n",
      "126/194, train_loss: 0.9431\n",
      "127/194, train_loss: 0.9764\n",
      "128/194, train_loss: 0.9502\n",
      "129/194, train_loss: 0.9583\n",
      "130/194, train_loss: 0.9582\n",
      "131/194, train_loss: 0.8978\n",
      "132/194, train_loss: 0.9613\n",
      "133/194, train_loss: 0.9352\n",
      "134/194, train_loss: 0.9502\n",
      "135/194, train_loss: 0.9634\n",
      "136/194, train_loss: 0.9671\n",
      "137/194, train_loss: 0.8970\n",
      "138/194, train_loss: 0.9350\n",
      "139/194, train_loss: 0.9206\n",
      "140/194, train_loss: 0.9642\n",
      "141/194, train_loss: 0.9478\n",
      "142/194, train_loss: 0.9571\n",
      "143/194, train_loss: 0.9539\n",
      "144/194, train_loss: 0.9127\n",
      "145/194, train_loss: 0.9265\n",
      "146/194, train_loss: 0.9658\n",
      "147/194, train_loss: 0.9399\n",
      "148/194, train_loss: 0.9429\n",
      "149/194, train_loss: 0.9339\n",
      "150/194, train_loss: 0.9571\n",
      "151/194, train_loss: 0.9056\n",
      "152/194, train_loss: 0.9323\n",
      "153/194, train_loss: 0.9459\n",
      "154/194, train_loss: 0.9487\n",
      "155/194, train_loss: 0.9515\n",
      "156/194, train_loss: 0.9716\n",
      "157/194, train_loss: 0.9729\n",
      "158/194, train_loss: 0.9598\n",
      "159/194, train_loss: 0.9486\n",
      "160/194, train_loss: 0.9281\n",
      "161/194, train_loss: 0.9190\n",
      "162/194, train_loss: 0.9364\n",
      "163/194, train_loss: 0.9526\n",
      "164/194, train_loss: 0.9357\n",
      "165/194, train_loss: 0.9249\n",
      "166/194, train_loss: 0.9912\n",
      "167/194, train_loss: 0.9666\n",
      "168/194, train_loss: 0.9181\n",
      "169/194, train_loss: 0.9121\n",
      "170/194, train_loss: 0.9710\n",
      "171/194, train_loss: 0.9178\n",
      "172/194, train_loss: 0.9324\n",
      "173/194, train_loss: 0.9405\n",
      "174/194, train_loss: 0.9753\n",
      "175/194, train_loss: 0.9575\n",
      "176/194, train_loss: 0.9314\n",
      "177/194, train_loss: 0.9762\n",
      "178/194, train_loss: 0.9750\n",
      "179/194, train_loss: 0.9339\n",
      "180/194, train_loss: 0.9433\n",
      "181/194, train_loss: 0.9446\n",
      "182/194, train_loss: 0.9706\n",
      "183/194, train_loss: 0.9361\n",
      "184/194, train_loss: 0.9277\n",
      "185/194, train_loss: 0.9249\n",
      "186/194, train_loss: 0.9444\n",
      "187/194, train_loss: 0.9551\n",
      "188/194, train_loss: 0.9121\n",
      "189/194, train_loss: 0.9426\n",
      "190/194, train_loss: 0.9421\n",
      "191/194, train_loss: 0.9642\n",
      "192/194, train_loss: 0.9284\n",
      "193/194, train_loss: 0.9609\n",
      "194/194, train_loss: 0.9709\n",
      "metric=0.10237315475630264, metric_tc=0.07969408218438427, metric_wt=0.1885757239845892, metric_et=0.0388496576245719\n",
      "metric=0.10237315475630264, metric_tc=0.07969408218438427, metric_wt=0.1885757239845892, metric_et=0.0388496576245719\n",
      "current epoch: 2 current epoch loss: 0.9445\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▎         | 2/80 [27:34<17:44:33, 818.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metric=0.10237315475630264, metric_tc=0.07969408218438427, metric_wt=0.1885757239845892, metric_et=0.0388496576245719\n",
      "0.10237315475630264\n",
      "saved new best metric model\n",
      "current epoch: 2 current mean dice: 0.1024 tc: 0.0797 wt: 0.1886 et: 0.0388\n",
      "best mean dice: 0.1024 at epoch: 2\n",
      "\n",
      " | Global Training Round : 3 |\n",
      "\n",
      "user 0 selected\n",
      "local epoch 1\n",
      "1/194, train_loss: 0.9407\n",
      "2/194, train_loss: 0.9004\n",
      "3/194, train_loss: 0.9441\n",
      "4/194, train_loss: 0.9661\n",
      "5/194, train_loss: 0.9159\n",
      "6/194, train_loss: 0.9468\n",
      "7/194, train_loss: 0.9496\n",
      "8/194, train_loss: 0.9273\n",
      "9/194, train_loss: 0.9690\n",
      "10/194, train_loss: 0.9802\n",
      "11/194, train_loss: 0.8978\n",
      "12/194, train_loss: 0.9305\n",
      "13/194, train_loss: 0.9616\n",
      "14/194, train_loss: 0.8766\n",
      "15/194, train_loss: 0.9409\n",
      "16/194, train_loss: 0.9268\n",
      "17/194, train_loss: 0.9400\n",
      "18/194, train_loss: 0.9517\n",
      "19/194, train_loss: 0.8850\n",
      "20/194, train_loss: 0.9068\n",
      "21/194, train_loss: 0.9348\n",
      "22/194, train_loss: 0.9438\n",
      "23/194, train_loss: 0.9416\n",
      "24/194, train_loss: 0.9164\n",
      "25/194, train_loss: 0.9416\n",
      "26/194, train_loss: 0.9610\n",
      "27/194, train_loss: 0.9195\n",
      "28/194, train_loss: 0.9418\n",
      "29/194, train_loss: 0.9226\n",
      "30/194, train_loss: 0.9404\n",
      "31/194, train_loss: 0.9868\n",
      "32/194, train_loss: 0.9864\n",
      "33/194, train_loss: 0.9572\n",
      "34/194, train_loss: 0.8957\n",
      "35/194, train_loss: 0.8790\n",
      "36/194, train_loss: 0.9322\n",
      "37/194, train_loss: 0.9373\n",
      "38/194, train_loss: 0.9425\n",
      "39/194, train_loss: 0.8797\n",
      "40/194, train_loss: 0.8807\n",
      "41/194, train_loss: 0.9365\n",
      "42/194, train_loss: 0.9836\n",
      "43/194, train_loss: 0.9240\n",
      "44/194, train_loss: 0.9412\n",
      "45/194, train_loss: 0.9415\n",
      "46/194, train_loss: 0.8798\n",
      "47/194, train_loss: 0.9342\n",
      "48/194, train_loss: 0.9451\n",
      "49/194, train_loss: 0.9258\n",
      "50/194, train_loss: 0.9410\n",
      "51/194, train_loss: 0.9645\n",
      "52/194, train_loss: 0.9336\n",
      "53/194, train_loss: 0.8917\n",
      "54/194, train_loss: 0.9451\n",
      "55/194, train_loss: 0.9254\n",
      "56/194, train_loss: 0.9544\n",
      "57/194, train_loss: 0.9243\n",
      "58/194, train_loss: 0.9377\n",
      "59/194, train_loss: 0.9535\n",
      "60/194, train_loss: 0.9727\n",
      "61/194, train_loss: 0.9250\n",
      "62/194, train_loss: 0.9479\n",
      "63/194, train_loss: 0.9211\n",
      "64/194, train_loss: 0.9425\n",
      "65/194, train_loss: 0.9266\n",
      "66/194, train_loss: 0.9527\n",
      "67/194, train_loss: 0.9316\n",
      "68/194, train_loss: 0.9240\n",
      "69/194, train_loss: 0.9627\n",
      "70/194, train_loss: 0.9359\n",
      "71/194, train_loss: 0.9264\n",
      "72/194, train_loss: 0.9768\n",
      "73/194, train_loss: 0.9235\n",
      "74/194, train_loss: 0.9348\n",
      "75/194, train_loss: 0.9310\n",
      "76/194, train_loss: 0.8983\n",
      "77/194, train_loss: 0.9440\n",
      "78/194, train_loss: 0.9594\n",
      "79/194, train_loss: 0.8973\n",
      "80/194, train_loss: 0.9380\n",
      "81/194, train_loss: 0.8974\n",
      "82/194, train_loss: 0.8866\n",
      "83/194, train_loss: 0.9525\n",
      "84/194, train_loss: 0.9477\n",
      "85/194, train_loss: 0.9561\n",
      "86/194, train_loss: 0.9395\n",
      "87/194, train_loss: 0.9216\n",
      "88/194, train_loss: 0.9552\n",
      "89/194, train_loss: 0.9342\n",
      "90/194, train_loss: 0.9393\n",
      "91/194, train_loss: 0.9567\n",
      "92/194, train_loss: 0.9120\n",
      "93/194, train_loss: 0.8773\n",
      "94/194, train_loss: 0.9364\n",
      "95/194, train_loss: 0.9669\n",
      "96/194, train_loss: 0.9152\n",
      "97/194, train_loss: 0.9459\n",
      "98/194, train_loss: 0.9477\n",
      "99/194, train_loss: 0.9068\n",
      "100/194, train_loss: 0.9463\n",
      "101/194, train_loss: 0.9705\n",
      "102/194, train_loss: 0.9500\n",
      "103/194, train_loss: 0.9197\n",
      "104/194, train_loss: 0.9341\n",
      "105/194, train_loss: 0.9119\n",
      "106/194, train_loss: 0.9432\n",
      "107/194, train_loss: 0.9128\n",
      "108/194, train_loss: 0.8869\n",
      "109/194, train_loss: 0.9764\n",
      "110/194, train_loss: 0.9463\n",
      "111/194, train_loss: 0.9123\n",
      "112/194, train_loss: 0.9188\n",
      "113/194, train_loss: 0.9345\n",
      "114/194, train_loss: 0.8765\n",
      "115/194, train_loss: 0.9724\n",
      "116/194, train_loss: 0.9260\n",
      "117/194, train_loss: 0.9228\n",
      "118/194, train_loss: 0.9340\n",
      "119/194, train_loss: 0.9939\n",
      "120/194, train_loss: 0.9833\n",
      "121/194, train_loss: 0.9278\n",
      "122/194, train_loss: 0.9847\n",
      "123/194, train_loss: 0.9499\n",
      "124/194, train_loss: 0.9332\n",
      "125/194, train_loss: 0.9786\n",
      "126/194, train_loss: 0.9790\n",
      "127/194, train_loss: 0.9624\n",
      "128/194, train_loss: 0.9298\n",
      "129/194, train_loss: 0.9309\n",
      "130/194, train_loss: 0.9752\n",
      "131/194, train_loss: 0.9508\n",
      "132/194, train_loss: 0.9292\n",
      "133/194, train_loss: 0.9245\n",
      "134/194, train_loss: 0.9454\n",
      "135/194, train_loss: 0.9588\n",
      "136/194, train_loss: 0.9349\n",
      "137/194, train_loss: 0.9488\n",
      "138/194, train_loss: 0.8993\n",
      "139/194, train_loss: 0.9613\n",
      "140/194, train_loss: 0.9445\n",
      "141/194, train_loss: 0.8797\n",
      "142/194, train_loss: 0.9587\n",
      "143/194, train_loss: 0.9566\n",
      "144/194, train_loss: 0.9198\n",
      "145/194, train_loss: 0.9453\n",
      "146/194, train_loss: 0.9649\n",
      "147/194, train_loss: 0.9248\n",
      "148/194, train_loss: 0.9695\n",
      "149/194, train_loss: 0.9031\n",
      "150/194, train_loss: 0.9480\n",
      "151/194, train_loss: 0.9723\n",
      "152/194, train_loss: 0.9454\n",
      "153/194, train_loss: 0.9430\n",
      "154/194, train_loss: 0.9520\n",
      "155/194, train_loss: 0.9536\n",
      "156/194, train_loss: 0.9400\n",
      "157/194, train_loss: 0.9349\n",
      "158/194, train_loss: 0.9380\n",
      "159/194, train_loss: 0.9436\n",
      "160/194, train_loss: 0.9762\n",
      "161/194, train_loss: 0.9645\n",
      "162/194, train_loss: 0.9647\n",
      "163/194, train_loss: 0.9861\n",
      "164/194, train_loss: 0.9554\n",
      "165/194, train_loss: 0.9456\n",
      "166/194, train_loss: 0.9412\n",
      "167/194, train_loss: 0.9426\n",
      "168/194, train_loss: 0.9651\n",
      "169/194, train_loss: 0.9058\n",
      "170/194, train_loss: 0.9295\n",
      "171/194, train_loss: 0.8982\n",
      "172/194, train_loss: 0.9474\n",
      "173/194, train_loss: 0.9880\n",
      "174/194, train_loss: 0.9165\n",
      "175/194, train_loss: 0.9134\n",
      "176/194, train_loss: 0.9659\n",
      "177/194, train_loss: 0.9156\n",
      "178/194, train_loss: 0.9509\n",
      "179/194, train_loss: 0.9100\n",
      "180/194, train_loss: 0.9690\n",
      "181/194, train_loss: 0.9303\n",
      "182/194, train_loss: 0.9368\n",
      "183/194, train_loss: 0.9001\n",
      "184/194, train_loss: 0.9581\n",
      "185/194, train_loss: 0.9156\n",
      "186/194, train_loss: 0.9111\n",
      "187/194, train_loss: 0.9750\n",
      "188/194, train_loss: 0.9250\n",
      "189/194, train_loss: 0.9447\n",
      "190/194, train_loss: 0.8888\n",
      "191/194, train_loss: 0.9839\n",
      "192/194, train_loss: 0.9006\n",
      "193/194, train_loss: 0.9027\n",
      "194/194, train_loss: 0.8804\n",
      "metric=0.11509615299291909, metric_tc=0.08988014876376837, metric_wt=0.21173203674455485, metric_et=0.04367627292716255\n",
      "metric=0.11509615299291909, metric_tc=0.08988014876376837, metric_wt=0.21173203674455485, metric_et=0.04367627292716255\n",
      "current epoch: 3 current epoch loss: 0.9369\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 3/80 [38:12<16:21:12, 764.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metric=0.11509615299291909, metric_tc=0.08988014876376837, metric_wt=0.21173203674455485, metric_et=0.04367627292716255\n",
      "0.11509615299291909\n",
      "saved new best metric model\n",
      "current epoch: 3 current mean dice: 0.1151 tc: 0.0899 wt: 0.2117 et: 0.0437\n",
      "best mean dice: 0.1151 at epoch: 3\n",
      "\n",
      " | Global Training Round : 4 |\n",
      "\n",
      "user 0 selected\n",
      "local epoch 1\n",
      "1/194, train_loss: 0.9514\n",
      "2/194, train_loss: 0.9323\n",
      "3/194, train_loss: 0.9303\n",
      "4/194, train_loss: 0.9249\n",
      "5/194, train_loss: 0.9395\n",
      "6/194, train_loss: 0.8802\n",
      "7/194, train_loss: 0.9238\n",
      "8/194, train_loss: 0.9105\n",
      "9/194, train_loss: 0.9621\n",
      "10/194, train_loss: 0.9234\n",
      "11/194, train_loss: 0.9668\n",
      "12/194, train_loss: 0.8756\n",
      "13/194, train_loss: 0.9140\n",
      "14/194, train_loss: 0.9016\n",
      "15/194, train_loss: 0.9244\n",
      "16/194, train_loss: 0.9879\n",
      "17/194, train_loss: 0.9822\n",
      "18/194, train_loss: 0.9603\n",
      "19/194, train_loss: 0.9504\n",
      "20/194, train_loss: 0.9314\n",
      "21/194, train_loss: 0.9110\n",
      "22/194, train_loss: 0.9338\n",
      "23/194, train_loss: 0.9662\n",
      "24/194, train_loss: 0.8693\n",
      "25/194, train_loss: 0.9434\n",
      "26/194, train_loss: 0.9476\n",
      "27/194, train_loss: 0.9000\n",
      "28/194, train_loss: 0.9402\n",
      "29/194, train_loss: 0.9231\n",
      "30/194, train_loss: 0.9158\n",
      "31/194, train_loss: 0.9811\n",
      "32/194, train_loss: 0.8863\n",
      "33/194, train_loss: 0.9609\n",
      "34/194, train_loss: 0.9474\n",
      "35/194, train_loss: 0.9186\n",
      "36/194, train_loss: 0.9061\n",
      "37/194, train_loss: 0.9630\n",
      "38/194, train_loss: 0.9159\n",
      "39/194, train_loss: 0.9554\n",
      "40/194, train_loss: 0.8815\n",
      "41/194, train_loss: 0.9306\n",
      "42/194, train_loss: 0.8942\n",
      "43/194, train_loss: 0.9361\n",
      "44/194, train_loss: 0.9031\n",
      "45/194, train_loss: 0.9357\n",
      "46/194, train_loss: 0.9151\n",
      "47/194, train_loss: 0.9234\n",
      "48/194, train_loss: 0.9635\n",
      "49/194, train_loss: 0.9167\n",
      "50/194, train_loss: 0.9040\n",
      "51/194, train_loss: 0.9034\n",
      "52/194, train_loss: 0.9386\n",
      "53/194, train_loss: 0.9647\n",
      "54/194, train_loss: 0.9563\n",
      "55/194, train_loss: 0.9028\n",
      "56/194, train_loss: 0.9255\n",
      "57/194, train_loss: 0.8901\n",
      "58/194, train_loss: 0.9248\n",
      "59/194, train_loss: 0.9275\n",
      "60/194, train_loss: 0.9316\n",
      "61/194, train_loss: 0.9105\n",
      "62/194, train_loss: 0.8525\n",
      "63/194, train_loss: 0.9193\n",
      "64/194, train_loss: 0.9641\n",
      "65/194, train_loss: 0.9727\n",
      "66/194, train_loss: 0.9466\n",
      "67/194, train_loss: 0.9555\n",
      "68/194, train_loss: 0.9480\n",
      "69/194, train_loss: 0.9081\n",
      "70/194, train_loss: 0.8872\n",
      "71/194, train_loss: 0.8784\n",
      "72/194, train_loss: 0.9407\n",
      "73/194, train_loss: 0.8677\n",
      "74/194, train_loss: 0.9412\n",
      "75/194, train_loss: 0.9250\n",
      "76/194, train_loss: 0.9443\n",
      "77/194, train_loss: 0.9525\n",
      "78/194, train_loss: 0.9439\n",
      "79/194, train_loss: 0.9794\n",
      "80/194, train_loss: 0.9610\n",
      "81/194, train_loss: 0.9750\n",
      "82/194, train_loss: 0.9129\n",
      "83/194, train_loss: 0.8968\n",
      "84/194, train_loss: 0.9177\n",
      "85/194, train_loss: 0.9180\n",
      "86/194, train_loss: 0.9601\n",
      "87/194, train_loss: 0.9439\n",
      "88/194, train_loss: 0.9657\n",
      "89/194, train_loss: 0.8634\n",
      "90/194, train_loss: 0.9323\n",
      "91/194, train_loss: 0.8812\n",
      "92/194, train_loss: 0.9118\n",
      "93/194, train_loss: 0.9060\n",
      "94/194, train_loss: 0.9427\n",
      "95/194, train_loss: 0.9484\n",
      "96/194, train_loss: 0.9631\n",
      "97/194, train_loss: 0.9947\n",
      "98/194, train_loss: 0.9539\n",
      "99/194, train_loss: 0.9597\n",
      "100/194, train_loss: 0.9548\n",
      "101/194, train_loss: 0.9118\n",
      "102/194, train_loss: 0.9481\n",
      "103/194, train_loss: 0.9721\n",
      "104/194, train_loss: 0.9755\n",
      "105/194, train_loss: 0.8977\n",
      "106/194, train_loss: 0.9008\n",
      "107/194, train_loss: 0.9162\n",
      "108/194, train_loss: 0.9331\n",
      "109/194, train_loss: 0.9591\n",
      "110/194, train_loss: 0.8975\n",
      "111/194, train_loss: 0.8659\n",
      "112/194, train_loss: 0.9491\n",
      "113/194, train_loss: 0.8995\n",
      "114/194, train_loss: 0.8998\n",
      "115/194, train_loss: 0.9351\n",
      "116/194, train_loss: 0.9353\n",
      "117/194, train_loss: 0.8695\n",
      "118/194, train_loss: 0.9276\n",
      "119/194, train_loss: 0.9569\n",
      "120/194, train_loss: 0.9036\n",
      "121/194, train_loss: 0.9574\n",
      "122/194, train_loss: 0.9568\n",
      "123/194, train_loss: 0.9334\n",
      "124/194, train_loss: 0.8942\n",
      "125/194, train_loss: 0.9620\n",
      "126/194, train_loss: 0.9237\n",
      "127/194, train_loss: 0.9379\n",
      "128/194, train_loss: 0.9199\n",
      "129/194, train_loss: 0.9221\n",
      "130/194, train_loss: 0.9611\n",
      "131/194, train_loss: 0.9428\n",
      "132/194, train_loss: 0.9507\n",
      "133/194, train_loss: 0.9719\n",
      "134/194, train_loss: 0.9185\n",
      "135/194, train_loss: 0.9335\n",
      "136/194, train_loss: 0.9579\n",
      "137/194, train_loss: 0.8858\n",
      "138/194, train_loss: 0.9346\n",
      "139/194, train_loss: 0.9511\n",
      "140/194, train_loss: 0.9798\n",
      "141/194, train_loss: 0.8949\n",
      "142/194, train_loss: 0.9404\n",
      "143/194, train_loss: 0.9248\n",
      "144/194, train_loss: 0.9289\n",
      "145/194, train_loss: 0.9618\n",
      "146/194, train_loss: 0.9403\n",
      "147/194, train_loss: 0.9271\n",
      "148/194, train_loss: 0.9335\n",
      "149/194, train_loss: 0.9382\n",
      "150/194, train_loss: 0.9627\n",
      "151/194, train_loss: 0.9797\n",
      "152/194, train_loss: 0.9447\n",
      "153/194, train_loss: 0.9793\n",
      "154/194, train_loss: 0.9080\n",
      "155/194, train_loss: 0.9314\n",
      "156/194, train_loss: 0.9451\n",
      "157/194, train_loss: 0.9193\n",
      "158/194, train_loss: 0.8572\n",
      "159/194, train_loss: 0.9437\n",
      "160/194, train_loss: 0.9375\n",
      "161/194, train_loss: 0.8519\n",
      "162/194, train_loss: 0.9051\n",
      "163/194, train_loss: 0.9054\n",
      "164/194, train_loss: 0.9941\n",
      "165/194, train_loss: 0.9584\n",
      "166/194, train_loss: 0.9414\n",
      "167/194, train_loss: 0.8969\n",
      "168/194, train_loss: 0.9589\n",
      "169/194, train_loss: 0.9068\n",
      "170/194, train_loss: 0.9342\n",
      "171/194, train_loss: 0.9374\n",
      "172/194, train_loss: 0.9501\n",
      "173/194, train_loss: 0.9345\n",
      "174/194, train_loss: 0.8131\n",
      "175/194, train_loss: 0.9419\n",
      "176/194, train_loss: 0.9223\n",
      "177/194, train_loss: 0.9722\n",
      "178/194, train_loss: 0.9530\n",
      "179/194, train_loss: 0.8493\n",
      "180/194, train_loss: 0.9143\n",
      "181/194, train_loss: 0.8722\n",
      "182/194, train_loss: 0.9609\n",
      "183/194, train_loss: 0.9015\n",
      "184/194, train_loss: 0.9600\n",
      "185/194, train_loss: 0.9617\n",
      "186/194, train_loss: 0.9594\n",
      "187/194, train_loss: 0.8986\n",
      "188/194, train_loss: 0.9763\n",
      "189/194, train_loss: 0.9222\n",
      "190/194, train_loss: 0.9400\n",
      "191/194, train_loss: 0.9380\n",
      "192/194, train_loss: 0.9406\n",
      "193/194, train_loss: 0.9447\n",
      "194/194, train_loss: 0.9321\n",
      "metric=0.1245993160797904, metric_tc=0.09727718382297705, metric_wt=0.22928230154017606, metric_et=0.04723846151803931\n",
      "metric=0.1245993160797904, metric_tc=0.09727718382297705, metric_wt=0.22928230154017606, metric_et=0.04723846151803931\n",
      "current epoch: 4 current epoch loss: 0.9305\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 4/80 [49:40<15:39:13, 741.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metric=0.1245993160797904, metric_tc=0.09727718382297705, metric_wt=0.22928230154017606, metric_et=0.04723846151803931\n",
      "0.1245993160797904\n",
      "saved new best metric model\n",
      "current epoch: 4 current mean dice: 0.1246 tc: 0.0973 wt: 0.2293 et: 0.0472\n",
      "best mean dice: 0.1246 at epoch: 4\n",
      "\n",
      " | Global Training Round : 5 |\n",
      "\n",
      "user 0 selected\n",
      "local epoch 1\n",
      "1/194, train_loss: 0.8759\n",
      "2/194, train_loss: 0.9747\n",
      "3/194, train_loss: 0.8701\n",
      "4/194, train_loss: 0.9500\n",
      "5/194, train_loss: 0.8643\n",
      "6/194, train_loss: 0.9605\n",
      "7/194, train_loss: 0.9171\n",
      "8/194, train_loss: 0.9212\n",
      "9/194, train_loss: 0.9500\n",
      "10/194, train_loss: 0.8930\n",
      "11/194, train_loss: 0.9791\n",
      "12/194, train_loss: 0.9452\n",
      "13/194, train_loss: 0.9668\n",
      "14/194, train_loss: 0.9406\n",
      "15/194, train_loss: 0.9032\n",
      "16/194, train_loss: 0.9820\n",
      "17/194, train_loss: 0.9098\n",
      "18/194, train_loss: 0.9449\n",
      "19/194, train_loss: 0.9215\n",
      "20/194, train_loss: 0.8873\n",
      "21/194, train_loss: 0.9523\n",
      "22/194, train_loss: 0.9264\n",
      "23/194, train_loss: 0.9381\n",
      "24/194, train_loss: 0.8836\n",
      "25/194, train_loss: 0.9233\n",
      "26/194, train_loss: 0.9181\n",
      "27/194, train_loss: 0.8925\n",
      "28/194, train_loss: 0.8837\n",
      "29/194, train_loss: 0.9116\n",
      "30/194, train_loss: 0.9439\n",
      "31/194, train_loss: 0.9109\n",
      "32/194, train_loss: 0.9251\n",
      "33/194, train_loss: 0.9023\n",
      "34/194, train_loss: 0.9386\n",
      "35/194, train_loss: 0.9146\n",
      "36/194, train_loss: 0.9634\n",
      "37/194, train_loss: 0.8874\n",
      "38/194, train_loss: 0.9302\n",
      "39/194, train_loss: 0.9590\n",
      "40/194, train_loss: 0.9241\n",
      "41/194, train_loss: 0.9625\n",
      "42/194, train_loss: 0.9130\n",
      "43/194, train_loss: 0.9414\n",
      "44/194, train_loss: 0.9240\n",
      "45/194, train_loss: 0.8668\n",
      "46/194, train_loss: 0.8079\n",
      "47/194, train_loss: 0.9267\n",
      "48/194, train_loss: 0.9079\n",
      "49/194, train_loss: 0.9522\n",
      "50/194, train_loss: 0.9121\n",
      "51/194, train_loss: 0.9569\n",
      "52/194, train_loss: 0.8937\n",
      "53/194, train_loss: 0.9535\n",
      "54/194, train_loss: 0.9639\n",
      "55/194, train_loss: 0.8835\n",
      "56/194, train_loss: 0.9529\n",
      "57/194, train_loss: 0.9150\n",
      "58/194, train_loss: 0.8915\n",
      "59/194, train_loss: 0.9381\n",
      "60/194, train_loss: 0.8882\n",
      "61/194, train_loss: 0.9154\n",
      "62/194, train_loss: 0.9065\n",
      "63/194, train_loss: 0.8793\n",
      "64/194, train_loss: 0.9789\n",
      "65/194, train_loss: 0.9489\n",
      "66/194, train_loss: 0.8747\n",
      "67/194, train_loss: 0.9534\n",
      "68/194, train_loss: 0.9167\n",
      "69/194, train_loss: 0.8836\n",
      "70/194, train_loss: 0.9573\n",
      "71/194, train_loss: 0.8953\n",
      "72/194, train_loss: 0.9266\n",
      "73/194, train_loss: 0.9078\n",
      "74/194, train_loss: 0.9180\n",
      "75/194, train_loss: 0.9383\n",
      "76/194, train_loss: 0.8963\n",
      "77/194, train_loss: 0.8822\n",
      "78/194, train_loss: 0.9491\n",
      "79/194, train_loss: 0.9107\n",
      "80/194, train_loss: 0.9259\n",
      "81/194, train_loss: 0.8923\n",
      "82/194, train_loss: 0.9268\n",
      "83/194, train_loss: 0.9507\n",
      "84/194, train_loss: 0.9150\n",
      "85/194, train_loss: 0.9486\n",
      "86/194, train_loss: 0.9597\n",
      "87/194, train_loss: 0.9247\n",
      "88/194, train_loss: 0.8999\n",
      "89/194, train_loss: 0.9706\n",
      "90/194, train_loss: 0.9190\n",
      "91/194, train_loss: 0.9464\n",
      "92/194, train_loss: 0.9599\n",
      "93/194, train_loss: 0.9164\n",
      "94/194, train_loss: 0.9185\n",
      "95/194, train_loss: 0.9398\n",
      "96/194, train_loss: 0.9666\n",
      "97/194, train_loss: 0.9521\n",
      "98/194, train_loss: 0.9334\n",
      "99/194, train_loss: 0.9240\n",
      "100/194, train_loss: 0.9109\n",
      "101/194, train_loss: 0.8782\n",
      "102/194, train_loss: 0.9119\n",
      "103/194, train_loss: 0.9067\n",
      "104/194, train_loss: 0.9196\n",
      "105/194, train_loss: 0.9259\n",
      "106/194, train_loss: 0.9550\n",
      "107/194, train_loss: 0.8851\n",
      "108/194, train_loss: 0.8671\n",
      "109/194, train_loss: 0.9027\n",
      "110/194, train_loss: 0.9232\n",
      "111/194, train_loss: 0.9290\n",
      "112/194, train_loss: 0.8942\n",
      "113/194, train_loss: 0.9171\n",
      "114/194, train_loss: 0.9329\n",
      "115/194, train_loss: 0.8762\n",
      "116/194, train_loss: 0.8978\n",
      "117/194, train_loss: 0.8982\n",
      "118/194, train_loss: 0.9871\n",
      "119/194, train_loss: 0.9359\n",
      "120/194, train_loss: 0.9050\n",
      "121/194, train_loss: 0.8990\n",
      "122/194, train_loss: 0.9363\n",
      "123/194, train_loss: 0.9086\n",
      "124/194, train_loss: 0.9030\n",
      "125/194, train_loss: 0.9440\n",
      "126/194, train_loss: 0.9073\n",
      "127/194, train_loss: 0.9259\n",
      "128/194, train_loss: 0.9635\n",
      "129/194, train_loss: 0.8442\n",
      "130/194, train_loss: 0.8796\n",
      "131/194, train_loss: 0.9150\n",
      "132/194, train_loss: 0.9209\n",
      "133/194, train_loss: 0.9393\n",
      "134/194, train_loss: 0.9512\n",
      "135/194, train_loss: 0.9136\n",
      "136/194, train_loss: 0.8926\n",
      "137/194, train_loss: 0.9464\n",
      "138/194, train_loss: 0.9473\n",
      "139/194, train_loss: 0.9550\n",
      "140/194, train_loss: 0.8992\n",
      "141/194, train_loss: 0.9642\n",
      "142/194, train_loss: 0.8631\n",
      "143/194, train_loss: 0.9589\n",
      "144/194, train_loss: 0.9381\n",
      "145/194, train_loss: 0.9733\n",
      "146/194, train_loss: 0.9718\n",
      "147/194, train_loss: 0.8852\n",
      "148/194, train_loss: 0.8710\n",
      "149/194, train_loss: 0.8920\n",
      "150/194, train_loss: 0.9117\n",
      "151/194, train_loss: 0.9212\n",
      "152/194, train_loss: 0.8395\n",
      "153/194, train_loss: 0.9055\n",
      "154/194, train_loss: 0.9374\n",
      "155/194, train_loss: 0.9455\n",
      "156/194, train_loss: 0.9317\n",
      "157/194, train_loss: 0.9281\n",
      "158/194, train_loss: 0.9842\n",
      "159/194, train_loss: 0.9527\n",
      "160/194, train_loss: 0.8541\n",
      "161/194, train_loss: 0.9779\n",
      "162/194, train_loss: 0.8913\n",
      "163/194, train_loss: 0.9425\n",
      "164/194, train_loss: 0.9302\n",
      "165/194, train_loss: 0.9698\n",
      "166/194, train_loss: 0.9790\n",
      "167/194, train_loss: 0.9802\n",
      "168/194, train_loss: 0.9163\n",
      "169/194, train_loss: 0.9259\n",
      "170/194, train_loss: 0.9279\n",
      "171/194, train_loss: 0.8843\n",
      "172/194, train_loss: 0.8900\n",
      "173/194, train_loss: 0.9627\n",
      "174/194, train_loss: 0.8898\n",
      "175/194, train_loss: 0.8748\n",
      "176/194, train_loss: 0.9370\n",
      "177/194, train_loss: 0.9278\n",
      "178/194, train_loss: 0.9393\n",
      "179/194, train_loss: 0.8808\n",
      "180/194, train_loss: 0.9237\n",
      "181/194, train_loss: 0.8485\n",
      "182/194, train_loss: 0.9728\n",
      "183/194, train_loss: 0.8770\n",
      "184/194, train_loss: 0.9121\n",
      "185/194, train_loss: 0.9433\n",
      "186/194, train_loss: 0.8847\n",
      "187/194, train_loss: 0.9605\n",
      "188/194, train_loss: 0.9554\n",
      "189/194, train_loss: 0.9431\n",
      "190/194, train_loss: 0.8807\n",
      "191/194, train_loss: 0.9241\n",
      "192/194, train_loss: 0.9261\n",
      "193/194, train_loss: 0.9149\n",
      "194/194, train_loss: 0.9262\n",
      "metric=0.1435890111606568, metric_tc=0.11320279697732379, metric_wt=0.2625415528503557, metric_et=0.055022686676238663\n",
      "metric=0.1435890111606568, metric_tc=0.11320279697732379, metric_wt=0.2625415528503557, metric_et=0.055022686676238663\n",
      "current epoch: 5 current epoch loss: 0.9220\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▋         | 5/80 [59:55<14:39:32, 703.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metric=0.1435890111606568, metric_tc=0.11320279697732379, metric_wt=0.2625415528503557, metric_et=0.055022686676238663\n",
      "0.1435890111606568\n",
      "saved new best metric model\n",
      "current epoch: 5 current mean dice: 0.1436 tc: 0.1132 wt: 0.2625 et: 0.0550\n",
      "best mean dice: 0.1436 at epoch: 5\n",
      "\n",
      " | Global Training Round : 6 |\n",
      "\n",
      "user 0 selected\n",
      "local epoch 1\n",
      "1/194, train_loss: 0.9155\n",
      "2/194, train_loss: 0.9119\n",
      "3/194, train_loss: 0.9299\n",
      "4/194, train_loss: 0.8417\n",
      "5/194, train_loss: 0.8885\n",
      "6/194, train_loss: 0.9140\n",
      "7/194, train_loss: 0.8914\n",
      "8/194, train_loss: 0.8844\n",
      "9/194, train_loss: 0.9784\n",
      "10/194, train_loss: 0.9346\n",
      "11/194, train_loss: 0.9661\n",
      "12/194, train_loss: 0.9517\n",
      "13/194, train_loss: 0.9466\n",
      "14/194, train_loss: 0.9711\n",
      "15/194, train_loss: 0.9241\n",
      "16/194, train_loss: 0.9087\n",
      "17/194, train_loss: 0.8358\n",
      "18/194, train_loss: 0.9527\n",
      "19/194, train_loss: 0.9839\n",
      "20/194, train_loss: 0.8757\n",
      "21/194, train_loss: 0.9625\n",
      "22/194, train_loss: 0.8823\n",
      "23/194, train_loss: 0.8877\n",
      "24/194, train_loss: 0.8441\n",
      "25/194, train_loss: 0.8990\n",
      "26/194, train_loss: 0.9333\n",
      "27/194, train_loss: 0.9348\n",
      "28/194, train_loss: 0.9402\n",
      "29/194, train_loss: 0.9087\n",
      "30/194, train_loss: 0.9479\n",
      "31/194, train_loss: 0.9218\n",
      "32/194, train_loss: 0.9410\n",
      "33/194, train_loss: 0.8601\n",
      "34/194, train_loss: 0.8793\n",
      "35/194, train_loss: 0.8984\n",
      "36/194, train_loss: 0.9241\n",
      "37/194, train_loss: 0.9115\n",
      "38/194, train_loss: 0.9288\n",
      "39/194, train_loss: 0.9434\n",
      "40/194, train_loss: 0.8369\n",
      "41/194, train_loss: 0.9405\n",
      "42/194, train_loss: 0.9263\n",
      "43/194, train_loss: 0.8549\n",
      "44/194, train_loss: 0.9250\n",
      "45/194, train_loss: 0.9340\n",
      "46/194, train_loss: 0.8675\n",
      "47/194, train_loss: 0.9453\n",
      "48/194, train_loss: 0.8690\n",
      "49/194, train_loss: 0.8073\n",
      "50/194, train_loss: 0.8637\n",
      "51/194, train_loss: 0.9241\n",
      "52/194, train_loss: 0.8500\n",
      "53/194, train_loss: 0.8850\n",
      "54/194, train_loss: 0.9561\n",
      "55/194, train_loss: 0.9685\n",
      "56/194, train_loss: 0.9228\n",
      "57/194, train_loss: 0.9401\n",
      "58/194, train_loss: 0.9368\n",
      "59/194, train_loss: 0.9084\n",
      "60/194, train_loss: 0.9367\n",
      "61/194, train_loss: 0.8405\n",
      "62/194, train_loss: 0.8642\n",
      "63/194, train_loss: 0.8788\n",
      "64/194, train_loss: 0.9071\n",
      "65/194, train_loss: 0.9346\n",
      "66/194, train_loss: 0.9207\n",
      "67/194, train_loss: 0.9278\n",
      "68/194, train_loss: 0.9788\n",
      "69/194, train_loss: 0.8879\n",
      "70/194, train_loss: 0.8743\n",
      "71/194, train_loss: 0.8680\n",
      "72/194, train_loss: 0.8787\n",
      "73/194, train_loss: 0.8807\n",
      "74/194, train_loss: 0.9499\n",
      "75/194, train_loss: 0.8931\n",
      "76/194, train_loss: 0.8656\n",
      "77/194, train_loss: 0.9443\n",
      "78/194, train_loss: 0.9143\n",
      "79/194, train_loss: 0.9119\n",
      "80/194, train_loss: 0.9709\n",
      "81/194, train_loss: 0.8680\n",
      "82/194, train_loss: 0.9068\n",
      "83/194, train_loss: 0.8181\n",
      "84/194, train_loss: 0.9545\n",
      "85/194, train_loss: 0.9412\n",
      "86/194, train_loss: 0.8559\n",
      "87/194, train_loss: 0.9364\n",
      "88/194, train_loss: 0.8611\n",
      "89/194, train_loss: 0.9415\n",
      "90/194, train_loss: 0.8947\n",
      "91/194, train_loss: 0.9557\n",
      "92/194, train_loss: 0.8264\n",
      "93/194, train_loss: 0.9491\n",
      "94/194, train_loss: 0.9475\n",
      "95/194, train_loss: 0.9712\n",
      "96/194, train_loss: 0.8882\n",
      "97/194, train_loss: 0.9657\n",
      "98/194, train_loss: 0.9207\n",
      "99/194, train_loss: 0.9360\n",
      "100/194, train_loss: 0.9706\n",
      "101/194, train_loss: 0.9188\n",
      "102/194, train_loss: 0.9230\n",
      "103/194, train_loss: 0.9527\n",
      "104/194, train_loss: 0.9516\n",
      "105/194, train_loss: 0.9497\n",
      "106/194, train_loss: 0.9534\n",
      "107/194, train_loss: 0.9666\n",
      "108/194, train_loss: 0.8272\n",
      "109/194, train_loss: 0.9552\n",
      "110/194, train_loss: 0.9215\n",
      "111/194, train_loss: 0.8812\n",
      "112/194, train_loss: 0.9073\n",
      "113/194, train_loss: 0.8880\n",
      "114/194, train_loss: 0.9396\n",
      "115/194, train_loss: 0.9165\n",
      "116/194, train_loss: 0.8905\n",
      "117/194, train_loss: 0.9645\n",
      "118/194, train_loss: 0.8594\n",
      "119/194, train_loss: 0.8789\n",
      "120/194, train_loss: 0.9329\n",
      "121/194, train_loss: 0.9740\n",
      "122/194, train_loss: 0.9513\n",
      "123/194, train_loss: 0.8494\n",
      "124/194, train_loss: 0.9157\n",
      "125/194, train_loss: 0.8807\n",
      "126/194, train_loss: 0.9534\n",
      "127/194, train_loss: 0.9372\n",
      "128/194, train_loss: 0.8814\n",
      "129/194, train_loss: 0.8689\n",
      "130/194, train_loss: 0.9187\n",
      "131/194, train_loss: 0.9238\n",
      "132/194, train_loss: 0.9402\n",
      "133/194, train_loss: 0.8355\n",
      "134/194, train_loss: 0.8737\n",
      "135/194, train_loss: 0.9163\n",
      "136/194, train_loss: 0.9402\n",
      "137/194, train_loss: 0.9270\n",
      "138/194, train_loss: 0.8202\n",
      "139/194, train_loss: 0.9698\n",
      "140/194, train_loss: 0.9693\n",
      "141/194, train_loss: 0.9128\n",
      "142/194, train_loss: 0.8903\n",
      "143/194, train_loss: 0.9147\n",
      "144/194, train_loss: 0.9094\n",
      "145/194, train_loss: 0.9022\n",
      "146/194, train_loss: 0.9587\n",
      "147/194, train_loss: 0.8830\n",
      "148/194, train_loss: 0.9425\n",
      "149/194, train_loss: 0.9566\n",
      "150/194, train_loss: 0.9080\n",
      "151/194, train_loss: 0.9249\n",
      "152/194, train_loss: 0.8793\n",
      "153/194, train_loss: 0.8680\n",
      "154/194, train_loss: 0.9350\n",
      "155/194, train_loss: 0.9656\n",
      "156/194, train_loss: 0.8711\n",
      "157/194, train_loss: 0.9289\n",
      "158/194, train_loss: 0.8695\n",
      "159/194, train_loss: 0.9535\n",
      "160/194, train_loss: 0.8923\n",
      "161/194, train_loss: 0.9647\n",
      "162/194, train_loss: 0.9784\n",
      "163/194, train_loss: 0.9433\n",
      "164/194, train_loss: 0.9307\n",
      "165/194, train_loss: 0.9476\n",
      "166/194, train_loss: 0.9267\n",
      "167/194, train_loss: 0.9519\n",
      "168/194, train_loss: 0.8727\n",
      "169/194, train_loss: 0.9488\n",
      "170/194, train_loss: 0.9028\n",
      "171/194, train_loss: 0.8731\n",
      "172/194, train_loss: 0.9113\n",
      "173/194, train_loss: 0.9053\n",
      "174/194, train_loss: 0.9441\n",
      "175/194, train_loss: 0.9268\n",
      "176/194, train_loss: 0.8663\n",
      "177/194, train_loss: 0.9214\n",
      "178/194, train_loss: 0.8888\n",
      "179/194, train_loss: 0.9543\n",
      "180/194, train_loss: 0.9541\n",
      "181/194, train_loss: 0.8365\n",
      "182/194, train_loss: 0.9549\n",
      "183/194, train_loss: 0.9326\n",
      "184/194, train_loss: 0.9128\n",
      "185/194, train_loss: 0.8845\n",
      "186/194, train_loss: 0.9641\n",
      "187/194, train_loss: 0.9179\n",
      "188/194, train_loss: 0.9052\n",
      "189/194, train_loss: 0.9263\n",
      "190/194, train_loss: 0.9583\n",
      "191/194, train_loss: 0.8987\n",
      "192/194, train_loss: 0.9302\n",
      "193/194, train_loss: 0.9096\n",
      "194/194, train_loss: 0.9087\n",
      "metric=0.15100218378938735, metric_tc=0.11935013990538816, metric_wt=0.2753480432244639, metric_et=0.058308357993761696\n",
      "metric=0.15100218378938735, metric_tc=0.11935013990538816, metric_wt=0.2753480432244639, metric_et=0.058308357993761696\n",
      "current epoch: 6 current epoch loss: 0.9144\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 6/80 [1:10:22<13:59:19, 680.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metric=0.15100218378938735, metric_tc=0.11935013990538816, metric_wt=0.2753480432244639, metric_et=0.058308357993761696\n",
      "0.15100218378938735\n",
      "saved new best metric model\n",
      "current epoch: 6 current mean dice: 0.1510 tc: 0.1194 wt: 0.2753 et: 0.0583\n",
      "best mean dice: 0.1510 at epoch: 6\n",
      "\n",
      " | Global Training Round : 7 |\n",
      "\n",
      "user 0 selected\n",
      "local epoch 1\n",
      "1/194, train_loss: 0.8330\n",
      "2/194, train_loss: 0.9615\n",
      "3/194, train_loss: 0.8656\n",
      "4/194, train_loss: 0.9533\n",
      "5/194, train_loss: 0.9317\n",
      "6/194, train_loss: 0.9075\n",
      "7/194, train_loss: 0.9775\n",
      "8/194, train_loss: 0.8877\n",
      "9/194, train_loss: 0.9105\n",
      "10/194, train_loss: 0.9047\n",
      "11/194, train_loss: 0.8930\n",
      "12/194, train_loss: 0.8969\n",
      "13/194, train_loss: 0.8723\n",
      "14/194, train_loss: 0.8863\n",
      "15/194, train_loss: 0.8821\n",
      "16/194, train_loss: 0.8102\n",
      "17/194, train_loss: 0.8169\n",
      "18/194, train_loss: 0.9179\n",
      "19/194, train_loss: 0.9114\n",
      "20/194, train_loss: 0.9183\n",
      "21/194, train_loss: 0.9424\n",
      "22/194, train_loss: 0.8905\n",
      "23/194, train_loss: 0.9583\n",
      "24/194, train_loss: 0.8760\n",
      "25/194, train_loss: 0.8657\n",
      "26/194, train_loss: 0.8418\n",
      "27/194, train_loss: 0.9772\n",
      "28/194, train_loss: 0.9384\n",
      "29/194, train_loss: 0.8827\n",
      "30/194, train_loss: 0.9883\n",
      "31/194, train_loss: 0.9588\n",
      "32/194, train_loss: 0.9231\n",
      "33/194, train_loss: 0.9189\n",
      "34/194, train_loss: 0.8665\n",
      "35/194, train_loss: 0.9511\n",
      "36/194, train_loss: 0.9073\n",
      "37/194, train_loss: 0.8958\n",
      "38/194, train_loss: 0.8496\n",
      "39/194, train_loss: 0.8727\n",
      "40/194, train_loss: 0.9226\n",
      "41/194, train_loss: 0.9117\n",
      "42/194, train_loss: 0.9513\n",
      "43/194, train_loss: 0.9322\n",
      "44/194, train_loss: 0.9436\n",
      "45/194, train_loss: 0.9206\n",
      "46/194, train_loss: 0.8941\n",
      "47/194, train_loss: 0.8281\n",
      "48/194, train_loss: 0.9322\n",
      "49/194, train_loss: 0.8767\n",
      "50/194, train_loss: 0.9619\n",
      "51/194, train_loss: 0.8459\n",
      "52/194, train_loss: 0.9220\n",
      "53/194, train_loss: 0.8826\n",
      "54/194, train_loss: 0.9062\n",
      "55/194, train_loss: 0.9112\n",
      "56/194, train_loss: 0.9198\n",
      "57/194, train_loss: 0.8629\n",
      "58/194, train_loss: 0.9273\n",
      "59/194, train_loss: 0.9385\n",
      "60/194, train_loss: 0.9094\n",
      "61/194, train_loss: 0.8060\n",
      "62/194, train_loss: 0.8092\n",
      "63/194, train_loss: 0.8391\n",
      "64/194, train_loss: 0.9064\n",
      "65/194, train_loss: 0.8179\n",
      "66/194, train_loss: 0.9582\n",
      "67/194, train_loss: 0.8333\n",
      "68/194, train_loss: 0.8608\n",
      "69/194, train_loss: 0.8769\n",
      "70/194, train_loss: 0.9590\n",
      "71/194, train_loss: 0.9001\n",
      "72/194, train_loss: 0.9284\n",
      "73/194, train_loss: 0.9349\n",
      "74/194, train_loss: 0.8305\n",
      "75/194, train_loss: 0.8919\n",
      "76/194, train_loss: 0.9457\n",
      "77/194, train_loss: 0.9472\n",
      "78/194, train_loss: 0.9328\n",
      "79/194, train_loss: 0.9074\n",
      "80/194, train_loss: 0.9108\n",
      "81/194, train_loss: 0.9633\n",
      "82/194, train_loss: 0.9215\n",
      "83/194, train_loss: 0.9504\n",
      "84/194, train_loss: 0.9641\n",
      "85/194, train_loss: 0.9184\n",
      "86/194, train_loss: 0.8835\n",
      "87/194, train_loss: 0.9184\n",
      "88/194, train_loss: 0.8701\n",
      "89/194, train_loss: 0.9212\n",
      "90/194, train_loss: 0.9000\n",
      "91/194, train_loss: 0.9246\n",
      "92/194, train_loss: 0.8709\n",
      "93/194, train_loss: 0.9001\n",
      "94/194, train_loss: 0.9364\n",
      "95/194, train_loss: 0.8879\n",
      "96/194, train_loss: 0.8987\n",
      "97/194, train_loss: 0.9702\n",
      "98/194, train_loss: 0.9436\n",
      "99/194, train_loss: 0.9523\n",
      "100/194, train_loss: 0.8945\n",
      "101/194, train_loss: 0.8980\n",
      "102/194, train_loss: 0.9143\n",
      "103/194, train_loss: 0.8768\n",
      "104/194, train_loss: 0.8711\n",
      "105/194, train_loss: 0.9321\n",
      "106/194, train_loss: 0.9003\n",
      "107/194, train_loss: 0.9524\n",
      "108/194, train_loss: 0.9354\n",
      "109/194, train_loss: 0.8895\n",
      "110/194, train_loss: 0.8690\n",
      "111/194, train_loss: 0.9793\n",
      "112/194, train_loss: 0.9222\n",
      "113/194, train_loss: 0.8779\n",
      "114/194, train_loss: 0.8804\n",
      "115/194, train_loss: 0.8696\n",
      "116/194, train_loss: 0.9581\n",
      "117/194, train_loss: 0.9248\n",
      "118/194, train_loss: 0.9602\n",
      "119/194, train_loss: 0.9363\n",
      "120/194, train_loss: 0.8496\n",
      "121/194, train_loss: 0.9515\n",
      "122/194, train_loss: 0.9296\n",
      "123/194, train_loss: 0.9168\n",
      "124/194, train_loss: 0.9431\n",
      "125/194, train_loss: 0.9065\n",
      "126/194, train_loss: 0.9792\n",
      "127/194, train_loss: 0.8873\n",
      "128/194, train_loss: 0.8942\n",
      "129/194, train_loss: 0.8904\n",
      "130/194, train_loss: 0.9715\n",
      "131/194, train_loss: 0.9367\n",
      "132/194, train_loss: 0.9366\n",
      "133/194, train_loss: 0.9482\n",
      "134/194, train_loss: 0.9122\n",
      "135/194, train_loss: 0.8858\n",
      "136/194, train_loss: 0.9230\n",
      "137/194, train_loss: 0.8972\n",
      "138/194, train_loss: 0.9676\n",
      "139/194, train_loss: 0.8253\n",
      "140/194, train_loss: 0.8852\n",
      "141/194, train_loss: 0.9018\n",
      "142/194, train_loss: 0.8270\n",
      "143/194, train_loss: 0.9587\n",
      "144/194, train_loss: 0.9261\n",
      "145/194, train_loss: 0.9831\n",
      "146/194, train_loss: 0.9095\n",
      "147/194, train_loss: 0.8858\n",
      "148/194, train_loss: 0.9115\n",
      "149/194, train_loss: 0.9330\n",
      "150/194, train_loss: 0.9151\n",
      "151/194, train_loss: 0.9635\n",
      "152/194, train_loss: 0.8716\n",
      "153/194, train_loss: 0.9192\n",
      "154/194, train_loss: 0.9266\n",
      "155/194, train_loss: 0.9625\n",
      "156/194, train_loss: 0.9234\n",
      "157/194, train_loss: 0.9109\n",
      "158/194, train_loss: 0.9132\n",
      "159/194, train_loss: 0.8864\n",
      "160/194, train_loss: 0.9334\n",
      "161/194, train_loss: 0.9217\n",
      "162/194, train_loss: 0.9891\n",
      "163/194, train_loss: 0.8806\n",
      "164/194, train_loss: 0.9379\n",
      "165/194, train_loss: 0.9100\n",
      "166/194, train_loss: 0.8864\n",
      "167/194, train_loss: 0.8468\n",
      "168/194, train_loss: 0.8853\n",
      "169/194, train_loss: 0.8805\n",
      "170/194, train_loss: 0.9229\n",
      "171/194, train_loss: 0.7980\n",
      "172/194, train_loss: 0.8450\n",
      "173/194, train_loss: 0.9453\n",
      "174/194, train_loss: 0.8615\n",
      "175/194, train_loss: 0.8846\n",
      "176/194, train_loss: 0.9119\n",
      "177/194, train_loss: 0.8081\n",
      "178/194, train_loss: 0.9370\n",
      "179/194, train_loss: 0.9308\n",
      "180/194, train_loss: 0.9553\n",
      "181/194, train_loss: 0.8509\n",
      "182/194, train_loss: 0.8646\n",
      "183/194, train_loss: 0.8691\n",
      "184/194, train_loss: 0.9364\n",
      "185/194, train_loss: 0.8754\n",
      "186/194, train_loss: 0.9257\n",
      "187/194, train_loss: 0.9504\n",
      "188/194, train_loss: 0.8822\n",
      "189/194, train_loss: 0.9509\n",
      "190/194, train_loss: 0.9384\n",
      "191/194, train_loss: 0.9119\n",
      "192/194, train_loss: 0.8692\n",
      "193/194, train_loss: 0.9077\n",
      "194/194, train_loss: 0.9554\n",
      "metric=0.1567940063929806, metric_tc=0.12517058996794125, metric_wt=0.2843492742006977, metric_et=0.06086215427300582\n",
      "metric=0.1567940063929806, metric_tc=0.12517058996794125, metric_wt=0.2843492742006977, metric_et=0.06086215427300582\n",
      "current epoch: 7 current epoch loss: 0.9078\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 7/80 [1:20:19<13:17:40, 655.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metric=0.1567940063929806, metric_tc=0.12517058996794125, metric_wt=0.2843492742006977, metric_et=0.06086215427300582\n",
      "0.1567940063929806\n",
      "saved new best metric model\n",
      "current epoch: 7 current mean dice: 0.1568 tc: 0.1252 wt: 0.2843 et: 0.0609\n",
      "best mean dice: 0.1568 at epoch: 7\n",
      "\n",
      " | Global Training Round : 8 |\n",
      "\n",
      "user 0 selected\n",
      "local epoch 1\n",
      "1/194, train_loss: 0.8531\n",
      "2/194, train_loss: 0.8861\n",
      "3/194, train_loss: 0.9322\n",
      "4/194, train_loss: 0.9221\n",
      "5/194, train_loss: 0.8805\n",
      "6/194, train_loss: 0.8937\n",
      "7/194, train_loss: 0.8475\n",
      "8/194, train_loss: 0.9330\n",
      "9/194, train_loss: 0.9167\n",
      "10/194, train_loss: 0.9434\n",
      "11/194, train_loss: 0.9182\n",
      "12/194, train_loss: 0.8893\n",
      "13/194, train_loss: 0.9035\n",
      "14/194, train_loss: 0.8857\n",
      "15/194, train_loss: 0.8572\n",
      "16/194, train_loss: 0.8590\n",
      "17/194, train_loss: 0.9378\n",
      "18/194, train_loss: 0.8147\n",
      "19/194, train_loss: 0.9274\n",
      "20/194, train_loss: 0.9433\n",
      "21/194, train_loss: 0.9578\n",
      "22/194, train_loss: 0.9444\n",
      "23/194, train_loss: 0.8852\n",
      "24/194, train_loss: 0.9252\n",
      "25/194, train_loss: 0.8696\n",
      "26/194, train_loss: 0.9120\n",
      "27/194, train_loss: 0.9138\n",
      "28/194, train_loss: 0.9134\n",
      "29/194, train_loss: 0.9562\n",
      "30/194, train_loss: 0.9312\n",
      "31/194, train_loss: 0.9115\n",
      "32/194, train_loss: 0.8741\n",
      "33/194, train_loss: 0.8790\n",
      "34/194, train_loss: 0.9164\n",
      "35/194, train_loss: 0.9458\n",
      "36/194, train_loss: 0.8778\n",
      "37/194, train_loss: 0.8793\n",
      "38/194, train_loss: 0.9318\n",
      "39/194, train_loss: 0.8102\n",
      "40/194, train_loss: 0.9006\n",
      "41/194, train_loss: 0.8731\n",
      "42/194, train_loss: 0.8573\n",
      "43/194, train_loss: 0.9360\n",
      "44/194, train_loss: 0.8973\n",
      "45/194, train_loss: 0.9738\n",
      "46/194, train_loss: 0.9799\n",
      "47/194, train_loss: 0.9554\n",
      "48/194, train_loss: 0.8872\n",
      "49/194, train_loss: 0.8903\n",
      "50/194, train_loss: 0.9376\n",
      "51/194, train_loss: 0.9353\n",
      "52/194, train_loss: 0.9379\n",
      "53/194, train_loss: 0.8671\n",
      "54/194, train_loss: 0.9319\n",
      "55/194, train_loss: 0.9235\n",
      "56/194, train_loss: 0.9518\n",
      "57/194, train_loss: 0.9211\n",
      "58/194, train_loss: 0.9422\n",
      "59/194, train_loss: 0.9424\n",
      "60/194, train_loss: 0.8489\n",
      "61/194, train_loss: 0.8633\n",
      "62/194, train_loss: 0.9068\n",
      "63/194, train_loss: 0.8499\n",
      "64/194, train_loss: 0.9625\n",
      "65/194, train_loss: 0.9229\n",
      "66/194, train_loss: 0.9451\n",
      "67/194, train_loss: 0.8835\n",
      "68/194, train_loss: 0.8653\n",
      "69/194, train_loss: 0.8680\n",
      "70/194, train_loss: 0.9410\n",
      "71/194, train_loss: 0.9051\n",
      "72/194, train_loss: 0.7999\n",
      "73/194, train_loss: 0.8580\n",
      "74/194, train_loss: 0.9210\n",
      "75/194, train_loss: 0.8958\n",
      "76/194, train_loss: 0.9604\n",
      "77/194, train_loss: 0.8482\n",
      "78/194, train_loss: 0.8927\n",
      "79/194, train_loss: 0.9661\n",
      "80/194, train_loss: 0.9331\n",
      "81/194, train_loss: 0.8520\n",
      "82/194, train_loss: 0.8948\n",
      "83/194, train_loss: 0.9104\n",
      "84/194, train_loss: 0.9029\n",
      "85/194, train_loss: 0.8341\n",
      "86/194, train_loss: 0.8388\n",
      "87/194, train_loss: 0.9009\n",
      "88/194, train_loss: 0.8481\n",
      "89/194, train_loss: 0.9402\n",
      "90/194, train_loss: 0.8781\n",
      "91/194, train_loss: 0.9025\n",
      "92/194, train_loss: 0.9154\n",
      "93/194, train_loss: 0.9106\n",
      "94/194, train_loss: 0.8929\n",
      "95/194, train_loss: 0.9319\n",
      "96/194, train_loss: 0.8289\n",
      "97/194, train_loss: 0.9347\n",
      "98/194, train_loss: 0.9513\n",
      "99/194, train_loss: 0.8931\n",
      "100/194, train_loss: 0.8455\n",
      "101/194, train_loss: 0.9273\n",
      "102/194, train_loss: 0.8912\n",
      "103/194, train_loss: 0.9450\n",
      "104/194, train_loss: 0.9567\n",
      "105/194, train_loss: 0.9215\n",
      "106/194, train_loss: 0.8481\n",
      "107/194, train_loss: 0.8500\n",
      "108/194, train_loss: 0.8825\n",
      "109/194, train_loss: 0.8671\n",
      "110/194, train_loss: 0.8486\n",
      "111/194, train_loss: 0.9604\n",
      "112/194, train_loss: 0.8383\n",
      "113/194, train_loss: 0.9127\n",
      "114/194, train_loss: 0.9095\n",
      "115/194, train_loss: 0.9128\n",
      "116/194, train_loss: 0.7955\n",
      "117/194, train_loss: 0.8450\n",
      "118/194, train_loss: 0.9284\n",
      "119/194, train_loss: 0.8253\n",
      "120/194, train_loss: 0.9015\n",
      "121/194, train_loss: 0.8806\n",
      "122/194, train_loss: 0.8966\n",
      "123/194, train_loss: 0.8927\n",
      "124/194, train_loss: 0.9432\n",
      "125/194, train_loss: 0.9399\n",
      "126/194, train_loss: 0.9754\n",
      "127/194, train_loss: 0.9553\n",
      "128/194, train_loss: 0.8280\n",
      "129/194, train_loss: 0.9542\n",
      "130/194, train_loss: 0.8896\n",
      "131/194, train_loss: 0.8387\n",
      "132/194, train_loss: 0.9180\n",
      "133/194, train_loss: 0.9199\n",
      "134/194, train_loss: 0.8836\n",
      "135/194, train_loss: 0.9052\n",
      "136/194, train_loss: 0.9037\n",
      "137/194, train_loss: 0.8329\n",
      "138/194, train_loss: 0.9346\n",
      "139/194, train_loss: 0.8904\n",
      "140/194, train_loss: 0.9034\n",
      "141/194, train_loss: 0.8623\n",
      "142/194, train_loss: 0.8331\n",
      "143/194, train_loss: 0.9198\n",
      "144/194, train_loss: 0.9246\n",
      "145/194, train_loss: 0.9470\n",
      "146/194, train_loss: 0.9371\n",
      "147/194, train_loss: 0.9504\n",
      "148/194, train_loss: 0.9756\n",
      "149/194, train_loss: 0.9323\n",
      "150/194, train_loss: 0.8937\n",
      "151/194, train_loss: 0.9097\n",
      "152/194, train_loss: 0.9528\n",
      "153/194, train_loss: 0.9242\n",
      "154/194, train_loss: 0.9821\n",
      "155/194, train_loss: 0.8931\n",
      "156/194, train_loss: 0.8838\n",
      "157/194, train_loss: 0.8861\n",
      "158/194, train_loss: 0.9137\n",
      "159/194, train_loss: 0.8836\n",
      "160/194, train_loss: 0.9094\n",
      "161/194, train_loss: 0.9119\n",
      "162/194, train_loss: 0.9393\n",
      "163/194, train_loss: 0.9307\n",
      "164/194, train_loss: 0.8238\n",
      "165/194, train_loss: 0.8724\n",
      "166/194, train_loss: 0.9300\n",
      "167/194, train_loss: 0.9139\n",
      "168/194, train_loss: 0.9099\n",
      "169/194, train_loss: 0.8783\n",
      "170/194, train_loss: 0.8971\n",
      "171/194, train_loss: 0.9075\n",
      "172/194, train_loss: 0.9752\n",
      "173/194, train_loss: 0.8502\n",
      "174/194, train_loss: 0.8489\n",
      "175/194, train_loss: 0.8815\n",
      "176/194, train_loss: 0.9039\n",
      "177/194, train_loss: 0.8721\n",
      "178/194, train_loss: 0.8528\n",
      "179/194, train_loss: 0.9207\n",
      "180/194, train_loss: 0.9124\n",
      "181/194, train_loss: 0.9009\n",
      "182/194, train_loss: 0.9298\n",
      "183/194, train_loss: 0.9269\n",
      "184/194, train_loss: 0.8071\n",
      "185/194, train_loss: 0.9153\n",
      "186/194, train_loss: 0.9289\n",
      "187/194, train_loss: 0.8058\n",
      "188/194, train_loss: 0.8696\n",
      "189/194, train_loss: 0.9016\n",
      "190/194, train_loss: 0.9342\n",
      "191/194, train_loss: 0.8363\n",
      "192/194, train_loss: 0.8939\n",
      "193/194, train_loss: 0.8736\n",
      "194/194, train_loss: 0.8884\n",
      "metric=0.1626990648607413, metric_tc=0.1308541715455552, metric_wt=0.2937529558936755, metric_et=0.0634900746808853\n",
      "metric=0.1626990648607413, metric_tc=0.1308541715455552, metric_wt=0.2937529558936755, metric_et=0.0634900746808853\n",
      "current epoch: 8 current epoch loss: 0.9009\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 8/80 [1:30:43<12:55:05, 645.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metric=0.1626990648607413, metric_tc=0.1308541715455552, metric_wt=0.2937529558936755, metric_et=0.0634900746808853\n",
      "0.1626990648607413\n",
      "saved new best metric model\n",
      "current epoch: 8 current mean dice: 0.1627 tc: 0.1309 wt: 0.2938 et: 0.0635\n",
      "best mean dice: 0.1627 at epoch: 8\n",
      "\n",
      " | Global Training Round : 9 |\n",
      "\n",
      "user 0 selected\n",
      "local epoch 1\n",
      "1/194, train_loss: 0.8616\n",
      "2/194, train_loss: 0.9245\n",
      "3/194, train_loss: 0.9032\n",
      "4/194, train_loss: 0.8268\n",
      "5/194, train_loss: 0.8385\n",
      "6/194, train_loss: 0.8798\n",
      "7/194, train_loss: 0.8518\n",
      "8/194, train_loss: 0.9014\n",
      "9/194, train_loss: 0.9014\n",
      "10/194, train_loss: 0.9321\n",
      "11/194, train_loss: 0.9318\n",
      "12/194, train_loss: 0.9456\n",
      "13/194, train_loss: 0.8159\n",
      "14/194, train_loss: 0.8480\n",
      "15/194, train_loss: 0.8438\n",
      "16/194, train_loss: 0.8995\n",
      "17/194, train_loss: 0.8862\n",
      "18/194, train_loss: 0.8370\n",
      "19/194, train_loss: 0.8977\n",
      "20/194, train_loss: 0.9189\n",
      "21/194, train_loss: 0.9184\n",
      "22/194, train_loss: 0.9540\n",
      "23/194, train_loss: 0.8670\n",
      "24/194, train_loss: 0.8543\n",
      "25/194, train_loss: 0.8492\n",
      "26/194, train_loss: 0.9248\n",
      "27/194, train_loss: 0.9484\n",
      "28/194, train_loss: 0.8108\n",
      "29/194, train_loss: 0.8324\n",
      "30/194, train_loss: 0.8496\n",
      "31/194, train_loss: 0.9025\n",
      "32/194, train_loss: 0.9159\n",
      "33/194, train_loss: 0.8521\n",
      "34/194, train_loss: 0.8387\n",
      "35/194, train_loss: 0.8913\n",
      "36/194, train_loss: 0.9040\n",
      "37/194, train_loss: 0.8470\n",
      "38/194, train_loss: 0.8366\n",
      "39/194, train_loss: 0.8666\n",
      "40/194, train_loss: 0.9113\n",
      "41/194, train_loss: 0.8856\n",
      "42/194, train_loss: 0.8578\n",
      "43/194, train_loss: 0.8279\n",
      "44/194, train_loss: 0.8845\n",
      "45/194, train_loss: 0.8173\n",
      "46/194, train_loss: 0.8151\n",
      "47/194, train_loss: 0.9582\n",
      "48/194, train_loss: 0.7775\n",
      "49/194, train_loss: 0.8657\n",
      "50/194, train_loss: 0.8794\n",
      "51/194, train_loss: 0.8752\n",
      "52/194, train_loss: 0.8891\n",
      "53/194, train_loss: 0.9394\n",
      "54/194, train_loss: 0.9228\n",
      "55/194, train_loss: 0.8967\n",
      "56/194, train_loss: 0.8520\n",
      "57/194, train_loss: 0.9109\n",
      "58/194, train_loss: 0.8719\n",
      "59/194, train_loss: 0.9008\n",
      "60/194, train_loss: 0.9553\n",
      "61/194, train_loss: 0.8767\n",
      "62/194, train_loss: 0.8238\n",
      "63/194, train_loss: 0.8896\n",
      "64/194, train_loss: 0.8672\n",
      "65/194, train_loss: 0.8756\n",
      "66/194, train_loss: 0.9281\n",
      "67/194, train_loss: 0.8392\n",
      "68/194, train_loss: 0.9437\n",
      "69/194, train_loss: 0.9014\n",
      "70/194, train_loss: 0.7765\n",
      "71/194, train_loss: 0.9038\n",
      "72/194, train_loss: 0.8906\n",
      "73/194, train_loss: 0.8952\n",
      "74/194, train_loss: 0.8123\n",
      "75/194, train_loss: 0.9240\n",
      "76/194, train_loss: 0.8414\n",
      "77/194, train_loss: 0.8607\n",
      "78/194, train_loss: 0.9103\n",
      "79/194, train_loss: 0.8437\n",
      "80/194, train_loss: 0.9448\n",
      "81/194, train_loss: 0.8957\n",
      "82/194, train_loss: 0.9470\n",
      "83/194, train_loss: 0.9277\n",
      "84/194, train_loss: 0.8930\n",
      "85/194, train_loss: 0.9378\n",
      "86/194, train_loss: 0.9030\n",
      "87/194, train_loss: 0.9419\n",
      "88/194, train_loss: 0.8546\n",
      "89/194, train_loss: 0.9412\n",
      "90/194, train_loss: 0.8999\n",
      "91/194, train_loss: 0.9119\n",
      "92/194, train_loss: 0.8402\n",
      "93/194, train_loss: 0.8689\n",
      "94/194, train_loss: 0.8803\n",
      "95/194, train_loss: 0.8766\n",
      "96/194, train_loss: 0.8826\n",
      "97/194, train_loss: 0.8662\n",
      "98/194, train_loss: 0.9054\n",
      "99/194, train_loss: 0.9223\n",
      "100/194, train_loss: 0.9296\n",
      "101/194, train_loss: 0.8766\n",
      "102/194, train_loss: 0.9368\n",
      "103/194, train_loss: 0.9073\n",
      "104/194, train_loss: 0.8475\n",
      "105/194, train_loss: 0.8816\n",
      "106/194, train_loss: 0.8525\n",
      "107/194, train_loss: 0.8795\n",
      "108/194, train_loss: 0.8418\n",
      "109/194, train_loss: 0.9142\n",
      "110/194, train_loss: 0.9312\n",
      "111/194, train_loss: 0.8912\n",
      "112/194, train_loss: 0.8964\n",
      "113/194, train_loss: 0.8879\n",
      "114/194, train_loss: 0.9052\n",
      "115/194, train_loss: 0.8410\n",
      "116/194, train_loss: 0.9261\n",
      "117/194, train_loss: 0.9266\n",
      "118/194, train_loss: 0.9602\n",
      "119/194, train_loss: 0.9216\n",
      "120/194, train_loss: 0.9302\n",
      "121/194, train_loss: 0.8437\n",
      "122/194, train_loss: 0.8992\n",
      "123/194, train_loss: 0.9432\n",
      "124/194, train_loss: 0.8951\n",
      "125/194, train_loss: 0.9127\n",
      "126/194, train_loss: 0.8345\n",
      "127/194, train_loss: 0.9237\n",
      "128/194, train_loss: 0.9799\n",
      "129/194, train_loss: 0.9372\n",
      "130/194, train_loss: 0.9261\n",
      "131/194, train_loss: 0.9140\n",
      "132/194, train_loss: 0.8428\n",
      "133/194, train_loss: 0.9163\n",
      "134/194, train_loss: 0.8581\n",
      "135/194, train_loss: 0.9080\n",
      "136/194, train_loss: 0.9504\n",
      "137/194, train_loss: 0.9554\n",
      "138/194, train_loss: 0.9576\n",
      "139/194, train_loss: 0.9344\n",
      "140/194, train_loss: 0.8522\n",
      "141/194, train_loss: 0.9646\n",
      "142/194, train_loss: 0.9046\n",
      "143/194, train_loss: 0.9311\n",
      "144/194, train_loss: 0.9308\n",
      "145/194, train_loss: 0.9160\n",
      "146/194, train_loss: 0.8320\n",
      "147/194, train_loss: 0.8986\n",
      "148/194, train_loss: 0.9326\n",
      "149/194, train_loss: 0.9410\n",
      "150/194, train_loss: 0.9584\n",
      "151/194, train_loss: 0.9647\n",
      "152/194, train_loss: 0.8534\n",
      "153/194, train_loss: 0.9060\n",
      "154/194, train_loss: 0.8018\n",
      "155/194, train_loss: 0.8694\n",
      "156/194, train_loss: 0.9421\n",
      "157/194, train_loss: 0.9281\n",
      "158/194, train_loss: 0.7816\n",
      "159/194, train_loss: 0.8781\n",
      "160/194, train_loss: 0.9321\n",
      "161/194, train_loss: 0.9058\n",
      "162/194, train_loss: 0.9414\n",
      "163/194, train_loss: 0.9097\n",
      "164/194, train_loss: 0.9043\n",
      "165/194, train_loss: 0.8628\n",
      "166/194, train_loss: 0.8505\n",
      "167/194, train_loss: 0.8921\n",
      "168/194, train_loss: 0.8806\n",
      "169/194, train_loss: 0.9260\n",
      "170/194, train_loss: 0.9280\n",
      "171/194, train_loss: 0.9120\n",
      "172/194, train_loss: 0.8960\n",
      "173/194, train_loss: 0.9248\n",
      "174/194, train_loss: 0.9438\n",
      "175/194, train_loss: 0.8555\n",
      "176/194, train_loss: 0.9292\n",
      "177/194, train_loss: 0.8687\n",
      "178/194, train_loss: 0.8668\n",
      "179/194, train_loss: 0.8701\n",
      "180/194, train_loss: 0.8407\n",
      "181/194, train_loss: 0.9135\n",
      "182/194, train_loss: 0.8299\n",
      "183/194, train_loss: 0.8793\n",
      "184/194, train_loss: 0.8436\n",
      "185/194, train_loss: 0.9908\n",
      "186/194, train_loss: 0.9478\n",
      "187/194, train_loss: 0.9547\n",
      "188/194, train_loss: 0.9034\n",
      "189/194, train_loss: 0.8414\n",
      "190/194, train_loss: 0.8817\n",
      "191/194, train_loss: 0.9235\n",
      "192/194, train_loss: 0.9271\n",
      "193/194, train_loss: 0.8332\n",
      "194/194, train_loss: 0.9031\n",
      "metric=0.1764375826654335, metric_tc=0.14277799311093986, metric_wt=0.316582166745017, metric_et=0.06995258537547973\n",
      "metric=0.1764375826654335, metric_tc=0.14277799311093986, metric_wt=0.316582166745017, metric_et=0.06995258537547973\n",
      "current epoch: 9 current epoch loss: 0.8921\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█▏        | 9/80 [1:40:40<12:27:16, 631.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metric=0.1764375826654335, metric_tc=0.14277799311093986, metric_wt=0.316582166745017, metric_et=0.06995258537547973\n",
      "0.1764375826654335\n",
      "saved new best metric model\n",
      "current epoch: 9 current mean dice: 0.1764 tc: 0.1428 wt: 0.3166 et: 0.0700\n",
      "best mean dice: 0.1764 at epoch: 9\n",
      "\n",
      " | Global Training Round : 10 |\n",
      "\n",
      "user 0 selected\n",
      "local epoch 1\n",
      "1/194, train_loss: 0.8336\n",
      "2/194, train_loss: 0.8351\n",
      "3/194, train_loss: 0.9730\n",
      "4/194, train_loss: 0.8336\n",
      "5/194, train_loss: 0.8495\n",
      "6/194, train_loss: 0.9439\n",
      "7/194, train_loss: 0.8475\n",
      "8/194, train_loss: 0.9363\n",
      "9/194, train_loss: 0.8144\n",
      "10/194, train_loss: 0.9200\n",
      "11/194, train_loss: 0.9789\n",
      "12/194, train_loss: 0.9203\n",
      "13/194, train_loss: 0.8948\n",
      "14/194, train_loss: 0.9406\n",
      "15/194, train_loss: 0.9542\n",
      "16/194, train_loss: 0.8950\n",
      "17/194, train_loss: 0.9312\n",
      "18/194, train_loss: 0.9443\n",
      "19/194, train_loss: 0.8076\n",
      "20/194, train_loss: 0.8459\n",
      "21/194, train_loss: 0.7974\n",
      "22/194, train_loss: 0.8923\n",
      "23/194, train_loss: 0.8636\n",
      "24/194, train_loss: 0.8535\n",
      "25/194, train_loss: 0.9604\n",
      "26/194, train_loss: 0.8762\n",
      "27/194, train_loss: 0.8947\n",
      "28/194, train_loss: 0.8275\n",
      "29/194, train_loss: 0.8512\n",
      "30/194, train_loss: 0.8052\n",
      "31/194, train_loss: 0.8891\n",
      "32/194, train_loss: 0.8813\n",
      "33/194, train_loss: 0.8337\n",
      "34/194, train_loss: 0.9003\n",
      "35/194, train_loss: 0.8550\n",
      "36/194, train_loss: 0.9176\n",
      "37/194, train_loss: 0.9257\n",
      "38/194, train_loss: 0.7860\n",
      "39/194, train_loss: 0.8686\n",
      "40/194, train_loss: 0.8714\n",
      "41/194, train_loss: 0.9144\n",
      "42/194, train_loss: 0.9655\n",
      "43/194, train_loss: 0.8798\n",
      "44/194, train_loss: 0.9077\n",
      "45/194, train_loss: 0.8513\n",
      "46/194, train_loss: 0.8907\n",
      "47/194, train_loss: 0.8895\n",
      "48/194, train_loss: 0.8262\n",
      "49/194, train_loss: 0.8194\n",
      "50/194, train_loss: 0.8478\n",
      "51/194, train_loss: 0.8786\n",
      "52/194, train_loss: 0.8747\n",
      "53/194, train_loss: 0.9456\n",
      "54/194, train_loss: 0.8161\n",
      "55/194, train_loss: 0.8940\n",
      "56/194, train_loss: 0.9088\n",
      "57/194, train_loss: 0.9092\n",
      "58/194, train_loss: 0.8935\n",
      "59/194, train_loss: 0.7970\n",
      "60/194, train_loss: 0.8816\n",
      "61/194, train_loss: 0.8781\n",
      "62/194, train_loss: 0.8308\n",
      "63/194, train_loss: 0.8512\n",
      "64/194, train_loss: 0.8398\n",
      "65/194, train_loss: 0.9129\n",
      "66/194, train_loss: 0.8935\n",
      "67/194, train_loss: 0.9622\n",
      "68/194, train_loss: 0.7604\n",
      "69/194, train_loss: 0.8344\n",
      "70/194, train_loss: 0.8184\n",
      "71/194, train_loss: 0.8998\n",
      "72/194, train_loss: 0.8302\n",
      "73/194, train_loss: 0.8903\n",
      "74/194, train_loss: 0.9024\n",
      "75/194, train_loss: 0.8756\n",
      "76/194, train_loss: 0.8614\n",
      "77/194, train_loss: 0.9522\n",
      "78/194, train_loss: 0.9392\n",
      "79/194, train_loss: 0.9420\n",
      "80/194, train_loss: 0.8984\n",
      "81/194, train_loss: 0.9466\n",
      "82/194, train_loss: 0.8831\n",
      "83/194, train_loss: 0.8549\n",
      "84/194, train_loss: 0.9369\n",
      "85/194, train_loss: 0.9524\n",
      "86/194, train_loss: 0.9542\n",
      "87/194, train_loss: 0.8647\n",
      "88/194, train_loss: 0.9534\n",
      "89/194, train_loss: 0.9129\n",
      "90/194, train_loss: 0.9130\n",
      "91/194, train_loss: 0.9682\n",
      "92/194, train_loss: 0.9394\n",
      "93/194, train_loss: 0.8743\n",
      "94/194, train_loss: 0.8559\n",
      "95/194, train_loss: 0.8464\n",
      "96/194, train_loss: 0.9665\n",
      "97/194, train_loss: 0.8774\n",
      "98/194, train_loss: 0.9270\n",
      "99/194, train_loss: 0.8645\n",
      "100/194, train_loss: 0.9301\n",
      "101/194, train_loss: 0.9204\n",
      "102/194, train_loss: 0.8585\n",
      "103/194, train_loss: 0.9480\n",
      "104/194, train_loss: 0.9258\n",
      "105/194, train_loss: 0.8721\n",
      "106/194, train_loss: 0.8729\n",
      "107/194, train_loss: 0.8124\n",
      "108/194, train_loss: 0.8553\n",
      "109/194, train_loss: 0.9188\n",
      "110/194, train_loss: 0.8865\n",
      "111/194, train_loss: 0.9095\n",
      "112/194, train_loss: 0.8677\n",
      "113/194, train_loss: 0.8578\n",
      "114/194, train_loss: 0.8700\n",
      "115/194, train_loss: 0.8570\n",
      "116/194, train_loss: 0.8653\n",
      "117/194, train_loss: 0.8270\n",
      "118/194, train_loss: 0.8599\n",
      "119/194, train_loss: 0.9526\n",
      "120/194, train_loss: 0.8793\n",
      "121/194, train_loss: 0.9295\n",
      "122/194, train_loss: 0.8426\n",
      "123/194, train_loss: 0.9432\n",
      "124/194, train_loss: 0.9005\n",
      "125/194, train_loss: 0.8194\n",
      "126/194, train_loss: 0.9394\n",
      "127/194, train_loss: 0.9580\n",
      "128/194, train_loss: 0.9348\n",
      "129/194, train_loss: 0.8535\n",
      "130/194, train_loss: 0.9104\n",
      "131/194, train_loss: 0.8626\n",
      "132/194, train_loss: 0.8557\n",
      "133/194, train_loss: 0.8864\n",
      "134/194, train_loss: 0.9136\n",
      "135/194, train_loss: 0.9209\n",
      "136/194, train_loss: 0.8638\n",
      "137/194, train_loss: 0.9415\n",
      "138/194, train_loss: 0.9367\n",
      "139/194, train_loss: 0.8353\n",
      "140/194, train_loss: 0.8751\n",
      "141/194, train_loss: 0.8502\n",
      "142/194, train_loss: 0.9187\n",
      "143/194, train_loss: 0.8367\n",
      "144/194, train_loss: 0.9474\n",
      "145/194, train_loss: 0.8568\n",
      "146/194, train_loss: 0.9139\n",
      "147/194, train_loss: 0.8445\n",
      "148/194, train_loss: 0.9201\n",
      "149/194, train_loss: 0.9563\n",
      "150/194, train_loss: 0.9319\n",
      "151/194, train_loss: 0.8278\n",
      "152/194, train_loss: 0.9406\n",
      "153/194, train_loss: 0.9069\n",
      "154/194, train_loss: 0.9166\n",
      "155/194, train_loss: 0.7413\n",
      "156/194, train_loss: 0.9735\n",
      "157/194, train_loss: 0.8312\n",
      "158/194, train_loss: 0.9133\n",
      "159/194, train_loss: 0.8578\n",
      "160/194, train_loss: 0.8157\n",
      "161/194, train_loss: 0.8609\n",
      "162/194, train_loss: 0.9389\n",
      "163/194, train_loss: 0.8924\n",
      "164/194, train_loss: 0.8284\n",
      "165/194, train_loss: 0.8240\n",
      "166/194, train_loss: 0.8888\n",
      "167/194, train_loss: 0.8591\n",
      "168/194, train_loss: 0.8405\n",
      "169/194, train_loss: 0.8271\n",
      "170/194, train_loss: 0.8356\n",
      "171/194, train_loss: 0.8192\n",
      "172/194, train_loss: 0.8635\n",
      "173/194, train_loss: 0.8657\n",
      "174/194, train_loss: 0.8375\n",
      "175/194, train_loss: 0.8729\n",
      "176/194, train_loss: 0.9349\n",
      "177/194, train_loss: 0.8473\n",
      "178/194, train_loss: 0.8851\n",
      "179/194, train_loss: 0.8954\n",
      "180/194, train_loss: 0.8240\n",
      "181/194, train_loss: 0.8620\n",
      "182/194, train_loss: 0.8341\n",
      "183/194, train_loss: 0.8384\n",
      "184/194, train_loss: 0.8440\n",
      "185/194, train_loss: 0.9615\n",
      "186/194, train_loss: 0.9630\n",
      "187/194, train_loss: 0.7978\n",
      "188/194, train_loss: 0.8761\n",
      "189/194, train_loss: 0.8803\n",
      "190/194, train_loss: 0.8316\n",
      "191/194, train_loss: 0.9512\n",
      "192/194, train_loss: 0.9008\n",
      "193/194, train_loss: 0.9002\n",
      "194/194, train_loss: 0.9115\n",
      "metric=0.18902687697360912, metric_tc=0.15567034669220448, metric_wt=0.33475414849817753, metric_et=0.07665613984378676\n",
      "metric=0.18902687697360912, metric_tc=0.15567034669220448, metric_wt=0.33475414849817753, metric_et=0.07665613984378676\n",
      "current epoch: 10 current epoch loss: 0.8839\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▎        | 10/80 [1:50:39<12:05:21, 621.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metric=0.18902687697360912, metric_tc=0.15567034669220448, metric_wt=0.33475414849817753, metric_et=0.07665613984378676\n",
      "0.18902687697360912\n",
      "saved new best metric model\n",
      "current epoch: 10 current mean dice: 0.1890 tc: 0.1557 wt: 0.3348 et: 0.0767\n",
      "best mean dice: 0.1890 at epoch: 10\n",
      "\n",
      " | Global Training Round : 11 |\n",
      "\n",
      "user 0 selected\n",
      "local epoch 1\n",
      "1/194, train_loss: 0.8512\n",
      "2/194, train_loss: 0.9426\n",
      "3/194, train_loss: 0.8834\n",
      "4/194, train_loss: 0.8773\n",
      "5/194, train_loss: 0.8959\n",
      "6/194, train_loss: 0.9370\n",
      "7/194, train_loss: 0.7602\n",
      "8/194, train_loss: 0.8293\n",
      "9/194, train_loss: 0.9422\n",
      "10/194, train_loss: 0.9516\n",
      "11/194, train_loss: 0.9201\n",
      "12/194, train_loss: 0.7535\n",
      "13/194, train_loss: 0.8079\n",
      "14/194, train_loss: 0.7304\n",
      "15/194, train_loss: 0.7680\n",
      "16/194, train_loss: 0.9123\n",
      "17/194, train_loss: 0.8907\n",
      "18/194, train_loss: 0.9484\n",
      "19/194, train_loss: 0.8128\n",
      "20/194, train_loss: 0.8519\n",
      "21/194, train_loss: 0.9106\n",
      "22/194, train_loss: 0.9487\n",
      "23/194, train_loss: 0.8878\n",
      "24/194, train_loss: 0.8196\n",
      "25/194, train_loss: 0.8632\n",
      "26/194, train_loss: 0.8156\n",
      "27/194, train_loss: 0.8714\n",
      "28/194, train_loss: 0.8605\n",
      "29/194, train_loss: 0.8301\n",
      "30/194, train_loss: 0.9201\n",
      "31/194, train_loss: 0.8420\n",
      "32/194, train_loss: 0.9392\n",
      "33/194, train_loss: 0.9571\n",
      "34/194, train_loss: 0.8349\n",
      "35/194, train_loss: 0.8347\n",
      "36/194, train_loss: 0.8222\n",
      "37/194, train_loss: 0.7481\n",
      "38/194, train_loss: 0.8783\n",
      "39/194, train_loss: 0.8257\n",
      "40/194, train_loss: 0.8907\n",
      "41/194, train_loss: 0.8976\n",
      "42/194, train_loss: 0.8334\n",
      "43/194, train_loss: 0.9034\n",
      "44/194, train_loss: 0.9197\n",
      "45/194, train_loss: 0.9153\n",
      "46/194, train_loss: 0.7711\n",
      "47/194, train_loss: 0.9282\n",
      "48/194, train_loss: 0.8716\n",
      "49/194, train_loss: 0.9085\n",
      "50/194, train_loss: 0.8699\n",
      "51/194, train_loss: 0.9157\n",
      "52/194, train_loss: 0.8017\n",
      "53/194, train_loss: 0.9425\n",
      "54/194, train_loss: 0.8845\n",
      "55/194, train_loss: 0.9449\n",
      "56/194, train_loss: 0.7569\n",
      "57/194, train_loss: 0.9509\n",
      "58/194, train_loss: 0.9356\n",
      "59/194, train_loss: 0.9542\n",
      "60/194, train_loss: 0.8795\n",
      "61/194, train_loss: 0.8494\n",
      "62/194, train_loss: 0.8116\n",
      "63/194, train_loss: 0.9200\n",
      "64/194, train_loss: 0.8435\n",
      "65/194, train_loss: 0.7484\n",
      "66/194, train_loss: 0.8852\n",
      "67/194, train_loss: 0.8950\n",
      "68/194, train_loss: 0.8425\n",
      "69/194, train_loss: 0.9376\n",
      "70/194, train_loss: 0.9467\n",
      "71/194, train_loss: 0.8297\n",
      "72/194, train_loss: 0.9133\n",
      "73/194, train_loss: 0.9529\n",
      "74/194, train_loss: 0.9327\n",
      "75/194, train_loss: 0.8568\n",
      "76/194, train_loss: 0.8992\n",
      "77/194, train_loss: 0.8738\n",
      "78/194, train_loss: 0.9482\n",
      "79/194, train_loss: 0.8394\n",
      "80/194, train_loss: 0.8950\n",
      "81/194, train_loss: 0.7916\n",
      "82/194, train_loss: 0.8126\n",
      "83/194, train_loss: 0.8456\n",
      "84/194, train_loss: 0.9040\n",
      "85/194, train_loss: 0.8793\n",
      "86/194, train_loss: 0.9296\n",
      "87/194, train_loss: 0.8418\n",
      "88/194, train_loss: 0.8261\n",
      "89/194, train_loss: 0.9279\n",
      "90/194, train_loss: 0.8625\n",
      "91/194, train_loss: 0.7718\n",
      "92/194, train_loss: 0.8706\n",
      "93/194, train_loss: 0.8963\n",
      "94/194, train_loss: 0.8138\n",
      "95/194, train_loss: 0.9205\n",
      "96/194, train_loss: 0.9430\n",
      "97/194, train_loss: 0.9169\n",
      "98/194, train_loss: 0.8847\n",
      "99/194, train_loss: 0.9318\n",
      "100/194, train_loss: 0.8905\n",
      "101/194, train_loss: 0.9023\n",
      "102/194, train_loss: 0.8667\n",
      "103/194, train_loss: 0.9149\n",
      "104/194, train_loss: 0.8080\n",
      "105/194, train_loss: 0.8263\n",
      "106/194, train_loss: 0.8775\n",
      "107/194, train_loss: 0.8575\n",
      "108/194, train_loss: 0.8660\n",
      "109/194, train_loss: 0.8754\n",
      "110/194, train_loss: 0.9115\n",
      "111/194, train_loss: 0.8695\n",
      "112/194, train_loss: 0.9020\n",
      "113/194, train_loss: 0.8025\n",
      "114/194, train_loss: 0.9351\n",
      "115/194, train_loss: 0.9047\n",
      "116/194, train_loss: 0.7944\n",
      "117/194, train_loss: 0.8564\n",
      "118/194, train_loss: 0.8135\n",
      "119/194, train_loss: 0.8694\n",
      "120/194, train_loss: 0.8442\n",
      "121/194, train_loss: 0.9697\n",
      "122/194, train_loss: 0.8880\n",
      "123/194, train_loss: 0.9552\n",
      "124/194, train_loss: 0.8607\n",
      "125/194, train_loss: 0.9286\n",
      "126/194, train_loss: 0.8824\n",
      "127/194, train_loss: 0.9127\n",
      "128/194, train_loss: 0.8759\n",
      "129/194, train_loss: 0.8487\n",
      "130/194, train_loss: 0.9293\n",
      "131/194, train_loss: 0.9669\n",
      "132/194, train_loss: 0.9319\n",
      "133/194, train_loss: 0.8525\n",
      "134/194, train_loss: 0.8807\n",
      "135/194, train_loss: 0.8727\n",
      "136/194, train_loss: 0.9165\n",
      "137/194, train_loss: 0.8827\n",
      "138/194, train_loss: 0.8519\n",
      "139/194, train_loss: 0.9286\n",
      "140/194, train_loss: 0.7448\n",
      "141/194, train_loss: 0.9099\n",
      "142/194, train_loss: 0.8959\n",
      "143/194, train_loss: 0.9177\n",
      "144/194, train_loss: 0.8118\n",
      "145/194, train_loss: 0.9417\n",
      "146/194, train_loss: 0.8326\n",
      "147/194, train_loss: 0.9146\n",
      "148/194, train_loss: 0.9353\n",
      "149/194, train_loss: 0.7581\n",
      "150/194, train_loss: 0.8710\n",
      "151/194, train_loss: 0.9147\n",
      "152/194, train_loss: 0.9159\n",
      "153/194, train_loss: 0.9291\n",
      "154/194, train_loss: 0.9509\n",
      "155/194, train_loss: 0.9455\n",
      "156/194, train_loss: 0.8974\n",
      "157/194, train_loss: 0.9296\n",
      "158/194, train_loss: 0.8963\n",
      "159/194, train_loss: 0.9635\n",
      "160/194, train_loss: 0.8994\n",
      "161/194, train_loss: 0.8848\n",
      "162/194, train_loss: 0.8543\n",
      "163/194, train_loss: 0.9296\n",
      "164/194, train_loss: 0.8625\n",
      "165/194, train_loss: 0.9441\n",
      "166/194, train_loss: 0.9478\n",
      "167/194, train_loss: 0.7661\n",
      "168/194, train_loss: 0.8835\n",
      "169/194, train_loss: 0.9212\n",
      "170/194, train_loss: 0.7928\n",
      "171/194, train_loss: 0.8939\n",
      "172/194, train_loss: 0.9178\n",
      "173/194, train_loss: 0.8019\n",
      "174/194, train_loss: 0.8534\n",
      "175/194, train_loss: 0.9174\n",
      "176/194, train_loss: 0.9369\n",
      "177/194, train_loss: 0.8433\n",
      "178/194, train_loss: 0.7657\n",
      "179/194, train_loss: 0.9317\n",
      "180/194, train_loss: 0.8721\n",
      "181/194, train_loss: 0.8566\n",
      "182/194, train_loss: 0.7055\n",
      "183/194, train_loss: 0.8383\n",
      "184/194, train_loss: 0.8504\n",
      "185/194, train_loss: 0.9367\n",
      "186/194, train_loss: 0.9176\n",
      "187/194, train_loss: 0.7966\n",
      "188/194, train_loss: 0.8973\n",
      "189/194, train_loss: 0.9137\n",
      "190/194, train_loss: 0.8998\n",
      "191/194, train_loss: 0.8939\n",
      "192/194, train_loss: 0.8987\n",
      "193/194, train_loss: 0.9390\n",
      "194/194, train_loss: 0.9064\n",
      "metric=0.19918634494145712, metric_tc=0.16550647319915393, metric_wt=0.35062406056871015, metric_et=0.08142849432382111\n",
      "metric=0.19918634494145712, metric_tc=0.16550647319915393, metric_wt=0.35062406056871015, metric_et=0.08142849432382111\n",
      "current epoch: 11 current epoch loss: 0.8784\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 11/80 [2:01:22<12:02:08, 627.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metric=0.19918634494145712, metric_tc=0.16550647319915393, metric_wt=0.35062406056871015, metric_et=0.08142849432382111\n",
      "0.19918634494145712\n",
      "saved new best metric model\n",
      "current epoch: 11 current mean dice: 0.1992 tc: 0.1655 wt: 0.3506 et: 0.0814\n",
      "best mean dice: 0.1992 at epoch: 11\n",
      "\n",
      " | Global Training Round : 12 |\n",
      "\n",
      "user 0 selected\n",
      "local epoch 1\n",
      "1/194, train_loss: 0.8267\n",
      "2/194, train_loss: 0.9032\n",
      "3/194, train_loss: 0.9472\n",
      "4/194, train_loss: 0.9725\n",
      "5/194, train_loss: 0.8359\n",
      "6/194, train_loss: 0.8870\n",
      "7/194, train_loss: 0.8880\n",
      "8/194, train_loss: 0.7381\n",
      "9/194, train_loss: 0.9436\n",
      "10/194, train_loss: 0.8628\n",
      "11/194, train_loss: 0.9300\n",
      "12/194, train_loss: 0.8789\n",
      "13/194, train_loss: 0.8782\n",
      "14/194, train_loss: 0.9869\n",
      "15/194, train_loss: 0.9089\n",
      "16/194, train_loss: 0.9175\n",
      "17/194, train_loss: 0.9705\n",
      "18/194, train_loss: 0.8287\n",
      "19/194, train_loss: 0.9127\n",
      "20/194, train_loss: 0.8929\n",
      "21/194, train_loss: 0.9114\n",
      "22/194, train_loss: 0.8509\n",
      "23/194, train_loss: 0.8527\n",
      "24/194, train_loss: 0.8904\n",
      "25/194, train_loss: 0.9217\n",
      "26/194, train_loss: 0.8793\n",
      "27/194, train_loss: 0.8851\n",
      "28/194, train_loss: 0.8653\n",
      "29/194, train_loss: 0.9096\n",
      "30/194, train_loss: 0.8594\n",
      "31/194, train_loss: 0.8997\n",
      "32/194, train_loss: 0.8371\n",
      "33/194, train_loss: 0.8660\n",
      "34/194, train_loss: 0.8282\n",
      "35/194, train_loss: 0.8899\n",
      "36/194, train_loss: 0.8568\n",
      "37/194, train_loss: 0.8120\n",
      "38/194, train_loss: 0.8900\n",
      "39/194, train_loss: 0.7609\n",
      "40/194, train_loss: 0.8247\n",
      "41/194, train_loss: 0.9219\n",
      "42/194, train_loss: 0.8646\n",
      "43/194, train_loss: 0.8900\n",
      "44/194, train_loss: 0.9200\n",
      "45/194, train_loss: 0.8343\n",
      "46/194, train_loss: 0.8439\n",
      "47/194, train_loss: 0.7824\n",
      "48/194, train_loss: 0.8126\n",
      "49/194, train_loss: 0.8817\n",
      "50/194, train_loss: 0.9262\n",
      "51/194, train_loss: 0.8107\n",
      "52/194, train_loss: 0.8967\n",
      "53/194, train_loss: 0.8359\n",
      "54/194, train_loss: 0.8210\n",
      "55/194, train_loss: 0.7851\n",
      "56/194, train_loss: 0.8700\n",
      "57/194, train_loss: 0.9181\n",
      "58/194, train_loss: 0.8543\n",
      "59/194, train_loss: 0.8310\n",
      "60/194, train_loss: 0.7739\n",
      "61/194, train_loss: 0.8011\n",
      "62/194, train_loss: 0.8346\n",
      "63/194, train_loss: 0.9030\n",
      "64/194, train_loss: 0.9166\n",
      "65/194, train_loss: 0.9335\n",
      "66/194, train_loss: 0.9444\n",
      "67/194, train_loss: 0.8622\n",
      "68/194, train_loss: 0.9034\n",
      "69/194, train_loss: 0.8429\n",
      "70/194, train_loss: 0.8608\n",
      "71/194, train_loss: 0.7808\n",
      "72/194, train_loss: 0.7514\n",
      "73/194, train_loss: 0.8459\n",
      "74/194, train_loss: 0.9187\n",
      "75/194, train_loss: 0.8279\n",
      "76/194, train_loss: 0.7770\n",
      "77/194, train_loss: 0.9195\n",
      "78/194, train_loss: 0.8546\n",
      "79/194, train_loss: 0.8874\n",
      "80/194, train_loss: 0.8228\n",
      "81/194, train_loss: 0.8523\n",
      "82/194, train_loss: 0.9173\n",
      "83/194, train_loss: 0.8369\n",
      "84/194, train_loss: 0.9525\n",
      "85/194, train_loss: 0.8486\n",
      "86/194, train_loss: 0.9246\n",
      "87/194, train_loss: 0.8684\n",
      "88/194, train_loss: 0.8677\n",
      "89/194, train_loss: 0.9124\n",
      "90/194, train_loss: 0.9152\n",
      "91/194, train_loss: 0.9082\n",
      "92/194, train_loss: 0.8588\n",
      "93/194, train_loss: 0.8753\n",
      "94/194, train_loss: 0.8820\n",
      "95/194, train_loss: 0.9308\n",
      "96/194, train_loss: 0.8745\n",
      "97/194, train_loss: 0.8451\n",
      "98/194, train_loss: 0.9169\n",
      "99/194, train_loss: 0.8278\n",
      "100/194, train_loss: 0.8613\n",
      "101/194, train_loss: 0.8497\n",
      "102/194, train_loss: 0.8800\n",
      "103/194, train_loss: 0.8658\n",
      "104/194, train_loss: 0.8459\n",
      "105/194, train_loss: 0.8083\n",
      "106/194, train_loss: 0.9358\n",
      "107/194, train_loss: 0.8720\n",
      "108/194, train_loss: 0.9538\n",
      "109/194, train_loss: 0.8922\n",
      "110/194, train_loss: 0.7826\n",
      "111/194, train_loss: 0.8978\n",
      "112/194, train_loss: 0.9375\n",
      "113/194, train_loss: 0.7968\n",
      "114/194, train_loss: 0.9141\n",
      "115/194, train_loss: 0.8004\n",
      "116/194, train_loss: 0.8950\n",
      "117/194, train_loss: 0.8265\n",
      "118/194, train_loss: 0.9102\n",
      "119/194, train_loss: 0.8826\n",
      "120/194, train_loss: 0.8449\n",
      "121/194, train_loss: 0.9254\n",
      "122/194, train_loss: 0.9544\n",
      "123/194, train_loss: 0.8196\n",
      "124/194, train_loss: 0.7870\n",
      "125/194, train_loss: 0.9118\n",
      "126/194, train_loss: 0.9593\n",
      "127/194, train_loss: 0.8919\n",
      "128/194, train_loss: 0.8900\n",
      "129/194, train_loss: 0.8780\n",
      "130/194, train_loss: 0.8627\n",
      "131/194, train_loss: 0.7746\n",
      "132/194, train_loss: 0.8862\n",
      "133/194, train_loss: 0.8151\n",
      "134/194, train_loss: 0.8603\n",
      "135/194, train_loss: 0.9562\n",
      "136/194, train_loss: 0.8947\n",
      "137/194, train_loss: 0.8825\n",
      "138/194, train_loss: 0.8730\n",
      "139/194, train_loss: 0.9604\n",
      "140/194, train_loss: 0.8651\n",
      "141/194, train_loss: 0.8307\n",
      "142/194, train_loss: 0.8472\n",
      "143/194, train_loss: 0.8296\n",
      "144/194, train_loss: 0.9529\n",
      "145/194, train_loss: 0.8821\n",
      "146/194, train_loss: 0.8554\n",
      "147/194, train_loss: 0.9796\n",
      "148/194, train_loss: 0.9081\n",
      "149/194, train_loss: 0.8812\n",
      "150/194, train_loss: 0.8640\n",
      "151/194, train_loss: 0.8510\n",
      "152/194, train_loss: 0.9227\n",
      "153/194, train_loss: 0.9292\n",
      "154/194, train_loss: 0.9331\n",
      "155/194, train_loss: 0.9245\n",
      "156/194, train_loss: 0.9246\n",
      "157/194, train_loss: 0.9370\n",
      "158/194, train_loss: 0.8736\n",
      "159/194, train_loss: 0.8164\n",
      "160/194, train_loss: 0.8582\n",
      "161/194, train_loss: 0.8894\n",
      "162/194, train_loss: 0.9270\n",
      "163/194, train_loss: 0.9305\n",
      "164/194, train_loss: 0.8258\n",
      "165/194, train_loss: 0.8599\n",
      "166/194, train_loss: 0.9263\n",
      "167/194, train_loss: 0.7958\n",
      "168/194, train_loss: 0.8808\n",
      "169/194, train_loss: 0.7870\n",
      "170/194, train_loss: 0.8573\n",
      "171/194, train_loss: 0.8347\n",
      "172/194, train_loss: 0.8227\n",
      "173/194, train_loss: 0.7950\n",
      "174/194, train_loss: 0.9058\n",
      "175/194, train_loss: 0.8567\n",
      "176/194, train_loss: 0.7994\n",
      "177/194, train_loss: 0.9587\n",
      "178/194, train_loss: 0.9111\n",
      "179/194, train_loss: 0.8877\n",
      "180/194, train_loss: 0.8686\n",
      "181/194, train_loss: 0.8357\n",
      "182/194, train_loss: 0.8170\n",
      "183/194, train_loss: 0.8752\n",
      "184/194, train_loss: 0.8001\n",
      "185/194, train_loss: 0.9686\n",
      "186/194, train_loss: 0.8898\n",
      "187/194, train_loss: 0.8084\n",
      "188/194, train_loss: 0.8647\n",
      "189/194, train_loss: 0.8887\n",
      "190/194, train_loss: 0.8590\n",
      "191/194, train_loss: 0.8966\n",
      "192/194, train_loss: 0.8359\n",
      "193/194, train_loss: 0.9133\n",
      "194/194, train_loss: 0.8624\n",
      "metric=0.2123275251748661, metric_tc=0.1803988324633489, metric_wt=0.36756952448437613, metric_et=0.0890142148709856\n",
      "metric=0.2123275251748661, metric_tc=0.1803988324633489, metric_wt=0.36756952448437613, metric_et=0.0890142148709856\n",
      "current epoch: 12 current epoch loss: 0.8733\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 12/80 [2:12:12<11:59:20, 634.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metric=0.2123275251748661, metric_tc=0.1803988324633489, metric_wt=0.36756952448437613, metric_et=0.0890142148709856\n",
      "0.2123275251748661\n",
      "saved new best metric model\n",
      "current epoch: 12 current mean dice: 0.2123 tc: 0.1804 wt: 0.3676 et: 0.0890\n",
      "best mean dice: 0.2123 at epoch: 12\n",
      "\n",
      " | Global Training Round : 13 |\n",
      "\n",
      "user 0 selected\n",
      "local epoch 1\n",
      "1/194, train_loss: 0.8846\n",
      "2/194, train_loss: 0.8730\n",
      "3/194, train_loss: 0.8629\n",
      "4/194, train_loss: 0.8710\n",
      "5/194, train_loss: 0.8812\n",
      "6/194, train_loss: 0.7800\n",
      "7/194, train_loss: 0.8841\n",
      "8/194, train_loss: 0.8449\n",
      "9/194, train_loss: 0.9370\n",
      "10/194, train_loss: 0.9482\n",
      "11/194, train_loss: 0.9536\n",
      "12/194, train_loss: 0.8370\n",
      "13/194, train_loss: 0.8859\n",
      "14/194, train_loss: 0.7172\n",
      "15/194, train_loss: 0.8241\n",
      "16/194, train_loss: 0.8649\n",
      "17/194, train_loss: 0.9376\n",
      "18/194, train_loss: 0.8147\n",
      "19/194, train_loss: 0.9100\n",
      "20/194, train_loss: 0.8584\n",
      "21/194, train_loss: 0.8566\n",
      "22/194, train_loss: 0.8801\n",
      "23/194, train_loss: 0.8271\n",
      "24/194, train_loss: 0.8074\n",
      "25/194, train_loss: 0.9138\n",
      "26/194, train_loss: 0.8761\n",
      "27/194, train_loss: 0.8078\n",
      "28/194, train_loss: 0.9398\n",
      "29/194, train_loss: 0.8415\n",
      "30/194, train_loss: 0.9594\n",
      "31/194, train_loss: 0.8988\n",
      "32/194, train_loss: 0.9285\n",
      "33/194, train_loss: 0.8672\n",
      "34/194, train_loss: 0.9149\n",
      "35/194, train_loss: 0.8998\n",
      "36/194, train_loss: 0.8501\n",
      "37/194, train_loss: 0.8796\n",
      "38/194, train_loss: 0.9298\n",
      "39/194, train_loss: 0.8764\n",
      "40/194, train_loss: 0.7964\n",
      "41/194, train_loss: 0.8553\n",
      "42/194, train_loss: 0.8586\n",
      "43/194, train_loss: 0.7425\n",
      "44/194, train_loss: 0.9172\n",
      "45/194, train_loss: 0.8808\n",
      "46/194, train_loss: 0.8825\n",
      "47/194, train_loss: 0.9256\n",
      "48/194, train_loss: 0.7902\n",
      "49/194, train_loss: 0.9187\n",
      "50/194, train_loss: 0.8410\n",
      "51/194, train_loss: 0.9502\n",
      "52/194, train_loss: 0.8678\n",
      "53/194, train_loss: 0.8937\n",
      "54/194, train_loss: 0.8665\n",
      "55/194, train_loss: 0.8841\n",
      "56/194, train_loss: 0.9385\n",
      "57/194, train_loss: 0.9512\n",
      "58/194, train_loss: 0.8728\n",
      "59/194, train_loss: 0.8652\n",
      "60/194, train_loss: 0.9691\n",
      "61/194, train_loss: 0.9258\n",
      "62/194, train_loss: 0.7342\n",
      "63/194, train_loss: 0.7704\n",
      "64/194, train_loss: 0.7369\n",
      "65/194, train_loss: 0.8390\n",
      "66/194, train_loss: 0.9607\n",
      "67/194, train_loss: 0.8098\n",
      "68/194, train_loss: 0.8582\n",
      "69/194, train_loss: 0.8634\n",
      "70/194, train_loss: 0.8088\n",
      "71/194, train_loss: 0.8182\n",
      "72/194, train_loss: 0.8507\n",
      "73/194, train_loss: 0.8968\n",
      "74/194, train_loss: 0.8982\n",
      "75/194, train_loss: 0.8817\n",
      "76/194, train_loss: 0.9200\n",
      "77/194, train_loss: 0.8210\n",
      "78/194, train_loss: 0.8255\n",
      "79/194, train_loss: 0.8245\n",
      "80/194, train_loss: 0.8740\n",
      "81/194, train_loss: 0.7981\n",
      "82/194, train_loss: 0.9223\n",
      "83/194, train_loss: 0.8738\n",
      "84/194, train_loss: 0.8348\n",
      "85/194, train_loss: 0.8360\n",
      "86/194, train_loss: 0.8503\n",
      "87/194, train_loss: 0.8603\n",
      "88/194, train_loss: 0.9262\n",
      "89/194, train_loss: 0.8849\n",
      "90/194, train_loss: 0.8814\n",
      "91/194, train_loss: 0.8702\n",
      "92/194, train_loss: 0.8657\n",
      "93/194, train_loss: 0.8828\n",
      "94/194, train_loss: 0.7901\n",
      "95/194, train_loss: 0.9357\n",
      "96/194, train_loss: 0.8473\n",
      "97/194, train_loss: 0.9664\n",
      "98/194, train_loss: 0.7965\n",
      "99/194, train_loss: 0.9210\n",
      "100/194, train_loss: 0.8853\n",
      "101/194, train_loss: 0.9105\n",
      "102/194, train_loss: 0.8681\n",
      "103/194, train_loss: 0.9110\n",
      "104/194, train_loss: 0.9233\n",
      "105/194, train_loss: 0.7819\n",
      "106/194, train_loss: 0.8249\n",
      "107/194, train_loss: 0.8692\n",
      "108/194, train_loss: 0.8841\n",
      "109/194, train_loss: 0.7301\n",
      "110/194, train_loss: 0.8706\n",
      "111/194, train_loss: 0.9629\n",
      "112/194, train_loss: 0.7910\n",
      "113/194, train_loss: 0.8869\n",
      "114/194, train_loss: 0.9330\n",
      "115/194, train_loss: 0.8465\n",
      "116/194, train_loss: 0.8664\n",
      "117/194, train_loss: 0.8312\n",
      "118/194, train_loss: 0.8942\n",
      "119/194, train_loss: 0.9327\n",
      "120/194, train_loss: 0.8643\n",
      "121/194, train_loss: 0.9032\n",
      "122/194, train_loss: 0.9273\n",
      "123/194, train_loss: 0.9632\n",
      "124/194, train_loss: 0.9587\n",
      "125/194, train_loss: 0.8566\n",
      "126/194, train_loss: 0.8334\n",
      "127/194, train_loss: 0.8414\n",
      "128/194, train_loss: 0.9412\n",
      "129/194, train_loss: 0.8818\n",
      "130/194, train_loss: 0.8243\n",
      "131/194, train_loss: 0.8801\n",
      "132/194, train_loss: 0.8643\n",
      "133/194, train_loss: 0.9861\n",
      "134/194, train_loss: 0.8609\n",
      "135/194, train_loss: 0.8371\n",
      "136/194, train_loss: 0.8231\n",
      "137/194, train_loss: 0.7965\n",
      "138/194, train_loss: 0.9318\n",
      "139/194, train_loss: 0.8267\n",
      "140/194, train_loss: 0.9525\n",
      "141/194, train_loss: 0.9288\n",
      "142/194, train_loss: 0.8672\n",
      "143/194, train_loss: 0.9079\n",
      "144/194, train_loss: 0.8023\n",
      "145/194, train_loss: 0.8900\n",
      "146/194, train_loss: 0.9307\n",
      "147/194, train_loss: 0.9186\n",
      "148/194, train_loss: 0.8238\n",
      "149/194, train_loss: 0.8003\n",
      "150/194, train_loss: 0.9050\n",
      "151/194, train_loss: 0.8589\n",
      "152/194, train_loss: 0.9221\n",
      "153/194, train_loss: 0.8965\n",
      "154/194, train_loss: 0.9113\n",
      "155/194, train_loss: 0.9762\n",
      "156/194, train_loss: 0.8363\n",
      "157/194, train_loss: 0.8754\n",
      "158/194, train_loss: 0.9248\n",
      "159/194, train_loss: 0.9142\n",
      "160/194, train_loss: 0.8011\n",
      "161/194, train_loss: 0.9247\n",
      "162/194, train_loss: 0.8191\n",
      "163/194, train_loss: 0.9252\n",
      "164/194, train_loss: 0.8571\n",
      "165/194, train_loss: 0.8418\n",
      "166/194, train_loss: 0.8920\n",
      "167/194, train_loss: 0.8917\n",
      "168/194, train_loss: 0.9772\n",
      "169/194, train_loss: 0.7450\n",
      "170/194, train_loss: 0.8456\n",
      "171/194, train_loss: 0.8241\n",
      "172/194, train_loss: 0.8293\n",
      "173/194, train_loss: 0.7706\n",
      "174/194, train_loss: 0.8356\n",
      "175/194, train_loss: 0.8791\n",
      "176/194, train_loss: 0.7897\n",
      "177/194, train_loss: 0.7851\n",
      "178/194, train_loss: 0.8799\n",
      "179/194, train_loss: 0.9190\n",
      "180/194, train_loss: 0.7976\n",
      "181/194, train_loss: 0.7198\n",
      "182/194, train_loss: 0.8541\n",
      "183/194, train_loss: 0.9336\n",
      "184/194, train_loss: 0.7953\n",
      "185/194, train_loss: 0.9069\n",
      "186/194, train_loss: 0.8031\n",
      "187/194, train_loss: 0.8223\n",
      "188/194, train_loss: 0.9088\n",
      "189/194, train_loss: 0.9209\n",
      "190/194, train_loss: 0.8955\n",
      "191/194, train_loss: 0.7955\n",
      "192/194, train_loss: 0.8804\n",
      "193/194, train_loss: 0.9194\n",
      "194/194, train_loss: 0.8521\n",
      "metric=0.2196385320276022, metric_tc=0.18548881673874953, metric_wt=0.3817230174317956, metric_et=0.09170375942873459\n",
      "metric=0.2196385320276022, metric_tc=0.18548881673874953, metric_wt=0.3817230174317956, metric_et=0.09170375942873459\n",
      "current epoch: 13 current epoch loss: 0.8698\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▋        | 13/80 [2:24:10<12:16:25, 659.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metric=0.2196385320276022, metric_tc=0.18548881673874953, metric_wt=0.3817230174317956, metric_et=0.09170375942873459\n",
      "0.2196385320276022\n",
      "saved new best metric model\n",
      "current epoch: 13 current mean dice: 0.2196 tc: 0.1855 wt: 0.3817 et: 0.0917\n",
      "best mean dice: 0.2196 at epoch: 13\n",
      "\n",
      " | Global Training Round : 14 |\n",
      "\n",
      "user 0 selected\n",
      "local epoch 1\n",
      "1/194, train_loss: 0.8716\n",
      "2/194, train_loss: 0.8844\n",
      "3/194, train_loss: 0.9064\n",
      "4/194, train_loss: 0.8527\n",
      "5/194, train_loss: 0.9203\n",
      "6/194, train_loss: 0.8054\n",
      "7/194, train_loss: 0.8683\n",
      "8/194, train_loss: 0.9099\n",
      "9/194, train_loss: 0.8220\n",
      "10/194, train_loss: 0.8735\n",
      "11/194, train_loss: 0.8063\n",
      "12/194, train_loss: 0.8267\n",
      "13/194, train_loss: 0.9030\n",
      "14/194, train_loss: 0.9332\n",
      "15/194, train_loss: 0.8144\n",
      "16/194, train_loss: 0.9134\n",
      "17/194, train_loss: 0.8543\n",
      "18/194, train_loss: 0.8877\n",
      "19/194, train_loss: 0.7845\n",
      "20/194, train_loss: 0.8473\n",
      "21/194, train_loss: 0.8779\n",
      "22/194, train_loss: 0.8969\n",
      "23/194, train_loss: 0.8973\n",
      "24/194, train_loss: 0.8119\n",
      "25/194, train_loss: 0.8593\n",
      "26/194, train_loss: 0.7876\n",
      "27/194, train_loss: 0.8698\n",
      "28/194, train_loss: 0.8787\n",
      "29/194, train_loss: 0.8656\n",
      "30/194, train_loss: 0.8999\n",
      "31/194, train_loss: 0.8439\n",
      "32/194, train_loss: 0.8776\n",
      "33/194, train_loss: 0.9224\n",
      "34/194, train_loss: 0.8215\n",
      "35/194, train_loss: 0.8121\n",
      "36/194, train_loss: 0.7846\n",
      "37/194, train_loss: 0.8487\n",
      "38/194, train_loss: 0.8545\n",
      "39/194, train_loss: 0.7505\n",
      "40/194, train_loss: 0.8934\n",
      "41/194, train_loss: 0.9191\n",
      "42/194, train_loss: 0.8353\n",
      "43/194, train_loss: 0.9229\n",
      "44/194, train_loss: 0.8553\n",
      "45/194, train_loss: 0.9369\n",
      "46/194, train_loss: 0.9014\n",
      "47/194, train_loss: 0.8965\n",
      "48/194, train_loss: 0.8024\n",
      "49/194, train_loss: 0.8455\n",
      "50/194, train_loss: 0.8186\n",
      "51/194, train_loss: 0.8879\n",
      "52/194, train_loss: 0.6902\n",
      "53/194, train_loss: 0.8156\n",
      "54/194, train_loss: 0.8800\n",
      "55/194, train_loss: 0.8091\n",
      "56/194, train_loss: 0.8595\n",
      "57/194, train_loss: 0.8961\n",
      "58/194, train_loss: 0.8117\n",
      "59/194, train_loss: 0.9159\n",
      "60/194, train_loss: 0.9620\n",
      "61/194, train_loss: 0.9012\n",
      "62/194, train_loss: 0.7427\n",
      "63/194, train_loss: 0.8753\n",
      "64/194, train_loss: 0.8756\n",
      "65/194, train_loss: 0.8403\n",
      "66/194, train_loss: 0.9745\n",
      "67/194, train_loss: 0.8348\n",
      "68/194, train_loss: 0.9020\n",
      "69/194, train_loss: 0.8800\n",
      "70/194, train_loss: 0.8968\n",
      "71/194, train_loss: 0.9164\n",
      "72/194, train_loss: 0.8642\n",
      "73/194, train_loss: 0.8383\n",
      "74/194, train_loss: 0.9173\n",
      "75/194, train_loss: 0.8573\n",
      "76/194, train_loss: 0.8480\n",
      "77/194, train_loss: 0.9427\n",
      "78/194, train_loss: 0.8768\n",
      "79/194, train_loss: 0.8633\n",
      "80/194, train_loss: 0.8141\n",
      "81/194, train_loss: 0.8462\n",
      "82/194, train_loss: 0.8682\n",
      "83/194, train_loss: 0.8461\n",
      "84/194, train_loss: 0.7634\n",
      "85/194, train_loss: 0.9454\n",
      "86/194, train_loss: 0.8517\n",
      "87/194, train_loss: 0.8797\n",
      "88/194, train_loss: 0.8824\n",
      "89/194, train_loss: 0.8675\n",
      "90/194, train_loss: 0.8867\n",
      "91/194, train_loss: 0.9572\n",
      "92/194, train_loss: 0.8530\n",
      "93/194, train_loss: 0.9381\n",
      "94/194, train_loss: 0.8601\n",
      "95/194, train_loss: 0.9327\n",
      "96/194, train_loss: 0.7523\n",
      "97/194, train_loss: 0.9528\n",
      "98/194, train_loss: 0.9010\n",
      "99/194, train_loss: 0.8054\n",
      "100/194, train_loss: 0.8628\n",
      "101/194, train_loss: 0.8165\n",
      "102/194, train_loss: 0.8630\n",
      "103/194, train_loss: 0.8027\n",
      "104/194, train_loss: 0.8774\n",
      "105/194, train_loss: 0.9031\n",
      "106/194, train_loss: 0.8487\n",
      "107/194, train_loss: 0.8152\n",
      "108/194, train_loss: 0.8049\n",
      "109/194, train_loss: 0.9301\n",
      "110/194, train_loss: 0.7561\n",
      "111/194, train_loss: 0.8432\n",
      "112/194, train_loss: 0.9150\n",
      "113/194, train_loss: 0.8331\n",
      "114/194, train_loss: 0.8027\n",
      "115/194, train_loss: 0.9022\n",
      "116/194, train_loss: 0.7964\n",
      "117/194, train_loss: 0.8833\n",
      "118/194, train_loss: 0.7877\n",
      "119/194, train_loss: 0.6442\n",
      "120/194, train_loss: 0.7720\n",
      "121/194, train_loss: 0.9297\n",
      "122/194, train_loss: 0.8482\n",
      "123/194, train_loss: 0.9279\n",
      "124/194, train_loss: 0.9107\n",
      "125/194, train_loss: 0.8483\n",
      "126/194, train_loss: 0.9173\n",
      "127/194, train_loss: 0.8843\n",
      "128/194, train_loss: 0.8388\n",
      "129/194, train_loss: 0.9061\n",
      "130/194, train_loss: 0.9279\n",
      "131/194, train_loss: 0.7859\n",
      "132/194, train_loss: 0.9045\n",
      "133/194, train_loss: 0.8291\n",
      "134/194, train_loss: 0.8576\n",
      "135/194, train_loss: 0.8065\n",
      "136/194, train_loss: 0.8606\n",
      "137/194, train_loss: 0.9234\n",
      "138/194, train_loss: 0.8869\n",
      "139/194, train_loss: 0.7793\n",
      "140/194, train_loss: 0.9222\n",
      "141/194, train_loss: 0.9610\n",
      "142/194, train_loss: 0.9488\n",
      "143/194, train_loss: 0.9823\n",
      "144/194, train_loss: 0.9123\n",
      "145/194, train_loss: 0.8585\n",
      "146/194, train_loss: 0.8374\n",
      "147/194, train_loss: 0.9124\n",
      "148/194, train_loss: 0.8365\n",
      "149/194, train_loss: 0.9462\n",
      "150/194, train_loss: 0.8627\n",
      "151/194, train_loss: 0.9063\n",
      "152/194, train_loss: 0.8221\n",
      "153/194, train_loss: 0.8777\n",
      "154/194, train_loss: 0.9080\n",
      "155/194, train_loss: 0.9567\n",
      "156/194, train_loss: 0.8093\n",
      "157/194, train_loss: 0.9038\n",
      "158/194, train_loss: 0.8606\n",
      "159/194, train_loss: 0.9337\n",
      "160/194, train_loss: 0.8129\n",
      "161/194, train_loss: 0.8120\n",
      "162/194, train_loss: 0.9025\n",
      "163/194, train_loss: 0.8396\n",
      "164/194, train_loss: 0.8238\n",
      "165/194, train_loss: 0.8398\n",
      "166/194, train_loss: 0.8030\n",
      "167/194, train_loss: 0.7177\n",
      "168/194, train_loss: 0.9364\n",
      "169/194, train_loss: 0.8871\n",
      "170/194, train_loss: 0.8993\n",
      "171/194, train_loss: 0.8262\n",
      "172/194, train_loss: 0.7491\n",
      "173/194, train_loss: 0.8058\n",
      "174/194, train_loss: 0.8386\n",
      "175/194, train_loss: 0.7536\n",
      "176/194, train_loss: 0.7424\n",
      "177/194, train_loss: 0.9237\n",
      "178/194, train_loss: 0.7648\n",
      "179/194, train_loss: 0.9378\n",
      "180/194, train_loss: 0.8271\n",
      "181/194, train_loss: 0.8776\n",
      "182/194, train_loss: 0.7593\n",
      "183/194, train_loss: 0.8485\n",
      "184/194, train_loss: 0.8313\n",
      "185/194, train_loss: 0.9385\n",
      "186/194, train_loss: 0.8765\n",
      "187/194, train_loss: 0.8443\n",
      "188/194, train_loss: 0.9503\n",
      "189/194, train_loss: 0.8563\n",
      "190/194, train_loss: 0.9258\n",
      "191/194, train_loss: 0.9322\n",
      "192/194, train_loss: 0.9373\n",
      "193/194, train_loss: 0.9569\n",
      "194/194, train_loss: 0.9000\n",
      "metric=0.24278892623260617, metric_tc=0.2066973861462126, metric_wt=0.4189010454962651, metric_et=0.10276833999281128\n",
      "metric=0.24278892623260617, metric_tc=0.2066973861462126, metric_wt=0.4189010454962651, metric_et=0.10276833999281128\n",
      "current epoch: 14 current epoch loss: 0.8635\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 14/80 [2:38:17<13:07:35, 715.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metric=0.24278892623260617, metric_tc=0.2066973861462126, metric_wt=0.4189010454962651, metric_et=0.10276833999281128\n",
      "0.24278892623260617\n",
      "saved new best metric model\n",
      "current epoch: 14 current mean dice: 0.2428 tc: 0.2067 wt: 0.4189 et: 0.1028\n",
      "best mean dice: 0.2428 at epoch: 14\n",
      "\n",
      " | Global Training Round : 15 |\n",
      "\n",
      "user 0 selected\n",
      "local epoch 1\n",
      "1/194, train_loss: 0.8236\n",
      "2/194, train_loss: 0.8054\n",
      "3/194, train_loss: 0.8960\n",
      "4/194, train_loss: 0.8299\n",
      "5/194, train_loss: 0.9022\n",
      "6/194, train_loss: 0.9255\n",
      "7/194, train_loss: 0.9365\n",
      "8/194, train_loss: 0.8888\n",
      "9/194, train_loss: 0.8308\n",
      "10/194, train_loss: 0.8871\n",
      "11/194, train_loss: 0.8626\n",
      "12/194, train_loss: 0.8050\n",
      "13/194, train_loss: 0.7727\n",
      "14/194, train_loss: 0.7812\n",
      "15/194, train_loss: 0.8780\n",
      "16/194, train_loss: 0.7819\n",
      "17/194, train_loss: 0.8439\n",
      "18/194, train_loss: 0.8622\n",
      "19/194, train_loss: 0.7876\n",
      "20/194, train_loss: 0.8517\n",
      "21/194, train_loss: 0.8909\n",
      "22/194, train_loss: 0.8610\n",
      "23/194, train_loss: 0.9095\n",
      "24/194, train_loss: 0.8731\n",
      "25/194, train_loss: 0.8675\n",
      "26/194, train_loss: 0.8926\n",
      "27/194, train_loss: 0.8645\n",
      "28/194, train_loss: 0.8182\n",
      "29/194, train_loss: 0.9211\n",
      "30/194, train_loss: 0.9073\n",
      "31/194, train_loss: 0.9257\n",
      "32/194, train_loss: 0.9153\n",
      "33/194, train_loss: 0.7916\n",
      "34/194, train_loss: 0.8858\n",
      "35/194, train_loss: 0.8297\n",
      "36/194, train_loss: 0.8325\n",
      "37/194, train_loss: 0.8440\n",
      "38/194, train_loss: 0.7681\n",
      "39/194, train_loss: 0.9666\n",
      "40/194, train_loss: 0.7493\n",
      "41/194, train_loss: 0.7704\n",
      "42/194, train_loss: 0.7975\n",
      "43/194, train_loss: 0.8990\n",
      "44/194, train_loss: 0.8379\n",
      "45/194, train_loss: 0.8232\n",
      "46/194, train_loss: 0.7716\n",
      "47/194, train_loss: 0.8439\n",
      "48/194, train_loss: 0.7538\n",
      "49/194, train_loss: 0.7744\n",
      "50/194, train_loss: 0.7133\n",
      "51/194, train_loss: 0.8492\n",
      "52/194, train_loss: 0.9293\n",
      "53/194, train_loss: 0.8721\n",
      "54/194, train_loss: 0.9499\n",
      "55/194, train_loss: 0.8650\n",
      "56/194, train_loss: 0.9244\n",
      "57/194, train_loss: 0.9068\n",
      "58/194, train_loss: 0.9804\n",
      "59/194, train_loss: 0.9356\n",
      "60/194, train_loss: 0.8505\n",
      "61/194, train_loss: 0.9451\n",
      "62/194, train_loss: 0.7671\n",
      "63/194, train_loss: 0.8618\n",
      "64/194, train_loss: 0.7347\n",
      "65/194, train_loss: 0.8893\n",
      "66/194, train_loss: 0.8029\n",
      "67/194, train_loss: 0.8933\n",
      "68/194, train_loss: 0.7986\n",
      "69/194, train_loss: 0.9294\n",
      "70/194, train_loss: 0.9024\n",
      "71/194, train_loss: 0.8869\n",
      "72/194, train_loss: 0.8166\n",
      "73/194, train_loss: 0.8820\n",
      "74/194, train_loss: 0.7818\n",
      "75/194, train_loss: 0.8578\n",
      "76/194, train_loss: 0.7542\n",
      "77/194, train_loss: 0.8077\n",
      "78/194, train_loss: 0.8948\n",
      "79/194, train_loss: 0.8008\n",
      "80/194, train_loss: 0.7596\n",
      "81/194, train_loss: 0.8988\n",
      "82/194, train_loss: 0.7859\n",
      "83/194, train_loss: 0.8194\n",
      "84/194, train_loss: 0.8998\n",
      "85/194, train_loss: 0.8530\n",
      "86/194, train_loss: 0.9486\n",
      "87/194, train_loss: 0.9109\n",
      "88/194, train_loss: 0.8437\n",
      "89/194, train_loss: 0.9047\n",
      "90/194, train_loss: 0.8580\n",
      "91/194, train_loss: 0.9026\n",
      "92/194, train_loss: 0.8730\n",
      "93/194, train_loss: 0.7891\n",
      "94/194, train_loss: 0.8028\n",
      "95/194, train_loss: 0.8460\n",
      "96/194, train_loss: 0.8463\n",
      "97/194, train_loss: 0.9135\n",
      "98/194, train_loss: 0.8872\n",
      "99/194, train_loss: 0.9603\n",
      "100/194, train_loss: 0.7461\n",
      "101/194, train_loss: 0.8985\n",
      "102/194, train_loss: 0.8588\n",
      "103/194, train_loss: 0.8005\n",
      "104/194, train_loss: 0.9132\n",
      "105/194, train_loss: 0.8620\n",
      "106/194, train_loss: 0.7304\n",
      "107/194, train_loss: 0.7697\n",
      "108/194, train_loss: 0.8765\n",
      "109/194, train_loss: 0.8783\n",
      "110/194, train_loss: 0.8820\n",
      "111/194, train_loss: 0.7708\n",
      "112/194, train_loss: 0.8132\n",
      "113/194, train_loss: 0.8684\n",
      "114/194, train_loss: 0.8844\n",
      "115/194, train_loss: 0.7810\n",
      "116/194, train_loss: 0.7102\n",
      "117/194, train_loss: 0.8427\n",
      "118/194, train_loss: 0.7466\n",
      "119/194, train_loss: 0.8048\n",
      "120/194, train_loss: 0.8956\n",
      "121/194, train_loss: 0.7945\n",
      "122/194, train_loss: 0.8146\n",
      "123/194, train_loss: 0.9659\n",
      "124/194, train_loss: 0.8067\n",
      "125/194, train_loss: 0.8938\n",
      "126/194, train_loss: 0.8844\n",
      "127/194, train_loss: 0.8996\n",
      "128/194, train_loss: 0.8401\n",
      "129/194, train_loss: 0.8741\n",
      "130/194, train_loss: 0.9346\n",
      "131/194, train_loss: 0.8909\n",
      "132/194, train_loss: 0.8507\n",
      "133/194, train_loss: 0.8660\n",
      "134/194, train_loss: 0.9324\n",
      "135/194, train_loss: 0.8298\n",
      "136/194, train_loss: 0.9269\n",
      "137/194, train_loss: 0.8484\n",
      "138/194, train_loss: 0.8305\n",
      "139/194, train_loss: 0.9181\n",
      "140/194, train_loss: 0.8530\n",
      "141/194, train_loss: 0.9365\n",
      "142/194, train_loss: 0.9847\n",
      "143/194, train_loss: 0.9177\n",
      "144/194, train_loss: 0.9784\n",
      "145/194, train_loss: 0.7963\n",
      "146/194, train_loss: 0.8326\n",
      "147/194, train_loss: 0.9412\n",
      "148/194, train_loss: 0.8886\n",
      "149/194, train_loss: 0.8605\n",
      "150/194, train_loss: 0.8839\n",
      "151/194, train_loss: 0.8817\n",
      "152/194, train_loss: 0.7868\n",
      "153/194, train_loss: 0.8377\n",
      "154/194, train_loss: 0.9193\n",
      "155/194, train_loss: 0.8534\n",
      "156/194, train_loss: 0.9404\n",
      "157/194, train_loss: 0.8682\n",
      "158/194, train_loss: 0.8697\n",
      "159/194, train_loss: 0.8193\n",
      "160/194, train_loss: 0.6554\n",
      "161/194, train_loss: 0.8157\n",
      "162/194, train_loss: 0.8537\n",
      "163/194, train_loss: 0.9082\n",
      "164/194, train_loss: 0.9600\n",
      "165/194, train_loss: 0.8641\n",
      "166/194, train_loss: 0.8561\n",
      "167/194, train_loss: 0.9583\n",
      "168/194, train_loss: 0.8817\n",
      "169/194, train_loss: 0.8483\n",
      "170/194, train_loss: 0.8240\n",
      "171/194, train_loss: 0.8123\n",
      "172/194, train_loss: 0.7781\n",
      "173/194, train_loss: 0.8659\n",
      "174/194, train_loss: 0.8941\n",
      "175/194, train_loss: 0.8452\n",
      "176/194, train_loss: 0.7816\n",
      "177/194, train_loss: 0.8114\n",
      "178/194, train_loss: 0.8449\n",
      "179/194, train_loss: 0.9665\n",
      "180/194, train_loss: 0.9448\n",
      "181/194, train_loss: 0.8567\n",
      "182/194, train_loss: 0.9158\n",
      "183/194, train_loss: 0.7560\n",
      "184/194, train_loss: 0.8984\n",
      "185/194, train_loss: 0.8810\n",
      "186/194, train_loss: 0.9139\n",
      "187/194, train_loss: 0.7590\n",
      "188/194, train_loss: 0.8769\n",
      "189/194, train_loss: 0.8587\n",
      "190/194, train_loss: 0.8283\n",
      "191/194, train_loss: 0.8235\n",
      "192/194, train_loss: 0.9564\n",
      "193/194, train_loss: 0.8192\n",
      "194/194, train_loss: 0.9220\n",
      "metric=0.24924600884939233, metric_tc=0.21350420638918877, metric_wt=0.428073617319266, metric_et=0.1061602004726107\n",
      "metric=0.24924600884939233, metric_tc=0.21350420638918877, metric_wt=0.428073617319266, metric_et=0.1061602004726107\n",
      "current epoch: 15 current epoch loss: 0.8569\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 15/80 [2:50:11<12:54:56, 715.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metric=0.24924600884939233, metric_tc=0.21350420638918877, metric_wt=0.428073617319266, metric_et=0.1061602004726107\n",
      "0.24924600884939233\n",
      "saved new best metric model\n",
      "current epoch: 15 current mean dice: 0.2492 tc: 0.2135 wt: 0.4281 et: 0.1062\n",
      "best mean dice: 0.2492 at epoch: 15\n",
      "\n",
      " | Global Training Round : 16 |\n",
      "\n",
      "user 0 selected\n",
      "local epoch 1\n",
      "1/194, train_loss: 0.8920\n",
      "2/194, train_loss: 0.9086\n",
      "3/194, train_loss: 0.9072\n",
      "4/194, train_loss: 0.8825\n",
      "5/194, train_loss: 0.8447\n",
      "6/194, train_loss: 0.8546\n",
      "7/194, train_loss: 0.8899\n",
      "8/194, train_loss: 0.7765\n",
      "9/194, train_loss: 0.7606\n",
      "10/194, train_loss: 0.8251\n",
      "11/194, train_loss: 0.9323\n",
      "12/194, train_loss: 0.7672\n",
      "13/194, train_loss: 0.8946\n",
      "14/194, train_loss: 0.9096\n",
      "15/194, train_loss: 0.8550\n",
      "16/194, train_loss: 0.7917\n",
      "17/194, train_loss: 0.8880\n",
      "18/194, train_loss: 0.8720\n",
      "19/194, train_loss: 0.7394\n",
      "20/194, train_loss: 0.8407\n",
      "21/194, train_loss: 0.8476\n",
      "22/194, train_loss: 0.8516\n",
      "23/194, train_loss: 0.9495\n",
      "24/194, train_loss: 0.7856\n",
      "25/194, train_loss: 0.8011\n",
      "26/194, train_loss: 0.8294\n",
      "27/194, train_loss: 0.9477\n",
      "28/194, train_loss: 0.8770\n",
      "29/194, train_loss: 0.7904\n",
      "30/194, train_loss: 0.7699\n",
      "31/194, train_loss: 0.9302\n",
      "32/194, train_loss: 0.8008\n",
      "33/194, train_loss: 0.8218\n",
      "34/194, train_loss: 0.7412\n",
      "35/194, train_loss: 0.7886\n",
      "36/194, train_loss: 0.7471\n",
      "37/194, train_loss: 0.8617\n",
      "38/194, train_loss: 0.7102\n",
      "39/194, train_loss: 0.8416\n",
      "40/194, train_loss: 0.7243\n",
      "41/194, train_loss: 0.8363\n",
      "42/194, train_loss: 0.8718\n",
      "43/194, train_loss: 0.9005\n",
      "44/194, train_loss: 0.8476\n",
      "45/194, train_loss: 0.7670\n",
      "46/194, train_loss: 0.9160\n",
      "47/194, train_loss: 0.7706\n",
      "48/194, train_loss: 0.8060\n",
      "49/194, train_loss: 0.8217\n",
      "50/194, train_loss: 0.9582\n",
      "51/194, train_loss: 0.8816\n",
      "52/194, train_loss: 0.6671\n",
      "53/194, train_loss: 0.9097\n",
      "54/194, train_loss: 0.8811\n",
      "55/194, train_loss: 0.8564\n",
      "56/194, train_loss: 0.9141\n",
      "57/194, train_loss: 0.8743\n",
      "58/194, train_loss: 0.8576\n",
      "59/194, train_loss: 0.9348\n",
      "60/194, train_loss: 0.9415\n",
      "61/194, train_loss: 0.8437\n",
      "62/194, train_loss: 0.9227\n",
      "63/194, train_loss: 0.8563\n",
      "64/194, train_loss: 0.9078\n",
      "65/194, train_loss: 0.8605\n",
      "66/194, train_loss: 0.8681\n",
      "67/194, train_loss: 0.8446\n",
      "68/194, train_loss: 0.7479\n",
      "69/194, train_loss: 0.8487\n",
      "70/194, train_loss: 0.9004\n",
      "71/194, train_loss: 0.9092\n",
      "72/194, train_loss: 0.8081\n",
      "73/194, train_loss: 0.8073\n",
      "74/194, train_loss: 0.7708\n",
      "75/194, train_loss: 0.8225\n",
      "76/194, train_loss: 0.8752\n",
      "77/194, train_loss: 0.8489\n",
      "78/194, train_loss: 0.7391\n",
      "79/194, train_loss: 0.8820\n",
      "80/194, train_loss: 0.7466\n",
      "81/194, train_loss: 0.8711\n",
      "82/194, train_loss: 0.8078\n",
      "83/194, train_loss: 0.9025\n",
      "84/194, train_loss: 0.9029\n",
      "85/194, train_loss: 0.9113\n",
      "86/194, train_loss: 0.8984\n",
      "87/194, train_loss: 0.8901\n",
      "88/194, train_loss: 0.8396\n",
      "89/194, train_loss: 0.8756\n",
      "90/194, train_loss: 0.8879\n",
      "91/194, train_loss: 0.8111\n",
      "92/194, train_loss: 0.9137\n",
      "93/194, train_loss: 0.7599\n",
      "94/194, train_loss: 0.7330\n",
      "95/194, train_loss: 0.7671\n",
      "96/194, train_loss: 0.8015\n",
      "97/194, train_loss: 0.9003\n",
      "98/194, train_loss: 0.9432\n",
      "99/194, train_loss: 0.8505\n",
      "100/194, train_loss: 0.8980\n",
      "101/194, train_loss: 0.9181\n",
      "102/194, train_loss: 0.8997\n",
      "103/194, train_loss: 0.9590\n",
      "104/194, train_loss: 0.9534\n",
      "105/194, train_loss: 0.8672\n",
      "106/194, train_loss: 0.7718\n",
      "107/194, train_loss: 0.7495\n",
      "108/194, train_loss: 0.8532\n",
      "109/194, train_loss: 0.7453\n",
      "110/194, train_loss: 0.8671\n",
      "111/194, train_loss: 0.8893\n",
      "112/194, train_loss: 0.8371\n",
      "113/194, train_loss: 0.9273\n",
      "114/194, train_loss: 0.8677\n",
      "115/194, train_loss: 0.7700\n",
      "116/194, train_loss: 0.8271\n",
      "117/194, train_loss: 0.8623\n",
      "118/194, train_loss: 0.7889\n",
      "119/194, train_loss: 0.9562\n",
      "120/194, train_loss: 0.8887\n",
      "121/194, train_loss: 0.8826\n",
      "122/194, train_loss: 0.9542\n",
      "123/194, train_loss: 0.8817\n",
      "124/194, train_loss: 0.8913\n",
      "125/194, train_loss: 0.9284\n",
      "126/194, train_loss: 0.8871\n",
      "127/194, train_loss: 0.8531\n",
      "128/194, train_loss: 0.8883\n",
      "129/194, train_loss: 0.8746\n",
      "130/194, train_loss: 0.7232\n",
      "131/194, train_loss: 0.8477\n",
      "132/194, train_loss: 0.8315\n",
      "133/194, train_loss: 0.8665\n",
      "134/194, train_loss: 0.8348\n",
      "135/194, train_loss: 0.8140\n",
      "136/194, train_loss: 0.9276\n",
      "137/194, train_loss: 0.8731\n",
      "138/194, train_loss: 0.8502\n",
      "139/194, train_loss: 0.8311\n",
      "140/194, train_loss: 0.7336\n",
      "141/194, train_loss: 0.7569\n",
      "142/194, train_loss: 0.9874\n",
      "143/194, train_loss: 0.9190\n",
      "144/194, train_loss: 0.8609\n",
      "145/194, train_loss: 0.8900\n",
      "146/194, train_loss: 0.8489\n",
      "147/194, train_loss: 0.8599\n",
      "148/194, train_loss: 0.8882\n",
      "149/194, train_loss: 0.8734\n",
      "150/194, train_loss: 0.8428\n",
      "151/194, train_loss: 0.9016\n",
      "152/194, train_loss: 0.9008\n",
      "153/194, train_loss: 0.9050\n",
      "154/194, train_loss: 0.8814\n",
      "155/194, train_loss: 0.9555\n",
      "156/194, train_loss: 0.9462\n",
      "157/194, train_loss: 0.8604\n",
      "158/194, train_loss: 0.9405\n",
      "159/194, train_loss: 0.8643\n",
      "160/194, train_loss: 0.8592\n",
      "161/194, train_loss: 0.8912\n",
      "162/194, train_loss: 0.7899\n",
      "163/194, train_loss: 0.7868\n",
      "164/194, train_loss: 0.8484\n",
      "165/194, train_loss: 0.8630\n",
      "166/194, train_loss: 0.8127\n",
      "167/194, train_loss: 0.8004\n",
      "168/194, train_loss: 0.8776\n",
      "169/194, train_loss: 0.8346\n",
      "170/194, train_loss: 0.8409\n",
      "171/194, train_loss: 0.7572\n",
      "172/194, train_loss: 0.9097\n",
      "173/194, train_loss: 0.8230\n",
      "174/194, train_loss: 0.6971\n",
      "175/194, train_loss: 0.7262\n",
      "176/194, train_loss: 0.8960\n",
      "177/194, train_loss: 0.9181\n",
      "178/194, train_loss: 0.9086\n",
      "179/194, train_loss: 0.8279\n",
      "180/194, train_loss: 0.9589\n",
      "181/194, train_loss: 0.7950\n",
      "182/194, train_loss: 0.8719\n",
      "183/194, train_loss: 0.7575\n",
      "184/194, train_loss: 0.7897\n",
      "185/194, train_loss: 0.9691\n",
      "186/194, train_loss: 0.7997\n",
      "187/194, train_loss: 0.9079\n",
      "188/194, train_loss: 0.8334\n",
      "189/194, train_loss: 0.8367\n",
      "190/194, train_loss: 0.8905\n",
      "191/194, train_loss: 0.9050\n",
      "192/194, train_loss: 0.8645\n",
      "193/194, train_loss: 0.7425\n",
      "194/194, train_loss: 0.7708\n",
      "metric=0.24814198926712075, metric_tc=0.21808789872253934, metric_wt=0.41659082161883515, metric_et=0.10974723721543948\n",
      "metric=0.24814198926712075, metric_tc=0.21808789872253934, metric_wt=0.41659082161883515, metric_et=0.10974723721543948\n",
      "current epoch: 16 current epoch loss: 0.8518\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 16/80 [3:01:08<12:24:20, 697.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metric=0.24814198926712075, metric_tc=0.21808789872253934, metric_wt=0.41659082161883515, metric_et=0.10974723721543948\n",
      "0.24814198926712075\n",
      "current epoch: 16 current mean dice: 0.2481 tc: 0.2181 wt: 0.4166 et: 0.1097\n",
      "best mean dice: 0.2492 at epoch: 15\n",
      "\n",
      " | Global Training Round : 17 |\n",
      "\n",
      "user 0 selected\n",
      "local epoch 1\n",
      "1/194, train_loss: 0.9263\n",
      "2/194, train_loss: 0.7639\n",
      "3/194, train_loss: 0.7520\n",
      "4/194, train_loss: 0.8471\n",
      "5/194, train_loss: 0.9268\n",
      "6/194, train_loss: 0.9198\n",
      "7/194, train_loss: 0.8540\n",
      "8/194, train_loss: 0.8061\n",
      "9/194, train_loss: 0.8469\n",
      "10/194, train_loss: 0.7187\n",
      "11/194, train_loss: 0.8826\n",
      "12/194, train_loss: 0.8399\n",
      "13/194, train_loss: 0.6433\n",
      "14/194, train_loss: 0.7145\n",
      "15/194, train_loss: 0.7378\n",
      "16/194, train_loss: 0.7534\n",
      "17/194, train_loss: 0.7976\n",
      "18/194, train_loss: 0.7845\n",
      "19/194, train_loss: 0.7968\n",
      "20/194, train_loss: 0.8017\n",
      "21/194, train_loss: 0.8963\n",
      "22/194, train_loss: 0.8355\n",
      "23/194, train_loss: 0.7882\n",
      "24/194, train_loss: 0.8787\n",
      "25/194, train_loss: 0.8887\n",
      "26/194, train_loss: 0.9276\n",
      "27/194, train_loss: 0.8896\n",
      "28/194, train_loss: 0.9076\n",
      "29/194, train_loss: 0.9036\n",
      "30/194, train_loss: 0.8301\n",
      "31/194, train_loss: 0.8752\n",
      "32/194, train_loss: 0.7145\n",
      "33/194, train_loss: 0.8341\n",
      "34/194, train_loss: 0.8377\n",
      "35/194, train_loss: 0.7754\n",
      "36/194, train_loss: 0.8633\n",
      "37/194, train_loss: 0.8226\n",
      "38/194, train_loss: 0.8181\n",
      "39/194, train_loss: 0.9259\n",
      "40/194, train_loss: 0.8013\n",
      "41/194, train_loss: 0.7612\n",
      "42/194, train_loss: 0.7886\n",
      "43/194, train_loss: 0.9288\n",
      "44/194, train_loss: 0.7758\n",
      "45/194, train_loss: 0.8805\n",
      "46/194, train_loss: 0.8110\n",
      "47/194, train_loss: 0.8620\n",
      "48/194, train_loss: 0.7988\n",
      "49/194, train_loss: 0.8538\n",
      "50/194, train_loss: 0.8221\n",
      "51/194, train_loss: 0.8179\n",
      "52/194, train_loss: 0.8685\n",
      "53/194, train_loss: 0.8594\n",
      "54/194, train_loss: 0.8694\n",
      "55/194, train_loss: 0.8593\n",
      "56/194, train_loss: 0.8441\n",
      "57/194, train_loss: 0.8660\n",
      "58/194, train_loss: 0.9505\n",
      "59/194, train_loss: 0.8334\n",
      "60/194, train_loss: 0.9455\n",
      "61/194, train_loss: 0.7709\n",
      "62/194, train_loss: 0.8036\n",
      "63/194, train_loss: 0.8217\n",
      "64/194, train_loss: 0.8797\n",
      "65/194, train_loss: 0.9770\n",
      "66/194, train_loss: 0.8131\n",
      "67/194, train_loss: 0.8869\n",
      "68/194, train_loss: 0.8289\n",
      "69/194, train_loss: 0.8189\n",
      "70/194, train_loss: 0.9481\n",
      "71/194, train_loss: 0.9475\n",
      "72/194, train_loss: 0.9207\n",
      "73/194, train_loss: 0.6312\n",
      "74/194, train_loss: 0.9302\n",
      "75/194, train_loss: 0.9109\n",
      "76/194, train_loss: 0.8698\n",
      "77/194, train_loss: 0.8311\n",
      "78/194, train_loss: 0.7923\n",
      "79/194, train_loss: 0.7057\n",
      "80/194, train_loss: 0.8864\n",
      "81/194, train_loss: 0.9251\n",
      "82/194, train_loss: 0.7696\n",
      "83/194, train_loss: 0.8491\n",
      "84/194, train_loss: 0.7892\n",
      "85/194, train_loss: 0.9661\n",
      "86/194, train_loss: 0.8459\n",
      "87/194, train_loss: 0.9152\n",
      "88/194, train_loss: 0.9074\n",
      "89/194, train_loss: 0.9729\n",
      "90/194, train_loss: 0.8132\n",
      "91/194, train_loss: 0.8729\n",
      "92/194, train_loss: 0.8904\n",
      "93/194, train_loss: 0.7690\n",
      "94/194, train_loss: 0.7913\n",
      "95/194, train_loss: 0.8046\n",
      "96/194, train_loss: 0.7979\n",
      "97/194, train_loss: 0.8566\n",
      "98/194, train_loss: 0.9089\n",
      "99/194, train_loss: 0.7101\n",
      "100/194, train_loss: 0.9185\n",
      "101/194, train_loss: 0.8181\n",
      "102/194, train_loss: 0.8953\n",
      "103/194, train_loss: 0.9002\n",
      "104/194, train_loss: 0.8749\n",
      "105/194, train_loss: 0.9311\n",
      "106/194, train_loss: 0.8337\n",
      "107/194, train_loss: 0.7852\n",
      "108/194, train_loss: 0.8929\n",
      "109/194, train_loss: 0.8690\n",
      "110/194, train_loss: 0.9054\n",
      "111/194, train_loss: 0.9406\n",
      "112/194, train_loss: 0.7944\n",
      "113/194, train_loss: 0.7629\n",
      "114/194, train_loss: 0.7733\n",
      "115/194, train_loss: 0.9403\n",
      "116/194, train_loss: 0.9382\n",
      "117/194, train_loss: 0.9091\n",
      "118/194, train_loss: 0.8792\n",
      "119/194, train_loss: 0.7291\n",
      "120/194, train_loss: 0.8949\n",
      "121/194, train_loss: 0.9674\n",
      "122/194, train_loss: 0.8082\n",
      "123/194, train_loss: 0.8763\n",
      "124/194, train_loss: 0.9068\n",
      "125/194, train_loss: 0.8861\n",
      "126/194, train_loss: 0.7788\n",
      "127/194, train_loss: 0.9430\n",
      "128/194, train_loss: 0.8713\n",
      "129/194, train_loss: 0.7806\n",
      "130/194, train_loss: 0.7288\n",
      "131/194, train_loss: 0.8856\n",
      "132/194, train_loss: 0.7924\n",
      "133/194, train_loss: 0.9276\n",
      "134/194, train_loss: 0.8844\n",
      "135/194, train_loss: 0.8463\n",
      "136/194, train_loss: 0.7811\n",
      "137/194, train_loss: 0.9018\n",
      "138/194, train_loss: 0.8730\n",
      "139/194, train_loss: 0.7924\n",
      "140/194, train_loss: 0.8138\n",
      "141/194, train_loss: 0.8696\n",
      "142/194, train_loss: 0.9594\n",
      "143/194, train_loss: 0.9394\n",
      "144/194, train_loss: 0.9943\n",
      "145/194, train_loss: 0.8786\n",
      "146/194, train_loss: 0.9501\n",
      "147/194, train_loss: 0.8777\n",
      "148/194, train_loss: 0.9410\n",
      "149/194, train_loss: 0.8925\n",
      "150/194, train_loss: 0.9701\n",
      "151/194, train_loss: 0.8826\n",
      "152/194, train_loss: 0.8583\n",
      "153/194, train_loss: 0.9771\n",
      "154/194, train_loss: 0.8269\n",
      "155/194, train_loss: 0.9519\n",
      "156/194, train_loss: 0.8558\n",
      "157/194, train_loss: 0.8427\n",
      "158/194, train_loss: 0.8248\n",
      "159/194, train_loss: 0.8609\n",
      "160/194, train_loss: 0.8554\n",
      "161/194, train_loss: 0.8646\n",
      "162/194, train_loss: 0.8229\n",
      "163/194, train_loss: 0.9032\n",
      "164/194, train_loss: 0.9223\n",
      "165/194, train_loss: 0.8688\n",
      "166/194, train_loss: 0.8487\n",
      "167/194, train_loss: 0.8061\n",
      "168/194, train_loss: 0.7779\n",
      "169/194, train_loss: 0.7840\n",
      "170/194, train_loss: 0.8047\n",
      "171/194, train_loss: 0.7811\n",
      "172/194, train_loss: 0.8515\n",
      "173/194, train_loss: 0.7385\n",
      "174/194, train_loss: 0.8177\n",
      "175/194, train_loss: 0.7837\n",
      "176/194, train_loss: 0.7591\n",
      "177/194, train_loss: 0.8218\n",
      "178/194, train_loss: 0.9050\n",
      "179/194, train_loss: 0.8971\n",
      "180/194, train_loss: 0.8101\n",
      "181/194, train_loss: 0.8217\n",
      "182/194, train_loss: 0.8913\n",
      "183/194, train_loss: 0.9186\n",
      "184/194, train_loss: 0.7752\n",
      "185/194, train_loss: 0.8439\n",
      "186/194, train_loss: 0.9082\n",
      "187/194, train_loss: 0.8659\n",
      "188/194, train_loss: 0.8617\n",
      "189/194, train_loss: 0.8231\n",
      "190/194, train_loss: 0.7620\n",
      "191/194, train_loss: 0.8620\n",
      "192/194, train_loss: 0.8765\n",
      "193/194, train_loss: 0.8788\n",
      "194/194, train_loss: 0.7098\n",
      "metric=0.25518839930494625, metric_tc=0.22750725550577044, metric_wt=0.4235943102588256, metric_et=0.11446363081146653\n",
      "metric=0.25518839930494625, metric_tc=0.22750725550577044, metric_wt=0.4235943102588256, metric_et=0.11446363081146653\n",
      "current epoch: 17 current epoch loss: 0.8498\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██▏       | 17/80 [3:11:59<11:57:55, 683.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metric=0.25518839930494625, metric_tc=0.22750725550577044, metric_wt=0.4235943102588256, metric_et=0.11446363081146653\n",
      "0.25518839930494625\n",
      "saved new best metric model\n",
      "current epoch: 17 current mean dice: 0.2552 tc: 0.2275 wt: 0.4236 et: 0.1145\n",
      "best mean dice: 0.2552 at epoch: 17\n",
      "\n",
      " | Global Training Round : 18 |\n",
      "\n",
      "user 0 selected\n",
      "local epoch 1\n",
      "1/194, train_loss: 0.7831\n",
      "2/194, train_loss: 0.7273\n",
      "3/194, train_loss: 0.7989\n",
      "4/194, train_loss: 0.8168\n",
      "5/194, train_loss: 0.8939\n",
      "6/194, train_loss: 0.8786\n",
      "7/194, train_loss: 0.7363\n",
      "8/194, train_loss: 0.8543\n",
      "9/194, train_loss: 0.9111\n",
      "10/194, train_loss: 0.7904\n",
      "11/194, train_loss: 0.7928\n",
      "12/194, train_loss: 0.8932\n",
      "13/194, train_loss: 0.8255\n",
      "14/194, train_loss: 0.7605\n",
      "15/194, train_loss: 0.7324\n",
      "16/194, train_loss: 0.8831\n",
      "17/194, train_loss: 0.7632\n",
      "18/194, train_loss: 0.8203\n",
      "19/194, train_loss: 0.7550\n",
      "20/194, train_loss: 0.7437\n",
      "21/194, train_loss: 0.7271\n",
      "22/194, train_loss: 0.8145\n",
      "23/194, train_loss: 0.6668\n",
      "24/194, train_loss: 0.8346\n",
      "25/194, train_loss: 0.8916\n",
      "26/194, train_loss: 0.8263\n",
      "27/194, train_loss: 0.8196\n",
      "28/194, train_loss: 0.7117\n",
      "29/194, train_loss: 0.9758\n",
      "30/194, train_loss: 0.8269\n",
      "31/194, train_loss: 0.8296\n",
      "32/194, train_loss: 0.7507\n",
      "33/194, train_loss: 0.8027\n",
      "34/194, train_loss: 0.8261\n",
      "35/194, train_loss: 0.9387\n",
      "36/194, train_loss: 0.7914\n",
      "37/194, train_loss: 0.7349\n",
      "38/194, train_loss: 0.8503\n",
      "39/194, train_loss: 0.9420\n",
      "40/194, train_loss: 0.8640\n",
      "41/194, train_loss: 0.7988\n",
      "42/194, train_loss: 0.9088\n",
      "43/194, train_loss: 0.8990\n",
      "44/194, train_loss: 0.8981\n",
      "45/194, train_loss: 0.8513\n",
      "46/194, train_loss: 0.8232\n",
      "47/194, train_loss: 0.6933\n",
      "48/194, train_loss: 0.8421\n",
      "49/194, train_loss: 0.7419\n",
      "50/194, train_loss: 0.8245\n",
      "51/194, train_loss: 0.8549\n",
      "52/194, train_loss: 0.7999\n",
      "53/194, train_loss: 0.9418\n",
      "54/194, train_loss: 0.8701\n",
      "55/194, train_loss: 0.9315\n",
      "56/194, train_loss: 0.8766\n",
      "57/194, train_loss: 0.8255\n",
      "58/194, train_loss: 0.8544\n",
      "59/194, train_loss: 0.9006\n",
      "60/194, train_loss: 0.8390\n",
      "61/194, train_loss: 0.8436\n",
      "62/194, train_loss: 0.7862\n",
      "63/194, train_loss: 0.7708\n",
      "64/194, train_loss: 0.6963\n",
      "65/194, train_loss: 0.7707\n",
      "66/194, train_loss: 0.8144\n",
      "67/194, train_loss: 0.8349\n",
      "68/194, train_loss: 0.8611\n",
      "69/194, train_loss: 0.8451\n",
      "70/194, train_loss: 0.8179\n",
      "71/194, train_loss: 0.7665\n",
      "72/194, train_loss: 0.7617\n",
      "73/194, train_loss: 0.8086\n",
      "74/194, train_loss: 0.8111\n",
      "75/194, train_loss: 0.7957\n",
      "76/194, train_loss: 0.7031\n",
      "77/194, train_loss: 0.8359\n",
      "78/194, train_loss: 0.8787\n",
      "79/194, train_loss: 0.8385\n",
      "80/194, train_loss: 0.8434\n",
      "81/194, train_loss: 0.9496\n",
      "82/194, train_loss: 0.7132\n",
      "83/194, train_loss: 0.8935\n",
      "84/194, train_loss: 0.8718\n",
      "85/194, train_loss: 0.8711\n",
      "86/194, train_loss: 0.9110\n",
      "87/194, train_loss: 0.8257\n",
      "88/194, train_loss: 0.8373\n",
      "89/194, train_loss: 0.8561\n",
      "90/194, train_loss: 0.8054\n",
      "91/194, train_loss: 0.8512\n",
      "92/194, train_loss: 0.8041\n",
      "93/194, train_loss: 0.8321\n",
      "94/194, train_loss: 0.8044\n",
      "95/194, train_loss: 0.8239\n",
      "96/194, train_loss: 0.8843\n",
      "97/194, train_loss: 0.9296\n",
      "98/194, train_loss: 0.8469\n",
      "99/194, train_loss: 0.9197\n",
      "100/194, train_loss: 0.7943\n",
      "101/194, train_loss: 0.8764\n",
      "102/194, train_loss: 0.8678\n",
      "103/194, train_loss: 0.9423\n",
      "104/194, train_loss: 0.8831\n",
      "105/194, train_loss: 0.8087\n",
      "106/194, train_loss: 0.8522\n",
      "107/194, train_loss: 0.9653\n",
      "108/194, train_loss: 0.9268\n",
      "109/194, train_loss: 0.8193\n",
      "110/194, train_loss: 0.7982\n",
      "111/194, train_loss: 0.6964\n",
      "112/194, train_loss: 0.9215\n",
      "113/194, train_loss: 0.8283\n",
      "114/194, train_loss: 0.8757\n",
      "115/194, train_loss: 0.9293\n",
      "116/194, train_loss: 0.8390\n",
      "117/194, train_loss: 0.7943\n",
      "118/194, train_loss: 0.7936\n",
      "119/194, train_loss: 0.7985\n",
      "120/194, train_loss: 0.8763\n",
      "121/194, train_loss: 0.8929\n",
      "122/194, train_loss: 0.8977\n",
      "123/194, train_loss: 0.9015\n",
      "124/194, train_loss: 0.9083\n",
      "125/194, train_loss: 0.8810\n",
      "126/194, train_loss: 0.9302\n",
      "127/194, train_loss: 0.8272\n",
      "128/194, train_loss: 0.8648\n",
      "129/194, train_loss: 0.9205\n",
      "130/194, train_loss: 0.8333\n",
      "131/194, train_loss: 0.9019\n",
      "132/194, train_loss: 0.8250\n",
      "133/194, train_loss: 0.8036\n",
      "134/194, train_loss: 0.7455\n",
      "135/194, train_loss: 0.7463\n",
      "136/194, train_loss: 0.8770\n",
      "137/194, train_loss: 0.8100\n",
      "138/194, train_loss: 0.8869\n",
      "139/194, train_loss: 0.8518\n",
      "140/194, train_loss: 0.8808\n",
      "141/194, train_loss: 0.8068\n",
      "142/194, train_loss: 0.9596\n",
      "143/194, train_loss: 0.9749\n",
      "144/194, train_loss: 0.9244\n",
      "145/194, train_loss: 0.8718\n",
      "146/194, train_loss: 0.9449\n",
      "147/194, train_loss: 0.8474\n",
      "148/194, train_loss: 0.9222\n",
      "149/194, train_loss: 0.8328\n",
      "150/194, train_loss: 0.8684\n",
      "151/194, train_loss: 0.7885\n",
      "152/194, train_loss: 0.8502\n",
      "153/194, train_loss: 0.9483\n",
      "154/194, train_loss: 0.9494\n",
      "155/194, train_loss: 0.9704\n",
      "156/194, train_loss: 0.8465\n",
      "157/194, train_loss: 0.9208\n",
      "158/194, train_loss: 0.8197\n",
      "159/194, train_loss: 0.9465\n",
      "160/194, train_loss: 0.9204\n",
      "161/194, train_loss: 0.8307\n",
      "162/194, train_loss: 0.8520\n",
      "163/194, train_loss: 0.8786\n",
      "164/194, train_loss: 0.9317\n",
      "165/194, train_loss: 0.7939\n",
      "166/194, train_loss: 0.8351\n",
      "167/194, train_loss: 0.8324\n",
      "168/194, train_loss: 0.7872\n",
      "169/194, train_loss: 0.8387\n",
      "170/194, train_loss: 0.8439\n",
      "171/194, train_loss: 0.7719\n",
      "172/194, train_loss: 0.8515\n",
      "173/194, train_loss: 0.9633\n",
      "174/194, train_loss: 0.8886\n",
      "175/194, train_loss: 0.9661\n",
      "176/194, train_loss: 0.7085\n",
      "177/194, train_loss: 0.7925\n",
      "178/194, train_loss: 0.9680\n",
      "179/194, train_loss: 0.9436\n",
      "180/194, train_loss: 0.9580\n",
      "181/194, train_loss: 0.9126\n",
      "182/194, train_loss: 0.7998\n",
      "183/194, train_loss: 0.7523\n",
      "184/194, train_loss: 0.6130\n",
      "185/194, train_loss: 0.8227\n",
      "186/194, train_loss: 0.9538\n",
      "187/194, train_loss: 0.8356\n",
      "188/194, train_loss: 0.8601\n",
      "189/194, train_loss: 0.8391\n",
      "190/194, train_loss: 0.8781\n",
      "191/194, train_loss: 0.9000\n",
      "192/194, train_loss: 0.9768\n",
      "193/194, train_loss: 0.8407\n",
      "194/194, train_loss: 0.8118\n",
      "metric=0.2644118595247467, metric_tc=0.2379435890664657, metric_wt=0.4344835088898738, metric_et=0.12080848154922326\n",
      "metric=0.2644118595247467, metric_tc=0.2379435890664657, metric_wt=0.4344835088898738, metric_et=0.12080848154922326\n",
      "current epoch: 18 current epoch loss: 0.8448\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▎       | 18/80 [3:22:34<11:31:24, 669.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metric=0.2644118595247467, metric_tc=0.2379435890664657, metric_wt=0.4344835088898738, metric_et=0.12080848154922326\n",
      "0.2644118595247467\n",
      "saved new best metric model\n",
      "current epoch: 18 current mean dice: 0.2644 tc: 0.2379 wt: 0.4345 et: 0.1208\n",
      "best mean dice: 0.2644 at epoch: 18\n",
      "\n",
      " | Global Training Round : 19 |\n",
      "\n",
      "user 0 selected\n",
      "local epoch 1\n",
      "1/194, train_loss: 0.7086\n",
      "2/194, train_loss: 0.8230\n",
      "3/194, train_loss: 0.8308\n",
      "4/194, train_loss: 0.9301\n",
      "5/194, train_loss: 0.7585\n",
      "6/194, train_loss: 0.8283\n",
      "7/194, train_loss: 0.8866\n",
      "8/194, train_loss: 0.8601\n",
      "9/194, train_loss: 0.8762\n",
      "10/194, train_loss: 0.8277\n",
      "11/194, train_loss: 0.8041\n",
      "12/194, train_loss: 0.9246\n",
      "13/194, train_loss: 0.8952\n",
      "14/194, train_loss: 0.7826\n",
      "15/194, train_loss: 0.7434\n",
      "16/194, train_loss: 0.7391\n",
      "17/194, train_loss: 0.8383\n",
      "18/194, train_loss: 0.7673\n",
      "19/194, train_loss: 0.7701\n",
      "20/194, train_loss: 0.8273\n",
      "21/194, train_loss: 0.8393\n",
      "22/194, train_loss: 0.7284\n",
      "23/194, train_loss: 0.8152\n",
      "24/194, train_loss: 0.8429\n",
      "25/194, train_loss: 0.7579\n",
      "26/194, train_loss: 0.7724\n",
      "27/194, train_loss: 0.9271\n",
      "28/194, train_loss: 0.9023\n",
      "29/194, train_loss: 0.9017\n",
      "30/194, train_loss: 0.9157\n",
      "31/194, train_loss: 0.8071\n",
      "32/194, train_loss: 0.8751\n",
      "33/194, train_loss: 0.8763\n",
      "34/194, train_loss: 0.7656\n",
      "35/194, train_loss: 0.8848\n",
      "36/194, train_loss: 0.7646\n",
      "37/194, train_loss: 0.8976\n",
      "38/194, train_loss: 0.8430\n",
      "39/194, train_loss: 0.8945\n",
      "40/194, train_loss: 0.7253\n",
      "41/194, train_loss: 0.7648\n",
      "42/194, train_loss: 0.9696\n",
      "43/194, train_loss: 0.8507\n",
      "44/194, train_loss: 0.8692\n",
      "45/194, train_loss: 0.8376\n",
      "46/194, train_loss: 0.8208\n",
      "47/194, train_loss: 0.7048\n",
      "48/194, train_loss: 0.6494\n",
      "49/194, train_loss: 0.7503\n",
      "50/194, train_loss: 0.8038\n",
      "51/194, train_loss: 0.8858\n",
      "52/194, train_loss: 0.8432\n",
      "53/194, train_loss: 0.8263\n",
      "54/194, train_loss: 0.9193\n",
      "55/194, train_loss: 0.8664\n",
      "56/194, train_loss: 0.8250\n",
      "57/194, train_loss: 0.8768\n",
      "58/194, train_loss: 0.8067\n",
      "59/194, train_loss: 0.9207\n",
      "60/194, train_loss: 0.8373\n",
      "61/194, train_loss: 0.7723\n",
      "62/194, train_loss: 0.8194\n",
      "63/194, train_loss: 0.9485\n",
      "64/194, train_loss: 0.8631\n",
      "65/194, train_loss: 0.8243\n",
      "66/194, train_loss: 0.8890\n",
      "67/194, train_loss: 0.8004\n",
      "68/194, train_loss: 0.9137\n",
      "69/194, train_loss: 0.8120\n",
      "70/194, train_loss: 0.8071\n",
      "71/194, train_loss: 0.7922\n",
      "72/194, train_loss: 0.8767\n",
      "73/194, train_loss: 0.7979\n",
      "74/194, train_loss: 0.8451\n",
      "75/194, train_loss: 0.8378\n",
      "76/194, train_loss: 0.7995\n",
      "77/194, train_loss: 0.8834\n",
      "78/194, train_loss: 0.9158\n",
      "79/194, train_loss: 0.8292\n",
      "80/194, train_loss: 0.7967\n",
      "81/194, train_loss: 0.8388\n",
      "82/194, train_loss: 0.9037\n",
      "83/194, train_loss: 0.8151\n",
      "84/194, train_loss: 0.8488\n",
      "85/194, train_loss: 0.8602\n",
      "86/194, train_loss: 0.8662\n",
      "87/194, train_loss: 0.8229\n",
      "88/194, train_loss: 0.9202\n",
      "89/194, train_loss: 0.8192\n",
      "90/194, train_loss: 0.8894\n",
      "91/194, train_loss: 0.9597\n",
      "92/194, train_loss: 0.8549\n",
      "93/194, train_loss: 0.8451\n",
      "94/194, train_loss: 0.8060\n",
      "95/194, train_loss: 0.8810\n",
      "96/194, train_loss: 0.9033\n",
      "97/194, train_loss: 0.8625\n",
      "98/194, train_loss: 0.8933\n",
      "99/194, train_loss: 0.8090\n",
      "100/194, train_loss: 0.8282\n",
      "101/194, train_loss: 0.8548\n",
      "102/194, train_loss: 0.9006\n",
      "103/194, train_loss: 0.8740\n",
      "104/194, train_loss: 0.8449\n",
      "105/194, train_loss: 0.8878\n",
      "106/194, train_loss: 0.8500\n",
      "107/194, train_loss: 0.9168\n",
      "108/194, train_loss: 0.9581\n",
      "109/194, train_loss: 0.8910\n",
      "110/194, train_loss: 0.6966\n",
      "111/194, train_loss: 0.8668\n",
      "112/194, train_loss: 0.7328\n",
      "113/194, train_loss: 0.8521\n",
      "114/194, train_loss: 0.9327\n",
      "115/194, train_loss: 0.8677\n",
      "116/194, train_loss: 0.8393\n",
      "117/194, train_loss: 0.9304\n",
      "118/194, train_loss: 0.7812\n",
      "119/194, train_loss: 0.8292\n",
      "120/194, train_loss: 0.6700\n",
      "121/194, train_loss: 0.9201\n",
      "122/194, train_loss: 0.8436\n",
      "123/194, train_loss: 0.8032\n",
      "124/194, train_loss: 0.9040\n",
      "125/194, train_loss: 0.8043\n",
      "126/194, train_loss: 0.8409\n",
      "127/194, train_loss: 0.8026\n",
      "128/194, train_loss: 0.8829\n",
      "129/194, train_loss: 0.9113\n",
      "130/194, train_loss: 0.9104\n",
      "131/194, train_loss: 0.8079\n",
      "132/194, train_loss: 0.8216\n",
      "133/194, train_loss: 0.8329\n",
      "134/194, train_loss: 0.7950\n",
      "135/194, train_loss: 0.9632\n",
      "136/194, train_loss: 0.8941\n",
      "137/194, train_loss: 0.7511\n",
      "138/194, train_loss: 0.6633\n",
      "139/194, train_loss: 0.7841\n",
      "140/194, train_loss: 0.7920\n",
      "141/194, train_loss: 0.8389\n",
      "142/194, train_loss: 0.8357\n",
      "143/194, train_loss: 0.9005\n",
      "144/194, train_loss: 0.9323\n",
      "145/194, train_loss: 0.8912\n",
      "146/194, train_loss: 0.9256\n",
      "147/194, train_loss: 0.8705\n",
      "148/194, train_loss: 0.9025\n",
      "149/194, train_loss: 0.7906\n",
      "150/194, train_loss: 0.8501\n",
      "151/194, train_loss: 0.7831\n",
      "152/194, train_loss: 0.9274\n",
      "153/194, train_loss: 0.9477\n",
      "154/194, train_loss: 0.8929\n",
      "155/194, train_loss: 0.9162\n",
      "156/194, train_loss: 0.9587\n",
      "157/194, train_loss: 0.9366\n",
      "158/194, train_loss: 0.8711\n",
      "159/194, train_loss: 0.9037\n",
      "160/194, train_loss: 0.8706\n",
      "161/194, train_loss: 0.9554\n",
      "162/194, train_loss: 0.9793\n",
      "163/194, train_loss: 0.8905\n",
      "164/194, train_loss: 0.9380\n",
      "165/194, train_loss: 0.8959\n",
      "166/194, train_loss: 0.8298\n",
      "167/194, train_loss: 0.8894\n",
      "168/194, train_loss: 0.7298\n",
      "169/194, train_loss: 0.7993\n",
      "170/194, train_loss: 0.8218\n",
      "171/194, train_loss: 0.7956\n",
      "172/194, train_loss: 0.8404\n",
      "173/194, train_loss: 0.7123\n",
      "174/194, train_loss: 0.7931\n",
      "175/194, train_loss: 0.8007\n",
      "176/194, train_loss: 0.8006\n",
      "177/194, train_loss: 0.9145\n",
      "178/194, train_loss: 0.8882\n",
      "179/194, train_loss: 0.8428\n",
      "180/194, train_loss: 0.9093\n",
      "181/194, train_loss: 0.7433\n",
      "182/194, train_loss: 0.7951\n",
      "183/194, train_loss: 0.8380\n",
      "184/194, train_loss: 0.7542\n",
      "185/194, train_loss: 0.8336\n",
      "186/194, train_loss: 0.7785\n",
      "187/194, train_loss: 0.8597\n",
      "188/194, train_loss: 0.8399\n",
      "189/194, train_loss: 0.8520\n",
      "190/194, train_loss: 0.7320\n",
      "191/194, train_loss: 0.8359\n",
      "192/194, train_loss: 0.8749\n",
      "193/194, train_loss: 0.8000\n",
      "194/194, train_loss: 0.8701\n",
      "metric=0.26140248992790777, metric_tc=0.23989560812090835, metric_wt=0.42139083581666154, metric_et=0.1229210245073773\n",
      "metric=0.26140248992790777, metric_tc=0.23989560812090835, metric_wt=0.42139083581666154, metric_et=0.1229210245073773\n",
      "current epoch: 19 current epoch loss: 0.8439\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 19/80 [3:32:54<11:05:16, 654.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metric=0.26140248992790777, metric_tc=0.23989560812090835, metric_wt=0.42139083581666154, metric_et=0.1229210245073773\n",
      "0.26140248992790777\n",
      "current epoch: 19 current mean dice: 0.2614 tc: 0.2399 wt: 0.4214 et: 0.1229\n",
      "best mean dice: 0.2644 at epoch: 18\n",
      "\n",
      " | Global Training Round : 20 |\n",
      "\n",
      "user 0 selected\n",
      "local epoch 1\n",
      "1/194, train_loss: 0.9116\n",
      "2/194, train_loss: 0.6620\n",
      "3/194, train_loss: 0.8293\n",
      "4/194, train_loss: 0.7957\n",
      "5/194, train_loss: 0.7792\n",
      "6/194, train_loss: 0.8618\n",
      "7/194, train_loss: 0.8479\n",
      "8/194, train_loss: 0.7765\n",
      "9/194, train_loss: 0.9363\n",
      "10/194, train_loss: 0.9021\n",
      "11/194, train_loss: 0.7874\n",
      "12/194, train_loss: 0.8259\n",
      "13/194, train_loss: 0.8981\n",
      "14/194, train_loss: 0.7121\n",
      "15/194, train_loss: 0.8144\n",
      "16/194, train_loss: 0.8037\n",
      "17/194, train_loss: 0.7260\n",
      "18/194, train_loss: 0.8403\n",
      "19/194, train_loss: 0.7430\n",
      "20/194, train_loss: 0.9378\n",
      "21/194, train_loss: 0.8266\n",
      "22/194, train_loss: 0.7325\n",
      "23/194, train_loss: 0.9238\n",
      "24/194, train_loss: 0.8486\n",
      "25/194, train_loss: 0.9413\n",
      "26/194, train_loss: 0.9428\n",
      "27/194, train_loss: 0.8481\n",
      "28/194, train_loss: 0.8245\n",
      "29/194, train_loss: 0.8129\n",
      "30/194, train_loss: 0.9203\n",
      "31/194, train_loss: 0.8353\n",
      "32/194, train_loss: 0.9574\n",
      "33/194, train_loss: 0.7978\n",
      "34/194, train_loss: 0.9690\n",
      "35/194, train_loss: 0.8370\n",
      "36/194, train_loss: 0.8104\n",
      "37/194, train_loss: 0.7409\n",
      "38/194, train_loss: 0.9181\n",
      "39/194, train_loss: 0.9484\n",
      "40/194, train_loss: 0.6855\n",
      "41/194, train_loss: 0.8690\n",
      "42/194, train_loss: 0.8386\n",
      "43/194, train_loss: 0.7876\n",
      "44/194, train_loss: 0.7783\n",
      "45/194, train_loss: 0.7602\n",
      "46/194, train_loss: 0.8351\n",
      "47/194, train_loss: 0.8562\n",
      "48/194, train_loss: 0.7689\n",
      "49/194, train_loss: 0.8212\n",
      "50/194, train_loss: 0.7929\n",
      "51/194, train_loss: 0.7648\n",
      "52/194, train_loss: 0.7921\n",
      "53/194, train_loss: 0.9428\n",
      "54/194, train_loss: 0.7850\n",
      "55/194, train_loss: 0.8756\n",
      "56/194, train_loss: 0.7819\n",
      "57/194, train_loss: 0.9031\n",
      "58/194, train_loss: 0.8737\n",
      "59/194, train_loss: 0.8219\n",
      "60/194, train_loss: 0.8610\n",
      "61/194, train_loss: 0.7797\n",
      "62/194, train_loss: 0.7348\n",
      "63/194, train_loss: 0.8090\n",
      "64/194, train_loss: 0.8985\n",
      "65/194, train_loss: 0.8889\n",
      "66/194, train_loss: 0.8400\n",
      "67/194, train_loss: 0.7718\n",
      "68/194, train_loss: 0.9245\n",
      "69/194, train_loss: 0.8161\n",
      "70/194, train_loss: 0.8796\n",
      "71/194, train_loss: 0.8403\n",
      "72/194, train_loss: 0.8860\n",
      "73/194, train_loss: 0.7850\n",
      "74/194, train_loss: 0.8259\n",
      "75/194, train_loss: 0.7415\n",
      "76/194, train_loss: 0.8615\n",
      "77/194, train_loss: 0.9372\n",
      "78/194, train_loss: 0.8987\n",
      "79/194, train_loss: 0.6743\n",
      "80/194, train_loss: 0.8028\n",
      "81/194, train_loss: 0.6907\n",
      "82/194, train_loss: 0.8158\n",
      "83/194, train_loss: 0.8541\n",
      "84/194, train_loss: 0.8698\n",
      "85/194, train_loss: 0.8930\n",
      "86/194, train_loss: 0.8697\n",
      "87/194, train_loss: 0.9586\n",
      "88/194, train_loss: 0.8767\n",
      "89/194, train_loss: 0.7157\n",
      "90/194, train_loss: 0.8163\n",
      "91/194, train_loss: 0.9510\n",
      "92/194, train_loss: 0.9328\n",
      "93/194, train_loss: 0.8416\n",
      "94/194, train_loss: 0.8688\n",
      "95/194, train_loss: 0.8163\n",
      "96/194, train_loss: 0.7957\n",
      "97/194, train_loss: 0.8304\n",
      "98/194, train_loss: 0.8530\n",
      "99/194, train_loss: 0.8157\n",
      "100/194, train_loss: 0.8679\n",
      "101/194, train_loss: 0.8787\n",
      "102/194, train_loss: 0.9545\n",
      "103/194, train_loss: 0.8564\n",
      "104/194, train_loss: 0.7685\n",
      "105/194, train_loss: 0.8561\n",
      "106/194, train_loss: 0.9608\n",
      "107/194, train_loss: 0.8187\n",
      "108/194, train_loss: 0.7972\n",
      "109/194, train_loss: 0.8013\n",
      "110/194, train_loss: 0.7892\n",
      "111/194, train_loss: 0.8524\n",
      "112/194, train_loss: 0.8978\n",
      "113/194, train_loss: 0.8733\n",
      "114/194, train_loss: 0.6841\n",
      "115/194, train_loss: 0.8034\n",
      "116/194, train_loss: 0.8868\n",
      "117/194, train_loss: 0.7158\n",
      "118/194, train_loss: 0.9425\n",
      "119/194, train_loss: 0.8198\n",
      "120/194, train_loss: 0.7957\n",
      "121/194, train_loss: 0.8238\n",
      "122/194, train_loss: 0.8128\n",
      "123/194, train_loss: 0.9247\n",
      "124/194, train_loss: 0.8312\n",
      "125/194, train_loss: 0.9460\n",
      "126/194, train_loss: 0.9683\n",
      "127/194, train_loss: 0.8968\n",
      "128/194, train_loss: 0.9197\n",
      "129/194, train_loss: 0.8970\n",
      "130/194, train_loss: 0.8026\n",
      "131/194, train_loss: 0.6818\n",
      "132/194, train_loss: 0.9055\n",
      "133/194, train_loss: 0.9325\n",
      "134/194, train_loss: 0.8492\n",
      "135/194, train_loss: 0.9502\n",
      "136/194, train_loss: 0.7710\n",
      "137/194, train_loss: 0.8193\n",
      "138/194, train_loss: 0.7974\n",
      "139/194, train_loss: 0.7803\n",
      "140/194, train_loss: 0.8593\n",
      "141/194, train_loss: 0.8414\n",
      "142/194, train_loss: 0.8450\n",
      "143/194, train_loss: 0.8943\n",
      "144/194, train_loss: 0.9635\n",
      "145/194, train_loss: 0.8212\n",
      "146/194, train_loss: 0.9275\n",
      "147/194, train_loss: 0.8451\n",
      "148/194, train_loss: 0.8483\n",
      "149/194, train_loss: 0.7998\n",
      "150/194, train_loss: 0.7404\n",
      "151/194, train_loss: 0.6826\n",
      "152/194, train_loss: 0.8388\n",
      "153/194, train_loss: 0.8355\n",
      "154/194, train_loss: 0.8250\n",
      "155/194, train_loss: 0.7676\n",
      "156/194, train_loss: 0.8221\n",
      "157/194, train_loss: 0.7381\n",
      "158/194, train_loss: 0.9139\n",
      "159/194, train_loss: 0.8390\n",
      "160/194, train_loss: 0.7447\n",
      "161/194, train_loss: 0.8342\n",
      "162/194, train_loss: 0.8856\n",
      "163/194, train_loss: 0.9128\n",
      "164/194, train_loss: 0.8819\n",
      "165/194, train_loss: 0.8217\n",
      "166/194, train_loss: 0.8338\n",
      "167/194, train_loss: 0.8844\n",
      "168/194, train_loss: 0.7843\n",
      "169/194, train_loss: 0.7289\n",
      "170/194, train_loss: 0.7731\n",
      "171/194, train_loss: 0.6693\n",
      "172/194, train_loss: 0.7224\n",
      "173/194, train_loss: 0.9351\n",
      "174/194, train_loss: 0.7882\n",
      "175/194, train_loss: 0.7492\n",
      "176/194, train_loss: 0.6483\n",
      "177/194, train_loss: 0.7745\n",
      "178/194, train_loss: 0.8194\n",
      "179/194, train_loss: 0.8024\n",
      "180/194, train_loss: 0.9063\n",
      "181/194, train_loss: 0.8213\n",
      "182/194, train_loss: 0.8173\n",
      "183/194, train_loss: 0.6975\n",
      "184/194, train_loss: 0.7147\n",
      "185/194, train_loss: 0.9130\n",
      "186/194, train_loss: 0.8780\n",
      "187/194, train_loss: 0.9007\n",
      "188/194, train_loss: 0.8641\n",
      "189/194, train_loss: 0.7897\n",
      "190/194, train_loss: 0.8129\n",
      "191/194, train_loss: 0.8555\n",
      "192/194, train_loss: 0.8576\n",
      "193/194, train_loss: 0.8540\n",
      "194/194, train_loss: 0.7934\n",
      "metric=0.24901964825888476, metric_tc=0.2310394695183883, metric_wt=0.39762925263494253, metric_et=0.1183902220800519\n",
      "metric=0.24901964825888476, metric_tc=0.2310394695183883, metric_wt=0.39762925263494253, metric_et=0.1183902220800519\n",
      "current epoch: 20 current epoch loss: 0.8337\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 20/80 [3:43:18<10:45:12, 645.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metric=0.24901964825888476, metric_tc=0.2310394695183883, metric_wt=0.39762925263494253, metric_et=0.1183902220800519\n",
      "0.24901964825888476\n",
      "current epoch: 20 current mean dice: 0.2490 tc: 0.2310 wt: 0.3976 et: 0.1184\n",
      "best mean dice: 0.2644 at epoch: 18\n",
      "\n",
      " | Global Training Round : 21 |\n",
      "\n",
      "user 0 selected\n",
      "local epoch 1\n",
      "1/194, train_loss: 0.8585\n",
      "2/194, train_loss: 0.8208\n",
      "3/194, train_loss: 0.8161\n",
      "4/194, train_loss: 0.6804\n",
      "5/194, train_loss: 0.8254\n",
      "6/194, train_loss: 0.6998\n",
      "7/194, train_loss: 0.8284\n",
      "8/194, train_loss: 0.8746\n",
      "9/194, train_loss: 0.7305\n",
      "10/194, train_loss: 0.8796\n",
      "11/194, train_loss: 0.7690\n",
      "12/194, train_loss: 0.8093\n",
      "13/194, train_loss: 0.8634\n",
      "14/194, train_loss: 0.7830\n",
      "15/194, train_loss: 0.7767\n",
      "16/194, train_loss: 0.7967\n",
      "17/194, train_loss: 0.8195\n",
      "18/194, train_loss: 0.7971\n",
      "19/194, train_loss: 0.9216\n",
      "20/194, train_loss: 0.6221\n",
      "21/194, train_loss: 0.8676\n",
      "22/194, train_loss: 0.9689\n",
      "23/194, train_loss: 0.8495\n",
      "24/194, train_loss: 0.8541\n",
      "25/194, train_loss: 0.8980\n",
      "26/194, train_loss: 0.9432\n",
      "27/194, train_loss: 0.8746\n",
      "28/194, train_loss: 0.8705\n",
      "29/194, train_loss: 0.7732\n",
      "30/194, train_loss: 0.8232\n",
      "31/194, train_loss: 0.8461\n",
      "32/194, train_loss: 0.7360\n",
      "33/194, train_loss: 0.8422\n",
      "34/194, train_loss: 0.8560\n",
      "35/194, train_loss: 0.9301\n",
      "36/194, train_loss: 0.7003\n",
      "37/194, train_loss: 0.7207\n",
      "38/194, train_loss: 0.8429\n",
      "39/194, train_loss: 0.8253\n",
      "40/194, train_loss: 0.7492\n",
      "41/194, train_loss: 0.8580\n",
      "42/194, train_loss: 0.8904\n",
      "43/194, train_loss: 0.9009\n",
      "44/194, train_loss: 0.8526\n",
      "45/194, train_loss: 0.7475\n",
      "46/194, train_loss: 0.6538\n",
      "47/194, train_loss: 0.7865\n",
      "48/194, train_loss: 0.7439\n",
      "49/194, train_loss: 0.8295\n",
      "50/194, train_loss: 0.8328\n",
      "51/194, train_loss: 0.7734\n",
      "52/194, train_loss: 0.7731\n",
      "53/194, train_loss: 0.8997\n",
      "54/194, train_loss: 0.7732\n",
      "55/194, train_loss: 0.8433\n",
      "56/194, train_loss: 0.7765\n",
      "57/194, train_loss: 0.9948\n",
      "58/194, train_loss: 0.9528\n",
      "59/194, train_loss: 0.9277\n",
      "60/194, train_loss: 0.9332\n",
      "61/194, train_loss: 0.6325\n",
      "62/194, train_loss: 0.7374\n",
      "63/194, train_loss: 0.8843\n",
      "64/194, train_loss: 0.6967\n",
      "65/194, train_loss: 0.8552\n",
      "66/194, train_loss: 0.7473\n",
      "67/194, train_loss: 0.7389\n",
      "68/194, train_loss: 0.9254\n",
      "69/194, train_loss: 0.8417\n",
      "70/194, train_loss: 0.9440\n",
      "71/194, train_loss: 0.8672\n",
      "72/194, train_loss: 0.7242\n",
      "73/194, train_loss: 0.8155\n",
      "74/194, train_loss: 0.8301\n",
      "75/194, train_loss: 0.8279\n",
      "76/194, train_loss: 0.7402\n",
      "77/194, train_loss: 0.8030\n",
      "78/194, train_loss: 0.8425\n",
      "79/194, train_loss: 0.8445\n",
      "80/194, train_loss: 0.6870\n",
      "81/194, train_loss: 0.8101\n",
      "82/194, train_loss: 0.8193\n",
      "83/194, train_loss: 0.9130\n",
      "84/194, train_loss: 0.9270\n",
      "85/194, train_loss: 0.7748\n",
      "86/194, train_loss: 0.9323\n",
      "87/194, train_loss: 0.8847\n",
      "88/194, train_loss: 0.8636\n",
      "89/194, train_loss: 0.8797\n",
      "90/194, train_loss: 0.8921\n",
      "91/194, train_loss: 0.9067\n",
      "92/194, train_loss: 0.8995\n",
      "93/194, train_loss: 0.8204\n",
      "94/194, train_loss: 0.7749\n",
      "95/194, train_loss: 0.8856\n",
      "96/194, train_loss: 0.8240\n",
      "97/194, train_loss: 0.8481\n",
      "98/194, train_loss: 0.9159\n",
      "99/194, train_loss: 0.8979\n",
      "100/194, train_loss: 0.8822\n",
      "101/194, train_loss: 0.7908\n",
      "102/194, train_loss: 0.8286\n",
      "103/194, train_loss: 0.9129\n",
      "104/194, train_loss: 0.8681\n",
      "105/194, train_loss: 0.8370\n",
      "106/194, train_loss: 0.7704\n",
      "107/194, train_loss: 0.7441\n",
      "108/194, train_loss: 0.7270\n",
      "109/194, train_loss: 0.6982\n",
      "110/194, train_loss: 0.8573\n",
      "111/194, train_loss: 0.7881\n",
      "112/194, train_loss: 0.7284\n",
      "113/194, train_loss: 0.8917\n",
      "114/194, train_loss: 0.9559\n",
      "115/194, train_loss: 0.8811\n",
      "116/194, train_loss: 0.8075\n",
      "117/194, train_loss: 0.8728\n",
      "118/194, train_loss: 0.8486\n",
      "119/194, train_loss: 0.7593\n",
      "120/194, train_loss: 0.8227\n",
      "121/194, train_loss: 0.8662\n",
      "122/194, train_loss: 0.9852\n",
      "123/194, train_loss: 0.8689\n",
      "124/194, train_loss: 0.8820\n",
      "125/194, train_loss: 0.9722\n",
      "126/194, train_loss: 0.9637\n",
      "127/194, train_loss: 0.8672\n",
      "128/194, train_loss: 0.8661\n",
      "129/194, train_loss: 0.8561\n",
      "130/194, train_loss: 0.8316\n",
      "131/194, train_loss: 0.7796\n",
      "132/194, train_loss: 0.8506\n",
      "133/194, train_loss: 0.8551\n",
      "134/194, train_loss: 0.9809\n",
      "135/194, train_loss: 0.9518\n",
      "136/194, train_loss: 0.8012\n",
      "137/194, train_loss: 0.8806\n",
      "138/194, train_loss: 0.6692\n",
      "139/194, train_loss: 0.7595\n",
      "140/194, train_loss: 0.7445\n",
      "141/194, train_loss: 0.8130\n",
      "142/194, train_loss: 0.8254\n",
      "143/194, train_loss: 0.7736\n",
      "144/194, train_loss: 0.6408\n",
      "145/194, train_loss: 0.7976\n",
      "146/194, train_loss: 0.8903\n",
      "147/194, train_loss: 0.8190\n",
      "148/194, train_loss: 0.9821\n",
      "149/194, train_loss: 0.9134\n",
      "150/194, train_loss: 0.9262\n",
      "151/194, train_loss: 0.8783\n",
      "152/194, train_loss: 0.8509\n",
      "153/194, train_loss: 0.8637\n",
      "154/194, train_loss: 0.9073\n",
      "155/194, train_loss: 0.9318\n",
      "156/194, train_loss: 0.8749\n",
      "157/194, train_loss: 0.9868\n",
      "158/194, train_loss: 0.8363\n",
      "159/194, train_loss: 0.9609\n",
      "160/194, train_loss: 0.9027\n",
      "161/194, train_loss: 0.9014\n",
      "162/194, train_loss: 0.8367\n",
      "163/194, train_loss: 0.8224\n",
      "164/194, train_loss: 0.8555\n",
      "165/194, train_loss: 0.8738\n",
      "166/194, train_loss: 0.8890\n",
      "167/194, train_loss: 0.8635\n",
      "168/194, train_loss: 0.8612\n",
      "169/194, train_loss: 0.7106\n",
      "170/194, train_loss: 0.8351\n",
      "171/194, train_loss: 0.7528\n",
      "172/194, train_loss: 0.8619\n",
      "173/194, train_loss: 0.7661\n",
      "174/194, train_loss: 0.6976\n",
      "175/194, train_loss: 0.7366\n",
      "176/194, train_loss: 0.8765\n",
      "177/194, train_loss: 0.9036\n",
      "178/194, train_loss: 0.9209\n",
      "179/194, train_loss: 0.7775\n",
      "180/194, train_loss: 0.8204\n",
      "181/194, train_loss: 0.8646\n",
      "182/194, train_loss: 0.8437\n",
      "183/194, train_loss: 0.6659\n",
      "184/194, train_loss: 0.7031\n",
      "185/194, train_loss: 0.7931\n",
      "186/194, train_loss: 0.8459\n",
      "187/194, train_loss: 0.8748\n",
      "188/194, train_loss: 0.8657\n",
      "189/194, train_loss: 0.9318\n",
      "190/194, train_loss: 0.8540\n",
      "191/194, train_loss: 0.9041\n",
      "192/194, train_loss: 0.8183\n",
      "193/194, train_loss: 0.8890\n",
      "194/194, train_loss: 0.8723\n",
      "metric=0.30486989409352344, metric_tc=0.2837295299395919, metric_wt=0.48404441587626934, metric_et=0.14683572781117013\n",
      "metric=0.30486989409352344, metric_tc=0.2837295299395919, metric_wt=0.48404441587626934, metric_et=0.14683572781117013\n",
      "current epoch: 21 current epoch loss: 0.8356\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▋       | 21/80 [3:53:54<10:31:53, 642.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metric=0.30486989409352344, metric_tc=0.2837295299395919, metric_wt=0.48404441587626934, metric_et=0.14683572781117013\n",
      "0.30486989409352344\n",
      "saved new best metric model\n",
      "current epoch: 21 current mean dice: 0.3049 tc: 0.2837 wt: 0.4840 et: 0.1468\n",
      "best mean dice: 0.3049 at epoch: 21\n",
      "\n",
      " | Global Training Round : 22 |\n",
      "\n",
      "user 0 selected\n",
      "local epoch 1\n",
      "1/194, train_loss: 0.8188\n",
      "2/194, train_loss: 0.8729\n",
      "3/194, train_loss: 0.7296\n",
      "4/194, train_loss: 0.8358\n",
      "5/194, train_loss: 0.7801\n",
      "6/194, train_loss: 0.7161\n",
      "7/194, train_loss: 0.8808\n",
      "8/194, train_loss: 0.8839\n",
      "9/194, train_loss: 0.8328\n",
      "10/194, train_loss: 0.8381\n",
      "11/194, train_loss: 0.8046\n",
      "12/194, train_loss: 0.8617\n",
      "13/194, train_loss: 0.7784\n",
      "14/194, train_loss: 0.7253\n",
      "15/194, train_loss: 0.6277\n",
      "16/194, train_loss: 0.9561\n",
      "17/194, train_loss: 0.9150\n",
      "18/194, train_loss: 0.7788\n",
      "19/194, train_loss: 0.7044\n",
      "20/194, train_loss: 0.9205\n",
      "21/194, train_loss: 0.8216\n",
      "22/194, train_loss: 0.7334\n",
      "23/194, train_loss: 0.7902\n",
      "24/194, train_loss: 0.7814\n",
      "25/194, train_loss: 0.8232\n",
      "26/194, train_loss: 0.7988\n",
      "27/194, train_loss: 0.8512\n",
      "28/194, train_loss: 0.8429\n",
      "29/194, train_loss: 0.9482\n",
      "30/194, train_loss: 0.9005\n",
      "31/194, train_loss: 0.8699\n",
      "32/194, train_loss: 0.8999\n",
      "33/194, train_loss: 0.7903\n",
      "34/194, train_loss: 0.7351\n",
      "35/194, train_loss: 0.8664\n",
      "36/194, train_loss: 0.8287\n",
      "37/194, train_loss: 0.7934\n",
      "38/194, train_loss: 0.7568\n",
      "39/194, train_loss: 0.7957\n",
      "40/194, train_loss: 0.8989\n",
      "41/194, train_loss: 0.8176\n",
      "42/194, train_loss: 0.8634\n",
      "43/194, train_loss: 0.8230\n",
      "44/194, train_loss: 0.9048\n",
      "45/194, train_loss: 0.8894\n",
      "46/194, train_loss: 0.8898\n",
      "47/194, train_loss: 0.8551\n",
      "48/194, train_loss: 0.7927\n",
      "49/194, train_loss: 0.7344\n",
      "50/194, train_loss: 0.9820\n",
      "51/194, train_loss: 0.8415\n",
      "52/194, train_loss: 0.8150\n",
      "53/194, train_loss: 0.8147\n",
      "54/194, train_loss: 0.8622\n",
      "55/194, train_loss: 0.6128\n",
      "56/194, train_loss: 0.9471\n",
      "57/194, train_loss: 0.8526\n",
      "58/194, train_loss: 0.8667\n",
      "59/194, train_loss: 0.9132\n",
      "60/194, train_loss: 0.8714\n",
      "61/194, train_loss: 0.7812\n",
      "62/194, train_loss: 0.7059\n",
      "63/194, train_loss: 0.8514\n",
      "64/194, train_loss: 0.9081\n",
      "65/194, train_loss: 0.8118\n",
      "66/194, train_loss: 0.8046\n",
      "67/194, train_loss: 0.8077\n",
      "68/194, train_loss: 0.6322\n",
      "69/194, train_loss: 0.7693\n",
      "70/194, train_loss: 0.8051\n",
      "71/194, train_loss: 0.8227\n",
      "72/194, train_loss: 0.6859\n",
      "73/194, train_loss: 0.6547\n",
      "74/194, train_loss: 0.8441\n",
      "75/194, train_loss: 0.7762\n",
      "76/194, train_loss: 0.9075\n",
      "77/194, train_loss: 0.9214\n",
      "78/194, train_loss: 0.8465\n",
      "79/194, train_loss: 0.8335\n",
      "80/194, train_loss: 0.7395\n",
      "81/194, train_loss: 0.8380\n",
      "82/194, train_loss: 0.8270\n",
      "83/194, train_loss: 0.8569\n",
      "84/194, train_loss: 0.8643\n",
      "85/194, train_loss: 0.9637\n",
      "86/194, train_loss: 0.9510\n",
      "87/194, train_loss: 0.9298\n",
      "88/194, train_loss: 0.9149\n",
      "89/194, train_loss: 0.9155\n",
      "90/194, train_loss: 0.7429\n",
      "91/194, train_loss: 0.9546\n",
      "92/194, train_loss: 0.9207\n",
      "93/194, train_loss: 0.8339\n",
      "94/194, train_loss: 0.7708\n",
      "95/194, train_loss: 0.7654\n",
      "96/194, train_loss: 0.8595\n",
      "97/194, train_loss: 0.8219\n",
      "98/194, train_loss: 0.8542\n",
      "99/194, train_loss: 0.9048\n",
      "100/194, train_loss: 0.7859\n",
      "101/194, train_loss: 0.9184\n",
      "102/194, train_loss: 0.7691\n",
      "103/194, train_loss: 0.9122\n",
      "104/194, train_loss: 0.8750\n",
      "105/194, train_loss: 0.7966\n",
      "106/194, train_loss: 0.7445\n",
      "107/194, train_loss: 0.9205\n",
      "108/194, train_loss: 0.9663\n",
      "109/194, train_loss: 0.6618\n",
      "110/194, train_loss: 0.8131\n",
      "111/194, train_loss: 0.7380\n",
      "112/194, train_loss: 0.7651\n",
      "113/194, train_loss: 0.8199\n",
      "114/194, train_loss: 0.9041\n",
      "115/194, train_loss: 0.7916\n",
      "116/194, train_loss: 0.8784\n",
      "117/194, train_loss: 0.9062\n",
      "118/194, train_loss: 0.9292\n",
      "119/194, train_loss: 0.7231\n",
      "120/194, train_loss: 0.7873\n",
      "121/194, train_loss: 0.9031\n",
      "122/194, train_loss: 0.9667\n",
      "123/194, train_loss: 0.9254\n",
      "124/194, train_loss: 0.9314\n",
      "125/194, train_loss: 0.9230\n",
      "126/194, train_loss: 0.8548\n",
      "127/194, train_loss: 0.9076\n",
      "128/194, train_loss: 0.9519\n",
      "129/194, train_loss: 0.7236\n",
      "130/194, train_loss: 0.8081\n",
      "131/194, train_loss: 0.7946\n",
      "132/194, train_loss: 0.7828\n",
      "133/194, train_loss: 0.7771\n",
      "134/194, train_loss: 0.8720\n",
      "135/194, train_loss: 0.7944\n",
      "136/194, train_loss: 0.8380\n",
      "137/194, train_loss: 0.7603\n",
      "138/194, train_loss: 0.8244\n",
      "139/194, train_loss: 0.7266\n",
      "140/194, train_loss: 0.7766\n",
      "141/194, train_loss: 0.9381\n",
      "142/194, train_loss: 0.9044\n",
      "143/194, train_loss: 0.8526\n",
      "144/194, train_loss: 0.8980\n",
      "145/194, train_loss: 0.9019\n",
      "146/194, train_loss: 0.7885\n",
      "147/194, train_loss: 0.8560\n",
      "148/194, train_loss: 0.7812\n",
      "149/194, train_loss: 0.9225\n",
      "150/194, train_loss: 0.8089\n",
      "151/194, train_loss: 0.7846\n",
      "152/194, train_loss: 0.7957\n",
      "153/194, train_loss: 0.8686\n",
      "154/194, train_loss: 0.9118\n",
      "155/194, train_loss: 0.8662\n",
      "156/194, train_loss: 0.8923\n",
      "157/194, train_loss: 0.8929\n",
      "158/194, train_loss: 0.8677\n",
      "159/194, train_loss: 0.9037\n",
      "160/194, train_loss: 0.8409\n",
      "161/194, train_loss: 0.8964\n",
      "162/194, train_loss: 0.8851\n",
      "163/194, train_loss: 0.8796\n",
      "164/194, train_loss: 0.9117\n",
      "165/194, train_loss: 0.8111\n",
      "166/194, train_loss: 0.8284\n",
      "167/194, train_loss: 0.7753\n",
      "168/194, train_loss: 0.8383\n",
      "169/194, train_loss: 0.8001\n",
      "170/194, train_loss: 0.7401\n",
      "171/194, train_loss: 0.8791\n",
      "172/194, train_loss: 0.8033\n",
      "173/194, train_loss: 0.8723\n",
      "174/194, train_loss: 0.8186\n",
      "175/194, train_loss: 0.8076\n",
      "176/194, train_loss: 0.8951\n",
      "177/194, train_loss: 0.8511\n",
      "178/194, train_loss: 0.7791\n",
      "179/194, train_loss: 0.8336\n",
      "180/194, train_loss: 0.9272\n",
      "181/194, train_loss: 0.9146\n",
      "182/194, train_loss: 0.9115\n",
      "183/194, train_loss: 0.8340\n",
      "184/194, train_loss: 0.7977\n",
      "185/194, train_loss: 0.8001\n",
      "186/194, train_loss: 0.8297\n",
      "187/194, train_loss: 0.7424\n",
      "188/194, train_loss: 0.8634\n",
      "189/194, train_loss: 0.7383\n",
      "190/194, train_loss: 0.8915\n",
      "191/194, train_loss: 0.8694\n",
      "192/194, train_loss: 0.7824\n",
      "193/194, train_loss: 0.8045\n",
      "194/194, train_loss: 0.8631\n",
      "metric=0.28417261643335223, metric_tc=0.26103600750987727, metric_wt=0.45774585598458845, metric_et=0.13373597885947675\n",
      "metric=0.28417261643335223, metric_tc=0.26103600750987727, metric_wt=0.45774585598458845, metric_et=0.13373597885947675\n",
      "current epoch: 22 current epoch loss: 0.8358\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 22/80 [4:04:44<10:23:12, 644.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metric=0.28417261643335223, metric_tc=0.26103600750987727, metric_wt=0.45774585598458845, metric_et=0.13373597885947675\n",
      "0.28417261643335223\n",
      "current epoch: 22 current mean dice: 0.2842 tc: 0.2610 wt: 0.4577 et: 0.1337\n",
      "best mean dice: 0.3049 at epoch: 21\n",
      "\n",
      " | Global Training Round : 23 |\n",
      "\n",
      "user 0 selected\n",
      "local epoch 1\n",
      "1/194, train_loss: 0.8686\n",
      "2/194, train_loss: 0.7115\n",
      "3/194, train_loss: 0.8539\n",
      "4/194, train_loss: 0.7863\n",
      "5/194, train_loss: 0.7411\n",
      "6/194, train_loss: 0.9064\n",
      "7/194, train_loss: 0.8278\n",
      "8/194, train_loss: 0.8419\n",
      "9/194, train_loss: 0.9189\n",
      "10/194, train_loss: 0.8779\n",
      "11/194, train_loss: 0.8393\n",
      "12/194, train_loss: 0.7947\n",
      "13/194, train_loss: 0.7930\n",
      "14/194, train_loss: 0.7417\n",
      "15/194, train_loss: 0.7998\n",
      "16/194, train_loss: 0.7987\n",
      "17/194, train_loss: 0.7784\n",
      "18/194, train_loss: 0.8080\n",
      "19/194, train_loss: 0.8493\n",
      "20/194, train_loss: 0.8982\n",
      "21/194, train_loss: 0.8194\n",
      "22/194, train_loss: 0.8811\n",
      "23/194, train_loss: 0.7842\n",
      "24/194, train_loss: 0.9056\n",
      "25/194, train_loss: 0.9102\n",
      "26/194, train_loss: 0.6268\n",
      "27/194, train_loss: 0.8741\n",
      "28/194, train_loss: 0.7279\n",
      "29/194, train_loss: 0.8917\n",
      "30/194, train_loss: 0.8186\n",
      "31/194, train_loss: 0.7858\n",
      "32/194, train_loss: 0.8649\n",
      "33/194, train_loss: 0.8886\n",
      "34/194, train_loss: 0.7289\n",
      "35/194, train_loss: 0.8253\n",
      "36/194, train_loss: 0.5437\n",
      "37/194, train_loss: 0.8174\n",
      "38/194, train_loss: 0.8554\n",
      "39/194, train_loss: 0.7717\n",
      "40/194, train_loss: 0.8176\n",
      "41/194, train_loss: 0.8372\n",
      "42/194, train_loss: 0.9046\n",
      "43/194, train_loss: 0.8887\n",
      "44/194, train_loss: 0.8545\n",
      "45/194, train_loss: 0.7722\n",
      "46/194, train_loss: 0.8903\n",
      "47/194, train_loss: 0.8965\n",
      "48/194, train_loss: 0.8861\n",
      "49/194, train_loss: 0.5848\n",
      "50/194, train_loss: 0.7467\n",
      "51/194, train_loss: 0.8563\n",
      "52/194, train_loss: 0.8303\n",
      "53/194, train_loss: 0.9117\n",
      "54/194, train_loss: 0.8162\n",
      "55/194, train_loss: 0.8971\n",
      "56/194, train_loss: 0.8772\n",
      "57/194, train_loss: 0.9216\n",
      "58/194, train_loss: 0.7552\n",
      "59/194, train_loss: 0.9316\n",
      "60/194, train_loss: 0.7698\n",
      "61/194, train_loss: 0.8372\n",
      "62/194, train_loss: 0.9350\n",
      "63/194, train_loss: 0.6659\n",
      "64/194, train_loss: 0.6648\n",
      "65/194, train_loss: 0.7520\n",
      "66/194, train_loss: 0.7422\n",
      "67/194, train_loss: 0.6387\n",
      "68/194, train_loss: 0.7650\n",
      "69/194, train_loss: 0.9169\n",
      "70/194, train_loss: 0.7034\n",
      "71/194, train_loss: 0.7289\n",
      "72/194, train_loss: 0.9130\n",
      "73/194, train_loss: 0.6369\n",
      "74/194, train_loss: 0.7273\n",
      "75/194, train_loss: 0.7425\n",
      "76/194, train_loss: 0.7229\n",
      "77/194, train_loss: 0.8311\n",
      "78/194, train_loss: 0.7383\n",
      "79/194, train_loss: 0.8201\n",
      "80/194, train_loss: 0.7377\n",
      "81/194, train_loss: 0.7943\n",
      "82/194, train_loss: 0.7817\n",
      "83/194, train_loss: 0.8874\n",
      "84/194, train_loss: 0.8150\n",
      "85/194, train_loss: 0.7731\n",
      "86/194, train_loss: 0.9023\n",
      "87/194, train_loss: 0.9580\n",
      "88/194, train_loss: 0.8268\n",
      "89/194, train_loss: 0.7048\n",
      "90/194, train_loss: 0.8781\n",
      "91/194, train_loss: 0.7776\n",
      "92/194, train_loss: 0.9007\n",
      "93/194, train_loss: 0.8712\n",
      "94/194, train_loss: 0.7526\n",
      "95/194, train_loss: 0.8245\n",
      "96/194, train_loss: 0.8992\n",
      "97/194, train_loss: 0.8573\n",
      "98/194, train_loss: 0.8426\n",
      "99/194, train_loss: 0.9070\n",
      "100/194, train_loss: 0.7179\n",
      "101/194, train_loss: 0.8499\n",
      "102/194, train_loss: 0.7180\n",
      "103/194, train_loss: 0.8148\n",
      "104/194, train_loss: 0.8914\n",
      "105/194, train_loss: 0.8426\n",
      "106/194, train_loss: 0.8285\n",
      "107/194, train_loss: 0.8432\n",
      "108/194, train_loss: 0.7702\n",
      "109/194, train_loss: 0.7688\n",
      "110/194, train_loss: 0.9490\n",
      "111/194, train_loss: 0.8228\n",
      "112/194, train_loss: 0.8103\n",
      "113/194, train_loss: 0.7976\n",
      "114/194, train_loss: 0.8496\n",
      "115/194, train_loss: 0.9655\n",
      "116/194, train_loss: 0.9291\n",
      "117/194, train_loss: 0.9203\n",
      "118/194, train_loss: 0.9120\n",
      "119/194, train_loss: 0.8121\n",
      "120/194, train_loss: 0.8154\n",
      "121/194, train_loss: 0.7554\n",
      "122/194, train_loss: 0.8350\n",
      "123/194, train_loss: 0.8506\n",
      "124/194, train_loss: 0.8549\n",
      "125/194, train_loss: 0.9680\n",
      "126/194, train_loss: 0.9191\n",
      "127/194, train_loss: 0.9111\n",
      "128/194, train_loss: 0.9181\n",
      "129/194, train_loss: 0.7957\n",
      "130/194, train_loss: 0.8117\n",
      "131/194, train_loss: 0.6801\n",
      "132/194, train_loss: 0.9434\n",
      "133/194, train_loss: 0.8969\n",
      "134/194, train_loss: 0.8325\n",
      "135/194, train_loss: 0.8155\n",
      "136/194, train_loss: 0.8207\n",
      "137/194, train_loss: 0.8963\n",
      "138/194, train_loss: 0.8118\n",
      "139/194, train_loss: 0.7799\n",
      "140/194, train_loss: 0.7154\n",
      "141/194, train_loss: 0.9233\n",
      "142/194, train_loss: 0.9348\n",
      "143/194, train_loss: 0.9395\n",
      "144/194, train_loss: 0.8823\n",
      "145/194, train_loss: 0.7974\n",
      "146/194, train_loss: 0.7887\n",
      "147/194, train_loss: 0.8696\n",
      "148/194, train_loss: 0.8731\n",
      "149/194, train_loss: 0.8286\n",
      "150/194, train_loss: 0.8877\n",
      "151/194, train_loss: 0.7583\n",
      "152/194, train_loss: 0.9046\n",
      "153/194, train_loss: 0.7349\n",
      "154/194, train_loss: 0.9402\n",
      "155/194, train_loss: 0.7992\n",
      "156/194, train_loss: 0.9322\n",
      "157/194, train_loss: 0.8434\n",
      "158/194, train_loss: 0.5884\n",
      "159/194, train_loss: 0.7372\n",
      "160/194, train_loss: 0.7385\n",
      "161/194, train_loss: 0.9167\n",
      "162/194, train_loss: 0.8721\n",
      "163/194, train_loss: 0.8678\n",
      "164/194, train_loss: 0.8766\n",
      "165/194, train_loss: 0.8483\n",
      "166/194, train_loss: 0.5410\n",
      "167/194, train_loss: 0.8868\n",
      "168/194, train_loss: 0.8031\n",
      "169/194, train_loss: 0.7708\n",
      "170/194, train_loss: 0.7728\n",
      "171/194, train_loss: 0.8049\n",
      "172/194, train_loss: 0.6443\n",
      "173/194, train_loss: 0.7674\n",
      "174/194, train_loss: 0.8073\n",
      "175/194, train_loss: 0.8415\n",
      "176/194, train_loss: 0.7858\n",
      "177/194, train_loss: 0.8782\n",
      "178/194, train_loss: 0.8735\n",
      "179/194, train_loss: 0.9050\n",
      "180/194, train_loss: 0.8006\n",
      "181/194, train_loss: 0.7031\n",
      "182/194, train_loss: 0.7625\n",
      "183/194, train_loss: 0.8884\n",
      "184/194, train_loss: 0.7845\n",
      "185/194, train_loss: 0.7977\n",
      "186/194, train_loss: 0.8578\n",
      "187/194, train_loss: 0.8827\n",
      "188/194, train_loss: 0.7476\n",
      "189/194, train_loss: 0.7920\n",
      "190/194, train_loss: 0.8122\n",
      "191/194, train_loss: 0.9055\n",
      "192/194, train_loss: 0.7098\n",
      "193/194, train_loss: 0.7466\n",
      "194/194, train_loss: 0.8759\n",
      "metric=0.30875028235216934, metric_tc=0.29412512527778745, metric_wt=0.4790551671758294, metric_et=0.15307055764909214\n",
      "metric=0.30875028235216934, metric_tc=0.29412512527778745, metric_wt=0.4790551671758294, metric_et=0.15307055764909214\n",
      "current epoch: 23 current epoch loss: 0.8209\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 23/80 [4:15:01<10:04:42, 636.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metric=0.30875028235216934, metric_tc=0.29412512527778745, metric_wt=0.4790551671758294, metric_et=0.15307055764909214\n",
      "0.30875028235216934\n",
      "saved new best metric model\n",
      "current epoch: 23 current mean dice: 0.3088 tc: 0.2941 wt: 0.4791 et: 0.1531\n",
      "best mean dice: 0.3088 at epoch: 23\n",
      "\n",
      " | Global Training Round : 24 |\n",
      "\n",
      "user 0 selected\n",
      "local epoch 1\n",
      "1/194, train_loss: 0.8843\n",
      "2/194, train_loss: 0.7129\n",
      "3/194, train_loss: 0.8922\n",
      "4/194, train_loss: 0.8273\n",
      "5/194, train_loss: 0.8800\n",
      "6/194, train_loss: 0.8893\n",
      "7/194, train_loss: 0.7729\n",
      "8/194, train_loss: 0.8985\n",
      "9/194, train_loss: 0.8194\n",
      "10/194, train_loss: 0.7973\n",
      "11/194, train_loss: 0.8320\n",
      "12/194, train_loss: 0.8152\n",
      "13/194, train_loss: 0.6847\n",
      "14/194, train_loss: 0.7776\n",
      "15/194, train_loss: 0.7573\n",
      "16/194, train_loss: 0.8427\n",
      "17/194, train_loss: 0.7524\n",
      "18/194, train_loss: 0.7888\n",
      "19/194, train_loss: 0.7713\n",
      "20/194, train_loss: 0.8002\n",
      "21/194, train_loss: 0.9019\n",
      "22/194, train_loss: 0.8493\n",
      "23/194, train_loss: 0.8447\n",
      "24/194, train_loss: 0.7336\n",
      "25/194, train_loss: 0.9278\n",
      "26/194, train_loss: 0.8305\n",
      "27/194, train_loss: 0.8703\n",
      "28/194, train_loss: 0.8532\n",
      "29/194, train_loss: 0.8751\n",
      "30/194, train_loss: 0.7532\n",
      "31/194, train_loss: 0.7833\n",
      "32/194, train_loss: 0.7032\n",
      "33/194, train_loss: 0.8584\n",
      "34/194, train_loss: 0.9064\n",
      "35/194, train_loss: 0.8445\n",
      "36/194, train_loss: 0.7046\n",
      "37/194, train_loss: 0.9259\n",
      "38/194, train_loss: 0.7801\n",
      "39/194, train_loss: 0.8260\n",
      "40/194, train_loss: 0.7343\n",
      "41/194, train_loss: 0.9024\n",
      "42/194, train_loss: 0.8835\n",
      "43/194, train_loss: 0.7720\n",
      "44/194, train_loss: 0.7290\n",
      "45/194, train_loss: 0.8262\n",
      "46/194, train_loss: 0.7018\n",
      "47/194, train_loss: 0.6670\n",
      "48/194, train_loss: 0.7788\n",
      "49/194, train_loss: 0.8626\n",
      "50/194, train_loss: 0.7768\n",
      "51/194, train_loss: 0.7602\n",
      "52/194, train_loss: 0.7344\n",
      "53/194, train_loss: 0.8934\n",
      "54/194, train_loss: 0.8510\n",
      "55/194, train_loss: 0.7905\n",
      "56/194, train_loss: 0.7562\n",
      "57/194, train_loss: 0.8587\n",
      "58/194, train_loss: 0.7997\n",
      "59/194, train_loss: 0.8603\n",
      "60/194, train_loss: 0.9570\n",
      "61/194, train_loss: 0.9255\n",
      "62/194, train_loss: 0.6346\n",
      "63/194, train_loss: 0.8934\n",
      "64/194, train_loss: 0.8036\n",
      "65/194, train_loss: 0.8119\n",
      "66/194, train_loss: 0.7324\n",
      "67/194, train_loss: 0.8325\n",
      "68/194, train_loss: 0.8578\n",
      "69/194, train_loss: 0.8758\n",
      "70/194, train_loss: 0.8572\n",
      "71/194, train_loss: 0.8150\n",
      "72/194, train_loss: 0.6356\n",
      "73/194, train_loss: 0.7572\n",
      "74/194, train_loss: 0.8958\n",
      "75/194, train_loss: 0.8288\n",
      "76/194, train_loss: 0.8007\n",
      "77/194, train_loss: 0.7879\n",
      "78/194, train_loss: 0.8290\n",
      "79/194, train_loss: 0.7378\n",
      "80/194, train_loss: 0.6780\n",
      "81/194, train_loss: 0.8178\n",
      "82/194, train_loss: 0.8311\n",
      "83/194, train_loss: 0.8756\n",
      "84/194, train_loss: 0.8407\n",
      "85/194, train_loss: 0.8972\n",
      "86/194, train_loss: 0.8658\n",
      "87/194, train_loss: 0.9256\n",
      "88/194, train_loss: 0.8660\n",
      "89/194, train_loss: 0.7917\n",
      "90/194, train_loss: 0.8757\n",
      "91/194, train_loss: 0.7897\n",
      "92/194, train_loss: 0.9005\n",
      "93/194, train_loss: 0.8334\n",
      "94/194, train_loss: 0.9173\n",
      "95/194, train_loss: 0.9038\n",
      "96/194, train_loss: 0.7961\n",
      "97/194, train_loss: 0.8892\n",
      "98/194, train_loss: 0.7813\n",
      "99/194, train_loss: 0.6645\n",
      "100/194, train_loss: 0.9400\n",
      "101/194, train_loss: 0.7878\n",
      "102/194, train_loss: 0.8672\n",
      "103/194, train_loss: 0.8487\n",
      "104/194, train_loss: 0.8171\n",
      "105/194, train_loss: 0.8771\n",
      "106/194, train_loss: 0.6343\n",
      "107/194, train_loss: 0.8179\n",
      "108/194, train_loss: 0.8283\n",
      "109/194, train_loss: 0.8104\n",
      "110/194, train_loss: 0.8117\n",
      "111/194, train_loss: 0.8531\n",
      "112/194, train_loss: 0.8345\n",
      "113/194, train_loss: 0.9010\n",
      "114/194, train_loss: 0.8591\n",
      "115/194, train_loss: 0.8811\n",
      "116/194, train_loss: 0.7858\n",
      "117/194, train_loss: 0.8887\n",
      "118/194, train_loss: 0.8632\n",
      "119/194, train_loss: 0.8934\n",
      "120/194, train_loss: 0.8115\n",
      "121/194, train_loss: 0.8277\n",
      "122/194, train_loss: 0.9272\n",
      "123/194, train_loss: 0.8981\n",
      "124/194, train_loss: 0.9116\n",
      "125/194, train_loss: 0.8679\n",
      "126/194, train_loss: 0.8838\n",
      "127/194, train_loss: 0.8751\n",
      "128/194, train_loss: 0.9023\n",
      "129/194, train_loss: 0.9341\n",
      "130/194, train_loss: 0.8400\n",
      "131/194, train_loss: 0.8291\n",
      "132/194, train_loss: 0.8212\n",
      "133/194, train_loss: 0.7515\n",
      "134/194, train_loss: 0.8529\n",
      "135/194, train_loss: 0.7734\n",
      "136/194, train_loss: 0.8238\n",
      "137/194, train_loss: 0.7863\n",
      "138/194, train_loss: 0.9191\n",
      "139/194, train_loss: 0.8342\n",
      "140/194, train_loss: 0.8583\n",
      "141/194, train_loss: 0.9071\n",
      "142/194, train_loss: 0.8885\n",
      "143/194, train_loss: 0.8377\n",
      "144/194, train_loss: 0.7770\n",
      "145/194, train_loss: 0.8311\n",
      "146/194, train_loss: 0.8265\n",
      "147/194, train_loss: 0.8606\n",
      "148/194, train_loss: 0.9068\n",
      "149/194, train_loss: 0.9300\n",
      "150/194, train_loss: 0.8549\n",
      "151/194, train_loss: 0.7553\n",
      "152/194, train_loss: 0.8810\n",
      "153/194, train_loss: 0.7880\n",
      "154/194, train_loss: 0.9787\n",
      "155/194, train_loss: 0.9367\n",
      "156/194, train_loss: 0.8225\n",
      "157/194, train_loss: 0.7884\n",
      "158/194, train_loss: 0.8512\n",
      "159/194, train_loss: 0.8553\n",
      "160/194, train_loss: 0.9026\n",
      "161/194, train_loss: 0.8828\n",
      "162/194, train_loss: 0.7889\n",
      "163/194, train_loss: 0.8349\n",
      "164/194, train_loss: 0.8696\n",
      "165/194, train_loss: 0.8867\n",
      "166/194, train_loss: 0.9078\n",
      "167/194, train_loss: 0.8039\n",
      "168/194, train_loss: 0.9322\n",
      "169/194, train_loss: 0.7534\n",
      "170/194, train_loss: 0.7694\n",
      "171/194, train_loss: 0.7480\n",
      "172/194, train_loss: 0.7749\n",
      "173/194, train_loss: 0.8132\n",
      "174/194, train_loss: 0.8713\n",
      "175/194, train_loss: 0.7782\n",
      "176/194, train_loss: 0.9206\n",
      "177/194, train_loss: 0.7942\n",
      "178/194, train_loss: 0.8476\n",
      "179/194, train_loss: 0.9042\n",
      "180/194, train_loss: 0.7611\n",
      "181/194, train_loss: 0.7106\n",
      "182/194, train_loss: 0.7488\n",
      "183/194, train_loss: 0.7332\n",
      "184/194, train_loss: 0.9089\n",
      "185/194, train_loss: 0.8570\n",
      "186/194, train_loss: 0.8961\n",
      "187/194, train_loss: 0.7169\n",
      "188/194, train_loss: 0.8383\n",
      "189/194, train_loss: 0.8619\n",
      "190/194, train_loss: 0.7669\n",
      "191/194, train_loss: 0.7272\n",
      "192/194, train_loss: 0.8259\n",
      "193/194, train_loss: 0.8776\n",
      "194/194, train_loss: 0.8374\n",
      "metric=0.2839088379405439, metric_tc=0.2613290410178403, metric_wt=0.45391738787293434, metric_et=0.1364800859397898\n",
      "metric=0.2839088379405439, metric_tc=0.2613290410178403, metric_wt=0.45391738787293434, metric_et=0.1364800859397898\n",
      "current epoch: 24 current epoch loss: 0.8287\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 24/80 [4:25:27<9:50:55, 633.13s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metric=0.2839088379405439, metric_tc=0.2613290410178403, metric_wt=0.45391738787293434, metric_et=0.1364800859397898\n",
      "0.2839088379405439\n",
      "current epoch: 24 current mean dice: 0.2839 tc: 0.2613 wt: 0.4539 et: 0.1365\n",
      "best mean dice: 0.3088 at epoch: 23\n",
      "\n",
      " | Global Training Round : 25 |\n",
      "\n",
      "user 0 selected\n",
      "local epoch 1\n",
      "1/194, train_loss: 0.8410\n",
      "2/194, train_loss: 0.8119\n",
      "3/194, train_loss: 0.7549\n",
      "4/194, train_loss: 0.8515\n",
      "5/194, train_loss: 0.9149\n",
      "6/194, train_loss: 0.7053\n",
      "7/194, train_loss: 0.7906\n",
      "8/194, train_loss: 0.7691\n",
      "9/194, train_loss: 0.8326\n",
      "10/194, train_loss: 0.8438\n",
      "11/194, train_loss: 0.7143\n",
      "12/194, train_loss: 0.6782\n",
      "13/194, train_loss: 0.8947\n",
      "14/194, train_loss: 0.8732\n",
      "15/194, train_loss: 0.8484\n",
      "16/194, train_loss: 0.7970\n",
      "17/194, train_loss: 0.7506\n",
      "18/194, train_loss: 0.6442\n",
      "19/194, train_loss: 0.7433\n",
      "20/194, train_loss: 0.8970\n",
      "21/194, train_loss: 0.8062\n",
      "22/194, train_loss: 0.9040\n",
      "23/194, train_loss: 0.7136\n",
      "24/194, train_loss: 0.7366\n",
      "25/194, train_loss: 0.9099\n",
      "26/194, train_loss: 0.8755\n",
      "27/194, train_loss: 0.7983\n",
      "28/194, train_loss: 0.7752\n",
      "29/194, train_loss: 0.8266\n",
      "30/194, train_loss: 0.7007\n",
      "31/194, train_loss: 0.7765\n",
      "32/194, train_loss: 0.7215\n",
      "33/194, train_loss: 0.7746\n",
      "34/194, train_loss: 0.8519\n",
      "35/194, train_loss: 0.9063\n",
      "36/194, train_loss: 0.8228\n",
      "37/194, train_loss: 0.8674\n",
      "38/194, train_loss: 0.7329\n",
      "39/194, train_loss: 0.8824\n",
      "40/194, train_loss: 0.8157\n",
      "41/194, train_loss: 0.9127\n",
      "42/194, train_loss: 0.9493\n",
      "43/194, train_loss: 0.8304\n",
      "44/194, train_loss: 0.7388\n",
      "45/194, train_loss: 0.7096\n",
      "46/194, train_loss: 0.8158\n",
      "47/194, train_loss: 0.7795\n",
      "48/194, train_loss: 0.7702\n",
      "49/194, train_loss: 0.8145\n",
      "50/194, train_loss: 0.8413\n",
      "51/194, train_loss: 0.8464\n",
      "52/194, train_loss: 0.8455\n",
      "53/194, train_loss: 0.9899\n",
      "54/194, train_loss: 0.6719\n",
      "55/194, train_loss: 0.8270\n",
      "56/194, train_loss: 0.7964\n",
      "57/194, train_loss: 0.8824\n",
      "58/194, train_loss: 0.8962\n",
      "59/194, train_loss: 0.6937\n",
      "60/194, train_loss: 0.9581\n",
      "61/194, train_loss: 0.6877\n",
      "62/194, train_loss: 0.7410\n",
      "63/194, train_loss: 0.8369\n",
      "64/194, train_loss: 0.7096\n",
      "65/194, train_loss: 0.7974\n",
      "66/194, train_loss: 0.5965\n",
      "67/194, train_loss: 0.7815\n",
      "68/194, train_loss: 0.8867\n",
      "69/194, train_loss: 0.8311\n",
      "70/194, train_loss: 0.7872\n",
      "71/194, train_loss: 0.7617\n",
      "72/194, train_loss: 0.6962\n",
      "73/194, train_loss: 0.7959\n",
      "74/194, train_loss: 0.9062\n",
      "75/194, train_loss: 0.7178\n",
      "76/194, train_loss: 0.7881\n",
      "77/194, train_loss: 0.7584\n",
      "78/194, train_loss: 0.8754\n",
      "79/194, train_loss: 0.7620\n",
      "80/194, train_loss: 0.7824\n",
      "81/194, train_loss: 0.6974\n",
      "82/194, train_loss: 0.8939\n",
      "83/194, train_loss: 0.8865\n",
      "84/194, train_loss: 0.8426\n",
      "85/194, train_loss: 0.8956\n",
      "86/194, train_loss: 0.8960\n",
      "87/194, train_loss: 0.7919\n",
      "88/194, train_loss: 0.8641\n",
      "89/194, train_loss: 0.8621\n",
      "90/194, train_loss: 0.8773\n",
      "91/194, train_loss: 0.8558\n",
      "92/194, train_loss: 0.9628\n",
      "93/194, train_loss: 0.8849\n",
      "94/194, train_loss: 0.8427\n",
      "95/194, train_loss: 0.9249\n",
      "96/194, train_loss: 0.7224\n",
      "97/194, train_loss: 0.9256\n",
      "98/194, train_loss: 0.8593\n",
      "99/194, train_loss: 0.7630\n",
      "100/194, train_loss: 0.9432\n",
      "101/194, train_loss: 0.9126\n",
      "102/194, train_loss: 0.9346\n",
      "103/194, train_loss: 0.8767\n",
      "104/194, train_loss: 0.8917\n",
      "105/194, train_loss: 0.9004\n",
      "106/194, train_loss: 0.6827\n",
      "107/194, train_loss: 0.7499\n",
      "108/194, train_loss: 0.7443\n",
      "109/194, train_loss: 0.8272\n",
      "110/194, train_loss: 0.8587\n",
      "111/194, train_loss: 0.9183\n",
      "112/194, train_loss: 0.7688\n",
      "113/194, train_loss: 0.8801\n",
      "114/194, train_loss: 0.8262\n",
      "115/194, train_loss: 0.6900\n",
      "116/194, train_loss: 0.8304\n",
      "117/194, train_loss: 0.8227\n",
      "118/194, train_loss: 0.8784\n",
      "119/194, train_loss: 0.7959\n",
      "120/194, train_loss: 0.7914\n",
      "121/194, train_loss: 0.9109\n",
      "122/194, train_loss: 0.8414\n",
      "123/194, train_loss: 0.8617\n",
      "124/194, train_loss: 0.8642\n",
      "125/194, train_loss: 0.9287\n",
      "126/194, train_loss: 0.9368\n",
      "127/194, train_loss: 0.8508\n",
      "128/194, train_loss: 0.7782\n",
      "129/194, train_loss: 0.7139\n",
      "130/194, train_loss: 0.7825\n",
      "131/194, train_loss: 0.8855\n",
      "132/194, train_loss: 0.8278\n",
      "133/194, train_loss: 0.7968\n",
      "134/194, train_loss: 0.7957\n",
      "135/194, train_loss: 0.8071\n",
      "136/194, train_loss: 0.7491\n",
      "137/194, train_loss: 0.6910\n",
      "138/194, train_loss: 0.7136\n",
      "139/194, train_loss: 0.8539\n",
      "140/194, train_loss: 0.8223\n",
      "141/194, train_loss: 0.8728\n",
      "142/194, train_loss: 0.9878\n",
      "143/194, train_loss: 0.9360\n",
      "144/194, train_loss: 0.8510\n",
      "145/194, train_loss: 0.9155\n",
      "146/194, train_loss: 0.8078\n",
      "147/194, train_loss: 0.9029\n",
      "148/194, train_loss: 0.8767\n",
      "149/194, train_loss: 0.9303\n",
      "150/194, train_loss: 0.8811\n",
      "151/194, train_loss: 0.8485\n",
      "152/194, train_loss: 0.6478\n",
      "153/194, train_loss: 0.9366\n",
      "154/194, train_loss: 0.7218\n",
      "155/194, train_loss: 0.8602\n",
      "156/194, train_loss: 0.8547\n",
      "157/194, train_loss: 0.8345\n",
      "158/194, train_loss: 0.9372\n",
      "159/194, train_loss: 0.7840\n",
      "160/194, train_loss: 0.9030\n",
      "161/194, train_loss: 0.8849\n",
      "162/194, train_loss: 0.8538\n",
      "163/194, train_loss: 0.7537\n",
      "164/194, train_loss: 0.7964\n",
      "165/194, train_loss: 0.7074\n",
      "166/194, train_loss: 0.8473\n",
      "167/194, train_loss: 0.8021\n",
      "168/194, train_loss: 0.7880\n",
      "169/194, train_loss: 0.8288\n",
      "170/194, train_loss: 0.8815\n",
      "171/194, train_loss: 0.8862\n",
      "172/194, train_loss: 0.7489\n",
      "173/194, train_loss: 0.7456\n",
      "174/194, train_loss: 0.7676\n",
      "175/194, train_loss: 0.8373\n",
      "176/194, train_loss: 0.8264\n",
      "177/194, train_loss: 0.8074\n",
      "178/194, train_loss: 0.7286\n",
      "179/194, train_loss: 0.8895\n",
      "180/194, train_loss: 0.8334\n",
      "181/194, train_loss: 0.8628\n",
      "182/194, train_loss: 0.7741\n",
      "183/194, train_loss: 0.7919\n",
      "184/194, train_loss: 0.7955\n",
      "185/194, train_loss: 0.8953\n",
      "186/194, train_loss: 0.8469\n",
      "187/194, train_loss: 0.9303\n",
      "188/194, train_loss: 0.9116\n",
      "189/194, train_loss: 0.8206\n",
      "190/194, train_loss: 0.7821\n",
      "191/194, train_loss: 0.7170\n",
      "192/194, train_loss: 0.7907\n",
      "193/194, train_loss: 0.9359\n",
      "194/194, train_loss: 0.7217\n",
      "metric=0.28285679624726373, metric_tc=0.2717687062298258, metric_wt=0.43426866953571636, metric_et=0.14253301382996142\n",
      "metric=0.28285679624726373, metric_tc=0.2717687062298258, metric_wt=0.43426866953571636, metric_et=0.14253301382996142\n",
      "current epoch: 25 current epoch loss: 0.8221\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███▏      | 25/80 [4:35:56<9:39:25, 632.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metric=0.28285679624726373, metric_tc=0.2717687062298258, metric_wt=0.43426866953571636, metric_et=0.14253301382996142\n",
      "0.28285679624726373\n",
      "current epoch: 25 current mean dice: 0.2829 tc: 0.2718 wt: 0.4343 et: 0.1425\n",
      "best mean dice: 0.3088 at epoch: 23\n",
      "\n",
      " | Global Training Round : 26 |\n",
      "\n",
      "user 0 selected\n",
      "local epoch 1\n",
      "1/194, train_loss: 0.7258\n",
      "2/194, train_loss: 0.9077\n",
      "3/194, train_loss: 0.9597\n",
      "4/194, train_loss: 0.7768\n",
      "5/194, train_loss: 0.7752\n",
      "6/194, train_loss: 0.8680\n",
      "7/194, train_loss: 0.8279\n",
      "8/194, train_loss: 0.7511\n",
      "9/194, train_loss: 0.8417\n",
      "10/194, train_loss: 0.8203\n",
      "11/194, train_loss: 0.8211\n",
      "12/194, train_loss: 0.8120\n",
      "13/194, train_loss: 0.7787\n",
      "14/194, train_loss: 0.7466\n",
      "15/194, train_loss: 0.6345\n",
      "16/194, train_loss: 0.7825\n",
      "17/194, train_loss: 0.7970\n",
      "18/194, train_loss: 0.7791\n",
      "19/194, train_loss: 0.8760\n",
      "20/194, train_loss: 0.8431\n",
      "21/194, train_loss: 0.7246\n",
      "22/194, train_loss: 0.7631\n",
      "23/194, train_loss: 0.9120\n",
      "24/194, train_loss: 0.8084\n",
      "25/194, train_loss: 0.7041\n",
      "26/194, train_loss: 0.8160\n",
      "27/194, train_loss: 0.8155\n",
      "28/194, train_loss: 0.8376\n",
      "29/194, train_loss: 0.7802\n",
      "30/194, train_loss: 0.8533\n",
      "31/194, train_loss: 0.9544\n",
      "32/194, train_loss: 0.7112\n",
      "33/194, train_loss: 0.8803\n",
      "34/194, train_loss: 0.6727\n",
      "35/194, train_loss: 0.8293\n",
      "36/194, train_loss: 0.9235\n",
      "37/194, train_loss: 0.8903\n",
      "38/194, train_loss: 0.8370\n",
      "39/194, train_loss: 0.7477\n",
      "40/194, train_loss: 0.6334\n",
      "41/194, train_loss: 0.7972\n",
      "42/194, train_loss: 0.8200\n",
      "43/194, train_loss: 0.7912\n",
      "44/194, train_loss: 0.9059\n",
      "45/194, train_loss: 0.6638\n",
      "46/194, train_loss: 0.7441\n",
      "47/194, train_loss: 0.9191\n",
      "48/194, train_loss: 0.6384\n",
      "49/194, train_loss: 0.8158\n",
      "50/194, train_loss: 0.7807\n",
      "51/194, train_loss: 0.6357\n",
      "52/194, train_loss: 0.8561\n",
      "53/194, train_loss: 0.8939\n",
      "54/194, train_loss: 0.8058\n",
      "55/194, train_loss: 0.7283\n",
      "56/194, train_loss: 0.7419\n",
      "57/194, train_loss: 0.9083\n",
      "58/194, train_loss: 0.9060\n",
      "59/194, train_loss: 0.8299\n",
      "60/194, train_loss: 0.8702\n",
      "61/194, train_loss: 0.8974\n",
      "62/194, train_loss: 0.7798\n",
      "63/194, train_loss: 0.8542\n",
      "64/194, train_loss: 0.8545\n",
      "65/194, train_loss: 0.9031\n",
      "66/194, train_loss: 0.8347\n",
      "67/194, train_loss: 0.7543\n",
      "68/194, train_loss: 0.7930\n",
      "69/194, train_loss: 0.9484\n",
      "70/194, train_loss: 0.6708\n",
      "71/194, train_loss: 0.8975\n",
      "72/194, train_loss: 0.8011\n",
      "73/194, train_loss: 0.8845\n",
      "74/194, train_loss: 0.6743\n",
      "75/194, train_loss: 0.9036\n",
      "76/194, train_loss: 0.8728\n",
      "77/194, train_loss: 0.8223\n",
      "78/194, train_loss: 0.8222\n",
      "79/194, train_loss: 0.8243\n",
      "80/194, train_loss: 0.6684\n",
      "81/194, train_loss: 0.8716\n",
      "82/194, train_loss: 0.8615\n",
      "83/194, train_loss: 0.7695\n",
      "84/194, train_loss: 0.8840\n",
      "85/194, train_loss: 0.9089\n",
      "86/194, train_loss: 0.8606\n",
      "87/194, train_loss: 0.8334\n",
      "88/194, train_loss: 0.8019\n",
      "89/194, train_loss: 0.8341\n",
      "90/194, train_loss: 0.8734\n",
      "91/194, train_loss: 0.8794\n",
      "92/194, train_loss: 0.8231\n",
      "93/194, train_loss: 0.6846\n",
      "94/194, train_loss: 0.8470\n",
      "95/194, train_loss: 0.7868\n",
      "96/194, train_loss: 0.8948\n",
      "97/194, train_loss: 0.8401\n",
      "98/194, train_loss: 0.8886\n",
      "99/194, train_loss: 0.7810\n",
      "100/194, train_loss: 0.8234\n",
      "101/194, train_loss: 0.8324\n",
      "102/194, train_loss: 0.8602\n",
      "103/194, train_loss: 0.8544\n",
      "104/194, train_loss: 0.9088\n",
      "105/194, train_loss: 0.6709\n",
      "106/194, train_loss: 0.8444\n",
      "107/194, train_loss: 0.8472\n",
      "108/194, train_loss: 0.8130\n",
      "109/194, train_loss: 0.7226\n",
      "110/194, train_loss: 0.8013\n",
      "111/194, train_loss: 0.7090\n",
      "112/194, train_loss: 0.7770\n",
      "113/194, train_loss: 0.8929\n",
      "114/194, train_loss: 0.8562\n",
      "115/194, train_loss: 0.7314\n",
      "116/194, train_loss: 0.8032\n",
      "117/194, train_loss: 0.9477\n",
      "118/194, train_loss: 0.8421\n",
      "119/194, train_loss: 0.8556\n",
      "120/194, train_loss: 0.8619\n",
      "121/194, train_loss: 0.8347\n",
      "122/194, train_loss: 0.7441\n",
      "123/194, train_loss: 0.9524\n",
      "124/194, train_loss: 0.8205\n",
      "125/194, train_loss: 0.9044\n",
      "126/194, train_loss: 0.9318\n",
      "127/194, train_loss: 0.9229\n",
      "128/194, train_loss: 0.7773\n",
      "129/194, train_loss: 0.7641\n",
      "130/194, train_loss: 0.8366\n",
      "131/194, train_loss: 0.7811\n",
      "132/194, train_loss: 0.8297\n",
      "133/194, train_loss: 0.8957\n",
      "134/194, train_loss: 0.9118\n",
      "135/194, train_loss: 0.7740\n",
      "136/194, train_loss: 0.8107\n",
      "137/194, train_loss: 0.6740\n",
      "138/194, train_loss: 0.9098\n",
      "139/194, train_loss: 0.6936\n",
      "140/194, train_loss: 0.8386\n",
      "141/194, train_loss: 0.9032\n",
      "142/194, train_loss: 0.8374\n",
      "143/194, train_loss: 0.8565\n",
      "144/194, train_loss: 0.9491\n",
      "145/194, train_loss: 0.8595\n",
      "146/194, train_loss: 0.8773\n",
      "147/194, train_loss: 0.8649\n",
      "148/194, train_loss: 0.9175\n",
      "149/194, train_loss: 0.7276\n",
      "150/194, train_loss: 0.8669\n",
      "151/194, train_loss: 0.8007\n",
      "152/194, train_loss: 0.7924\n",
      "153/194, train_loss: 0.9455\n",
      "154/194, train_loss: 0.7654\n",
      "155/194, train_loss: 0.9447\n",
      "156/194, train_loss: 0.8195\n",
      "157/194, train_loss: 0.8575\n",
      "158/194, train_loss: 0.7593\n",
      "159/194, train_loss: 0.8531\n",
      "160/194, train_loss: 0.9275\n",
      "161/194, train_loss: 0.8791\n",
      "162/194, train_loss: 0.9088\n",
      "163/194, train_loss: 0.8747\n",
      "164/194, train_loss: 0.9331\n",
      "165/194, train_loss: 0.7514\n",
      "166/194, train_loss: 0.8256\n",
      "167/194, train_loss: 0.8612\n",
      "168/194, train_loss: 0.8306\n",
      "169/194, train_loss: 0.8336\n",
      "170/194, train_loss: 0.8279\n",
      "171/194, train_loss: 0.8004\n",
      "172/194, train_loss: 0.9249\n",
      "173/194, train_loss: 0.7446\n",
      "174/194, train_loss: 0.8138\n",
      "175/194, train_loss: 0.7910\n",
      "176/194, train_loss: 0.8090\n",
      "177/194, train_loss: 0.9248\n",
      "178/194, train_loss: 0.7695\n",
      "179/194, train_loss: 0.8093\n",
      "180/194, train_loss: 0.7599\n",
      "181/194, train_loss: 0.7174\n",
      "182/194, train_loss: 0.7197\n",
      "183/194, train_loss: 0.9400\n",
      "184/194, train_loss: 0.7734\n",
      "185/194, train_loss: 0.9189\n",
      "186/194, train_loss: 0.8702\n",
      "187/194, train_loss: 0.8287\n",
      "188/194, train_loss: 0.9076\n",
      "189/194, train_loss: 0.6629\n",
      "190/194, train_loss: 0.8412\n",
      "191/194, train_loss: 0.8441\n",
      "192/194, train_loss: 0.7379\n",
      "193/194, train_loss: 0.8412\n",
      "194/194, train_loss: 0.8904\n",
      "metric=0.3388268941392501, metric_tc=0.33006511023268104, metric_wt=0.5118049923330545, metric_et=0.17461057643716535\n",
      "metric=0.3388268941392501, metric_tc=0.33006511023268104, metric_wt=0.5118049923330545, metric_et=0.17461057643716535\n",
      "current epoch: 26 current epoch loss: 0.8238\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▎      | 26/80 [4:46:46<9:33:31, 637.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metric=0.3388268941392501, metric_tc=0.33006511023268104, metric_wt=0.5118049923330545, metric_et=0.17461057643716535\n",
      "0.3388268941392501\n",
      "saved new best metric model\n",
      "current epoch: 26 current mean dice: 0.3388 tc: 0.3301 wt: 0.5118 et: 0.1746\n",
      "best mean dice: 0.3388 at epoch: 26\n",
      "\n",
      " | Global Training Round : 27 |\n",
      "\n",
      "user 0 selected\n",
      "local epoch 1\n",
      "1/194, train_loss: 0.7487\n",
      "2/194, train_loss: 0.8613\n",
      "3/194, train_loss: 0.9206\n",
      "4/194, train_loss: 0.7954\n",
      "5/194, train_loss: 0.8115\n",
      "6/194, train_loss: 0.8555\n",
      "7/194, train_loss: 0.8223\n",
      "8/194, train_loss: 0.7902\n",
      "9/194, train_loss: 0.8376\n",
      "10/194, train_loss: 0.7223\n",
      "11/194, train_loss: 0.7622\n",
      "12/194, train_loss: 0.9225\n",
      "13/194, train_loss: 0.8197\n",
      "14/194, train_loss: 0.7837\n",
      "15/194, train_loss: 0.8286\n",
      "16/194, train_loss: 0.7159\n",
      "17/194, train_loss: 0.8433\n",
      "18/194, train_loss: 0.7349\n",
      "19/194, train_loss: 0.7788\n",
      "20/194, train_loss: 0.8216\n",
      "21/194, train_loss: 0.9139\n",
      "22/194, train_loss: 0.7965\n",
      "23/194, train_loss: 0.8687\n",
      "24/194, train_loss: 0.8348\n",
      "25/194, train_loss: 0.7461\n",
      "26/194, train_loss: 0.8639\n",
      "27/194, train_loss: 0.7164\n",
      "28/194, train_loss: 0.7516\n",
      "29/194, train_loss: 0.9298\n",
      "30/194, train_loss: 0.8879\n",
      "31/194, train_loss: 0.8894\n",
      "32/194, train_loss: 0.7642\n",
      "33/194, train_loss: 0.9059\n",
      "34/194, train_loss: 0.9506\n",
      "35/194, train_loss: 0.8953\n",
      "36/194, train_loss: 0.8625\n",
      "37/194, train_loss: 0.6646\n",
      "38/194, train_loss: 0.8530\n",
      "39/194, train_loss: 0.8149\n",
      "40/194, train_loss: 0.7721\n",
      "41/194, train_loss: 0.7540\n",
      "42/194, train_loss: 0.7653\n",
      "43/194, train_loss: 0.7611\n",
      "44/194, train_loss: 0.7418\n",
      "45/194, train_loss: 0.7763\n",
      "46/194, train_loss: 0.7838\n",
      "47/194, train_loss: 0.7389\n",
      "48/194, train_loss: 0.7665\n",
      "49/194, train_loss: 0.7768\n",
      "50/194, train_loss: 0.7606\n",
      "51/194, train_loss: 0.8516\n",
      "52/194, train_loss: 0.7677\n",
      "53/194, train_loss: 0.8278\n",
      "54/194, train_loss: 0.7250\n",
      "55/194, train_loss: 0.7231\n",
      "56/194, train_loss: 0.7389\n",
      "57/194, train_loss: 0.8847\n",
      "58/194, train_loss: 0.7892\n",
      "59/194, train_loss: 0.7423\n",
      "60/194, train_loss: 0.9085\n",
      "61/194, train_loss: 0.9353\n",
      "62/194, train_loss: 0.7240\n",
      "63/194, train_loss: 0.6815\n",
      "64/194, train_loss: 0.8849\n",
      "65/194, train_loss: 0.7268\n",
      "66/194, train_loss: 0.8348\n",
      "67/194, train_loss: 0.8573\n",
      "68/194, train_loss: 0.8010\n",
      "69/194, train_loss: 0.8910\n",
      "70/194, train_loss: 0.8533\n",
      "71/194, train_loss: 0.8367\n",
      "72/194, train_loss: 0.8269\n",
      "73/194, train_loss: 0.8011\n",
      "74/194, train_loss: 0.6461\n",
      "75/194, train_loss: 0.7413\n",
      "76/194, train_loss: 0.8993\n",
      "77/194, train_loss: 0.7537\n",
      "78/194, train_loss: 0.8067\n",
      "79/194, train_loss: 0.7097\n",
      "80/194, train_loss: 0.8494\n",
      "81/194, train_loss: 0.7822\n",
      "82/194, train_loss: 0.8127\n",
      "83/194, train_loss: 0.8385\n",
      "84/194, train_loss: 0.8425\n",
      "85/194, train_loss: 0.8163\n",
      "86/194, train_loss: 0.8093\n",
      "87/194, train_loss: 0.8482\n",
      "88/194, train_loss: 0.6466\n",
      "89/194, train_loss: 0.9452\n",
      "90/194, train_loss: 0.8545\n",
      "91/194, train_loss: 0.8376\n",
      "92/194, train_loss: 0.9170\n",
      "93/194, train_loss: 0.8282\n",
      "94/194, train_loss: 0.8835\n",
      "95/194, train_loss: 0.8148\n",
      "96/194, train_loss: 0.7505\n",
      "97/194, train_loss: 0.9056\n",
      "98/194, train_loss: 0.9300\n",
      "99/194, train_loss: 0.8762\n",
      "100/194, train_loss: 0.7959\n",
      "101/194, train_loss: 0.9185\n",
      "102/194, train_loss: 0.8060\n",
      "103/194, train_loss: 0.8223\n",
      "104/194, train_loss: 0.7332\n",
      "105/194, train_loss: 0.6991\n",
      "106/194, train_loss: 0.7601\n",
      "107/194, train_loss: 0.8308\n",
      "108/194, train_loss: 0.7554\n",
      "109/194, train_loss: 0.7953\n",
      "110/194, train_loss: 0.8536\n",
      "111/194, train_loss: 0.8080\n",
      "112/194, train_loss: 0.7550\n",
      "113/194, train_loss: 0.8562\n",
      "114/194, train_loss: 0.7528\n",
      "115/194, train_loss: 0.7045\n",
      "116/194, train_loss: 0.6583\n",
      "117/194, train_loss: 0.8166\n",
      "118/194, train_loss: 0.8172\n",
      "119/194, train_loss: 0.8600\n",
      "120/194, train_loss: 0.7410\n",
      "121/194, train_loss: 0.9028\n",
      "122/194, train_loss: 0.8684\n",
      "123/194, train_loss: 0.8443\n",
      "124/194, train_loss: 0.8744\n",
      "125/194, train_loss: 0.8784\n",
      "126/194, train_loss: 0.8894\n",
      "127/194, train_loss: 0.8977\n",
      "128/194, train_loss: 0.8851\n",
      "129/194, train_loss: 0.9471\n",
      "130/194, train_loss: 0.8610\n",
      "131/194, train_loss: 0.9059\n",
      "132/194, train_loss: 0.8687\n",
      "133/194, train_loss: 0.7003\n",
      "134/194, train_loss: 0.9231\n",
      "135/194, train_loss: 0.7565\n",
      "136/194, train_loss: 0.6695\n",
      "137/194, train_loss: 0.8254\n",
      "138/194, train_loss: 0.7799\n",
      "139/194, train_loss: 0.8016\n",
      "140/194, train_loss: 0.8668\n",
      "141/194, train_loss: 0.8332\n",
      "142/194, train_loss: 0.8593\n",
      "143/194, train_loss: 0.8947\n",
      "144/194, train_loss: 0.7319\n",
      "145/194, train_loss: 0.9253\n",
      "146/194, train_loss: 0.8544\n",
      "147/194, train_loss: 0.8277\n",
      "148/194, train_loss: 0.9074\n",
      "149/194, train_loss: 0.8250\n",
      "150/194, train_loss: 0.8313\n",
      "151/194, train_loss: 0.8874\n",
      "152/194, train_loss: 0.9541\n",
      "153/194, train_loss: 0.9211\n",
      "154/194, train_loss: 0.9546\n",
      "155/194, train_loss: 0.8829\n",
      "156/194, train_loss: 0.9173\n",
      "157/194, train_loss: 0.9512\n",
      "158/194, train_loss: 0.9508\n",
      "159/194, train_loss: 0.8603\n",
      "160/194, train_loss: 0.8836\n",
      "161/194, train_loss: 0.8788\n",
      "162/194, train_loss: 0.8322\n",
      "163/194, train_loss: 0.8099\n",
      "164/194, train_loss: 0.9022\n",
      "165/194, train_loss: 0.7883\n",
      "166/194, train_loss: 0.8730\n",
      "167/194, train_loss: 0.8375\n",
      "168/194, train_loss: 0.9223\n",
      "169/194, train_loss: 0.6865\n",
      "170/194, train_loss: 0.7357\n",
      "171/194, train_loss: 0.8928\n",
      "172/194, train_loss: 0.7796\n",
      "173/194, train_loss: 0.7013\n",
      "174/194, train_loss: 0.8197\n",
      "175/194, train_loss: 0.6889\n",
      "176/194, train_loss: 0.8622\n",
      "177/194, train_loss: 0.7782\n",
      "178/194, train_loss: 0.9136\n",
      "179/194, train_loss: 0.9071\n",
      "180/194, train_loss: 0.8620\n",
      "181/194, train_loss: 0.7979\n",
      "182/194, train_loss: 0.8559\n",
      "183/194, train_loss: 0.6738\n",
      "184/194, train_loss: 0.7421\n",
      "185/194, train_loss: 0.8429\n",
      "186/194, train_loss: 0.8760\n",
      "187/194, train_loss: 0.9464\n",
      "188/194, train_loss: 0.8268\n",
      "189/194, train_loss: 0.8334\n",
      "190/194, train_loss: 0.7737\n",
      "191/194, train_loss: 0.9557\n",
      "192/194, train_loss: 0.8456\n",
      "193/194, train_loss: 0.8757\n",
      "194/194, train_loss: 0.8871\n",
      "metric=0.3179547190666199, metric_tc=0.3080263303903242, metric_wt=0.4880348313599825, metric_et=0.1578029872228702\n",
      "metric=0.3179547190666199, metric_tc=0.3080263303903242, metric_wt=0.4880348313599825, metric_et=0.1578029872228702\n",
      "current epoch: 27 current epoch loss: 0.8236\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 27/80 [4:57:09<9:19:07, 632.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metric=0.3179547190666199, metric_tc=0.3080263303903242, metric_wt=0.4880348313599825, metric_et=0.1578029872228702\n",
      "0.3179547190666199\n",
      "current epoch: 27 current mean dice: 0.3180 tc: 0.3080 wt: 0.4880 et: 0.1578\n",
      "best mean dice: 0.3388 at epoch: 26\n",
      "\n",
      " | Global Training Round : 28 |\n",
      "\n",
      "user 0 selected\n",
      "local epoch 1\n",
      "1/194, train_loss: 0.8885\n",
      "2/194, train_loss: 0.7352\n",
      "3/194, train_loss: 0.8204\n",
      "4/194, train_loss: 0.8827\n",
      "5/194, train_loss: 0.7526\n",
      "6/194, train_loss: 0.6343\n",
      "7/194, train_loss: 0.9651\n",
      "8/194, train_loss: 0.7474\n",
      "9/194, train_loss: 0.9408\n",
      "10/194, train_loss: 0.7400\n",
      "11/194, train_loss: 0.7663\n",
      "12/194, train_loss: 0.6159\n",
      "13/194, train_loss: 0.7449\n",
      "14/194, train_loss: 0.7187\n",
      "15/194, train_loss: 0.7766\n",
      "16/194, train_loss: 0.8190\n",
      "17/194, train_loss: 0.7688\n",
      "18/194, train_loss: 0.7943\n",
      "19/194, train_loss: 0.7865\n",
      "20/194, train_loss: 0.7944\n",
      "21/194, train_loss: 0.8985\n",
      "22/194, train_loss: 0.7336\n",
      "23/194, train_loss: 0.7145\n",
      "24/194, train_loss: 0.8588\n",
      "25/194, train_loss: 0.8218\n",
      "26/194, train_loss: 0.8301\n",
      "27/194, train_loss: 0.7954\n",
      "28/194, train_loss: 0.8084\n",
      "29/194, train_loss: 0.7579\n",
      "30/194, train_loss: 0.9236\n",
      "31/194, train_loss: 0.7670\n",
      "32/194, train_loss: 0.9681\n",
      "33/194, train_loss: 0.8575\n",
      "34/194, train_loss: 0.7491\n",
      "35/194, train_loss: 0.8399\n",
      "36/194, train_loss: 0.8496\n",
      "37/194, train_loss: 0.8096\n",
      "38/194, train_loss: 0.6920\n",
      "39/194, train_loss: 0.7495\n",
      "40/194, train_loss: 0.7528\n",
      "41/194, train_loss: 0.8398\n",
      "42/194, train_loss: 0.8472\n",
      "43/194, train_loss: 0.8146\n",
      "44/194, train_loss: 0.8758\n",
      "45/194, train_loss: 0.8751\n",
      "46/194, train_loss: 0.8804\n",
      "47/194, train_loss: 0.7695\n",
      "48/194, train_loss: 0.6220\n",
      "49/194, train_loss: 0.6286\n",
      "50/194, train_loss: 0.6216\n",
      "51/194, train_loss: 0.6990\n",
      "52/194, train_loss: 0.8353\n",
      "53/194, train_loss: 0.8000\n",
      "54/194, train_loss: 0.8393\n",
      "55/194, train_loss: 0.8055\n",
      "56/194, train_loss: 0.8651\n",
      "57/194, train_loss: 0.8952\n",
      "58/194, train_loss: 0.8399\n",
      "59/194, train_loss: 0.8063\n",
      "60/194, train_loss: 0.9207\n",
      "61/194, train_loss: 0.8091\n",
      "62/194, train_loss: 0.9053\n",
      "63/194, train_loss: 0.7302\n",
      "64/194, train_loss: 0.7768\n",
      "65/194, train_loss: 0.7609\n",
      "66/194, train_loss: 0.8501\n",
      "67/194, train_loss: 0.7932\n",
      "68/194, train_loss: 0.9576\n",
      "69/194, train_loss: 0.6869\n",
      "70/194, train_loss: 0.7935\n",
      "71/194, train_loss: 0.9004\n",
      "72/194, train_loss: 0.5680\n",
      "73/194, train_loss: 0.6943\n",
      "74/194, train_loss: 0.8318\n",
      "75/194, train_loss: 0.9300\n",
      "76/194, train_loss: 0.7609\n",
      "77/194, train_loss: 0.7972\n",
      "78/194, train_loss: 0.8399\n",
      "79/194, train_loss: 0.8087\n",
      "80/194, train_loss: 0.8403\n",
      "81/194, train_loss: 0.8511\n",
      "82/194, train_loss: 0.7585\n",
      "83/194, train_loss: 0.8724\n",
      "84/194, train_loss: 0.7548\n",
      "85/194, train_loss: 0.8366\n",
      "86/194, train_loss: 0.8231\n",
      "87/194, train_loss: 0.9178\n",
      "88/194, train_loss: 0.8895\n",
      "89/194, train_loss: 0.8485\n",
      "90/194, train_loss: 0.8361\n",
      "91/194, train_loss: 0.8809\n",
      "92/194, train_loss: 0.9186\n",
      "93/194, train_loss: 0.8068\n",
      "94/194, train_loss: 0.7446\n",
      "95/194, train_loss: 0.8671\n",
      "96/194, train_loss: 0.6929\n",
      "97/194, train_loss: 0.8629\n",
      "98/194, train_loss: 0.7330\n",
      "99/194, train_loss: 0.9273\n",
      "100/194, train_loss: 0.7804\n",
      "101/194, train_loss: 0.8514\n",
      "102/194, train_loss: 0.8232\n",
      "103/194, train_loss: 0.9034\n",
      "104/194, train_loss: 0.8863\n",
      "105/194, train_loss: 0.8959\n",
      "106/194, train_loss: 0.7395\n",
      "107/194, train_loss: 0.8410\n",
      "108/194, train_loss: 0.7088\n",
      "109/194, train_loss: 0.7213\n",
      "110/194, train_loss: 0.7763\n",
      "111/194, train_loss: 0.8635\n",
      "112/194, train_loss: 0.6757\n",
      "113/194, train_loss: 0.9299\n",
      "114/194, train_loss: 0.9516\n",
      "115/194, train_loss: 0.7537\n",
      "116/194, train_loss: 0.7891\n",
      "117/194, train_loss: 0.9255\n",
      "118/194, train_loss: 0.8642\n",
      "119/194, train_loss: 0.9122\n",
      "120/194, train_loss: 0.8830\n",
      "121/194, train_loss: 0.8553\n",
      "122/194, train_loss: 0.8018\n",
      "123/194, train_loss: 0.9245\n",
      "124/194, train_loss: 0.9300\n",
      "125/194, train_loss: 0.8936\n",
      "126/194, train_loss: 0.8816\n",
      "127/194, train_loss: 0.8659\n",
      "128/194, train_loss: 0.7306\n",
      "129/194, train_loss: 0.6566\n",
      "130/194, train_loss: 0.8774\n",
      "131/194, train_loss: 0.7243\n",
      "132/194, train_loss: 0.6848\n",
      "133/194, train_loss: 0.8501\n",
      "134/194, train_loss: 0.8342\n",
      "135/194, train_loss: 0.7803\n",
      "136/194, train_loss: 0.8196\n",
      "137/194, train_loss: 0.8354\n",
      "138/194, train_loss: 0.7773\n",
      "139/194, train_loss: 0.8854\n",
      "140/194, train_loss: 0.8528\n",
      "141/194, train_loss: 0.8087\n",
      "142/194, train_loss: 0.8904\n",
      "143/194, train_loss: 0.8190\n",
      "144/194, train_loss: 0.8699\n",
      "145/194, train_loss: 0.9396\n",
      "146/194, train_loss: 0.8367\n",
      "147/194, train_loss: 0.8144\n",
      "148/194, train_loss: 0.7414\n",
      "149/194, train_loss: 0.8929\n",
      "150/194, train_loss: 0.8629\n",
      "151/194, train_loss: 0.9561\n",
      "152/194, train_loss: 0.8193\n",
      "153/194, train_loss: 0.8740\n",
      "154/194, train_loss: 0.8792\n",
      "155/194, train_loss: 0.9047\n",
      "156/194, train_loss: 0.9271\n",
      "157/194, train_loss: 0.7770\n",
      "158/194, train_loss: 0.8080\n",
      "159/194, train_loss: 0.7514\n",
      "160/194, train_loss: 0.5280\n",
      "161/194, train_loss: 0.8074\n",
      "162/194, train_loss: 0.7514\n",
      "163/194, train_loss: 0.8821\n",
      "164/194, train_loss: 0.8195\n",
      "165/194, train_loss: 0.8534\n",
      "166/194, train_loss: 0.9240\n",
      "167/194, train_loss: 0.8686\n",
      "168/194, train_loss: 0.7130\n",
      "169/194, train_loss: 0.7999\n",
      "170/194, train_loss: 0.8234\n",
      "171/194, train_loss: 0.8879\n",
      "172/194, train_loss: 0.6762\n",
      "173/194, train_loss: 0.6252\n",
      "174/194, train_loss: 0.7928\n",
      "175/194, train_loss: 0.8178\n",
      "176/194, train_loss: 0.7147\n",
      "177/194, train_loss: 0.8034\n",
      "178/194, train_loss: 0.8032\n",
      "179/194, train_loss: 0.7574\n",
      "180/194, train_loss: 0.8835\n",
      "181/194, train_loss: 0.8002\n",
      "182/194, train_loss: 0.6783\n",
      "183/194, train_loss: 0.8579\n",
      "184/194, train_loss: 0.8601\n",
      "185/194, train_loss: 0.8718\n",
      "186/194, train_loss: 0.8840\n",
      "187/194, train_loss: 0.8461\n",
      "188/194, train_loss: 0.7371\n",
      "189/194, train_loss: 0.7729\n",
      "190/194, train_loss: 0.7956\n",
      "191/194, train_loss: 0.8269\n",
      "192/194, train_loss: 0.8575\n",
      "193/194, train_loss: 0.7154\n",
      "194/194, train_loss: 0.7741\n",
      "metric=0.2712850412353873, metric_tc=0.26874260293940705, metric_wt=0.40160903551926214, metric_et=0.1435034852474928\n",
      "metric=0.2712850412353873, metric_tc=0.26874260293940705, metric_wt=0.40160903551926214, metric_et=0.1435034852474928\n",
      "current epoch: 28 current epoch loss: 0.8130\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 28/80 [5:07:34<9:06:38, 630.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metric=0.2712850412353873, metric_tc=0.26874260293940705, metric_wt=0.40160903551926214, metric_et=0.1435034852474928\n",
      "0.2712850412353873\n",
      "current epoch: 28 current mean dice: 0.2713 tc: 0.2687 wt: 0.4016 et: 0.1435\n",
      "best mean dice: 0.3388 at epoch: 26\n",
      "\n",
      " | Global Training Round : 29 |\n",
      "\n",
      "user 0 selected\n",
      "local epoch 1\n",
      "1/194, train_loss: 0.8334\n",
      "2/194, train_loss: 0.8213\n",
      "3/194, train_loss: 0.8499\n",
      "4/194, train_loss: 0.7181\n",
      "5/194, train_loss: 0.8120\n",
      "6/194, train_loss: 0.7269\n",
      "7/194, train_loss: 0.8863\n",
      "8/194, train_loss: 0.8029\n",
      "9/194, train_loss: 0.8547\n",
      "10/194, train_loss: 0.6876\n",
      "11/194, train_loss: 0.9581\n",
      "12/194, train_loss: 0.8096\n",
      "13/194, train_loss: 0.7632\n",
      "14/194, train_loss: 0.6538\n",
      "15/194, train_loss: 0.8487\n",
      "16/194, train_loss: 0.7293\n",
      "17/194, train_loss: 0.8503\n",
      "18/194, train_loss: 0.7885\n",
      "19/194, train_loss: 0.8215\n",
      "20/194, train_loss: 0.7713\n",
      "21/194, train_loss: 0.8380\n",
      "22/194, train_loss: 0.8674\n",
      "23/194, train_loss: 0.7465\n",
      "24/194, train_loss: 0.6331\n",
      "25/194, train_loss: 0.8309\n",
      "26/194, train_loss: 0.8580\n",
      "27/194, train_loss: 0.8178\n",
      "28/194, train_loss: 0.9152\n",
      "29/194, train_loss: 0.9905\n",
      "30/194, train_loss: 0.8927\n",
      "31/194, train_loss: 0.8218\n",
      "32/194, train_loss: 0.7621\n",
      "33/194, train_loss: 0.8160\n",
      "34/194, train_loss: 0.8719\n",
      "35/194, train_loss: 0.7704\n",
      "36/194, train_loss: 0.6884\n",
      "37/194, train_loss: 0.6914\n",
      "38/194, train_loss: 0.7947\n",
      "39/194, train_loss: 0.8897\n",
      "40/194, train_loss: 0.8419\n",
      "41/194, train_loss: 0.7736\n",
      "42/194, train_loss: 0.7285\n",
      "43/194, train_loss: 0.7349\n",
      "44/194, train_loss: 0.8965\n",
      "45/194, train_loss: 0.8450\n",
      "46/194, train_loss: 0.7290\n",
      "47/194, train_loss: 0.7851\n",
      "48/194, train_loss: 0.6456\n",
      "49/194, train_loss: 0.7882\n",
      "50/194, train_loss: 0.7233\n",
      "51/194, train_loss: 0.8991\n",
      "52/194, train_loss: 0.8014\n",
      "53/194, train_loss: 0.8967\n",
      "54/194, train_loss: 0.7739\n",
      "55/194, train_loss: 0.8632\n",
      "56/194, train_loss: 0.7122\n",
      "57/194, train_loss: 0.8957\n",
      "58/194, train_loss: 0.8909\n",
      "59/194, train_loss: 0.8532\n",
      "60/194, train_loss: 0.8518\n",
      "61/194, train_loss: 0.6248\n",
      "62/194, train_loss: 0.7265\n",
      "63/194, train_loss: 0.7867\n",
      "64/194, train_loss: 0.9423\n",
      "65/194, train_loss: 0.6604\n",
      "66/194, train_loss: 0.7447\n",
      "67/194, train_loss: 0.6782\n",
      "68/194, train_loss: 0.7597\n",
      "69/194, train_loss: 0.8209\n",
      "70/194, train_loss: 0.9332\n",
      "71/194, train_loss: 0.8853\n",
      "72/194, train_loss: 0.8490\n",
      "73/194, train_loss: 0.8663\n",
      "74/194, train_loss: 0.8214\n",
      "75/194, train_loss: 0.8210\n",
      "76/194, train_loss: 0.7164\n",
      "77/194, train_loss: 0.7382\n",
      "78/194, train_loss: 0.8077\n",
      "79/194, train_loss: 0.7153\n",
      "80/194, train_loss: 0.5529\n",
      "81/194, train_loss: 0.8932\n",
      "82/194, train_loss: 0.9513\n",
      "83/194, train_loss: 0.9566\n",
      "84/194, train_loss: 0.9073\n",
      "85/194, train_loss: 0.7338\n",
      "86/194, train_loss: 0.8026\n",
      "87/194, train_loss: 0.8968\n",
      "88/194, train_loss: 0.8285\n",
      "89/194, train_loss: 0.8772\n",
      "90/194, train_loss: 0.9842\n",
      "91/194, train_loss: 0.7781\n",
      "92/194, train_loss: 0.8700\n",
      "93/194, train_loss: 0.8165\n",
      "94/194, train_loss: 0.7907\n",
      "95/194, train_loss: 0.7966\n",
      "96/194, train_loss: 0.9248\n",
      "97/194, train_loss: 0.7684\n",
      "98/194, train_loss: 0.8806\n",
      "99/194, train_loss: 0.9848\n",
      "100/194, train_loss: 0.8156\n",
      "101/194, train_loss: 0.8273\n",
      "102/194, train_loss: 0.8042\n",
      "103/194, train_loss: 0.9145\n",
      "104/194, train_loss: 0.8280\n",
      "105/194, train_loss: 0.7486\n",
      "106/194, train_loss: 0.7440\n",
      "107/194, train_loss: 0.6431\n",
      "108/194, train_loss: 0.7198\n",
      "109/194, train_loss: 0.7646\n",
      "110/194, train_loss: 0.8407\n",
      "111/194, train_loss: 0.7651\n",
      "112/194, train_loss: 0.7948\n",
      "113/194, train_loss: 0.8673\n",
      "114/194, train_loss: 0.8984\n",
      "115/194, train_loss: 0.5873\n",
      "116/194, train_loss: 0.9182\n",
      "117/194, train_loss: 0.7419\n",
      "118/194, train_loss: 0.6915\n",
      "119/194, train_loss: 0.8141\n",
      "120/194, train_loss: 0.7139\n",
      "121/194, train_loss: 0.9478\n",
      "122/194, train_loss: 0.9504\n",
      "123/194, train_loss: 0.9680\n",
      "124/194, train_loss: 0.7893\n",
      "125/194, train_loss: 0.8926\n",
      "126/194, train_loss: 0.8255\n",
      "127/194, train_loss: 0.7851\n",
      "128/194, train_loss: 0.8553\n",
      "129/194, train_loss: 0.8418\n",
      "130/194, train_loss: 0.7097\n",
      "131/194, train_loss: 0.8096\n",
      "132/194, train_loss: 0.8827\n",
      "133/194, train_loss: 0.7770\n",
      "134/194, train_loss: 0.8855\n",
      "135/194, train_loss: 0.9021\n",
      "136/194, train_loss: 0.8283\n",
      "137/194, train_loss: 0.5187\n",
      "138/194, train_loss: 0.7588\n",
      "139/194, train_loss: 0.6845\n",
      "140/194, train_loss: 0.7907\n",
      "141/194, train_loss: 0.8009\n",
      "142/194, train_loss: 0.6792\n",
      "143/194, train_loss: 0.8554\n",
      "144/194, train_loss: 0.8052\n",
      "145/194, train_loss: 0.7830\n",
      "146/194, train_loss: 0.7099\n",
      "147/194, train_loss: 0.8764\n",
      "148/194, train_loss: 0.7436\n",
      "149/194, train_loss: 0.8623\n",
      "150/194, train_loss: 0.8903\n",
      "151/194, train_loss: 0.9582\n",
      "152/194, train_loss: 0.8684\n",
      "153/194, train_loss: 0.8661\n",
      "154/194, train_loss: 0.8979\n",
      "155/194, train_loss: 0.9051\n",
      "156/194, train_loss: 0.8433\n",
      "157/194, train_loss: 0.9263\n",
      "158/194, train_loss: 0.9320\n",
      "159/194, train_loss: 0.9214\n",
      "160/194, train_loss: 0.9104\n",
      "161/194, train_loss: 0.7521\n",
      "162/194, train_loss: 0.8287\n",
      "163/194, train_loss: 0.7934\n",
      "164/194, train_loss: 0.7395\n",
      "165/194, train_loss: 0.7189\n",
      "166/194, train_loss: 0.8758\n",
      "167/194, train_loss: 0.9253\n",
      "168/194, train_loss: 0.7800\n",
      "169/194, train_loss: 0.6452\n",
      "170/194, train_loss: 0.8667\n",
      "171/194, train_loss: 0.6789\n",
      "172/194, train_loss: 0.7749\n",
      "173/194, train_loss: 0.7113\n",
      "174/194, train_loss: 0.7506\n",
      "175/194, train_loss: 0.6224\n",
      "176/194, train_loss: 0.7613\n",
      "177/194, train_loss: 0.7846\n",
      "178/194, train_loss: 0.7749\n",
      "179/194, train_loss: 0.8101\n",
      "180/194, train_loss: 0.8194\n",
      "181/194, train_loss: 0.8334\n",
      "182/194, train_loss: 0.6922\n",
      "183/194, train_loss: 0.6037\n",
      "184/194, train_loss: 0.7607\n",
      "185/194, train_loss: 0.7783\n",
      "186/194, train_loss: 0.9219\n",
      "187/194, train_loss: 0.7892\n",
      "188/194, train_loss: 0.8019\n",
      "189/194, train_loss: 0.7828\n",
      "190/194, train_loss: 0.7772\n",
      "191/194, train_loss: 0.9084\n",
      "192/194, train_loss: 0.7803\n",
      "193/194, train_loss: 0.9145\n",
      "194/194, train_loss: 0.8572\n",
      "metric=0.3342140316963196, metric_tc=0.32850446334729594, metric_wt=0.5029165493324399, metric_et=0.17122108194356164\n",
      "metric=0.3342140316963196, metric_tc=0.32850446334729594, metric_wt=0.5029165493324399, metric_et=0.17122108194356164\n",
      "current epoch: 29 current epoch loss: 0.8083\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▋      | 29/80 [5:17:43<8:50:36, 624.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metric=0.3342140316963196, metric_tc=0.32850446334729594, metric_wt=0.5029165493324399, metric_et=0.17122108194356164\n",
      "0.3342140316963196\n",
      "current epoch: 29 current mean dice: 0.3342 tc: 0.3285 wt: 0.5029 et: 0.1712\n",
      "best mean dice: 0.3388 at epoch: 26\n",
      "\n",
      " | Global Training Round : 30 |\n",
      "\n",
      "user 0 selected\n",
      "local epoch 1\n",
      "1/194, train_loss: 0.8226\n",
      "2/194, train_loss: 0.9364\n",
      "3/194, train_loss: 0.7614\n",
      "4/194, train_loss: 0.8779\n",
      "5/194, train_loss: 0.8346\n",
      "6/194, train_loss: 0.8091\n",
      "7/194, train_loss: 0.8421\n",
      "8/194, train_loss: 0.7283\n",
      "9/194, train_loss: 0.7975\n",
      "10/194, train_loss: 0.8848\n",
      "11/194, train_loss: 0.8889\n",
      "12/194, train_loss: 0.6373\n",
      "13/194, train_loss: 0.7549\n",
      "14/194, train_loss: 0.8048\n",
      "15/194, train_loss: 0.6974\n",
      "16/194, train_loss: 0.7320\n",
      "17/194, train_loss: 0.9150\n",
      "18/194, train_loss: 0.7397\n",
      "19/194, train_loss: 0.8858\n",
      "20/194, train_loss: 0.9170\n",
      "21/194, train_loss: 0.8653\n",
      "22/194, train_loss: 0.8978\n",
      "23/194, train_loss: 0.8587\n",
      "24/194, train_loss: 0.7548\n",
      "25/194, train_loss: 0.9002\n",
      "26/194, train_loss: 0.8672\n",
      "27/194, train_loss: 0.8032\n",
      "28/194, train_loss: 0.9475\n",
      "29/194, train_loss: 0.9403\n",
      "30/194, train_loss: 0.8799\n",
      "31/194, train_loss: 0.8843\n",
      "32/194, train_loss: 0.8442\n",
      "33/194, train_loss: 0.8101\n",
      "34/194, train_loss: 0.8294\n",
      "35/194, train_loss: 0.8138\n",
      "36/194, train_loss: 0.8147\n",
      "37/194, train_loss: 0.7713\n",
      "38/194, train_loss: 0.8733\n",
      "39/194, train_loss: 0.8483\n",
      "40/194, train_loss: 0.7259\n",
      "41/194, train_loss: 0.8520\n",
      "42/194, train_loss: 0.7763\n",
      "43/194, train_loss: 0.7005\n",
      "44/194, train_loss: 0.8392\n",
      "45/194, train_loss: 0.7218\n",
      "46/194, train_loss: 0.7417\n",
      "47/194, train_loss: 0.8013\n",
      "48/194, train_loss: 0.8060\n",
      "49/194, train_loss: 0.7902\n",
      "50/194, train_loss: 0.7460\n",
      "51/194, train_loss: 0.8887\n",
      "52/194, train_loss: 0.6696\n",
      "53/194, train_loss: 0.8483\n",
      "54/194, train_loss: 0.8588\n",
      "55/194, train_loss: 0.8154\n",
      "56/194, train_loss: 0.8036\n",
      "57/194, train_loss: 0.8866\n",
      "58/194, train_loss: 0.9701\n",
      "59/194, train_loss: 0.7732\n",
      "60/194, train_loss: 0.9108\n",
      "61/194, train_loss: 0.8310\n",
      "62/194, train_loss: 0.7234\n",
      "63/194, train_loss: 0.9349\n",
      "64/194, train_loss: 0.7985\n",
      "65/194, train_loss: 0.8569\n",
      "66/194, train_loss: 0.9188\n",
      "67/194, train_loss: 0.8870\n",
      "68/194, train_loss: 0.8249\n",
      "69/194, train_loss: 0.7755\n",
      "70/194, train_loss: 0.9286\n",
      "71/194, train_loss: 0.8161\n",
      "72/194, train_loss: 0.7444\n",
      "73/194, train_loss: 0.7908\n",
      "74/194, train_loss: 0.7626\n",
      "75/194, train_loss: 0.7553\n",
      "76/194, train_loss: 0.8122\n",
      "77/194, train_loss: 0.6457\n",
      "78/194, train_loss: 0.8347\n",
      "79/194, train_loss: 0.9087\n",
      "80/194, train_loss: 0.7144\n",
      "81/194, train_loss: 0.9292\n",
      "82/194, train_loss: 0.8047\n",
      "83/194, train_loss: 0.8727\n",
      "84/194, train_loss: 0.8028\n",
      "85/194, train_loss: 0.9037\n",
      "86/194, train_loss: 0.8638\n",
      "87/194, train_loss: 0.8212\n",
      "88/194, train_loss: 0.8826\n",
      "89/194, train_loss: 0.8651\n",
      "90/194, train_loss: 0.8478\n",
      "91/194, train_loss: 0.9431\n",
      "92/194, train_loss: 0.8622\n",
      "93/194, train_loss: 0.7932\n",
      "94/194, train_loss: 0.8965\n",
      "95/194, train_loss: 0.8362\n",
      "96/194, train_loss: 0.7951\n",
      "97/194, train_loss: 0.7044\n",
      "98/194, train_loss: 0.7921\n",
      "99/194, train_loss: 0.7204\n",
      "100/194, train_loss: 0.8365\n",
      "101/194, train_loss: 0.8052\n",
      "102/194, train_loss: 0.7872\n",
      "103/194, train_loss: 0.7047\n",
      "104/194, train_loss: 0.8575\n",
      "105/194, train_loss: 0.7550\n",
      "106/194, train_loss: 0.7759\n",
      "107/194, train_loss: 0.8306\n",
      "108/194, train_loss: 0.7746\n",
      "109/194, train_loss: 0.6544\n",
      "110/194, train_loss: 0.8146\n",
      "111/194, train_loss: 0.8654\n",
      "112/194, train_loss: 0.9083\n",
      "113/194, train_loss: 0.8579\n",
      "114/194, train_loss: 0.8931\n",
      "115/194, train_loss: 0.8263\n",
      "116/194, train_loss: 0.8319\n",
      "117/194, train_loss: 0.7642\n",
      "118/194, train_loss: 0.7371\n",
      "119/194, train_loss: 0.9127\n",
      "120/194, train_loss: 0.6953\n",
      "121/194, train_loss: 0.9406\n",
      "122/194, train_loss: 0.9324\n",
      "123/194, train_loss: 0.8672\n",
      "124/194, train_loss: 0.8777\n",
      "125/194, train_loss: 0.6946\n",
      "126/194, train_loss: 0.8868\n",
      "127/194, train_loss: 0.9457\n",
      "128/194, train_loss: 0.8857\n",
      "129/194, train_loss: 0.7112\n",
      "130/194, train_loss: 0.9070\n",
      "131/194, train_loss: 0.7606\n",
      "132/194, train_loss: 0.7544\n",
      "133/194, train_loss: 0.8851\n",
      "134/194, train_loss: 0.8657\n",
      "135/194, train_loss: 0.7813\n",
      "136/194, train_loss: 0.7797\n",
      "137/194, train_loss: 0.8945\n",
      "138/194, train_loss: 0.6688\n",
      "139/194, train_loss: 0.8365\n",
      "140/194, train_loss: 0.6823\n",
      "141/194, train_loss: 0.9039\n",
      "142/194, train_loss: 0.7089\n",
      "143/194, train_loss: 0.8610\n",
      "144/194, train_loss: 0.7614\n",
      "145/194, train_loss: 0.9443\n",
      "146/194, train_loss: 0.7797\n",
      "147/194, train_loss: 0.8931\n",
      "148/194, train_loss: 0.7902\n",
      "149/194, train_loss: 0.8624\n",
      "150/194, train_loss: 0.9229\n",
      "151/194, train_loss: 0.9340\n",
      "152/194, train_loss: 0.7979\n",
      "153/194, train_loss: 0.7658\n",
      "154/194, train_loss: 0.8699\n",
      "155/194, train_loss: 0.9375\n",
      "156/194, train_loss: 0.8552\n",
      "157/194, train_loss: 0.9307\n",
      "158/194, train_loss: 0.9150\n",
      "159/194, train_loss: 0.6579\n",
      "160/194, train_loss: 0.8131\n",
      "161/194, train_loss: 0.8647\n",
      "162/194, train_loss: 0.8429\n",
      "163/194, train_loss: 0.8141\n",
      "164/194, train_loss: 0.8862\n",
      "165/194, train_loss: 0.8488\n",
      "166/194, train_loss: 0.8475\n",
      "167/194, train_loss: 0.7879\n",
      "168/194, train_loss: 0.8830\n",
      "169/194, train_loss: 0.8513\n",
      "170/194, train_loss: 0.8185\n",
      "171/194, train_loss: 0.7946\n",
      "172/194, train_loss: 0.8177\n",
      "173/194, train_loss: 0.7492\n",
      "174/194, train_loss: 0.8163\n",
      "175/194, train_loss: 0.7472\n",
      "176/194, train_loss: 0.7445\n",
      "177/194, train_loss: 0.8811\n",
      "178/194, train_loss: 0.6351\n",
      "179/194, train_loss: 0.7864\n",
      "180/194, train_loss: 0.7915\n",
      "181/194, train_loss: 0.9039\n",
      "182/194, train_loss: 0.7174\n",
      "183/194, train_loss: 0.6806\n",
      "184/194, train_loss: 0.7082\n",
      "185/194, train_loss: 0.8853\n",
      "186/194, train_loss: 0.8892\n",
      "187/194, train_loss: 0.8500\n",
      "188/194, train_loss: 0.8330\n",
      "189/194, train_loss: 0.7871\n",
      "190/194, train_loss: 0.8170\n",
      "191/194, train_loss: 0.8028\n",
      "192/194, train_loss: 0.9013\n",
      "193/194, train_loss: 0.8442\n",
      "194/194, train_loss: 0.8648\n",
      "metric=0.29603972658514977, metric_tc=0.2893551971452932, metric_wt=0.44304550004502136, metric_et=0.15571848093532026\n",
      "metric=0.29603972658514977, metric_tc=0.2893551971452932, metric_wt=0.44304550004502136, metric_et=0.15571848093532026\n",
      "current epoch: 30 current epoch loss: 0.8229\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 30/80 [5:27:57<8:37:36, 621.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metric=0.29603972658514977, metric_tc=0.2893551971452932, metric_wt=0.44304550004502136, metric_et=0.15571848093532026\n",
      "0.29603972658514977\n",
      "current epoch: 30 current mean dice: 0.2960 tc: 0.2894 wt: 0.4430 et: 0.1557\n",
      "best mean dice: 0.3388 at epoch: 26\n",
      "\n",
      " | Global Training Round : 31 |\n",
      "\n",
      "user 0 selected\n",
      "local epoch 1\n",
      "1/194, train_loss: 0.7651\n",
      "2/194, train_loss: 0.7464\n",
      "3/194, train_loss: 0.8192\n",
      "4/194, train_loss: 0.8228\n",
      "5/194, train_loss: 0.8893\n",
      "6/194, train_loss: 0.8999\n",
      "7/194, train_loss: 0.7918\n",
      "8/194, train_loss: 0.9500\n",
      "9/194, train_loss: 0.9173\n",
      "10/194, train_loss: 0.8844\n",
      "11/194, train_loss: 0.8175\n",
      "12/194, train_loss: 0.8812\n",
      "13/194, train_loss: 0.7821\n",
      "14/194, train_loss: 0.7701\n",
      "15/194, train_loss: 0.7537\n",
      "16/194, train_loss: 0.7463\n",
      "17/194, train_loss: 0.8434\n",
      "18/194, train_loss: 0.8282\n",
      "19/194, train_loss: 0.7572\n",
      "20/194, train_loss: 0.8604\n",
      "21/194, train_loss: 0.7972\n",
      "22/194, train_loss: 0.7765\n",
      "23/194, train_loss: 0.8564\n",
      "24/194, train_loss: 0.6144\n",
      "25/194, train_loss: 0.7855\n",
      "26/194, train_loss: 0.7517\n",
      "27/194, train_loss: 0.8556\n",
      "28/194, train_loss: 0.9073\n",
      "29/194, train_loss: 0.8998\n",
      "30/194, train_loss: 0.8815\n",
      "31/194, train_loss: 0.7527\n",
      "32/194, train_loss: 0.7771\n",
      "33/194, train_loss: 0.9582\n",
      "34/194, train_loss: 0.7791\n",
      "35/194, train_loss: 0.8473\n",
      "36/194, train_loss: 0.6447\n",
      "37/194, train_loss: 0.6935\n",
      "38/194, train_loss: 0.7046\n",
      "39/194, train_loss: 0.6609\n",
      "40/194, train_loss: 0.8363\n",
      "41/194, train_loss: 0.7751\n",
      "42/194, train_loss: 0.9108\n",
      "43/194, train_loss: 0.8741\n",
      "44/194, train_loss: 0.8573\n",
      "45/194, train_loss: 0.7472\n",
      "46/194, train_loss: 0.6717\n",
      "47/194, train_loss: 0.8273\n",
      "48/194, train_loss: 0.7881\n",
      "49/194, train_loss: 0.8321\n",
      "50/194, train_loss: 0.7914\n",
      "51/194, train_loss: 0.8402\n",
      "52/194, train_loss: 0.8844\n",
      "53/194, train_loss: 0.7797\n",
      "54/194, train_loss: 0.8798\n",
      "55/194, train_loss: 0.8587\n",
      "56/194, train_loss: 0.7861\n",
      "57/194, train_loss: 0.7742\n",
      "58/194, train_loss: 0.9475\n",
      "59/194, train_loss: 0.8989\n",
      "60/194, train_loss: 0.8177\n",
      "61/194, train_loss: 0.6813\n",
      "62/194, train_loss: 0.7444\n",
      "63/194, train_loss: 0.8261\n",
      "64/194, train_loss: 0.8161\n",
      "65/194, train_loss: 0.8761\n",
      "66/194, train_loss: 0.7644\n",
      "67/194, train_loss: 0.6428\n",
      "68/194, train_loss: 0.8604\n",
      "69/194, train_loss: 0.7846\n",
      "70/194, train_loss: 0.8998\n",
      "71/194, train_loss: 0.8320\n",
      "72/194, train_loss: 0.7519\n",
      "73/194, train_loss: 0.7428\n",
      "74/194, train_loss: 0.7736\n",
      "75/194, train_loss: 0.8839\n",
      "76/194, train_loss: 0.7719\n",
      "77/194, train_loss: 0.7271\n",
      "78/194, train_loss: 0.6331\n",
      "79/194, train_loss: 0.8716\n",
      "80/194, train_loss: 0.8582\n",
      "81/194, train_loss: 0.9432\n",
      "82/194, train_loss: 0.8592\n",
      "83/194, train_loss: 0.8382\n",
      "84/194, train_loss: 0.8190\n",
      "85/194, train_loss: 0.8028\n",
      "86/194, train_loss: 0.8887\n",
      "87/194, train_loss: 0.7280\n",
      "88/194, train_loss: 0.8173\n",
      "89/194, train_loss: 0.7201\n",
      "90/194, train_loss: 0.9224\n",
      "91/194, train_loss: 0.7777\n",
      "92/194, train_loss: 0.9203\n",
      "93/194, train_loss: 0.7326\n",
      "94/194, train_loss: 0.7965\n",
      "95/194, train_loss: 0.7448\n",
      "96/194, train_loss: 0.8163\n",
      "97/194, train_loss: 0.7974\n",
      "98/194, train_loss: 0.9039\n",
      "99/194, train_loss: 0.8921\n",
      "100/194, train_loss: 0.8376\n",
      "101/194, train_loss: 0.9195\n",
      "102/194, train_loss: 0.6517\n",
      "103/194, train_loss: 0.8746\n",
      "104/194, train_loss: 0.6146\n",
      "105/194, train_loss: 0.8002\n",
      "106/194, train_loss: 0.8371\n",
      "107/194, train_loss: 0.9028\n",
      "108/194, train_loss: 0.7211\n",
      "109/194, train_loss: 0.8667\n",
      "110/194, train_loss: 0.7554\n",
      "111/194, train_loss: 0.9178\n",
      "112/194, train_loss: 0.7661\n",
      "113/194, train_loss: 0.8602\n",
      "114/194, train_loss: 0.8216\n",
      "115/194, train_loss: 0.8923\n",
      "116/194, train_loss: 0.7844\n",
      "117/194, train_loss: 0.7276\n",
      "118/194, train_loss: 0.8426\n",
      "119/194, train_loss: 0.7263\n",
      "120/194, train_loss: 0.8048\n",
      "121/194, train_loss: 0.7750\n",
      "122/194, train_loss: 0.9189\n",
      "123/194, train_loss: 0.9586\n",
      "124/194, train_loss: 0.9069\n",
      "125/194, train_loss: 0.9203\n",
      "126/194, train_loss: 0.8548\n",
      "127/194, train_loss: 0.7603\n",
      "128/194, train_loss: 0.9145\n",
      "129/194, train_loss: 0.8134\n",
      "130/194, train_loss: 0.7859\n",
      "131/194, train_loss: 0.7904\n",
      "132/194, train_loss: 0.8766\n",
      "133/194, train_loss: 0.7610\n",
      "134/194, train_loss: 0.7798\n",
      "135/194, train_loss: 0.7937\n",
      "136/194, train_loss: 0.8585\n",
      "137/194, train_loss: 0.7136\n",
      "138/194, train_loss: 0.7525\n",
      "139/194, train_loss: 0.8348\n",
      "140/194, train_loss: 0.7909\n",
      "141/194, train_loss: 0.9552\n",
      "142/194, train_loss: 0.8889\n",
      "143/194, train_loss: 0.8817\n",
      "144/194, train_loss: 0.8045\n",
      "145/194, train_loss: 0.9106\n",
      "146/194, train_loss: 0.9127\n",
      "147/194, train_loss: 0.7088\n",
      "148/194, train_loss: 0.7875\n",
      "149/194, train_loss: 0.7241\n",
      "150/194, train_loss: 0.7768\n",
      "151/194, train_loss: 0.9293\n",
      "152/194, train_loss: 0.7410\n",
      "153/194, train_loss: 0.8863\n",
      "154/194, train_loss: 0.9091\n",
      "155/194, train_loss: 0.9319\n",
      "156/194, train_loss: 0.9638\n",
      "157/194, train_loss: 0.8354\n",
      "158/194, train_loss: 0.8071\n",
      "159/194, train_loss: 0.8653\n",
      "160/194, train_loss: 0.8878\n",
      "161/194, train_loss: 0.9739\n",
      "162/194, train_loss: 0.7569\n",
      "163/194, train_loss: 0.8356\n",
      "164/194, train_loss: 0.8746\n",
      "165/194, train_loss: 0.7672\n",
      "166/194, train_loss: 0.9364\n",
      "167/194, train_loss: 0.8539\n",
      "168/194, train_loss: 0.8133\n",
      "169/194, train_loss: 0.7419\n",
      "170/194, train_loss: 0.7908\n",
      "171/194, train_loss: 0.7518\n",
      "172/194, train_loss: 0.6758\n",
      "173/194, train_loss: 0.7060\n",
      "174/194, train_loss: 0.5868\n",
      "175/194, train_loss: 0.8249\n",
      "176/194, train_loss: 0.7721\n",
      "177/194, train_loss: 0.7954\n",
      "178/194, train_loss: 0.8431\n",
      "179/194, train_loss: 0.8099\n",
      "180/194, train_loss: 0.7210\n",
      "181/194, train_loss: 0.8729\n",
      "182/194, train_loss: 0.8035\n",
      "183/194, train_loss: 0.8370\n",
      "184/194, train_loss: 0.5001\n",
      "185/194, train_loss: 0.8121\n",
      "186/194, train_loss: 0.8839\n",
      "187/194, train_loss: 0.8458\n",
      "188/194, train_loss: 0.8194\n",
      "189/194, train_loss: 0.9371\n",
      "190/194, train_loss: 0.8300\n",
      "191/194, train_loss: 0.8882\n",
      "192/194, train_loss: 0.8394\n",
      "193/194, train_loss: 0.7523\n",
      "194/194, train_loss: 0.7002\n",
      "metric=0.31238982019325096, metric_tc=0.3099303827621043, metric_wt=0.4596268019328515, metric_et=0.16761227472064397\n",
      "metric=0.31238982019325096, metric_tc=0.3099303827621043, metric_wt=0.4596268019328515, metric_et=0.16761227472064397\n",
      "current epoch: 31 current epoch loss: 0.8147\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▉      | 31/80 [5:38:00<8:22:53, 615.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metric=0.31238982019325096, metric_tc=0.3099303827621043, metric_wt=0.4596268019328515, metric_et=0.16761227472064397\n",
      "0.31238982019325096\n",
      "current epoch: 31 current mean dice: 0.3124 tc: 0.3099 wt: 0.4596 et: 0.1676\n",
      "best mean dice: 0.3388 at epoch: 26\n",
      "\n",
      " | Global Training Round : 32 |\n",
      "\n",
      "user 0 selected\n",
      "local epoch 1\n",
      "1/194, train_loss: 0.7641\n",
      "2/194, train_loss: 0.7362\n",
      "3/194, train_loss: 0.7891\n",
      "4/194, train_loss: 0.7906\n",
      "5/194, train_loss: 0.8261\n",
      "6/194, train_loss: 0.8248\n",
      "7/194, train_loss: 0.8384\n",
      "8/194, train_loss: 0.7247\n",
      "9/194, train_loss: 0.7091\n",
      "10/194, train_loss: 0.7147\n",
      "11/194, train_loss: 0.8328\n",
      "12/194, train_loss: 0.6351\n",
      "13/194, train_loss: 0.8551\n",
      "14/194, train_loss: 0.7993\n",
      "15/194, train_loss: 0.6793\n",
      "16/194, train_loss: 0.7947\n",
      "17/194, train_loss: 0.9231\n",
      "18/194, train_loss: 0.7779\n",
      "19/194, train_loss: 0.8259\n",
      "20/194, train_loss: 0.7236\n",
      "21/194, train_loss: 0.8516\n",
      "22/194, train_loss: 0.8008\n",
      "23/194, train_loss: 0.7860\n",
      "24/194, train_loss: 0.7722\n",
      "25/194, train_loss: 0.8702\n",
      "26/194, train_loss: 0.7562\n",
      "27/194, train_loss: 0.8135\n",
      "28/194, train_loss: 0.7801\n",
      "29/194, train_loss: 0.8161\n",
      "30/194, train_loss: 0.9285\n",
      "31/194, train_loss: 0.8240\n",
      "32/194, train_loss: 0.9339\n",
      "33/194, train_loss: 0.5956\n",
      "34/194, train_loss: 0.7990\n",
      "35/194, train_loss: 0.8268\n",
      "36/194, train_loss: 0.7530\n",
      "37/194, train_loss: 0.8693\n",
      "38/194, train_loss: 0.7021\n",
      "39/194, train_loss: 0.7187\n",
      "40/194, train_loss: 0.7976\n",
      "41/194, train_loss: 0.8635\n",
      "42/194, train_loss: 0.7400\n",
      "43/194, train_loss: 0.8417\n",
      "44/194, train_loss: 0.8299\n",
      "45/194, train_loss: 0.6434\n",
      "46/194, train_loss: 0.7949\n",
      "47/194, train_loss: 0.8364\n",
      "48/194, train_loss: 0.8619\n",
      "49/194, train_loss: 0.8060\n",
      "50/194, train_loss: 0.7376\n",
      "51/194, train_loss: 0.7569\n",
      "52/194, train_loss: 0.6569\n",
      "53/194, train_loss: 0.8889\n",
      "54/194, train_loss: 0.8866\n",
      "55/194, train_loss: 0.8674\n",
      "56/194, train_loss: 0.8326\n",
      "57/194, train_loss: 0.8588\n",
      "58/194, train_loss: 0.8664\n",
      "59/194, train_loss: 0.7582\n",
      "60/194, train_loss: 0.8276\n",
      "61/194, train_loss: 0.7249\n",
      "62/194, train_loss: 0.8097\n",
      "63/194, train_loss: 0.9075\n",
      "64/194, train_loss: 0.8724\n",
      "65/194, train_loss: 0.7887\n",
      "66/194, train_loss: 0.7317\n",
      "67/194, train_loss: 0.6035\n",
      "68/194, train_loss: 0.8132\n",
      "69/194, train_loss: 0.8093\n",
      "70/194, train_loss: 0.8754\n",
      "71/194, train_loss: 0.8479\n",
      "72/194, train_loss: 0.6594\n",
      "73/194, train_loss: 0.9047\n",
      "74/194, train_loss: 0.8328\n",
      "75/194, train_loss: 0.7953\n",
      "76/194, train_loss: 0.8400\n",
      "77/194, train_loss: 0.8987\n",
      "78/194, train_loss: 0.7879\n",
      "79/194, train_loss: 0.7971\n",
      "80/194, train_loss: 0.8839\n",
      "81/194, train_loss: 0.7819\n",
      "82/194, train_loss: 0.8338\n",
      "83/194, train_loss: 0.8409\n",
      "84/194, train_loss: 0.7112\n",
      "85/194, train_loss: 0.8328\n",
      "86/194, train_loss: 0.8553\n",
      "87/194, train_loss: 0.7539\n",
      "88/194, train_loss: 0.8366\n",
      "89/194, train_loss: 0.8333\n",
      "90/194, train_loss: 0.8438\n",
      "91/194, train_loss: 0.9409\n",
      "92/194, train_loss: 0.7725\n",
      "93/194, train_loss: 0.8952\n",
      "94/194, train_loss: 0.7656\n",
      "95/194, train_loss: 0.7603\n",
      "96/194, train_loss: 0.8561\n",
      "97/194, train_loss: 0.7343\n",
      "98/194, train_loss: 0.7908\n",
      "99/194, train_loss: 0.7328\n",
      "100/194, train_loss: 0.7633\n",
      "101/194, train_loss: 0.9131\n",
      "102/194, train_loss: 0.8683\n",
      "103/194, train_loss: 0.8972\n",
      "104/194, train_loss: 0.6869\n",
      "105/194, train_loss: 0.7848\n",
      "106/194, train_loss: 0.7796\n",
      "107/194, train_loss: 0.9263\n",
      "108/194, train_loss: 0.8878\n",
      "109/194, train_loss: 0.8364\n",
      "110/194, train_loss: 0.7664\n",
      "111/194, train_loss: 0.7458\n",
      "112/194, train_loss: 0.6269\n",
      "113/194, train_loss: 0.8415\n",
      "114/194, train_loss: 0.9019\n",
      "115/194, train_loss: 0.6226\n",
      "116/194, train_loss: 0.8576\n",
      "117/194, train_loss: 0.9105\n",
      "118/194, train_loss: 0.7945\n",
      "119/194, train_loss: 0.8290\n",
      "120/194, train_loss: 0.7004\n",
      "121/194, train_loss: 0.8838\n",
      "122/194, train_loss: 0.9022\n",
      "123/194, train_loss: 0.8710\n",
      "124/194, train_loss: 0.9151\n",
      "125/194, train_loss: 0.9493\n",
      "126/194, train_loss: 0.8233\n",
      "127/194, train_loss: 0.8629\n",
      "128/194, train_loss: 0.9293\n",
      "129/194, train_loss: 0.7512\n",
      "130/194, train_loss: 0.8352\n",
      "131/194, train_loss: 0.8319\n",
      "132/194, train_loss: 0.8794\n",
      "133/194, train_loss: 0.8534\n",
      "134/194, train_loss: 0.8537\n",
      "135/194, train_loss: 0.6980\n",
      "136/194, train_loss: 0.8878\n",
      "137/194, train_loss: 0.7891\n",
      "138/194, train_loss: 0.8105\n",
      "139/194, train_loss: 0.7998\n",
      "140/194, train_loss: 0.6226\n",
      "141/194, train_loss: 0.9323\n",
      "142/194, train_loss: 0.7976\n",
      "143/194, train_loss: 0.9316\n",
      "144/194, train_loss: 0.9799\n",
      "145/194, train_loss: 0.6864\n",
      "146/194, train_loss: 0.9549\n",
      "147/194, train_loss: 0.7820\n",
      "148/194, train_loss: 0.7608\n",
      "149/194, train_loss: 0.8513\n",
      "150/194, train_loss: 0.8344\n",
      "151/194, train_loss: 0.6107\n",
      "152/194, train_loss: 0.8686\n",
      "153/194, train_loss: 0.8362\n",
      "154/194, train_loss: 0.9300\n",
      "155/194, train_loss: 0.9159\n",
      "156/194, train_loss: 0.9225\n",
      "157/194, train_loss: 0.9469\n",
      "158/194, train_loss: 0.7886\n",
      "159/194, train_loss: 0.5399\n",
      "160/194, train_loss: 0.7201\n",
      "161/194, train_loss: 0.8555\n",
      "162/194, train_loss: 0.8416\n",
      "163/194, train_loss: 0.9167\n",
      "164/194, train_loss: 0.8218\n",
      "165/194, train_loss: 0.8161\n",
      "166/194, train_loss: 0.8418\n",
      "167/194, train_loss: 0.7976\n",
      "168/194, train_loss: 0.8694\n",
      "169/194, train_loss: 0.7635\n",
      "170/194, train_loss: 0.7243\n",
      "171/194, train_loss: 0.7716\n",
      "172/194, train_loss: 0.7593\n",
      "173/194, train_loss: 0.8317\n",
      "174/194, train_loss: 0.8819\n",
      "175/194, train_loss: 0.8197\n",
      "176/194, train_loss: 0.8213\n",
      "177/194, train_loss: 0.9321\n",
      "178/194, train_loss: 0.8954\n",
      "179/194, train_loss: 0.8248\n",
      "180/194, train_loss: 0.8185\n",
      "181/194, train_loss: 0.7094\n",
      "182/194, train_loss: 0.6877\n",
      "183/194, train_loss: 0.8364\n",
      "184/194, train_loss: 0.7196\n",
      "185/194, train_loss: 0.9416\n",
      "186/194, train_loss: 0.9259\n",
      "187/194, train_loss: 0.8325\n",
      "188/194, train_loss: 0.7505\n",
      "189/194, train_loss: 0.7603\n",
      "190/194, train_loss: 0.7685\n",
      "191/194, train_loss: 0.9019\n",
      "192/194, train_loss: 0.8502\n",
      "193/194, train_loss: 0.7763\n",
      "194/194, train_loss: 0.9059\n",
      "metric=0.3333725867172082, metric_tc=0.3341916490656634, metric_wt=0.485598910599947, metric_et=0.18032719295782348\n",
      "metric=0.3333725867172082, metric_tc=0.3341916490656634, metric_wt=0.485598910599947, metric_et=0.18032719295782348\n",
      "current epoch: 32 current epoch loss: 0.8120\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 32/80 [5:48:24<8:14:26, 618.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metric=0.3333725867172082, metric_tc=0.3341916490656634, metric_wt=0.485598910599947, metric_et=0.18032719295782348\n",
      "0.3333725867172082\n",
      "current epoch: 32 current mean dice: 0.3334 tc: 0.3342 wt: 0.4856 et: 0.1803\n",
      "best mean dice: 0.3388 at epoch: 26\n",
      "\n",
      " | Global Training Round : 33 |\n",
      "\n",
      "user 0 selected\n",
      "local epoch 1\n",
      "1/194, train_loss: 0.7305\n",
      "2/194, train_loss: 0.8344\n",
      "3/194, train_loss: 0.8706\n",
      "4/194, train_loss: 0.8940\n",
      "5/194, train_loss: 0.8496\n",
      "6/194, train_loss: 0.7052\n",
      "7/194, train_loss: 0.7574\n",
      "8/194, train_loss: 0.7450\n",
      "9/194, train_loss: 0.8350\n",
      "10/194, train_loss: 0.8982\n",
      "11/194, train_loss: 0.7737\n",
      "12/194, train_loss: 0.8867\n",
      "13/194, train_loss: 0.8179\n",
      "14/194, train_loss: 0.8079\n",
      "15/194, train_loss: 0.7926\n",
      "16/194, train_loss: 0.8439\n",
      "17/194, train_loss: 0.7422\n",
      "18/194, train_loss: 0.7072\n",
      "19/194, train_loss: 0.8444\n",
      "20/194, train_loss: 0.8481\n",
      "21/194, train_loss: 0.8604\n",
      "22/194, train_loss: 0.7542\n",
      "23/194, train_loss: 0.8726\n",
      "24/194, train_loss: 0.9010\n",
      "25/194, train_loss: 0.7861\n",
      "26/194, train_loss: 0.8780\n",
      "27/194, train_loss: 0.8848\n",
      "28/194, train_loss: 0.7888\n",
      "29/194, train_loss: 0.8603\n",
      "30/194, train_loss: 0.7732\n",
      "31/194, train_loss: 0.6644\n",
      "32/194, train_loss: 0.6480\n",
      "33/194, train_loss: 0.8052\n",
      "34/194, train_loss: 0.7125\n",
      "35/194, train_loss: 0.7123\n",
      "36/194, train_loss: 0.8743\n",
      "37/194, train_loss: 0.7858\n",
      "38/194, train_loss: 0.7904\n",
      "39/194, train_loss: 0.9246\n",
      "40/194, train_loss: 0.7918\n",
      "41/194, train_loss: 0.9145\n",
      "42/194, train_loss: 0.7959\n",
      "43/194, train_loss: 0.7684\n",
      "44/194, train_loss: 0.9309\n",
      "45/194, train_loss: 0.8865\n",
      "46/194, train_loss: 0.7091\n",
      "47/194, train_loss: 0.7440\n",
      "48/194, train_loss: 0.6413\n",
      "49/194, train_loss: 0.7233\n",
      "50/194, train_loss: 0.7953\n",
      "51/194, train_loss: 0.8410\n",
      "52/194, train_loss: 0.5640\n",
      "53/194, train_loss: 0.8351\n",
      "54/194, train_loss: 0.9290\n",
      "55/194, train_loss: 0.8507\n",
      "56/194, train_loss: 0.9081\n",
      "57/194, train_loss: 0.8983\n",
      "58/194, train_loss: 0.8096\n",
      "59/194, train_loss: 0.8791\n",
      "60/194, train_loss: 0.7682\n",
      "61/194, train_loss: 0.8358\n",
      "62/194, train_loss: 0.8022\n",
      "63/194, train_loss: 0.8716\n",
      "64/194, train_loss: 0.6038\n",
      "65/194, train_loss: 0.8043\n",
      "66/194, train_loss: 0.7728\n",
      "67/194, train_loss: 0.8244\n",
      "68/194, train_loss: 0.6861\n",
      "69/194, train_loss: 0.7643\n",
      "70/194, train_loss: 0.8117\n",
      "71/194, train_loss: 0.7297\n",
      "72/194, train_loss: 0.8781\n",
      "73/194, train_loss: 0.7201\n",
      "74/194, train_loss: 0.7238\n",
      "75/194, train_loss: 0.8227\n",
      "76/194, train_loss: 0.6861\n",
      "77/194, train_loss: 0.7668\n",
      "78/194, train_loss: 0.6833\n",
      "79/194, train_loss: 0.8267\n",
      "80/194, train_loss: 0.7102\n",
      "81/194, train_loss: 0.8047\n",
      "82/194, train_loss: 0.8322\n",
      "83/194, train_loss: 0.7683\n",
      "84/194, train_loss: 0.8351\n",
      "85/194, train_loss: 0.8005\n",
      "86/194, train_loss: 0.8920\n",
      "87/194, train_loss: 0.8927\n",
      "88/194, train_loss: 0.8390\n",
      "89/194, train_loss: 0.9047\n",
      "90/194, train_loss: 0.7879\n",
      "91/194, train_loss: 0.7484\n",
      "92/194, train_loss: 0.9422\n",
      "93/194, train_loss: 0.7132\n",
      "94/194, train_loss: 0.8617\n",
      "95/194, train_loss: 0.7247\n",
      "96/194, train_loss: 0.7610\n",
      "97/194, train_loss: 0.7120\n",
      "98/194, train_loss: 0.7080\n",
      "99/194, train_loss: 0.9574\n",
      "100/194, train_loss: 0.9000\n",
      "101/194, train_loss: 0.8332\n",
      "102/194, train_loss: 0.8669\n",
      "103/194, train_loss: 0.9164\n",
      "104/194, train_loss: 0.9483\n",
      "105/194, train_loss: 0.8860\n",
      "106/194, train_loss: 0.7244\n",
      "107/194, train_loss: 0.7376\n",
      "108/194, train_loss: 0.8893\n",
      "109/194, train_loss: 0.7494\n",
      "110/194, train_loss: 0.7253\n",
      "111/194, train_loss: 0.7569\n",
      "112/194, train_loss: 0.7988\n",
      "113/194, train_loss: 0.8743\n",
      "114/194, train_loss: 0.7839\n",
      "115/194, train_loss: 0.7651\n",
      "116/194, train_loss: 0.7357\n",
      "117/194, train_loss: 0.6690\n",
      "118/194, train_loss: 0.9147\n",
      "119/194, train_loss: 0.8587\n",
      "120/194, train_loss: 0.7605\n",
      "121/194, train_loss: 0.9220\n",
      "122/194, train_loss: 0.9622\n",
      "123/194, train_loss: 0.7390\n",
      "124/194, train_loss: 0.9145\n",
      "125/194, train_loss: 0.8782\n",
      "126/194, train_loss: 0.8807\n",
      "127/194, train_loss: 0.9130\n",
      "128/194, train_loss: 0.9322\n",
      "129/194, train_loss: 0.8891\n",
      "130/194, train_loss: 0.8258\n",
      "131/194, train_loss: 0.9031\n",
      "132/194, train_loss: 0.7848\n",
      "133/194, train_loss: 0.8073\n",
      "134/194, train_loss: 0.8122\n",
      "135/194, train_loss: 0.7845\n",
      "136/194, train_loss: 0.7294\n",
      "137/194, train_loss: 0.9893\n",
      "138/194, train_loss: 0.7733\n",
      "139/194, train_loss: 0.8080\n",
      "140/194, train_loss: 0.7897\n",
      "141/194, train_loss: 0.7907\n",
      "142/194, train_loss: 0.9354\n",
      "143/194, train_loss: 0.8734\n",
      "144/194, train_loss: 0.7639\n",
      "145/194, train_loss: 0.8028\n",
      "146/194, train_loss: 0.9329\n",
      "147/194, train_loss: 0.7030\n",
      "148/194, train_loss: 0.8401\n",
      "149/194, train_loss: 0.9092\n",
      "150/194, train_loss: 0.8432\n",
      "151/194, train_loss: 0.8407\n",
      "152/194, train_loss: 0.9389\n",
      "153/194, train_loss: 0.8057\n",
      "154/194, train_loss: 0.9074\n",
      "155/194, train_loss: 0.8497\n",
      "156/194, train_loss: 0.8244\n",
      "157/194, train_loss: 0.7126\n",
      "158/194, train_loss: 0.6834\n",
      "159/194, train_loss: 0.9058\n",
      "160/194, train_loss: 0.8491\n",
      "161/194, train_loss: 0.8429\n",
      "162/194, train_loss: 0.8982\n",
      "163/194, train_loss: 0.7819\n",
      "164/194, train_loss: 0.8889\n",
      "165/194, train_loss: 0.8941\n",
      "166/194, train_loss: 0.7582\n",
      "167/194, train_loss: 0.9400\n",
      "168/194, train_loss: 0.8885\n",
      "169/194, train_loss: 0.8380\n",
      "170/194, train_loss: 0.6547\n",
      "171/194, train_loss: 0.8042\n",
      "172/194, train_loss: 0.7926\n",
      "173/194, train_loss: 0.7498\n",
      "174/194, train_loss: 0.6661\n",
      "175/194, train_loss: 0.7619\n",
      "176/194, train_loss: 0.6540\n",
      "177/194, train_loss: 0.8874\n",
      "178/194, train_loss: 0.7391\n",
      "179/194, train_loss: 0.8117\n",
      "180/194, train_loss: 0.8257\n",
      "181/194, train_loss: 0.6354\n",
      "182/194, train_loss: 0.7295\n",
      "183/194, train_loss: 0.6469\n",
      "184/194, train_loss: 0.5944\n",
      "185/194, train_loss: 0.8367\n",
      "186/194, train_loss: 0.8802\n",
      "187/194, train_loss: 0.9322\n",
      "188/194, train_loss: 0.7635\n",
      "189/194, train_loss: 0.6346\n",
      "190/194, train_loss: 0.7915\n",
      "191/194, train_loss: 0.8025\n",
      "192/194, train_loss: 0.8901\n",
      "193/194, train_loss: 0.7275\n",
      "194/194, train_loss: 0.7912\n",
      "metric=0.34290738093356293, metric_tc=0.33742608362808824, metric_wt=0.5124237301448981, metric_et=0.17887233612903705\n",
      "metric=0.34290738093356293, metric_tc=0.33742608362808824, metric_wt=0.5124237301448981, metric_et=0.17887233612903705\n",
      "current epoch: 33 current epoch loss: 0.8084\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████▏     | 33/80 [5:58:50<8:06:01, 620.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metric=0.34290738093356293, metric_tc=0.33742608362808824, metric_wt=0.5124237301448981, metric_et=0.17887233612903705\n",
      "0.34290738093356293\n",
      "saved new best metric model\n",
      "current epoch: 33 current mean dice: 0.3429 tc: 0.3374 wt: 0.5124 et: 0.1789\n",
      "best mean dice: 0.3429 at epoch: 33\n",
      "\n",
      " | Global Training Round : 34 |\n",
      "\n",
      "user 0 selected\n",
      "local epoch 1\n",
      "1/194, train_loss: 0.7687\n",
      "2/194, train_loss: 0.6382\n",
      "3/194, train_loss: 0.7357\n",
      "4/194, train_loss: 0.8650\n",
      "5/194, train_loss: 0.8817\n",
      "6/194, train_loss: 0.8630\n",
      "7/194, train_loss: 0.8924\n",
      "8/194, train_loss: 0.8757\n",
      "9/194, train_loss: 0.7145\n",
      "10/194, train_loss: 0.7768\n",
      "11/194, train_loss: 0.8372\n",
      "12/194, train_loss: 0.7530\n",
      "13/194, train_loss: 0.7844\n",
      "14/194, train_loss: 0.7892\n",
      "15/194, train_loss: 0.5944\n",
      "16/194, train_loss: 0.8463\n",
      "17/194, train_loss: 0.9253\n",
      "18/194, train_loss: 0.7605\n",
      "19/194, train_loss: 0.6378\n",
      "20/194, train_loss: 0.8457\n",
      "21/194, train_loss: 0.8361\n",
      "22/194, train_loss: 0.7902\n",
      "23/194, train_loss: 0.8695\n",
      "24/194, train_loss: 0.8409\n",
      "25/194, train_loss: 0.7797\n",
      "26/194, train_loss: 0.8569\n",
      "27/194, train_loss: 0.8091\n",
      "28/194, train_loss: 0.7509\n",
      "29/194, train_loss: 0.7481\n",
      "30/194, train_loss: 0.9236\n",
      "31/194, train_loss: 0.8395\n",
      "32/194, train_loss: 0.7771\n",
      "33/194, train_loss: 0.8214\n",
      "34/194, train_loss: 0.7902\n",
      "35/194, train_loss: 0.8304\n",
      "36/194, train_loss: 0.8588\n",
      "37/194, train_loss: 0.6478\n",
      "38/194, train_loss: 0.6956\n",
      "39/194, train_loss: 0.8687\n",
      "40/194, train_loss: 0.6562\n",
      "41/194, train_loss: 0.8249\n",
      "42/194, train_loss: 0.7333\n",
      "43/194, train_loss: 0.7652\n",
      "44/194, train_loss: 0.7145\n",
      "45/194, train_loss: 0.7616\n",
      "46/194, train_loss: 0.7809\n",
      "47/194, train_loss: 0.7214\n",
      "48/194, train_loss: 0.8390\n",
      "49/194, train_loss: 0.6671\n",
      "50/194, train_loss: 0.7627\n",
      "51/194, train_loss: 0.8611\n",
      "52/194, train_loss: 0.6008\n",
      "53/194, train_loss: 0.9241\n",
      "54/194, train_loss: 0.8166\n",
      "55/194, train_loss: 0.8637\n",
      "56/194, train_loss: 0.7924\n",
      "57/194, train_loss: 0.9594\n",
      "58/194, train_loss: 0.8836\n",
      "59/194, train_loss: 0.8215\n",
      "60/194, train_loss: 0.8014\n",
      "61/194, train_loss: 0.8011\n",
      "62/194, train_loss: 0.9270\n",
      "63/194, train_loss: 0.7600\n",
      "64/194, train_loss: 0.7035\n",
      "65/194, train_loss: 0.9096\n",
      "66/194, train_loss: 0.7958\n",
      "67/194, train_loss: 0.7534\n",
      "68/194, train_loss: 0.8338\n",
      "69/194, train_loss: 0.8075\n",
      "70/194, train_loss: 0.8780\n",
      "71/194, train_loss: 0.9199\n",
      "72/194, train_loss: 0.8721\n",
      "73/194, train_loss: 0.8020\n",
      "74/194, train_loss: 0.9593\n",
      "75/194, train_loss: 0.7574\n",
      "76/194, train_loss: 0.8473\n",
      "77/194, train_loss: 0.9008\n",
      "78/194, train_loss: 0.8241\n",
      "79/194, train_loss: 0.8154\n",
      "80/194, train_loss: 0.8147\n",
      "81/194, train_loss: 0.7816\n",
      "82/194, train_loss: 0.7296\n",
      "83/194, train_loss: 0.8491\n",
      "84/194, train_loss: 0.8789\n",
      "85/194, train_loss: 0.7509\n",
      "86/194, train_loss: 0.8431\n",
      "87/194, train_loss: 0.9245\n",
      "88/194, train_loss: 0.8644\n",
      "89/194, train_loss: 0.8797\n",
      "90/194, train_loss: 0.8514\n",
      "91/194, train_loss: 0.7771\n",
      "92/194, train_loss: 0.6791\n",
      "93/194, train_loss: 0.6336\n",
      "94/194, train_loss: 0.8661\n",
      "95/194, train_loss: 0.7867\n",
      "96/194, train_loss: 0.8410\n",
      "97/194, train_loss: 0.8689\n",
      "98/194, train_loss: 0.9041\n",
      "99/194, train_loss: 0.7438\n",
      "100/194, train_loss: 0.7461\n",
      "101/194, train_loss: 0.9054\n",
      "102/194, train_loss: 0.8802\n",
      "103/194, train_loss: 0.8428\n",
      "104/194, train_loss: 0.8593\n",
      "105/194, train_loss: 0.6865\n",
      "106/194, train_loss: 0.8179\n",
      "107/194, train_loss: 0.7256\n",
      "108/194, train_loss: 0.7036\n",
      "109/194, train_loss: 0.8126\n",
      "110/194, train_loss: 0.8414\n",
      "111/194, train_loss: 0.8211\n",
      "112/194, train_loss: 0.7580\n",
      "113/194, train_loss: 0.6485\n",
      "114/194, train_loss: 0.7111\n",
      "115/194, train_loss: 0.8605\n",
      "116/194, train_loss: 0.7933\n",
      "117/194, train_loss: 0.7199\n",
      "118/194, train_loss: 0.6978\n",
      "119/194, train_loss: 0.8250\n",
      "120/194, train_loss: 0.6585\n",
      "121/194, train_loss: 0.7106\n",
      "122/194, train_loss: 0.7103\n",
      "123/194, train_loss: 0.9142\n",
      "124/194, train_loss: 0.7146\n",
      "125/194, train_loss: 0.8465\n",
      "126/194, train_loss: 0.9473\n",
      "127/194, train_loss: 0.8052\n",
      "128/194, train_loss: 0.8629\n",
      "129/194, train_loss: 0.8396\n",
      "130/194, train_loss: 0.8948\n",
      "131/194, train_loss: 0.7660\n",
      "132/194, train_loss: 0.7924\n",
      "133/194, train_loss: 0.7895\n",
      "134/194, train_loss: 0.8383\n",
      "135/194, train_loss: 0.7818\n",
      "136/194, train_loss: 0.8779\n",
      "137/194, train_loss: 0.9183\n",
      "138/194, train_loss: 0.8545\n",
      "139/194, train_loss: 0.7379\n",
      "140/194, train_loss: 0.7435\n",
      "141/194, train_loss: 0.9161\n",
      "142/194, train_loss: 0.8761\n",
      "143/194, train_loss: 0.9192\n",
      "144/194, train_loss: 0.7823\n",
      "145/194, train_loss: 0.6380\n",
      "146/194, train_loss: 0.7844\n",
      "147/194, train_loss: 0.7989\n",
      "148/194, train_loss: 0.9112\n",
      "149/194, train_loss: 0.8853\n",
      "150/194, train_loss: 0.7341\n",
      "151/194, train_loss: 0.8323\n",
      "152/194, train_loss: 0.9191\n",
      "153/194, train_loss: 0.8957\n",
      "154/194, train_loss: 0.8817\n",
      "155/194, train_loss: 0.8813\n",
      "156/194, train_loss: 0.8031\n",
      "157/194, train_loss: 0.8097\n",
      "158/194, train_loss: 0.8647\n",
      "159/194, train_loss: 0.8652\n",
      "160/194, train_loss: 0.7182\n",
      "161/194, train_loss: 0.9108\n",
      "162/194, train_loss: 0.9650\n",
      "163/194, train_loss: 0.7662\n",
      "164/194, train_loss: 0.8281\n",
      "165/194, train_loss: 0.7997\n",
      "166/194, train_loss: 0.7776\n",
      "167/194, train_loss: 0.8050\n",
      "168/194, train_loss: 0.8547\n",
      "169/194, train_loss: 0.8229\n",
      "170/194, train_loss: 0.8748\n",
      "171/194, train_loss: 0.6233\n",
      "172/194, train_loss: 0.7350\n",
      "173/194, train_loss: 0.8246\n",
      "174/194, train_loss: 0.7964\n",
      "175/194, train_loss: 0.8406\n",
      "176/194, train_loss: 0.8713\n",
      "177/194, train_loss: 0.7675\n",
      "178/194, train_loss: 0.8840\n",
      "179/194, train_loss: 0.8279\n",
      "180/194, train_loss: 0.8610\n",
      "181/194, train_loss: 0.6355\n",
      "182/194, train_loss: 0.7782\n",
      "183/194, train_loss: 0.8302\n",
      "184/194, train_loss: 0.8066\n",
      "185/194, train_loss: 0.8007\n",
      "186/194, train_loss: 0.7556\n",
      "187/194, train_loss: 0.8976\n",
      "188/194, train_loss: 0.8905\n",
      "189/194, train_loss: 0.8249\n",
      "190/194, train_loss: 0.7824\n",
      "191/194, train_loss: 0.9133\n",
      "192/194, train_loss: 0.8643\n",
      "193/194, train_loss: 0.8266\n",
      "194/194, train_loss: 0.7882\n",
      "metric=0.34237441668907803, metric_tc=0.33194064861163497, metric_wt=0.5189492249240478, metric_et=0.1762333910446614\n",
      "metric=0.34237441668907803, metric_tc=0.33194064861163497, metric_wt=0.5189492249240478, metric_et=0.1762333910446614\n",
      "current epoch: 34 current epoch loss: 0.8094\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▎     | 34/80 [6:09:04<7:54:09, 618.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metric=0.34237441668907803, metric_tc=0.33194064861163497, metric_wt=0.5189492249240478, metric_et=0.1762333910446614\n",
      "0.34237441668907803\n",
      "current epoch: 34 current mean dice: 0.3424 tc: 0.3319 wt: 0.5189 et: 0.1762\n",
      "best mean dice: 0.3429 at epoch: 33\n",
      "\n",
      " | Global Training Round : 35 |\n",
      "\n",
      "user 0 selected\n",
      "local epoch 1\n",
      "1/194, train_loss: 0.8692\n",
      "2/194, train_loss: 0.6959\n",
      "3/194, train_loss: 0.7895\n",
      "4/194, train_loss: 0.7622\n",
      "5/194, train_loss: 0.8445\n",
      "6/194, train_loss: 0.7017\n",
      "7/194, train_loss: 0.8898\n",
      "8/194, train_loss: 0.8576\n",
      "9/194, train_loss: 0.7032\n",
      "10/194, train_loss: 0.8757\n",
      "11/194, train_loss: 0.9116\n",
      "12/194, train_loss: 0.8328\n",
      "13/194, train_loss: 0.6763\n",
      "14/194, train_loss: 0.6351\n",
      "15/194, train_loss: 0.8222\n",
      "16/194, train_loss: 0.8523\n",
      "17/194, train_loss: 0.6142\n",
      "18/194, train_loss: 0.8237\n",
      "19/194, train_loss: 0.7968\n",
      "20/194, train_loss: 0.6808\n",
      "21/194, train_loss: 0.7964\n",
      "22/194, train_loss: 0.6832\n",
      "23/194, train_loss: 0.7143\n",
      "24/194, train_loss: 0.7071\n",
      "25/194, train_loss: 0.8403\n",
      "26/194, train_loss: 0.9183\n",
      "27/194, train_loss: 0.7447\n",
      "28/194, train_loss: 0.6931\n",
      "29/194, train_loss: 0.7756\n",
      "30/194, train_loss: 0.6890\n",
      "31/194, train_loss: 0.7992\n",
      "32/194, train_loss: 0.7824\n",
      "33/194, train_loss: 0.8940\n",
      "34/194, train_loss: 0.8128\n",
      "35/194, train_loss: 0.7889\n",
      "36/194, train_loss: 0.7444\n",
      "37/194, train_loss: 0.7322\n",
      "38/194, train_loss: 0.5874\n",
      "39/194, train_loss: 0.7700\n",
      "40/194, train_loss: 0.7763\n",
      "41/194, train_loss: 0.8723\n",
      "42/194, train_loss: 0.8684\n",
      "43/194, train_loss: 0.8223\n",
      "44/194, train_loss: 0.8034\n",
      "45/194, train_loss: 0.7967\n",
      "46/194, train_loss: 0.6871\n",
      "47/194, train_loss: 0.7489\n",
      "48/194, train_loss: 0.7862\n",
      "49/194, train_loss: 0.6072\n",
      "50/194, train_loss: 0.6900\n",
      "51/194, train_loss: 0.6340\n",
      "52/194, train_loss: 0.8121\n",
      "53/194, train_loss: 0.8155\n",
      "54/194, train_loss: 0.7090\n",
      "55/194, train_loss: 0.7424\n",
      "56/194, train_loss: 0.7476\n",
      "57/194, train_loss: 0.8858\n",
      "58/194, train_loss: 0.8022\n",
      "59/194, train_loss: 0.8924\n",
      "60/194, train_loss: 0.9395\n",
      "61/194, train_loss: 0.7321\n",
      "62/194, train_loss: 0.9167\n",
      "63/194, train_loss: 0.7628\n",
      "64/194, train_loss: 0.6874\n",
      "65/194, train_loss: 0.8447\n",
      "66/194, train_loss: 0.5912\n",
      "67/194, train_loss: 0.7220\n",
      "68/194, train_loss: 0.8546\n",
      "69/194, train_loss: 0.7256\n",
      "70/194, train_loss: 0.8335\n",
      "71/194, train_loss: 0.8006\n",
      "72/194, train_loss: 0.9040\n",
      "73/194, train_loss: 0.8608\n",
      "74/194, train_loss: 0.8846\n",
      "75/194, train_loss: 0.8251\n",
      "76/194, train_loss: 0.7582\n",
      "77/194, train_loss: 0.9012\n",
      "78/194, train_loss: 0.8704\n",
      "79/194, train_loss: 0.7722\n",
      "80/194, train_loss: 0.7919\n",
      "81/194, train_loss: 0.7985\n",
      "82/194, train_loss: 0.9222\n",
      "83/194, train_loss: 0.8752\n",
      "84/194, train_loss: 0.9205\n",
      "85/194, train_loss: 0.8369\n",
      "86/194, train_loss: 0.8212\n",
      "87/194, train_loss: 0.8926\n",
      "88/194, train_loss: 0.7930\n",
      "89/194, train_loss: 0.9049\n",
      "90/194, train_loss: 0.9369\n",
      "91/194, train_loss: 0.8714\n",
      "92/194, train_loss: 0.7995\n",
      "93/194, train_loss: 0.7421\n",
      "94/194, train_loss: 0.7444\n",
      "95/194, train_loss: 0.9553\n",
      "96/194, train_loss: 0.8757\n",
      "97/194, train_loss: 0.7222\n",
      "98/194, train_loss: 0.8910\n",
      "99/194, train_loss: 0.7237\n",
      "100/194, train_loss: 0.8926\n",
      "101/194, train_loss: 0.8708\n",
      "102/194, train_loss: 0.8217\n",
      "103/194, train_loss: 0.8565\n",
      "104/194, train_loss: 0.7387\n",
      "105/194, train_loss: 0.7931\n",
      "106/194, train_loss: 0.8536\n",
      "107/194, train_loss: 0.7291\n",
      "108/194, train_loss: 0.7714\n",
      "109/194, train_loss: 0.8809\n",
      "110/194, train_loss: 0.8728\n",
      "111/194, train_loss: 0.7710\n",
      "112/194, train_loss: 0.7827\n",
      "113/194, train_loss: 0.6986\n",
      "114/194, train_loss: 0.8218\n",
      "115/194, train_loss: 0.8182\n",
      "116/194, train_loss: 0.8211\n",
      "117/194, train_loss: 0.8285\n",
      "118/194, train_loss: 0.9402\n",
      "119/194, train_loss: 0.8194\n",
      "120/194, train_loss: 0.8644\n",
      "121/194, train_loss: 0.9226\n",
      "122/194, train_loss: 0.8891\n",
      "123/194, train_loss: 0.8474\n",
      "124/194, train_loss: 0.8904\n",
      "125/194, train_loss: 0.7237\n",
      "126/194, train_loss: 0.9618\n",
      "127/194, train_loss: 0.9312\n",
      "128/194, train_loss: 0.7929\n",
      "129/194, train_loss: 0.8974\n",
      "130/194, train_loss: 0.8383\n",
      "131/194, train_loss: 0.7761\n",
      "132/194, train_loss: 0.7485\n",
      "133/194, train_loss: 0.8262\n",
      "134/194, train_loss: 0.8287\n",
      "135/194, train_loss: 0.6712\n",
      "136/194, train_loss: 0.8733\n",
      "137/194, train_loss: 0.7155\n",
      "138/194, train_loss: 0.8469\n",
      "139/194, train_loss: 0.6698\n",
      "140/194, train_loss: 0.6502\n",
      "141/194, train_loss: 0.9013\n",
      "142/194, train_loss: 0.8987\n",
      "143/194, train_loss: 0.8201\n",
      "144/194, train_loss: 0.9700\n",
      "145/194, train_loss: 0.9429\n",
      "146/194, train_loss: 0.8677\n",
      "147/194, train_loss: 0.8782\n",
      "148/194, train_loss: 0.8153\n",
      "149/194, train_loss: 0.9192\n",
      "150/194, train_loss: 0.7015\n",
      "151/194, train_loss: 0.7475\n",
      "152/194, train_loss: 0.7883\n",
      "153/194, train_loss: 0.8383\n",
      "154/194, train_loss: 0.8422\n",
      "155/194, train_loss: 0.9156\n",
      "156/194, train_loss: 0.8132\n",
      "157/194, train_loss: 0.8279\n",
      "158/194, train_loss: 0.5717\n",
      "159/194, train_loss: 0.7630\n",
      "160/194, train_loss: 0.8891\n",
      "161/194, train_loss: 0.7621\n",
      "162/194, train_loss: 0.7829\n",
      "163/194, train_loss: 0.7725\n",
      "164/194, train_loss: 0.9146\n",
      "165/194, train_loss: 0.9061\n",
      "166/194, train_loss: 0.7792\n",
      "167/194, train_loss: 0.8865\n",
      "168/194, train_loss: 0.9058\n",
      "169/194, train_loss: 0.9238\n",
      "170/194, train_loss: 0.7621\n",
      "171/194, train_loss: 0.6081\n",
      "172/194, train_loss: 0.7382\n",
      "173/194, train_loss: 0.8420\n",
      "174/194, train_loss: 0.7629\n",
      "175/194, train_loss: 0.7135\n",
      "176/194, train_loss: 0.7414\n",
      "177/194, train_loss: 0.6916\n",
      "178/194, train_loss: 0.7967\n",
      "179/194, train_loss: 0.9255\n",
      "180/194, train_loss: 0.7622\n",
      "181/194, train_loss: 0.7521\n",
      "182/194, train_loss: 0.7133\n",
      "183/194, train_loss: 0.5823\n",
      "184/194, train_loss: 0.6344\n",
      "185/194, train_loss: 0.8188\n",
      "186/194, train_loss: 0.8722\n",
      "187/194, train_loss: 0.7729\n",
      "188/194, train_loss: 0.8055\n",
      "189/194, train_loss: 0.8194\n",
      "190/194, train_loss: 0.8874\n",
      "191/194, train_loss: 0.7167\n",
      "192/194, train_loss: 0.7842\n",
      "193/194, train_loss: 0.7606\n",
      "194/194, train_loss: 0.8912\n",
      "metric=0.36507528461515903, metric_tc=0.3636470064520836, metric_wt=0.5339344696452221, metric_et=0.19764438744944832\n",
      "metric=0.36507528461515903, metric_tc=0.3636470064520836, metric_wt=0.5339344696452221, metric_et=0.19764438744944832\n",
      "current epoch: 35 current epoch loss: 0.8024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 35/80 [6:19:17<7:42:41, 616.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metric=0.36507528461515903, metric_tc=0.3636470064520836, metric_wt=0.5339344696452221, metric_et=0.19764438744944832\n",
      "0.36507528461515903\n",
      "saved new best metric model\n",
      "current epoch: 35 current mean dice: 0.3651 tc: 0.3636 wt: 0.5339 et: 0.1976\n",
      "best mean dice: 0.3651 at epoch: 35\n",
      "\n",
      " | Global Training Round : 36 |\n",
      "\n",
      "user 0 selected\n",
      "local epoch 1\n",
      "1/194, train_loss: 0.7403\n",
      "2/194, train_loss: 0.7702\n",
      "3/194, train_loss: 0.9241\n",
      "4/194, train_loss: 0.7269\n",
      "5/194, train_loss: 0.7243\n",
      "6/194, train_loss: 0.8248\n",
      "7/194, train_loss: 0.8261\n",
      "8/194, train_loss: 0.8593\n",
      "9/194, train_loss: 0.7751\n",
      "10/194, train_loss: 0.7891\n",
      "11/194, train_loss: 0.7986\n",
      "12/194, train_loss: 0.6330\n",
      "13/194, train_loss: 0.7079\n",
      "14/194, train_loss: 0.6643\n",
      "15/194, train_loss: 0.7700\n",
      "16/194, train_loss: 0.7592\n",
      "17/194, train_loss: 0.6468\n",
      "18/194, train_loss: 0.8256\n",
      "19/194, train_loss: 0.7931\n",
      "20/194, train_loss: 0.7491\n",
      "21/194, train_loss: 0.8339\n",
      "22/194, train_loss: 0.8355\n",
      "23/194, train_loss: 0.8319\n",
      "24/194, train_loss: 0.5898\n",
      "25/194, train_loss: 0.7478\n",
      "26/194, train_loss: 0.8164\n",
      "27/194, train_loss: 0.7039\n",
      "28/194, train_loss: 0.8173\n",
      "29/194, train_loss: 0.9107\n",
      "30/194, train_loss: 0.8696\n",
      "31/194, train_loss: 0.7978\n",
      "32/194, train_loss: 0.8727\n",
      "33/194, train_loss: 0.7576\n",
      "34/194, train_loss: 0.7082\n",
      "35/194, train_loss: 0.9459\n",
      "36/194, train_loss: 0.7406\n",
      "37/194, train_loss: 0.8307\n",
      "38/194, train_loss: 0.7938\n",
      "39/194, train_loss: 0.7189\n",
      "40/194, train_loss: 0.8241\n",
      "41/194, train_loss: 0.8656\n",
      "42/194, train_loss: 0.8952\n",
      "43/194, train_loss: 0.7136\n",
      "44/194, train_loss: 0.8416\n",
      "45/194, train_loss: 0.9012\n",
      "46/194, train_loss: 0.7853\n",
      "47/194, train_loss: 0.7367\n",
      "48/194, train_loss: 0.8525\n",
      "49/194, train_loss: 0.8785\n",
      "50/194, train_loss: 0.6145\n",
      "51/194, train_loss: 0.7699\n",
      "52/194, train_loss: 0.7954\n",
      "53/194, train_loss: 0.8938\n",
      "54/194, train_loss: 0.8623\n",
      "55/194, train_loss: 0.8103\n",
      "56/194, train_loss: 0.8341\n",
      "57/194, train_loss: 0.8173\n",
      "58/194, train_loss: 0.8423\n",
      "59/194, train_loss: 0.9317\n",
      "60/194, train_loss: 0.8082\n",
      "61/194, train_loss: 0.8108\n",
      "62/194, train_loss: 0.7336\n",
      "63/194, train_loss: 0.7342\n",
      "64/194, train_loss: 0.7441\n",
      "65/194, train_loss: 0.7386\n",
      "66/194, train_loss: 0.7984\n",
      "67/194, train_loss: 0.6193\n",
      "68/194, train_loss: 0.8831\n",
      "69/194, train_loss: 0.9067\n",
      "70/194, train_loss: 0.7034\n",
      "71/194, train_loss: 0.7182\n",
      "72/194, train_loss: 0.6827\n",
      "73/194, train_loss: 0.8981\n",
      "74/194, train_loss: 0.6571\n",
      "75/194, train_loss: 0.8192\n",
      "76/194, train_loss: 0.8369\n",
      "77/194, train_loss: 0.8319\n",
      "78/194, train_loss: 0.7881\n",
      "79/194, train_loss: 0.6853\n",
      "80/194, train_loss: 0.7730\n",
      "81/194, train_loss: 0.8932\n",
      "82/194, train_loss: 0.7328\n",
      "83/194, train_loss: 0.8582\n",
      "84/194, train_loss: 0.7900\n",
      "85/194, train_loss: 0.7041\n",
      "86/194, train_loss: 0.8814\n",
      "87/194, train_loss: 0.8509\n",
      "88/194, train_loss: 0.8937\n",
      "89/194, train_loss: 0.7366\n",
      "90/194, train_loss: 0.8412\n",
      "91/194, train_loss: 0.8360\n",
      "92/194, train_loss: 0.9216\n",
      "93/194, train_loss: 0.8171\n",
      "94/194, train_loss: 0.7618\n",
      "95/194, train_loss: 0.9062\n",
      "96/194, train_loss: 0.7449\n",
      "97/194, train_loss: 0.8671\n",
      "98/194, train_loss: 0.7210\n",
      "99/194, train_loss: 0.8866\n",
      "100/194, train_loss: 0.7347\n",
      "101/194, train_loss: 0.8455\n",
      "102/194, train_loss: 0.9164\n",
      "103/194, train_loss: 0.6839\n",
      "104/194, train_loss: 0.8649\n",
      "105/194, train_loss: 0.7328\n",
      "106/194, train_loss: 0.8313\n",
      "107/194, train_loss: 0.8215\n",
      "108/194, train_loss: 0.9245\n",
      "109/194, train_loss: 0.7418\n",
      "110/194, train_loss: 0.7867\n",
      "111/194, train_loss: 0.6819\n",
      "112/194, train_loss: 0.6583\n",
      "113/194, train_loss: 0.8095\n",
      "114/194, train_loss: 0.7164\n",
      "115/194, train_loss: 0.8843\n",
      "116/194, train_loss: 0.7917\n",
      "117/194, train_loss: 0.7783\n",
      "118/194, train_loss: 0.8163\n",
      "119/194, train_loss: 0.6817\n",
      "120/194, train_loss: 0.8806\n",
      "121/194, train_loss: 0.9353\n",
      "122/194, train_loss: 0.9290\n",
      "123/194, train_loss: 0.8378\n",
      "124/194, train_loss: 0.8404\n",
      "125/194, train_loss: 0.8031\n",
      "126/194, train_loss: 0.8354\n",
      "127/194, train_loss: 0.9686\n",
      "128/194, train_loss: 0.8418\n",
      "129/194, train_loss: 0.7062\n",
      "130/194, train_loss: 0.9237\n",
      "131/194, train_loss: 0.8596\n",
      "132/194, train_loss: 0.6906\n",
      "133/194, train_loss: 0.8610\n",
      "134/194, train_loss: 0.7733\n",
      "135/194, train_loss: 0.7980\n",
      "136/194, train_loss: 0.8521\n",
      "137/194, train_loss: 0.8953\n",
      "138/194, train_loss: 0.7068\n",
      "139/194, train_loss: 0.7701\n",
      "140/194, train_loss: 0.6597\n",
      "141/194, train_loss: 0.9116\n",
      "142/194, train_loss: 0.9321\n",
      "143/194, train_loss: 0.9188\n",
      "144/194, train_loss: 0.7425\n",
      "145/194, train_loss: 0.7842\n",
      "146/194, train_loss: 0.7474\n",
      "147/194, train_loss: 0.7791\n",
      "148/194, train_loss: 0.7407\n",
      "149/194, train_loss: 0.8347\n",
      "150/194, train_loss: 0.8222\n",
      "151/194, train_loss: 0.8373\n",
      "152/194, train_loss: 0.9293\n",
      "153/194, train_loss: 0.9484\n",
      "154/194, train_loss: 0.9165\n",
      "155/194, train_loss: 0.8968\n",
      "156/194, train_loss: 0.8961\n",
      "157/194, train_loss: 0.6805\n",
      "158/194, train_loss: 0.9166\n",
      "159/194, train_loss: 0.9275\n",
      "160/194, train_loss: 0.8095\n",
      "161/194, train_loss: 0.8346\n",
      "162/194, train_loss: 0.8539\n",
      "163/194, train_loss: 0.8266\n",
      "164/194, train_loss: 0.8476\n",
      "165/194, train_loss: 0.8864\n",
      "166/194, train_loss: 0.8002\n",
      "167/194, train_loss: 0.8606\n",
      "168/194, train_loss: 0.7835\n",
      "169/194, train_loss: 0.6102\n",
      "170/194, train_loss: 0.8161\n",
      "171/194, train_loss: 0.7677\n",
      "172/194, train_loss: 0.5840\n",
      "173/194, train_loss: 0.7236\n",
      "174/194, train_loss: 0.6972\n",
      "175/194, train_loss: 0.8436\n",
      "176/194, train_loss: 0.7065\n",
      "177/194, train_loss: 0.9188\n",
      "178/194, train_loss: 0.7035\n",
      "179/194, train_loss: 0.7402\n",
      "180/194, train_loss: 0.9021\n",
      "181/194, train_loss: 0.7137\n",
      "182/194, train_loss: 0.8026\n",
      "183/194, train_loss: 0.7502\n",
      "184/194, train_loss: 0.6528\n",
      "185/194, train_loss: 0.8925\n",
      "186/194, train_loss: 0.8628\n",
      "187/194, train_loss: 0.8835\n",
      "188/194, train_loss: 0.7378\n",
      "189/194, train_loss: 0.7165\n",
      "190/194, train_loss: 0.7620\n",
      "191/194, train_loss: 0.8343\n",
      "192/194, train_loss: 0.7835\n",
      "193/194, train_loss: 0.8662\n",
      "194/194, train_loss: 0.8906\n",
      "metric=0.34761449073751766, metric_tc=0.3509516576305032, metric_wt=0.4985953892270724, metric_et=0.19329641914616028\n",
      "metric=0.34761449073751766, metric_tc=0.3509516576305032, metric_wt=0.4985953892270724, metric_et=0.19329641914616028\n",
      "current epoch: 36 current epoch loss: 0.8021\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 36/80 [6:30:52<7:49:41, 640.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metric=0.34761449073751766, metric_tc=0.3509516576305032, metric_wt=0.4985953892270724, metric_et=0.19329641914616028\n",
      "0.34761449073751766\n",
      "current epoch: 36 current mean dice: 0.3476 tc: 0.3510 wt: 0.4986 et: 0.1933\n",
      "best mean dice: 0.3651 at epoch: 35\n",
      "\n",
      " | Global Training Round : 37 |\n",
      "\n",
      "user 0 selected\n",
      "local epoch 1\n",
      "1/194, train_loss: 0.8953\n",
      "2/194, train_loss: 0.6741\n",
      "3/194, train_loss: 0.7275\n",
      "4/194, train_loss: 0.8740\n",
      "5/194, train_loss: 0.7317\n",
      "6/194, train_loss: 0.7186\n",
      "7/194, train_loss: 0.7611\n",
      "8/194, train_loss: 0.9079\n",
      "9/194, train_loss: 0.8644\n",
      "10/194, train_loss: 0.8249\n",
      "11/194, train_loss: 0.8657\n",
      "12/194, train_loss: 0.7109\n",
      "13/194, train_loss: 0.7444\n",
      "14/194, train_loss: 0.8235\n",
      "15/194, train_loss: 0.8963\n",
      "16/194, train_loss: 0.7089\n",
      "17/194, train_loss: 0.8998\n",
      "18/194, train_loss: 0.7581\n",
      "19/194, train_loss: 0.7436\n",
      "20/194, train_loss: 0.8045\n",
      "21/194, train_loss: 0.7737\n",
      "22/194, train_loss: 0.6309\n",
      "23/194, train_loss: 0.8188\n",
      "24/194, train_loss: 0.8136\n",
      "25/194, train_loss: 0.9346\n",
      "26/194, train_loss: 0.7388\n",
      "27/194, train_loss: 0.8941\n",
      "28/194, train_loss: 0.6373\n",
      "29/194, train_loss: 0.8548\n",
      "30/194, train_loss: 0.7585\n",
      "31/194, train_loss: 0.8821\n",
      "32/194, train_loss: 0.8325\n",
      "33/194, train_loss: 0.8037\n",
      "34/194, train_loss: 0.8924\n",
      "35/194, train_loss: 0.9255\n",
      "36/194, train_loss: 0.7669\n",
      "37/194, train_loss: 0.7739\n",
      "38/194, train_loss: 0.8061\n",
      "39/194, train_loss: 0.7771\n",
      "40/194, train_loss: 0.7319\n",
      "41/194, train_loss: 0.7611\n",
      "42/194, train_loss: 0.9341\n",
      "43/194, train_loss: 0.8652\n",
      "44/194, train_loss: 0.4576\n",
      "45/194, train_loss: 0.7727\n",
      "46/194, train_loss: 0.5426\n",
      "47/194, train_loss: 0.8839\n",
      "48/194, train_loss: 0.7315\n",
      "49/194, train_loss: 0.8832\n",
      "50/194, train_loss: 0.8835\n",
      "51/194, train_loss: 0.7289\n",
      "52/194, train_loss: 0.6769\n",
      "53/194, train_loss: 0.7963\n",
      "54/194, train_loss: 0.7238\n",
      "55/194, train_loss: 0.6811\n",
      "56/194, train_loss: 0.8571\n",
      "57/194, train_loss: 0.8773\n",
      "58/194, train_loss: 0.8135\n",
      "59/194, train_loss: 0.7910\n",
      "60/194, train_loss: 0.8444\n",
      "61/194, train_loss: 0.6672\n",
      "62/194, train_loss: 0.5742\n",
      "63/194, train_loss: 0.4807\n",
      "64/194, train_loss: 0.6168\n",
      "65/194, train_loss: 0.8309\n",
      "66/194, train_loss: 0.9201\n",
      "67/194, train_loss: 0.6777\n",
      "68/194, train_loss: 0.6934\n",
      "69/194, train_loss: 0.7874\n",
      "70/194, train_loss: 0.7703\n",
      "71/194, train_loss: 0.7340\n",
      "72/194, train_loss: 0.8359\n",
      "73/194, train_loss: 0.7641\n",
      "74/194, train_loss: 0.7746\n",
      "75/194, train_loss: 0.8305\n",
      "76/194, train_loss: 0.7738\n",
      "77/194, train_loss: 0.8982\n",
      "78/194, train_loss: 0.8022\n",
      "79/194, train_loss: 0.7905\n",
      "80/194, train_loss: 0.8463\n",
      "81/194, train_loss: 0.9122\n",
      "82/194, train_loss: 0.7666\n",
      "83/194, train_loss: 0.8430\n",
      "84/194, train_loss: 0.7980\n",
      "85/194, train_loss: 0.7693\n",
      "86/194, train_loss: 0.7533\n",
      "87/194, train_loss: 0.7706\n",
      "88/194, train_loss: 0.8306\n",
      "89/194, train_loss: 0.8695\n",
      "90/194, train_loss: 0.9568\n",
      "91/194, train_loss: 0.9468\n",
      "92/194, train_loss: 0.8649\n",
      "93/194, train_loss: 0.7877\n",
      "94/194, train_loss: 0.7416\n",
      "95/194, train_loss: 0.7243\n",
      "96/194, train_loss: 0.9240\n",
      "97/194, train_loss: 0.8470\n",
      "98/194, train_loss: 0.7439\n",
      "99/194, train_loss: 0.6779\n",
      "100/194, train_loss: 0.9078\n",
      "101/194, train_loss: 0.7743\n",
      "102/194, train_loss: 0.9734\n",
      "103/194, train_loss: 0.8231\n",
      "104/194, train_loss: 0.6749\n",
      "105/194, train_loss: 0.8351\n",
      "106/194, train_loss: 0.7960\n",
      "107/194, train_loss: 0.7075\n",
      "108/194, train_loss: 0.7104\n",
      "109/194, train_loss: 0.8086\n",
      "110/194, train_loss: 0.6149\n",
      "111/194, train_loss: 0.8095\n",
      "112/194, train_loss: 0.6186\n",
      "113/194, train_loss: 0.9438\n",
      "114/194, train_loss: 0.7453\n",
      "115/194, train_loss: 0.7547\n",
      "116/194, train_loss: 0.7953\n",
      "117/194, train_loss: 0.7997\n",
      "118/194, train_loss: 0.9427\n",
      "119/194, train_loss: 0.8625\n",
      "120/194, train_loss: 0.7706\n",
      "121/194, train_loss: 0.7684\n",
      "122/194, train_loss: 0.9460\n",
      "123/194, train_loss: 0.8229\n",
      "124/194, train_loss: 0.7938\n",
      "125/194, train_loss: 0.8076\n",
      "126/194, train_loss: 0.6813\n",
      "127/194, train_loss: 0.9427\n",
      "128/194, train_loss: 0.8840\n",
      "129/194, train_loss: 0.8788\n",
      "130/194, train_loss: 0.9469\n",
      "131/194, train_loss: 0.8269\n",
      "132/194, train_loss: 0.8123\n",
      "133/194, train_loss: 0.7254\n",
      "134/194, train_loss: 0.8375\n",
      "135/194, train_loss: 0.7548\n",
      "136/194, train_loss: 0.7826\n",
      "137/194, train_loss: 0.7395\n",
      "138/194, train_loss: 0.8436\n",
      "139/194, train_loss: 0.7876\n",
      "140/194, train_loss: 0.5609\n",
      "141/194, train_loss: 0.7989\n",
      "142/194, train_loss: 0.7410\n",
      "143/194, train_loss: 0.8623\n",
      "144/194, train_loss: 0.8908\n",
      "145/194, train_loss: 0.8729\n",
      "146/194, train_loss: 0.8330\n",
      "147/194, train_loss: 0.8932\n",
      "148/194, train_loss: 0.7949\n",
      "149/194, train_loss: 0.8060\n",
      "150/194, train_loss: 0.9232\n",
      "151/194, train_loss: 0.7980\n",
      "152/194, train_loss: 0.7956\n",
      "153/194, train_loss: 0.7822\n",
      "154/194, train_loss: 0.9395\n",
      "155/194, train_loss: 0.9632\n",
      "156/194, train_loss: 0.7072\n",
      "157/194, train_loss: 0.8117\n",
      "158/194, train_loss: 0.9251\n",
      "159/194, train_loss: 0.8957\n",
      "160/194, train_loss: 0.8638\n",
      "161/194, train_loss: 0.7569\n",
      "162/194, train_loss: 0.6849\n",
      "163/194, train_loss: 0.8950\n",
      "164/194, train_loss: 0.9121\n",
      "165/194, train_loss: 0.6379\n",
      "166/194, train_loss: 0.6799\n",
      "167/194, train_loss: 0.8493\n",
      "168/194, train_loss: 0.8207\n",
      "169/194, train_loss: 0.8102\n",
      "170/194, train_loss: 0.8962\n",
      "171/194, train_loss: 0.7584\n",
      "172/194, train_loss: 0.8393\n",
      "173/194, train_loss: 0.7078\n",
      "174/194, train_loss: 0.8385\n",
      "175/194, train_loss: 0.8855\n",
      "176/194, train_loss: 0.8312\n",
      "177/194, train_loss: 0.8138\n",
      "178/194, train_loss: 0.7586\n",
      "179/194, train_loss: 0.7893\n",
      "180/194, train_loss: 0.8312\n",
      "181/194, train_loss: 0.7749\n",
      "182/194, train_loss: 0.7554\n",
      "183/194, train_loss: 0.6795\n",
      "184/194, train_loss: 0.7113\n",
      "185/194, train_loss: 0.9295\n",
      "186/194, train_loss: 0.9403\n",
      "187/194, train_loss: 0.8354\n",
      "188/194, train_loss: 0.8894\n",
      "189/194, train_loss: 0.8806\n",
      "190/194, train_loss: 0.8621\n",
      "191/194, train_loss: 0.7208\n",
      "192/194, train_loss: 0.8871\n",
      "193/194, train_loss: 0.7385\n",
      "194/194, train_loss: 0.7300\n",
      "metric=0.3482339984426896, metric_tc=0.3601410708700617, metric_wt=0.4865828740100066, metric_et=0.19797804687793055\n",
      "metric=0.3482339984426896, metric_tc=0.3601410708700617, metric_wt=0.4865828740100066, metric_et=0.19797804687793055\n",
      "current epoch: 37 current epoch loss: 0.7996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▋     | 37/80 [6:41:11<7:34:19, 633.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metric=0.3482339984426896, metric_tc=0.3601410708700617, metric_wt=0.4865828740100066, metric_et=0.19797804687793055\n",
      "0.3482339984426896\n",
      "current epoch: 37 current mean dice: 0.3482 tc: 0.3601 wt: 0.4866 et: 0.1980\n",
      "best mean dice: 0.3651 at epoch: 35\n",
      "\n",
      " | Global Training Round : 38 |\n",
      "\n",
      "user 0 selected\n",
      "local epoch 1\n",
      "1/194, train_loss: 0.7918\n",
      "2/194, train_loss: 0.7648\n",
      "3/194, train_loss: 0.7503\n",
      "4/194, train_loss: 0.7754\n",
      "5/194, train_loss: 0.8549\n",
      "6/194, train_loss: 0.6832\n",
      "7/194, train_loss: 0.6159\n",
      "8/194, train_loss: 0.7914\n",
      "9/194, train_loss: 0.8413\n",
      "10/194, train_loss: 0.8861\n",
      "11/194, train_loss: 0.7192\n",
      "12/194, train_loss: 0.7673\n",
      "13/194, train_loss: 0.7307\n",
      "14/194, train_loss: 0.9332\n",
      "15/194, train_loss: 0.8692\n",
      "16/194, train_loss: 0.6981\n",
      "17/194, train_loss: 0.8509\n",
      "18/194, train_loss: 0.7058\n",
      "19/194, train_loss: 0.8024\n",
      "20/194, train_loss: 0.8897\n",
      "21/194, train_loss: 0.7916\n",
      "22/194, train_loss: 0.6267\n",
      "23/194, train_loss: 0.8720\n",
      "24/194, train_loss: 0.7260\n",
      "25/194, train_loss: 0.8338\n",
      "26/194, train_loss: 0.8008\n",
      "27/194, train_loss: 0.8486\n",
      "28/194, train_loss: 0.8142\n",
      "29/194, train_loss: 0.8843\n",
      "30/194, train_loss: 0.9684\n",
      "31/194, train_loss: 0.8793\n",
      "32/194, train_loss: 0.7023\n",
      "33/194, train_loss: 0.8841\n",
      "34/194, train_loss: 0.8650\n",
      "35/194, train_loss: 0.8079\n",
      "36/194, train_loss: 0.7146\n",
      "37/194, train_loss: 0.8041\n",
      "38/194, train_loss: 0.7857\n",
      "39/194, train_loss: 0.7131\n",
      "40/194, train_loss: 0.5933\n",
      "41/194, train_loss: 0.8060\n",
      "42/194, train_loss: 0.9193\n",
      "43/194, train_loss: 0.8955\n",
      "44/194, train_loss: 0.8230\n",
      "45/194, train_loss: 0.7706\n",
      "46/194, train_loss: 0.8137\n",
      "47/194, train_loss: 0.7204\n",
      "48/194, train_loss: 0.6979\n",
      "49/194, train_loss: 0.7471\n",
      "50/194, train_loss: 0.7630\n",
      "51/194, train_loss: 0.8534\n",
      "52/194, train_loss: 0.8638\n",
      "53/194, train_loss: 0.9441\n",
      "54/194, train_loss: 0.7939\n",
      "55/194, train_loss: 0.7649\n",
      "56/194, train_loss: 0.7599\n",
      "57/194, train_loss: 0.7825\n",
      "58/194, train_loss: 0.8570\n",
      "59/194, train_loss: 0.7895\n",
      "60/194, train_loss: 0.8499\n",
      "61/194, train_loss: 0.8686\n",
      "62/194, train_loss: 0.7016\n",
      "63/194, train_loss: 0.6852\n",
      "64/194, train_loss: 0.7867\n",
      "65/194, train_loss: 0.8766\n",
      "66/194, train_loss: 0.9103\n",
      "67/194, train_loss: 0.7143\n",
      "68/194, train_loss: 0.6837\n",
      "69/194, train_loss: 0.9451\n",
      "70/194, train_loss: 0.8332\n",
      "71/194, train_loss: 0.8289\n",
      "72/194, train_loss: 0.8466\n",
      "73/194, train_loss: 0.8362\n",
      "74/194, train_loss: 0.6844\n",
      "75/194, train_loss: 0.7868\n",
      "76/194, train_loss: 0.8528\n",
      "77/194, train_loss: 0.6592\n",
      "78/194, train_loss: 0.6804\n",
      "79/194, train_loss: 0.8353\n",
      "80/194, train_loss: 0.8529\n",
      "81/194, train_loss: 0.7201\n",
      "82/194, train_loss: 0.9114\n",
      "83/194, train_loss: 0.8150\n",
      "84/194, train_loss: 0.8495\n",
      "85/194, train_loss: 0.8775\n",
      "86/194, train_loss: 0.9338\n",
      "87/194, train_loss: 0.8366\n",
      "88/194, train_loss: 0.9271\n",
      "89/194, train_loss: 0.8405\n",
      "90/194, train_loss: 0.7122\n",
      "91/194, train_loss: 0.8015\n",
      "92/194, train_loss: 0.7559\n",
      "93/194, train_loss: 0.8995\n",
      "94/194, train_loss: 0.8886\n",
      "95/194, train_loss: 0.8565\n",
      "96/194, train_loss: 0.7380\n",
      "97/194, train_loss: 0.9320\n",
      "98/194, train_loss: 0.6996\n",
      "99/194, train_loss: 0.8301\n",
      "100/194, train_loss: 0.7095\n",
      "101/194, train_loss: 0.7915\n",
      "102/194, train_loss: 0.8415\n",
      "103/194, train_loss: 0.7685\n",
      "104/194, train_loss: 0.8419\n",
      "105/194, train_loss: 0.8450\n",
      "106/194, train_loss: 0.8275\n",
      "107/194, train_loss: 0.6613\n",
      "108/194, train_loss: 0.7939\n",
      "109/194, train_loss: 0.7626\n",
      "110/194, train_loss: 0.9036\n",
      "111/194, train_loss: 0.7961\n",
      "112/194, train_loss: 0.5392\n",
      "113/194, train_loss: 0.9429\n",
      "114/194, train_loss: 0.6946\n",
      "115/194, train_loss: 0.8017\n",
      "116/194, train_loss: 0.7749\n",
      "117/194, train_loss: 0.8534\n",
      "118/194, train_loss: 0.7350\n",
      "119/194, train_loss: 0.6777\n",
      "120/194, train_loss: 0.8276\n",
      "121/194, train_loss: 0.9374\n",
      "122/194, train_loss: 0.7398\n",
      "123/194, train_loss: 0.8391\n",
      "124/194, train_loss: 0.9020\n",
      "125/194, train_loss: 0.7700\n",
      "126/194, train_loss: 0.8531\n",
      "127/194, train_loss: 0.8322\n",
      "128/194, train_loss: 0.8636\n",
      "129/194, train_loss: 0.8279\n",
      "130/194, train_loss: 0.8412\n",
      "131/194, train_loss: 0.7911\n",
      "132/194, train_loss: 0.7371\n",
      "133/194, train_loss: 0.8499\n",
      "134/194, train_loss: 0.6201\n",
      "135/194, train_loss: 0.7438\n",
      "136/194, train_loss: 0.8404\n",
      "137/194, train_loss: 0.7242\n",
      "138/194, train_loss: 0.8161\n",
      "139/194, train_loss: 0.6711\n",
      "140/194, train_loss: 0.7638\n",
      "141/194, train_loss: 0.9664\n",
      "142/194, train_loss: 0.9564\n",
      "143/194, train_loss: 0.9116\n",
      "144/194, train_loss: 0.9356\n",
      "145/194, train_loss: 0.8029\n",
      "146/194, train_loss: 0.8685\n",
      "147/194, train_loss: 0.8471\n",
      "148/194, train_loss: 0.8038\n",
      "149/194, train_loss: 0.8904\n",
      "150/194, train_loss: 0.8456\n",
      "151/194, train_loss: 0.8078\n",
      "152/194, train_loss: 0.9098\n",
      "153/194, train_loss: 0.8903\n",
      "154/194, train_loss: 0.8725\n",
      "155/194, train_loss: 0.8325\n",
      "156/194, train_loss: 0.8344\n",
      "157/194, train_loss: 0.7991\n",
      "158/194, train_loss: 0.7281\n",
      "159/194, train_loss: 0.8659\n",
      "160/194, train_loss: 0.7667\n",
      "161/194, train_loss: 0.9097\n",
      "162/194, train_loss: 0.8475\n",
      "163/194, train_loss: 0.8688\n",
      "164/194, train_loss: 0.9189\n",
      "165/194, train_loss: 0.8125\n",
      "166/194, train_loss: 0.7556\n",
      "167/194, train_loss: 0.8373\n",
      "168/194, train_loss: 0.7404\n",
      "169/194, train_loss: 0.7171\n",
      "170/194, train_loss: 0.8175\n",
      "171/194, train_loss: 0.8733\n",
      "172/194, train_loss: 0.6881\n",
      "173/194, train_loss: 0.8167\n",
      "174/194, train_loss: 0.7918\n",
      "175/194, train_loss: 0.8849\n",
      "176/194, train_loss: 0.7558\n",
      "177/194, train_loss: 0.7925\n",
      "178/194, train_loss: 0.7840\n",
      "179/194, train_loss: 0.8005\n",
      "180/194, train_loss: 0.8696\n",
      "181/194, train_loss: 0.6316\n",
      "182/194, train_loss: 0.9102\n",
      "183/194, train_loss: 0.6922\n",
      "184/194, train_loss: 0.6604\n",
      "185/194, train_loss: 0.9383\n",
      "186/194, train_loss: 0.8840\n",
      "187/194, train_loss: 0.8009\n",
      "188/194, train_loss: 0.7994\n",
      "189/194, train_loss: 0.8023\n",
      "190/194, train_loss: 0.7647\n",
      "191/194, train_loss: 0.9565\n",
      "192/194, train_loss: 0.7706\n",
      "193/194, train_loss: 0.7582\n",
      "194/194, train_loss: 0.8510\n",
      "metric=0.32680610350022715, metric_tc=0.33531807688996196, metric_wt=0.4606617571165164, metric_et=0.1844384715271493\n",
      "metric=0.32680610350022715, metric_tc=0.33531807688996196, metric_wt=0.4606617571165164, metric_et=0.1844384715271493\n",
      "current epoch: 38 current epoch loss: 0.8069\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 38/80 [6:51:44<7:23:36, 633.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metric=0.32680610350022715, metric_tc=0.33531807688996196, metric_wt=0.4606617571165164, metric_et=0.1844384715271493\n",
      "0.32680610350022715\n",
      "current epoch: 38 current mean dice: 0.3268 tc: 0.3353 wt: 0.4607 et: 0.1844\n",
      "best mean dice: 0.3651 at epoch: 35\n",
      "\n",
      " | Global Training Round : 39 |\n",
      "\n",
      "user 0 selected\n",
      "local epoch 1\n",
      "1/194, train_loss: 0.8197\n",
      "2/194, train_loss: 0.7948\n",
      "3/194, train_loss: 0.8852\n",
      "4/194, train_loss: 0.8310\n",
      "5/194, train_loss: 0.7641\n",
      "6/194, train_loss: 0.6583\n",
      "7/194, train_loss: 0.7247\n",
      "8/194, train_loss: 0.8473\n",
      "9/194, train_loss: 0.6257\n",
      "10/194, train_loss: 0.8584\n",
      "11/194, train_loss: 0.8187\n",
      "12/194, train_loss: 0.8810\n",
      "13/194, train_loss: 0.4994\n",
      "14/194, train_loss: 0.7527\n",
      "15/194, train_loss: 0.7327\n",
      "16/194, train_loss: 0.8805\n",
      "17/194, train_loss: 0.8371\n",
      "18/194, train_loss: 0.9565\n",
      "19/194, train_loss: 0.6740\n",
      "20/194, train_loss: 0.8622\n",
      "21/194, train_loss: 0.8797\n",
      "22/194, train_loss: 0.8713\n",
      "23/194, train_loss: 0.7681\n",
      "24/194, train_loss: 0.6683\n",
      "25/194, train_loss: 0.7711\n",
      "26/194, train_loss: 0.8003\n",
      "27/194, train_loss: 0.7595\n",
      "28/194, train_loss: 0.7407\n",
      "29/194, train_loss: 0.8765\n",
      "30/194, train_loss: 0.8843\n",
      "31/194, train_loss: 0.8392\n",
      "32/194, train_loss: 0.8133\n",
      "33/194, train_loss: 0.8590\n",
      "34/194, train_loss: 0.7450\n",
      "35/194, train_loss: 0.7297\n",
      "36/194, train_loss: 0.7349\n",
      "37/194, train_loss: 0.8352\n",
      "38/194, train_loss: 0.8631\n",
      "39/194, train_loss: 0.7261\n",
      "40/194, train_loss: 0.6533\n",
      "41/194, train_loss: 0.7825\n",
      "42/194, train_loss: 0.7820\n",
      "43/194, train_loss: 0.9039\n",
      "44/194, train_loss: 0.7905\n",
      "45/194, train_loss: 0.7047\n",
      "46/194, train_loss: 0.7817\n",
      "47/194, train_loss: 0.8086\n",
      "48/194, train_loss: 0.7305\n",
      "49/194, train_loss: 0.7492\n",
      "50/194, train_loss: 0.7651\n",
      "51/194, train_loss: 0.5888\n",
      "52/194, train_loss: 0.6089\n",
      "53/194, train_loss: 0.6443\n",
      "54/194, train_loss: 0.8666\n",
      "55/194, train_loss: 0.6756\n",
      "56/194, train_loss: 0.9099\n",
      "57/194, train_loss: 0.8694\n",
      "58/194, train_loss: 0.9400\n",
      "59/194, train_loss: 0.9378\n",
      "60/194, train_loss: 0.8261\n",
      "61/194, train_loss: 0.7464\n",
      "62/194, train_loss: 0.7637\n",
      "63/194, train_loss: 0.8124\n",
      "64/194, train_loss: 0.8269\n",
      "65/194, train_loss: 0.7152\n",
      "66/194, train_loss: 0.7660\n",
      "67/194, train_loss: 0.8080\n",
      "68/194, train_loss: 0.6522\n",
      "69/194, train_loss: 0.9243\n",
      "70/194, train_loss: 0.7324\n",
      "71/194, train_loss: 0.9005\n",
      "72/194, train_loss: 0.7063\n",
      "73/194, train_loss: 0.6164\n",
      "74/194, train_loss: 0.7375\n",
      "75/194, train_loss: 0.7529\n",
      "76/194, train_loss: 0.7270\n",
      "77/194, train_loss: 0.6906\n",
      "78/194, train_loss: 0.8150\n",
      "79/194, train_loss: 0.7898\n",
      "80/194, train_loss: 0.8169\n",
      "81/194, train_loss: 0.8236\n",
      "82/194, train_loss: 0.8600\n",
      "83/194, train_loss: 0.7914\n",
      "84/194, train_loss: 0.8202\n",
      "85/194, train_loss: 0.7778\n",
      "86/194, train_loss: 0.7395\n",
      "87/194, train_loss: 0.8380\n",
      "88/194, train_loss: 0.8424\n",
      "89/194, train_loss: 0.8957\n",
      "90/194, train_loss: 0.8369\n",
      "91/194, train_loss: 0.8790\n",
      "92/194, train_loss: 0.8276\n",
      "93/194, train_loss: 0.7891\n",
      "94/194, train_loss: 0.8134\n",
      "95/194, train_loss: 0.7457\n",
      "96/194, train_loss: 0.7466\n",
      "97/194, train_loss: 0.8908\n",
      "98/194, train_loss: 0.8064\n",
      "99/194, train_loss: 0.8756\n",
      "100/194, train_loss: 0.9087\n",
      "101/194, train_loss: 0.8482\n",
      "102/194, train_loss: 0.9214\n",
      "103/194, train_loss: 0.7060\n",
      "104/194, train_loss: 0.7208\n",
      "105/194, train_loss: 0.8699\n",
      "106/194, train_loss: 0.7524\n",
      "107/194, train_loss: 0.8064\n",
      "108/194, train_loss: 0.7389\n",
      "109/194, train_loss: 0.6207\n",
      "110/194, train_loss: 0.6385\n",
      "111/194, train_loss: 0.7366\n",
      "112/194, train_loss: 0.8474\n",
      "113/194, train_loss: 0.8372\n",
      "114/194, train_loss: 0.8615\n",
      "115/194, train_loss: 0.7029\n",
      "116/194, train_loss: 0.7447\n",
      "117/194, train_loss: 0.7477\n",
      "118/194, train_loss: 0.7609\n",
      "119/194, train_loss: 0.7752\n",
      "120/194, train_loss: 0.7815\n",
      "121/194, train_loss: 0.8942\n",
      "122/194, train_loss: 0.7806\n",
      "123/194, train_loss: 0.8982\n",
      "124/194, train_loss: 0.7332\n",
      "125/194, train_loss: 0.8160\n",
      "126/194, train_loss: 0.7705\n",
      "127/194, train_loss: 0.9682\n",
      "128/194, train_loss: 0.8204\n",
      "129/194, train_loss: 0.7598\n",
      "130/194, train_loss: 0.8296\n",
      "131/194, train_loss: 0.8398\n",
      "132/194, train_loss: 0.8496\n",
      "133/194, train_loss: 0.8433\n",
      "134/194, train_loss: 0.6790\n",
      "135/194, train_loss: 0.8208\n",
      "136/194, train_loss: 0.7162\n",
      "137/194, train_loss: 0.7856\n",
      "138/194, train_loss: 0.8074\n",
      "139/194, train_loss: 0.9152\n",
      "140/194, train_loss: 0.8092\n",
      "141/194, train_loss: 0.6266\n",
      "142/194, train_loss: 0.7995\n",
      "143/194, train_loss: 0.9200\n",
      "144/194, train_loss: 0.7917\n",
      "145/194, train_loss: 0.9637\n",
      "146/194, train_loss: 0.9211\n",
      "147/194, train_loss: 0.9332\n",
      "148/194, train_loss: 0.8483\n",
      "149/194, train_loss: 0.8243\n",
      "150/194, train_loss: 0.9044\n",
      "151/194, train_loss: 0.7975\n",
      "152/194, train_loss: 0.8601\n",
      "153/194, train_loss: 0.7356\n",
      "154/194, train_loss: 0.8684\n",
      "155/194, train_loss: 0.9029\n",
      "156/194, train_loss: 0.7915\n",
      "157/194, train_loss: 0.9055\n",
      "158/194, train_loss: 0.9393\n",
      "159/194, train_loss: 0.8833\n",
      "160/194, train_loss: 0.6523\n",
      "161/194, train_loss: 0.9114\n",
      "162/194, train_loss: 0.8253\n",
      "163/194, train_loss: 0.8485\n",
      "164/194, train_loss: 0.8992\n",
      "165/194, train_loss: 0.7949\n",
      "166/194, train_loss: 0.7935\n",
      "167/194, train_loss: 0.8574\n",
      "168/194, train_loss: 0.9263\n",
      "169/194, train_loss: 0.7273\n",
      "170/194, train_loss: 0.8402\n",
      "171/194, train_loss: 0.6928\n",
      "172/194, train_loss: 0.7554\n",
      "173/194, train_loss: 0.7542\n",
      "174/194, train_loss: 0.7980\n",
      "175/194, train_loss: 0.8029\n",
      "176/194, train_loss: 0.8088\n",
      "177/194, train_loss: 0.9235\n",
      "178/194, train_loss: 0.8415\n",
      "179/194, train_loss: 0.7549\n",
      "180/194, train_loss: 0.8293\n",
      "181/194, train_loss: 0.5306\n",
      "182/194, train_loss: 0.8366\n",
      "183/194, train_loss: 0.7000\n",
      "184/194, train_loss: 0.6099\n",
      "185/194, train_loss: 0.8364\n",
      "186/194, train_loss: 0.8836\n",
      "187/194, train_loss: 0.8996\n",
      "188/194, train_loss: 0.9416\n",
      "189/194, train_loss: 0.7673\n",
      "190/194, train_loss: 0.8590\n",
      "191/194, train_loss: 0.6323\n",
      "192/194, train_loss: 0.7390\n",
      "193/194, train_loss: 0.7594\n",
      "194/194, train_loss: 0.7995\n",
      "metric=0.3663524438937505, metric_tc=0.380716972053051, metric_wt=0.510948346927762, metric_et=0.20739199228895208\n",
      "metric=0.3663524438937505, metric_tc=0.380716972053051, metric_wt=0.510948346927762, metric_et=0.20739199228895208\n",
      "current epoch: 39 current epoch loss: 0.7979\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▉     | 39/80 [7:01:54<7:08:07, 626.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metric=0.3663524438937505, metric_tc=0.380716972053051, metric_wt=0.510948346927762, metric_et=0.20739199228895208\n",
      "0.3663524438937505\n",
      "saved new best metric model\n",
      "current epoch: 39 current mean dice: 0.3664 tc: 0.3807 wt: 0.5109 et: 0.2074\n",
      "best mean dice: 0.3664 at epoch: 39\n",
      "\n",
      " | Global Training Round : 40 |\n",
      "\n",
      "user 0 selected\n",
      "local epoch 1\n",
      "1/194, train_loss: 0.6253\n",
      "2/194, train_loss: 0.7378\n",
      "3/194, train_loss: 0.7910\n",
      "4/194, train_loss: 0.6791\n",
      "5/194, train_loss: 0.6905\n",
      "6/194, train_loss: 0.7975\n",
      "7/194, train_loss: 0.8239\n",
      "8/194, train_loss: 0.7464\n",
      "9/194, train_loss: 0.8581\n",
      "10/194, train_loss: 0.5866\n",
      "11/194, train_loss: 0.7989\n",
      "12/194, train_loss: 0.9268\n",
      "13/194, train_loss: 0.7920\n",
      "14/194, train_loss: 0.8392\n",
      "15/194, train_loss: 0.8681\n",
      "16/194, train_loss: 0.7043\n",
      "17/194, train_loss: 0.7059\n",
      "18/194, train_loss: 0.7579\n",
      "19/194, train_loss: 0.6886\n",
      "20/194, train_loss: 0.7999\n",
      "21/194, train_loss: 0.8975\n",
      "22/194, train_loss: 0.6604\n",
      "23/194, train_loss: 0.6079\n",
      "24/194, train_loss: 0.7790\n",
      "25/194, train_loss: 0.9096\n",
      "26/194, train_loss: 0.7212\n",
      "27/194, train_loss: 0.6990\n",
      "28/194, train_loss: 0.7365\n",
      "29/194, train_loss: 0.7438\n",
      "30/194, train_loss: 0.6488\n",
      "31/194, train_loss: 0.8698\n",
      "32/194, train_loss: 0.5475\n",
      "33/194, train_loss: 0.8717\n",
      "34/194, train_loss: 0.7130\n",
      "35/194, train_loss: 0.7911\n",
      "36/194, train_loss: 0.7848\n",
      "37/194, train_loss: 0.6409\n",
      "38/194, train_loss: 0.6512\n",
      "39/194, train_loss: 0.7762\n",
      "40/194, train_loss: 0.8427\n",
      "41/194, train_loss: 0.8281\n",
      "42/194, train_loss: 0.8140\n",
      "43/194, train_loss: 0.7665\n",
      "44/194, train_loss: 0.8555\n",
      "45/194, train_loss: 0.7095\n",
      "46/194, train_loss: 0.8465\n",
      "47/194, train_loss: 0.8804\n",
      "48/194, train_loss: 0.8868\n",
      "49/194, train_loss: 0.8069\n",
      "50/194, train_loss: 0.7811\n",
      "51/194, train_loss: 0.9357\n",
      "52/194, train_loss: 0.8122\n",
      "53/194, train_loss: 0.9282\n",
      "54/194, train_loss: 0.7692\n",
      "55/194, train_loss: 0.9331\n",
      "56/194, train_loss: 0.8777\n",
      "57/194, train_loss: 0.8256\n",
      "58/194, train_loss: 0.7606\n",
      "59/194, train_loss: 0.8228\n",
      "60/194, train_loss: 0.8218\n",
      "61/194, train_loss: 0.8374\n",
      "62/194, train_loss: 0.7115\n",
      "63/194, train_loss: 0.8985\n",
      "64/194, train_loss: 0.7218\n",
      "65/194, train_loss: 0.8017\n",
      "66/194, train_loss: 0.8291\n",
      "67/194, train_loss: 0.7056\n",
      "68/194, train_loss: 0.8240\n",
      "69/194, train_loss: 0.8645\n",
      "70/194, train_loss: 0.7801\n",
      "71/194, train_loss: 0.7594\n",
      "72/194, train_loss: 0.7797\n",
      "73/194, train_loss: 0.7044\n",
      "74/194, train_loss: 0.7190\n",
      "75/194, train_loss: 0.7827\n",
      "76/194, train_loss: 0.7521\n",
      "77/194, train_loss: 0.6638\n",
      "78/194, train_loss: 0.7384\n",
      "79/194, train_loss: 0.6673\n",
      "80/194, train_loss: 0.5909\n",
      "81/194, train_loss: 0.8755\n",
      "82/194, train_loss: 0.7975\n",
      "83/194, train_loss: 0.7700\n",
      "84/194, train_loss: 0.7613\n",
      "85/194, train_loss: 0.9028\n",
      "86/194, train_loss: 0.8613\n",
      "87/194, train_loss: 0.9373\n",
      "88/194, train_loss: 0.8209\n",
      "89/194, train_loss: 0.8472\n",
      "90/194, train_loss: 0.9254\n",
      "91/194, train_loss: 0.8023\n",
      "92/194, train_loss: 0.7362\n",
      "93/194, train_loss: 0.6083\n",
      "94/194, train_loss: 0.8157\n",
      "95/194, train_loss: 0.5484\n",
      "96/194, train_loss: 0.8198\n",
      "97/194, train_loss: 0.9886\n",
      "98/194, train_loss: 0.7128\n",
      "99/194, train_loss: 0.7653\n",
      "100/194, train_loss: 0.7357\n",
      "101/194, train_loss: 0.8773\n",
      "102/194, train_loss: 0.8282\n",
      "103/194, train_loss: 0.8846\n",
      "104/194, train_loss: 0.9600\n",
      "105/194, train_loss: 0.6989\n",
      "106/194, train_loss: 0.8544\n",
      "107/194, train_loss: 0.7494\n",
      "108/194, train_loss: 0.7149\n",
      "109/194, train_loss: 0.8074\n",
      "110/194, train_loss: 0.6326\n",
      "111/194, train_loss: 0.5939\n",
      "112/194, train_loss: 0.6264\n",
      "113/194, train_loss: 0.8513\n",
      "114/194, train_loss: 0.7971\n",
      "115/194, train_loss: 0.8825\n",
      "116/194, train_loss: 0.8152\n",
      "117/194, train_loss: 0.8772\n",
      "118/194, train_loss: 0.8550\n",
      "119/194, train_loss: 0.8482\n",
      "120/194, train_loss: 0.8419\n",
      "121/194, train_loss: 0.8071\n",
      "122/194, train_loss: 0.8156\n",
      "123/194, train_loss: 0.7147\n",
      "124/194, train_loss: 0.8769\n",
      "125/194, train_loss: 0.9123\n",
      "126/194, train_loss: 0.8834\n",
      "127/194, train_loss: 0.8889\n",
      "128/194, train_loss: 0.8284\n",
      "129/194, train_loss: 0.7707\n",
      "130/194, train_loss: 0.9273\n",
      "131/194, train_loss: 0.9066\n",
      "132/194, train_loss: 0.7941\n",
      "133/194, train_loss: 0.7616\n",
      "134/194, train_loss: 0.6963\n",
      "135/194, train_loss: 0.6933\n",
      "136/194, train_loss: 0.8639\n",
      "137/194, train_loss: 0.7976\n",
      "138/194, train_loss: 0.9289\n",
      "139/194, train_loss: 0.8903\n",
      "140/194, train_loss: 0.9095\n",
      "141/194, train_loss: 0.7763\n",
      "142/194, train_loss: 0.8799\n",
      "143/194, train_loss: 0.7733\n",
      "144/194, train_loss: 0.6989\n",
      "145/194, train_loss: 0.9304\n",
      "146/194, train_loss: 0.8127\n",
      "147/194, train_loss: 0.8632\n",
      "148/194, train_loss: 0.8398\n",
      "149/194, train_loss: 0.9708\n",
      "150/194, train_loss: 0.8688\n",
      "151/194, train_loss: 0.8956\n",
      "152/194, train_loss: 0.9018\n",
      "153/194, train_loss: 0.9401\n",
      "154/194, train_loss: 0.8665\n",
      "155/194, train_loss: 0.8900\n",
      "156/194, train_loss: 0.8274\n",
      "157/194, train_loss: 0.8909\n",
      "158/194, train_loss: 0.8230\n",
      "159/194, train_loss: 0.8246\n",
      "160/194, train_loss: 0.8575\n",
      "161/194, train_loss: 0.8420\n",
      "162/194, train_loss: 0.8190\n",
      "163/194, train_loss: 0.7566\n",
      "164/194, train_loss: 0.8982\n",
      "165/194, train_loss: 0.7543\n",
      "166/194, train_loss: 0.7906\n",
      "167/194, train_loss: 0.7566\n",
      "168/194, train_loss: 0.8631\n",
      "169/194, train_loss: 0.7420\n",
      "170/194, train_loss: 0.7698\n",
      "171/194, train_loss: 0.7842\n",
      "172/194, train_loss: 0.8446\n",
      "173/194, train_loss: 0.8216\n",
      "174/194, train_loss: 0.9212\n",
      "175/194, train_loss: 0.8293\n",
      "176/194, train_loss: 0.8827\n",
      "177/194, train_loss: 0.9110\n",
      "178/194, train_loss: 0.8686\n",
      "179/194, train_loss: 0.7645\n",
      "180/194, train_loss: 0.8838\n",
      "181/194, train_loss: 0.8351\n",
      "182/194, train_loss: 0.7521\n",
      "183/194, train_loss: 0.7893\n",
      "184/194, train_loss: 0.7007\n",
      "185/194, train_loss: 0.8594\n",
      "186/194, train_loss: 0.8088\n",
      "187/194, train_loss: 0.8443\n",
      "188/194, train_loss: 0.7873\n",
      "189/194, train_loss: 0.8014\n",
      "190/194, train_loss: 0.7635\n",
      "191/194, train_loss: 0.7643\n",
      "192/194, train_loss: 0.8105\n",
      "193/194, train_loss: 0.6322\n",
      "194/194, train_loss: 0.7786\n",
      "metric=0.2946116781483094, metric_tc=0.2991062309592962, metric_wt=0.4249572266514103, metric_et=0.15977156705533466\n",
      "metric=0.2946116781483094, metric_tc=0.2991062309592962, metric_wt=0.4249572266514103, metric_et=0.15977156705533466\n",
      "current epoch: 40 current epoch loss: 0.7998\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 40/80 [7:12:28<6:59:07, 628.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metric=0.2946116781483094, metric_tc=0.2991062309592962, metric_wt=0.4249572266514103, metric_et=0.15977156705533466\n",
      "0.2946116781483094\n",
      "current epoch: 40 current mean dice: 0.2946 tc: 0.2991 wt: 0.4250 et: 0.1598\n",
      "best mean dice: 0.3664 at epoch: 39\n",
      "\n",
      " | Global Training Round : 41 |\n",
      "\n",
      "user 0 selected\n",
      "local epoch 1\n",
      "1/194, train_loss: 0.8140\n",
      "2/194, train_loss: 0.9041\n",
      "3/194, train_loss: 0.8137\n",
      "4/194, train_loss: 0.7591\n",
      "5/194, train_loss: 0.7835\n",
      "6/194, train_loss: 0.7279\n",
      "7/194, train_loss: 0.7856\n",
      "8/194, train_loss: 0.6550\n",
      "9/194, train_loss: 0.7610\n",
      "10/194, train_loss: 0.8628\n",
      "11/194, train_loss: 0.8483\n",
      "12/194, train_loss: 0.6311\n",
      "13/194, train_loss: 0.7187\n",
      "14/194, train_loss: 0.6508\n",
      "15/194, train_loss: 0.8078\n",
      "16/194, train_loss: 0.8128\n",
      "17/194, train_loss: 0.8248\n",
      "18/194, train_loss: 0.8627\n",
      "19/194, train_loss: 0.6776\n",
      "20/194, train_loss: 0.9131\n",
      "21/194, train_loss: 0.8163\n",
      "22/194, train_loss: 0.7637\n",
      "23/194, train_loss: 0.6408\n",
      "24/194, train_loss: 0.6083\n",
      "25/194, train_loss: 0.8690\n",
      "26/194, train_loss: 0.8310\n",
      "27/194, train_loss: 0.8133\n",
      "28/194, train_loss: 0.8267\n",
      "29/194, train_loss: 0.9033\n",
      "30/194, train_loss: 0.8684\n",
      "31/194, train_loss: 0.7577\n",
      "32/194, train_loss: 0.9227\n",
      "33/194, train_loss: 0.7298\n",
      "34/194, train_loss: 0.7979\n",
      "35/194, train_loss: 0.8049\n",
      "36/194, train_loss: 0.5459\n",
      "37/194, train_loss: 0.8953\n",
      "38/194, train_loss: 0.7273\n",
      "39/194, train_loss: 0.8069\n",
      "40/194, train_loss: 0.8791\n",
      "41/194, train_loss: 0.8276\n",
      "42/194, train_loss: 0.6766\n",
      "43/194, train_loss: 0.8576\n",
      "44/194, train_loss: 0.7132\n",
      "45/194, train_loss: 0.8849\n",
      "46/194, train_loss: 0.8069\n",
      "47/194, train_loss: 0.6871\n",
      "48/194, train_loss: 0.8252\n",
      "49/194, train_loss: 0.7437\n",
      "50/194, train_loss: 0.8050\n",
      "51/194, train_loss: 0.9004\n",
      "52/194, train_loss: 0.8026\n",
      "53/194, train_loss: 0.8253\n",
      "54/194, train_loss: 0.7613\n",
      "55/194, train_loss: 0.8207\n",
      "56/194, train_loss: 0.8449\n",
      "57/194, train_loss: 0.8637\n",
      "58/194, train_loss: 0.8134\n",
      "59/194, train_loss: 0.8556\n",
      "60/194, train_loss: 0.9096\n",
      "61/194, train_loss: 0.8372\n",
      "62/194, train_loss: 0.8268\n",
      "63/194, train_loss: 0.7464\n",
      "64/194, train_loss: 0.7717\n",
      "65/194, train_loss: 0.6843\n",
      "66/194, train_loss: 0.8015\n",
      "67/194, train_loss: 0.6686\n",
      "68/194, train_loss: 0.8044\n",
      "69/194, train_loss: 0.6906\n",
      "70/194, train_loss: 0.7359\n",
      "71/194, train_loss: 0.7989\n",
      "72/194, train_loss: 0.8754\n",
      "73/194, train_loss: 0.7183\n",
      "74/194, train_loss: 0.8334\n",
      "75/194, train_loss: 0.7722\n",
      "76/194, train_loss: 0.7364\n",
      "77/194, train_loss: 0.6393\n",
      "78/194, train_loss: 0.7251\n",
      "79/194, train_loss: 0.7853\n",
      "80/194, train_loss: 0.8155\n",
      "81/194, train_loss: 0.8091\n",
      "82/194, train_loss: 0.8899\n",
      "83/194, train_loss: 0.7711\n",
      "84/194, train_loss: 0.7231\n",
      "85/194, train_loss: 0.9807\n",
      "86/194, train_loss: 0.8769\n",
      "87/194, train_loss: 0.9522\n",
      "88/194, train_loss: 0.9491\n",
      "89/194, train_loss: 0.8835\n",
      "90/194, train_loss: 0.8235\n",
      "91/194, train_loss: 0.8760\n",
      "92/194, train_loss: 0.7470\n",
      "93/194, train_loss: 0.6964\n",
      "94/194, train_loss: 0.8497\n",
      "95/194, train_loss: 0.8671\n",
      "96/194, train_loss: 0.6075\n",
      "97/194, train_loss: 0.7019\n",
      "98/194, train_loss: 0.7146\n",
      "99/194, train_loss: 0.9325\n",
      "100/194, train_loss: 0.8608\n",
      "101/194, train_loss: 0.7881\n",
      "102/194, train_loss: 0.7654\n",
      "103/194, train_loss: 0.8892\n",
      "104/194, train_loss: 0.6714\n",
      "105/194, train_loss: 0.9017\n",
      "106/194, train_loss: 0.7782\n",
      "107/194, train_loss: 0.7789\n",
      "108/194, train_loss: 0.8997\n",
      "109/194, train_loss: 0.7425\n",
      "110/194, train_loss: 0.7955\n",
      "111/194, train_loss: 0.7021\n",
      "112/194, train_loss: 0.7845\n",
      "113/194, train_loss: 0.8241\n",
      "114/194, train_loss: 0.7754\n",
      "115/194, train_loss: 0.7431\n",
      "116/194, train_loss: 0.7731\n",
      "117/194, train_loss: 0.7780\n",
      "118/194, train_loss: 0.7176\n",
      "119/194, train_loss: 0.7897\n",
      "120/194, train_loss: 0.7697\n",
      "121/194, train_loss: 0.8325\n",
      "122/194, train_loss: 0.9020\n",
      "123/194, train_loss: 0.8416\n",
      "124/194, train_loss: 0.8524\n",
      "125/194, train_loss: 0.8131\n",
      "126/194, train_loss: 0.8993\n",
      "127/194, train_loss: 0.9397\n",
      "128/194, train_loss: 0.8009\n",
      "129/194, train_loss: 0.7873\n",
      "130/194, train_loss: 0.7769\n",
      "131/194, train_loss: 0.7518\n",
      "132/194, train_loss: 0.7085\n",
      "133/194, train_loss: 0.8614\n",
      "134/194, train_loss: 0.6607\n",
      "135/194, train_loss: 0.8759\n",
      "136/194, train_loss: 0.8112\n",
      "137/194, train_loss: 0.8430\n",
      "138/194, train_loss: 0.9048\n",
      "139/194, train_loss: 0.7811\n",
      "140/194, train_loss: 0.7259\n",
      "141/194, train_loss: 0.8390\n",
      "142/194, train_loss: 0.7799\n",
      "143/194, train_loss: 0.8527\n",
      "144/194, train_loss: 0.8990\n",
      "145/194, train_loss: 0.8654\n",
      "146/194, train_loss: 0.8063\n",
      "147/194, train_loss: 0.7671\n",
      "148/194, train_loss: 0.8830\n",
      "149/194, train_loss: 0.9624\n",
      "150/194, train_loss: 0.8522\n",
      "151/194, train_loss: 0.5995\n",
      "152/194, train_loss: 0.8096\n",
      "153/194, train_loss: 0.8784\n",
      "154/194, train_loss: 0.9500\n",
      "155/194, train_loss: 0.9451\n",
      "156/194, train_loss: 0.7326\n",
      "157/194, train_loss: 0.9018\n",
      "158/194, train_loss: 0.8461\n",
      "159/194, train_loss: 0.7739\n",
      "160/194, train_loss: 0.8067\n",
      "161/194, train_loss: 0.9125\n",
      "162/194, train_loss: 0.7234\n",
      "163/194, train_loss: 0.8420\n",
      "164/194, train_loss: 0.8772\n",
      "165/194, train_loss: 0.7026\n",
      "166/194, train_loss: 0.9216\n",
      "167/194, train_loss: 0.7341\n",
      "168/194, train_loss: 0.9038\n",
      "169/194, train_loss: 0.8351\n",
      "170/194, train_loss: 0.7026\n",
      "171/194, train_loss: 0.8330\n",
      "172/194, train_loss: 0.7592\n",
      "173/194, train_loss: 0.7445\n",
      "174/194, train_loss: 0.7506\n",
      "175/194, train_loss: 0.6939\n",
      "176/194, train_loss: 0.6291\n",
      "177/194, train_loss: 0.7145\n",
      "178/194, train_loss: 0.9132\n",
      "179/194, train_loss: 0.6634\n",
      "180/194, train_loss: 0.8104\n",
      "181/194, train_loss: 0.6674\n",
      "182/194, train_loss: 0.5285\n",
      "183/194, train_loss: 0.5863\n",
      "184/194, train_loss: 0.7680\n",
      "185/194, train_loss: 0.8444\n",
      "186/194, train_loss: 0.6891\n",
      "187/194, train_loss: 0.8595\n",
      "188/194, train_loss: 0.8070\n",
      "189/194, train_loss: 0.8992\n",
      "190/194, train_loss: 0.7114\n",
      "191/194, train_loss: 0.7897\n",
      "192/194, train_loss: 0.8922\n",
      "193/194, train_loss: 0.7351\n",
      "194/194, train_loss: 0.9153\n",
      "metric=0.37268558144569397, metric_tc=0.3738666055724025, metric_wt=0.5435105208307505, metric_et=0.20067961482952038\n",
      "metric=0.37268558144569397, metric_tc=0.3738666055724025, metric_wt=0.5435105208307505, metric_et=0.20067961482952038\n",
      "current epoch: 41 current epoch loss: 0.7968\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████▏    | 41/80 [7:22:51<6:47:28, 626.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metric=0.37268558144569397, metric_tc=0.3738666055724025, metric_wt=0.5435105208307505, metric_et=0.20067961482952038\n",
      "0.37268558144569397\n",
      "saved new best metric model\n",
      "current epoch: 41 current mean dice: 0.3727 tc: 0.3739 wt: 0.5435 et: 0.2007\n",
      "best mean dice: 0.3727 at epoch: 41\n",
      "\n",
      " | Global Training Round : 42 |\n",
      "\n",
      "user 0 selected\n",
      "local epoch 1\n",
      "1/194, train_loss: 0.7977\n",
      "2/194, train_loss: 0.8433\n",
      "3/194, train_loss: 0.7697\n",
      "4/194, train_loss: 0.7736\n",
      "5/194, train_loss: 0.7568\n",
      "6/194, train_loss: 0.7674\n",
      "7/194, train_loss: 0.8577\n",
      "8/194, train_loss: 0.8090\n",
      "9/194, train_loss: 0.8685\n",
      "10/194, train_loss: 0.7433\n",
      "11/194, train_loss: 0.8198\n",
      "12/194, train_loss: 0.8221\n",
      "13/194, train_loss: 0.8750\n",
      "14/194, train_loss: 0.7806\n",
      "15/194, train_loss: 0.8269\n",
      "16/194, train_loss: 0.7387\n",
      "17/194, train_loss: 0.8934\n",
      "18/194, train_loss: 0.8854\n",
      "19/194, train_loss: 0.6993\n",
      "20/194, train_loss: 0.8046\n",
      "21/194, train_loss: 0.5665\n",
      "22/194, train_loss: 0.7703\n",
      "23/194, train_loss: 0.6702\n",
      "24/194, train_loss: 0.7061\n",
      "25/194, train_loss: 0.8116\n",
      "26/194, train_loss: 0.8212\n",
      "27/194, train_loss: 0.7254\n",
      "28/194, train_loss: 0.8318\n",
      "29/194, train_loss: 0.8677\n",
      "30/194, train_loss: 0.8158\n",
      "31/194, train_loss: 0.8226\n",
      "32/194, train_loss: 0.8459\n",
      "33/194, train_loss: 0.6857\n",
      "34/194, train_loss: 0.8115\n",
      "35/194, train_loss: 0.7795\n",
      "36/194, train_loss: 0.7527\n",
      "37/194, train_loss: 0.7598\n",
      "38/194, train_loss: 0.7537\n",
      "39/194, train_loss: 0.7848\n",
      "40/194, train_loss: 0.6547\n",
      "41/194, train_loss: 0.7674\n",
      "42/194, train_loss: 0.8749\n",
      "43/194, train_loss: 0.6881\n",
      "44/194, train_loss: 0.8904\n",
      "45/194, train_loss: 0.7058\n",
      "46/194, train_loss: 0.8551\n",
      "47/194, train_loss: 0.6590\n",
      "48/194, train_loss: 0.8876\n",
      "49/194, train_loss: 0.7735\n",
      "50/194, train_loss: 0.6359\n",
      "51/194, train_loss: 0.8236\n",
      "52/194, train_loss: 0.8083\n",
      "53/194, train_loss: 0.9367\n",
      "54/194, train_loss: 0.7324\n",
      "55/194, train_loss: 0.6667\n",
      "56/194, train_loss: 0.7845\n",
      "57/194, train_loss: 0.8462\n",
      "58/194, train_loss: 0.8685\n",
      "59/194, train_loss: 0.8664\n",
      "60/194, train_loss: 0.9214\n",
      "61/194, train_loss: 0.6627\n",
      "62/194, train_loss: 0.7893\n",
      "63/194, train_loss: 0.7711\n",
      "64/194, train_loss: 0.7295\n",
      "65/194, train_loss: 0.8505\n",
      "66/194, train_loss: 0.7005\n",
      "67/194, train_loss: 0.9379\n",
      "68/194, train_loss: 0.8385\n",
      "69/194, train_loss: 0.8544\n",
      "70/194, train_loss: 0.9081\n",
      "71/194, train_loss: 0.8591\n",
      "72/194, train_loss: 0.7351\n",
      "73/194, train_loss: 0.7827\n",
      "74/194, train_loss: 0.5822\n",
      "75/194, train_loss: 0.7106\n",
      "76/194, train_loss: 0.7900\n",
      "77/194, train_loss: 0.5365\n",
      "78/194, train_loss: 0.8061\n",
      "79/194, train_loss: 0.8177\n",
      "80/194, train_loss: 0.7417\n",
      "81/194, train_loss: 0.6876\n",
      "82/194, train_loss: 0.8623\n",
      "83/194, train_loss: 0.9650\n",
      "84/194, train_loss: 0.6662\n",
      "85/194, train_loss: 0.8206\n",
      "86/194, train_loss: 0.8469\n",
      "87/194, train_loss: 0.9027\n",
      "88/194, train_loss: 0.8907\n",
      "89/194, train_loss: 0.7970\n",
      "90/194, train_loss: 0.6645\n",
      "91/194, train_loss: 0.8668\n",
      "92/194, train_loss: 0.6969\n",
      "93/194, train_loss: 0.7423\n",
      "94/194, train_loss: 0.7066\n",
      "95/194, train_loss: 0.7849\n",
      "96/194, train_loss: 0.7643\n",
      "97/194, train_loss: 0.8343\n",
      "98/194, train_loss: 0.7271\n",
      "99/194, train_loss: 0.7923\n",
      "100/194, train_loss: 0.7199\n",
      "101/194, train_loss: 0.8282\n",
      "102/194, train_loss: 0.8256\n",
      "103/194, train_loss: 0.9378\n",
      "104/194, train_loss: 0.9134\n",
      "105/194, train_loss: 0.8196\n",
      "106/194, train_loss: 0.9017\n",
      "107/194, train_loss: 0.7739\n",
      "108/194, train_loss: 0.8760\n",
      "109/194, train_loss: 0.7112\n",
      "110/194, train_loss: 0.7292\n",
      "111/194, train_loss: 0.7822\n",
      "112/194, train_loss: 0.8916\n",
      "113/194, train_loss: 0.6160\n",
      "114/194, train_loss: 0.6038\n",
      "115/194, train_loss: 0.8344\n",
      "116/194, train_loss: 0.7784\n",
      "117/194, train_loss: 0.7913\n",
      "118/194, train_loss: 0.9541\n",
      "119/194, train_loss: 0.7228\n",
      "120/194, train_loss: 0.8523\n",
      "121/194, train_loss: 0.8326\n",
      "122/194, train_loss: 0.9146\n",
      "123/194, train_loss: 0.9495\n",
      "124/194, train_loss: 0.8548\n",
      "125/194, train_loss: 0.9353\n",
      "126/194, train_loss: 0.9226\n",
      "127/194, train_loss: 0.9112\n",
      "128/194, train_loss: 0.8241\n",
      "129/194, train_loss: 0.7935\n",
      "130/194, train_loss: 0.8524\n",
      "131/194, train_loss: 0.7880\n",
      "132/194, train_loss: 0.8494\n",
      "133/194, train_loss: 0.8192\n",
      "134/194, train_loss: 0.6993\n",
      "135/194, train_loss: 0.7189\n",
      "136/194, train_loss: 0.6693\n",
      "137/194, train_loss: 0.8022\n",
      "138/194, train_loss: 0.7345\n",
      "139/194, train_loss: 0.7417\n",
      "140/194, train_loss: 0.6913\n",
      "141/194, train_loss: 0.8628\n",
      "142/194, train_loss: 0.9084\n",
      "143/194, train_loss: 0.9379\n",
      "144/194, train_loss: 0.7990\n",
      "145/194, train_loss: 0.8385\n",
      "146/194, train_loss: 0.8341\n",
      "147/194, train_loss: 0.8801\n",
      "148/194, train_loss: 0.8609\n",
      "149/194, train_loss: 0.7739\n",
      "150/194, train_loss: 0.7890\n",
      "151/194, train_loss: 0.9226\n",
      "152/194, train_loss: 0.7398\n",
      "153/194, train_loss: 0.7634\n",
      "154/194, train_loss: 0.9350\n",
      "155/194, train_loss: 0.8082\n",
      "156/194, train_loss: 0.8628\n",
      "157/194, train_loss: 0.7831\n",
      "158/194, train_loss: 0.8351\n",
      "159/194, train_loss: 0.8752\n",
      "160/194, train_loss: 0.7805\n",
      "161/194, train_loss: 0.7855\n",
      "162/194, train_loss: 0.7976\n",
      "163/194, train_loss: 0.8066\n",
      "164/194, train_loss: 0.8505\n",
      "165/194, train_loss: 0.9714\n",
      "166/194, train_loss: 0.7548\n",
      "167/194, train_loss: 0.6942\n",
      "168/194, train_loss: 0.8676\n",
      "169/194, train_loss: 0.7259\n",
      "170/194, train_loss: 0.7901\n",
      "171/194, train_loss: 0.8636\n",
      "172/194, train_loss: 0.8419\n",
      "173/194, train_loss: 0.7836\n",
      "174/194, train_loss: 0.7726\n",
      "175/194, train_loss: 0.7654\n",
      "176/194, train_loss: 0.7968\n",
      "177/194, train_loss: 0.9871\n",
      "178/194, train_loss: 0.8632\n",
      "179/194, train_loss: 0.8498\n",
      "180/194, train_loss: 0.7557\n",
      "181/194, train_loss: 0.6217\n",
      "182/194, train_loss: 0.6941\n",
      "183/194, train_loss: 0.7721\n",
      "184/194, train_loss: 0.6079\n",
      "185/194, train_loss: 0.8254\n",
      "186/194, train_loss: 0.7973\n",
      "187/194, train_loss: 0.8900\n",
      "188/194, train_loss: 0.8849\n",
      "189/194, train_loss: 0.8783\n",
      "190/194, train_loss: 0.8523\n",
      "191/194, train_loss: 0.8008\n",
      "192/194, train_loss: 0.7129\n",
      "193/194, train_loss: 0.6833\n",
      "194/194, train_loss: 0.7842\n",
      "metric=0.3611673442646861, metric_tc=0.36262512222553295, metric_wt=0.5281759997208914, metric_et=0.19270090650146207\n",
      "metric=0.3611673442646861, metric_tc=0.36262512222553295, metric_wt=0.5281759997208914, metric_et=0.19270090650146207\n",
      "current epoch: 42 current epoch loss: 0.7983\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▎    | 42/80 [7:33:25<6:38:29, 629.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metric=0.3611673442646861, metric_tc=0.36262512222553295, metric_wt=0.5281759997208914, metric_et=0.19270090650146207\n",
      "0.3611673442646861\n",
      "current epoch: 42 current mean dice: 0.3612 tc: 0.3626 wt: 0.5282 et: 0.1927\n",
      "best mean dice: 0.3727 at epoch: 41\n",
      "\n",
      " | Global Training Round : 43 |\n",
      "\n",
      "user 0 selected\n",
      "local epoch 1\n",
      "1/194, train_loss: 0.8248\n",
      "2/194, train_loss: 0.5673\n",
      "3/194, train_loss: 0.7480\n",
      "4/194, train_loss: 0.9098\n",
      "5/194, train_loss: 0.7834\n",
      "6/194, train_loss: 0.7392\n",
      "7/194, train_loss: 0.8014\n",
      "8/194, train_loss: 0.8429\n",
      "9/194, train_loss: 0.8798\n",
      "10/194, train_loss: 0.5447\n",
      "11/194, train_loss: 0.7839\n",
      "12/194, train_loss: 0.7682\n",
      "13/194, train_loss: 0.8647\n",
      "14/194, train_loss: 0.8567\n",
      "15/194, train_loss: 0.6923\n",
      "16/194, train_loss: 0.9618\n",
      "17/194, train_loss: 0.7805\n",
      "18/194, train_loss: 0.7623\n",
      "19/194, train_loss: 0.6312\n",
      "20/194, train_loss: 0.6805\n",
      "21/194, train_loss: 0.7012\n",
      "22/194, train_loss: 0.7745\n",
      "23/194, train_loss: 0.7436\n",
      "24/194, train_loss: 0.8732\n",
      "25/194, train_loss: 0.7394\n",
      "26/194, train_loss: 0.7235\n",
      "27/194, train_loss: 0.7118\n",
      "28/194, train_loss: 0.6182\n",
      "29/194, train_loss: 0.8474\n",
      "30/194, train_loss: 0.7386\n",
      "31/194, train_loss: 0.8303\n",
      "32/194, train_loss: 0.9295\n",
      "33/194, train_loss: 0.7888\n",
      "34/194, train_loss: 0.8198\n",
      "35/194, train_loss: 0.8632\n",
      "36/194, train_loss: 0.8828\n",
      "37/194, train_loss: 0.5757\n",
      "38/194, train_loss: 0.5549\n",
      "39/194, train_loss: 0.6311\n",
      "40/194, train_loss: 0.6649\n",
      "41/194, train_loss: 0.8227\n",
      "42/194, train_loss: 0.6956\n",
      "43/194, train_loss: 0.8850\n",
      "44/194, train_loss: 0.7400\n",
      "45/194, train_loss: 0.6557\n",
      "46/194, train_loss: 0.6330\n",
      "47/194, train_loss: 0.7884\n",
      "48/194, train_loss: 0.7284\n",
      "49/194, train_loss: 0.7288\n",
      "50/194, train_loss: 0.6946\n",
      "51/194, train_loss: 0.9020\n",
      "52/194, train_loss: 0.8941\n",
      "53/194, train_loss: 0.8971\n",
      "54/194, train_loss: 0.8268\n",
      "55/194, train_loss: 0.8409\n",
      "56/194, train_loss: 0.8539\n",
      "57/194, train_loss: 0.8426\n",
      "58/194, train_loss: 0.7213\n",
      "59/194, train_loss: 0.8173\n",
      "60/194, train_loss: 0.9289\n",
      "61/194, train_loss: 0.9424\n",
      "62/194, train_loss: 0.6524\n",
      "63/194, train_loss: 0.7940\n",
      "64/194, train_loss: 0.6175\n",
      "65/194, train_loss: 0.8965\n",
      "66/194, train_loss: 0.7913\n",
      "67/194, train_loss: 0.8922\n",
      "68/194, train_loss: 0.8475\n",
      "69/194, train_loss: 0.8550\n",
      "70/194, train_loss: 0.8683\n",
      "71/194, train_loss: 0.8840\n",
      "72/194, train_loss: 0.8330\n",
      "73/194, train_loss: 0.8137\n",
      "74/194, train_loss: 0.7944\n",
      "75/194, train_loss: 0.8162\n",
      "76/194, train_loss: 0.5973\n",
      "77/194, train_loss: 0.8831\n",
      "78/194, train_loss: 0.6264\n",
      "79/194, train_loss: 0.8300\n",
      "80/194, train_loss: 0.8225\n",
      "81/194, train_loss: 0.8984\n",
      "82/194, train_loss: 0.8265\n",
      "83/194, train_loss: 0.7186\n",
      "84/194, train_loss: 0.8902\n",
      "85/194, train_loss: 0.8359\n",
      "86/194, train_loss: 0.8627\n",
      "87/194, train_loss: 0.8224\n",
      "88/194, train_loss: 0.8440\n",
      "89/194, train_loss: 0.8312\n",
      "90/194, train_loss: 0.7688\n",
      "91/194, train_loss: 0.8408\n",
      "92/194, train_loss: 0.7793\n",
      "93/194, train_loss: 0.7158\n",
      "94/194, train_loss: 0.8548\n",
      "95/194, train_loss: 0.8249\n",
      "96/194, train_loss: 0.7411\n",
      "97/194, train_loss: 0.7913\n",
      "98/194, train_loss: 0.8574\n",
      "99/194, train_loss: 0.7579\n",
      "100/194, train_loss: 0.7840\n",
      "101/194, train_loss: 0.9038\n",
      "102/194, train_loss: 0.8686\n",
      "103/194, train_loss: 0.8456\n",
      "104/194, train_loss: 0.8643\n",
      "105/194, train_loss: 0.8310\n",
      "106/194, train_loss: 0.8086\n",
      "107/194, train_loss: 0.8484\n",
      "108/194, train_loss: 0.8585\n",
      "109/194, train_loss: 0.7306\n",
      "110/194, train_loss: 0.5785\n",
      "111/194, train_loss: 0.7406\n",
      "112/194, train_loss: 0.7395\n",
      "113/194, train_loss: 0.9094\n",
      "114/194, train_loss: 0.7492\n",
      "115/194, train_loss: 0.7962\n",
      "116/194, train_loss: 0.7465\n",
      "117/194, train_loss: 0.6385\n",
      "118/194, train_loss: 0.6985\n",
      "119/194, train_loss: 0.6450\n",
      "120/194, train_loss: 0.8450\n",
      "121/194, train_loss: 0.9012\n",
      "122/194, train_loss: 0.9472\n",
      "123/194, train_loss: 0.9065\n",
      "124/194, train_loss: 0.8383\n",
      "125/194, train_loss: 0.9109\n",
      "126/194, train_loss: 0.7418\n",
      "127/194, train_loss: 0.9301\n",
      "128/194, train_loss: 0.8649\n",
      "129/194, train_loss: 0.8086\n",
      "130/194, train_loss: 0.6490\n",
      "131/194, train_loss: 0.7974\n",
      "132/194, train_loss: 0.7723\n",
      "133/194, train_loss: 0.8374\n",
      "134/194, train_loss: 0.8204\n",
      "135/194, train_loss: 0.9067\n",
      "136/194, train_loss: 0.7887\n",
      "137/194, train_loss: 0.7942\n",
      "138/194, train_loss: 0.7448\n",
      "139/194, train_loss: 0.7346\n",
      "140/194, train_loss: 0.7096\n",
      "141/194, train_loss: 0.9387\n",
      "142/194, train_loss: 0.8564\n",
      "143/194, train_loss: 0.7082\n",
      "144/194, train_loss: 0.7951\n",
      "145/194, train_loss: 0.7333\n",
      "146/194, train_loss: 0.8590\n",
      "147/194, train_loss: 0.7105\n",
      "148/194, train_loss: 0.7966\n",
      "149/194, train_loss: 0.9585\n",
      "150/194, train_loss: 0.8916\n",
      "151/194, train_loss: 0.8481\n",
      "152/194, train_loss: 0.7393\n",
      "153/194, train_loss: 0.8113\n",
      "154/194, train_loss: 0.7340\n",
      "155/194, train_loss: 0.9113\n",
      "156/194, train_loss: 0.9420\n",
      "157/194, train_loss: 0.8921\n",
      "158/194, train_loss: 0.8667\n",
      "159/194, train_loss: 0.7807\n",
      "160/194, train_loss: 0.9076\n",
      "161/194, train_loss: 0.8035\n",
      "162/194, train_loss: 0.7468\n",
      "163/194, train_loss: 0.7320\n",
      "164/194, train_loss: 0.7466\n",
      "165/194, train_loss: 0.8681\n",
      "166/194, train_loss: 0.8056\n",
      "167/194, train_loss: 0.7871\n",
      "168/194, train_loss: 0.7847\n",
      "169/194, train_loss: 0.7306\n",
      "170/194, train_loss: 0.7926\n",
      "171/194, train_loss: 0.8144\n",
      "172/194, train_loss: 0.8518\n",
      "173/194, train_loss: 0.8139\n",
      "174/194, train_loss: 0.8073\n",
      "175/194, train_loss: 0.8467\n",
      "176/194, train_loss: 0.8782\n",
      "177/194, train_loss: 0.9406\n",
      "178/194, train_loss: 0.7703\n",
      "179/194, train_loss: 0.6659\n",
      "180/194, train_loss: 0.7694\n",
      "181/194, train_loss: 0.7455\n",
      "182/194, train_loss: 0.6673\n",
      "183/194, train_loss: 0.7439\n",
      "184/194, train_loss: 0.5297\n",
      "185/194, train_loss: 0.8903\n",
      "186/194, train_loss: 0.9066\n",
      "187/194, train_loss: 0.8573\n",
      "188/194, train_loss: 0.7631\n",
      "189/194, train_loss: 0.7765\n",
      "190/194, train_loss: 0.7570\n",
      "191/194, train_loss: 0.7707\n",
      "192/194, train_loss: 0.7240\n",
      "193/194, train_loss: 0.9080\n",
      "194/194, train_loss: 0.8281\n",
      "metric=0.3434297361721595, metric_tc=0.3579709798408051, metric_wt=0.47297097990910214, metric_et=0.19934725513060889\n",
      "metric=0.3434297361721595, metric_tc=0.3579709798408051, metric_wt=0.47297097990910214, metric_et=0.19934725513060889\n",
      "current epoch: 43 current epoch loss: 0.7948\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 43/80 [7:45:18<6:43:26, 654.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metric=0.3434297361721595, metric_tc=0.3579709798408051, metric_wt=0.47297097990910214, metric_et=0.19934725513060889\n",
      "0.3434297361721595\n",
      "current epoch: 43 current mean dice: 0.3434 tc: 0.3580 wt: 0.4730 et: 0.1993\n",
      "best mean dice: 0.3727 at epoch: 41\n",
      "\n",
      " | Global Training Round : 44 |\n",
      "\n",
      "user 0 selected\n",
      "local epoch 1\n",
      "1/194, train_loss: 0.7637\n",
      "2/194, train_loss: 0.7734\n",
      "3/194, train_loss: 0.7269\n",
      "4/194, train_loss: 0.7900\n",
      "5/194, train_loss: 0.8063\n",
      "6/194, train_loss: 0.7621\n",
      "7/194, train_loss: 0.8265\n",
      "8/194, train_loss: 0.7342\n",
      "9/194, train_loss: 0.9045\n",
      "10/194, train_loss: 0.9057\n",
      "11/194, train_loss: 0.9059\n",
      "12/194, train_loss: 0.7770\n",
      "13/194, train_loss: 0.5289\n",
      "14/194, train_loss: 0.7935\n",
      "15/194, train_loss: 0.7731\n",
      "16/194, train_loss: 0.7892\n",
      "17/194, train_loss: 0.7291\n",
      "18/194, train_loss: 0.8609\n",
      "19/194, train_loss: 0.6489\n",
      "20/194, train_loss: 0.8013\n",
      "21/194, train_loss: 0.7704\n",
      "22/194, train_loss: 0.6763\n",
      "23/194, train_loss: 0.6431\n",
      "24/194, train_loss: 0.8544\n",
      "25/194, train_loss: 0.8237\n",
      "26/194, train_loss: 0.8977\n",
      "27/194, train_loss: 0.7540\n",
      "28/194, train_loss: 0.7446\n",
      "29/194, train_loss: 0.8390\n",
      "30/194, train_loss: 0.7412\n",
      "31/194, train_loss: 0.7739\n",
      "32/194, train_loss: 0.7324\n",
      "33/194, train_loss: 0.6141\n",
      "34/194, train_loss: 0.9351\n",
      "35/194, train_loss: 0.7717\n",
      "36/194, train_loss: 0.7568\n",
      "37/194, train_loss: 0.7537\n",
      "38/194, train_loss: 0.7874\n",
      "39/194, train_loss: 0.7081\n",
      "40/194, train_loss: 0.7678\n",
      "41/194, train_loss: 0.8574\n",
      "42/194, train_loss: 0.7307\n",
      "43/194, train_loss: 0.8012\n",
      "44/194, train_loss: 0.7121\n",
      "45/194, train_loss: 0.7058\n",
      "46/194, train_loss: 0.6906\n",
      "47/194, train_loss: 0.7535\n",
      "48/194, train_loss: 0.9286\n",
      "49/194, train_loss: 0.9105\n",
      "50/194, train_loss: 0.7183\n",
      "51/194, train_loss: 0.7380\n",
      "52/194, train_loss: 0.7434\n",
      "53/194, train_loss: 0.8126\n",
      "54/194, train_loss: 0.9170\n",
      "55/194, train_loss: 0.9199\n",
      "56/194, train_loss: 0.8464\n",
      "57/194, train_loss: 0.8507\n",
      "58/194, train_loss: 0.8913\n",
      "59/194, train_loss: 0.7647\n",
      "60/194, train_loss: 0.8907\n",
      "61/194, train_loss: 0.7209\n",
      "62/194, train_loss: 0.8381\n",
      "63/194, train_loss: 0.8118\n",
      "64/194, train_loss: 0.7223\n",
      "65/194, train_loss: 0.6732\n",
      "66/194, train_loss: 0.8024\n",
      "67/194, train_loss: 0.8676\n",
      "68/194, train_loss: 0.8590\n",
      "69/194, train_loss: 0.7782\n",
      "70/194, train_loss: 0.7189\n",
      "71/194, train_loss: 0.7343\n",
      "72/194, train_loss: 0.8875\n",
      "73/194, train_loss: 0.8415\n",
      "74/194, train_loss: 0.6853\n",
      "75/194, train_loss: 0.6335\n",
      "76/194, train_loss: 0.8253\n",
      "77/194, train_loss: 0.6640\n",
      "78/194, train_loss: 0.6026\n",
      "79/194, train_loss: 0.7748\n",
      "80/194, train_loss: 0.6963\n",
      "81/194, train_loss: 0.7085\n",
      "82/194, train_loss: 0.7287\n",
      "83/194, train_loss: 0.8625\n",
      "84/194, train_loss: 0.8958\n",
      "85/194, train_loss: 0.8072\n",
      "86/194, train_loss: 0.7523\n",
      "87/194, train_loss: 0.8750\n",
      "88/194, train_loss: 0.9570\n",
      "89/194, train_loss: 0.9134\n",
      "90/194, train_loss: 0.7977\n",
      "91/194, train_loss: 0.7744\n",
      "92/194, train_loss: 0.9351\n",
      "93/194, train_loss: 0.5851\n",
      "94/194, train_loss: 0.6826\n",
      "95/194, train_loss: 0.6840\n",
      "96/194, train_loss: 0.7611\n",
      "97/194, train_loss: 0.7648\n",
      "98/194, train_loss: 0.8402\n",
      "99/194, train_loss: 0.8323\n",
      "100/194, train_loss: 0.7612\n",
      "101/194, train_loss: 0.9395\n",
      "102/194, train_loss: 0.8594\n",
      "103/194, train_loss: 0.8257\n",
      "104/194, train_loss: 0.7239\n",
      "105/194, train_loss: 0.8155\n",
      "106/194, train_loss: 0.7359\n",
      "107/194, train_loss: 0.7764\n",
      "108/194, train_loss: 0.7562\n",
      "109/194, train_loss: 0.7354\n",
      "110/194, train_loss: 0.6412\n",
      "111/194, train_loss: 0.6995\n",
      "112/194, train_loss: 0.6146\n",
      "113/194, train_loss: 0.8203\n",
      "114/194, train_loss: 0.7693\n",
      "115/194, train_loss: 0.8845\n",
      "116/194, train_loss: 0.8719\n",
      "117/194, train_loss: 0.8621\n",
      "118/194, train_loss: 0.8165\n",
      "119/194, train_loss: 0.8794\n",
      "120/194, train_loss: 0.7783\n",
      "121/194, train_loss: 0.9347\n",
      "122/194, train_loss: 0.8893\n",
      "123/194, train_loss: 0.6557\n",
      "124/194, train_loss: 0.9149\n",
      "125/194, train_loss: 0.9376\n",
      "126/194, train_loss: 0.8804\n",
      "127/194, train_loss: 0.8655\n",
      "128/194, train_loss: 0.8602\n",
      "129/194, train_loss: 0.7107\n",
      "130/194, train_loss: 0.7422\n",
      "131/194, train_loss: 0.8116\n",
      "132/194, train_loss: 0.6738\n",
      "133/194, train_loss: 0.7874\n",
      "134/194, train_loss: 0.9186\n",
      "135/194, train_loss: 0.8659\n",
      "136/194, train_loss: 0.7477\n",
      "137/194, train_loss: 0.7758\n",
      "138/194, train_loss: 0.6563\n",
      "139/194, train_loss: 0.7863\n",
      "140/194, train_loss: 0.7757\n",
      "141/194, train_loss: 0.8850\n",
      "142/194, train_loss: 0.8452\n",
      "143/194, train_loss: 0.9051\n",
      "144/194, train_loss: 0.9296\n",
      "145/194, train_loss: 0.9418\n",
      "146/194, train_loss: 0.8012\n",
      "147/194, train_loss: 0.8674\n",
      "148/194, train_loss: 0.8234\n",
      "149/194, train_loss: 0.8914\n",
      "150/194, train_loss: 0.9256\n",
      "151/194, train_loss: 0.9660\n",
      "152/194, train_loss: 0.7978\n",
      "153/194, train_loss: 0.9454\n",
      "154/194, train_loss: 0.8528\n",
      "155/194, train_loss: 0.8256\n",
      "156/194, train_loss: 0.8562\n",
      "157/194, train_loss: 0.7039\n",
      "158/194, train_loss: 0.7248\n",
      "159/194, train_loss: 0.8091\n",
      "160/194, train_loss: 0.8331\n",
      "161/194, train_loss: 0.8849\n",
      "162/194, train_loss: 0.8532\n",
      "163/194, train_loss: 0.7613\n",
      "164/194, train_loss: 0.8835\n",
      "165/194, train_loss: 0.7913\n",
      "166/194, train_loss: 0.8443\n",
      "167/194, train_loss: 0.6520\n",
      "168/194, train_loss: 0.9376\n",
      "169/194, train_loss: 0.6918\n",
      "170/194, train_loss: 0.8129\n",
      "171/194, train_loss: 0.8053\n",
      "172/194, train_loss: 0.6896\n",
      "173/194, train_loss: 0.7301\n",
      "174/194, train_loss: 0.7464\n",
      "175/194, train_loss: 0.8726\n",
      "176/194, train_loss: 0.8496\n",
      "177/194, train_loss: 0.7067\n",
      "178/194, train_loss: 0.7500\n",
      "179/194, train_loss: 0.8886\n",
      "180/194, train_loss: 0.8562\n",
      "181/194, train_loss: 0.7530\n",
      "182/194, train_loss: 0.7082\n",
      "183/194, train_loss: 0.5947\n",
      "184/194, train_loss: 0.8483\n",
      "185/194, train_loss: 0.7462\n",
      "186/194, train_loss: 0.7267\n",
      "187/194, train_loss: 0.7555\n",
      "188/194, train_loss: 0.8662\n",
      "189/194, train_loss: 0.9044\n",
      "190/194, train_loss: 0.8076\n",
      "191/194, train_loss: 0.9012\n",
      "192/194, train_loss: 0.8039\n",
      "193/194, train_loss: 0.6666\n",
      "194/194, train_loss: 0.7667\n",
      "metric=0.3546247957274318, metric_tc=0.3745803680891792, metric_wt=0.4816525758554538, metric_et=0.20764143811538815\n",
      "metric=0.3546247957274318, metric_tc=0.3745803680891792, metric_wt=0.4816525758554538, metric_et=0.20764143811538815\n",
      "current epoch: 44 current epoch loss: 0.7947\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 44/80 [7:58:13<6:54:19, 690.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metric=0.3546247957274318, metric_tc=0.3745803680891792, metric_wt=0.4816525758554538, metric_et=0.20764143811538815\n",
      "0.3546247957274318\n",
      "current epoch: 44 current mean dice: 0.3546 tc: 0.3746 wt: 0.4817 et: 0.2076\n",
      "best mean dice: 0.3727 at epoch: 41\n",
      "\n",
      " | Global Training Round : 45 |\n",
      "\n",
      "user 0 selected\n",
      "local epoch 1\n",
      "1/194, train_loss: 0.7532\n",
      "2/194, train_loss: 0.8179\n",
      "3/194, train_loss: 0.7632\n",
      "4/194, train_loss: 0.6845\n",
      "5/194, train_loss: 0.8742\n",
      "6/194, train_loss: 0.7850\n",
      "7/194, train_loss: 0.8456\n",
      "8/194, train_loss: 0.7266\n",
      "9/194, train_loss: 0.8118\n",
      "10/194, train_loss: 0.7146\n",
      "11/194, train_loss: 0.9399\n",
      "12/194, train_loss: 0.8439\n",
      "13/194, train_loss: 0.7335\n",
      "14/194, train_loss: 0.7092\n",
      "15/194, train_loss: 0.5821\n",
      "16/194, train_loss: 0.7991\n",
      "17/194, train_loss: 0.8713\n",
      "18/194, train_loss: 0.7811\n",
      "19/194, train_loss: 0.8145\n",
      "20/194, train_loss: 0.8290\n",
      "21/194, train_loss: 0.7648\n",
      "22/194, train_loss: 0.7188\n",
      "23/194, train_loss: 0.7317\n",
      "24/194, train_loss: 0.8854\n",
      "25/194, train_loss: 0.8127\n",
      "26/194, train_loss: 0.6934\n",
      "27/194, train_loss: 0.7973\n",
      "28/194, train_loss: 0.7517\n",
      "29/194, train_loss: 0.7456\n",
      "30/194, train_loss: 0.8940\n",
      "31/194, train_loss: 0.7377\n",
      "32/194, train_loss: 0.8159\n",
      "33/194, train_loss: 0.8228\n",
      "34/194, train_loss: 0.7318\n",
      "35/194, train_loss: 0.8174\n",
      "36/194, train_loss: 0.7558\n",
      "37/194, train_loss: 0.7919\n",
      "38/194, train_loss: 0.6010\n",
      "39/194, train_loss: 0.8865\n",
      "40/194, train_loss: 0.7051\n",
      "41/194, train_loss: 0.8388\n",
      "42/194, train_loss: 0.7157\n",
      "43/194, train_loss: 0.8489\n",
      "44/194, train_loss: 0.7948\n",
      "45/194, train_loss: 0.6659\n",
      "46/194, train_loss: 0.6890\n",
      "47/194, train_loss: 0.5830\n",
      "48/194, train_loss: 0.9139\n",
      "49/194, train_loss: 0.9129\n",
      "50/194, train_loss: 0.5529\n",
      "51/194, train_loss: 0.8211\n",
      "52/194, train_loss: 0.8371\n",
      "53/194, train_loss: 0.7006\n",
      "54/194, train_loss: 0.8159\n",
      "55/194, train_loss: 0.7010\n",
      "56/194, train_loss: 0.8458\n",
      "57/194, train_loss: 0.8813\n",
      "58/194, train_loss: 0.7833\n",
      "59/194, train_loss: 0.8860\n",
      "60/194, train_loss: 0.8797\n",
      "61/194, train_loss: 0.7169\n",
      "62/194, train_loss: 0.8318\n",
      "63/194, train_loss: 0.8580\n",
      "64/194, train_loss: 0.8002\n",
      "65/194, train_loss: 0.7840\n",
      "66/194, train_loss: 0.7835\n",
      "67/194, train_loss: 0.6434\n",
      "68/194, train_loss: 0.6497\n",
      "69/194, train_loss: 0.6318\n",
      "70/194, train_loss: 0.7228\n",
      "71/194, train_loss: 0.7680\n",
      "72/194, train_loss: 0.8710\n",
      "73/194, train_loss: 0.7326\n",
      "74/194, train_loss: 0.8702\n",
      "75/194, train_loss: 0.7900\n",
      "76/194, train_loss: 0.5339\n",
      "77/194, train_loss: 0.7330\n",
      "78/194, train_loss: 0.5798\n",
      "79/194, train_loss: 0.7095\n",
      "80/194, train_loss: 0.8924\n",
      "81/194, train_loss: 0.8482\n",
      "82/194, train_loss: 0.9002\n",
      "83/194, train_loss: 0.9733\n",
      "84/194, train_loss: 0.6874\n",
      "85/194, train_loss: 0.9167\n",
      "86/194, train_loss: 0.8972\n",
      "87/194, train_loss: 0.9035\n",
      "88/194, train_loss: 0.8799\n",
      "89/194, train_loss: 0.7886\n",
      "90/194, train_loss: 0.8045\n",
      "91/194, train_loss: 0.8802\n",
      "92/194, train_loss: 0.7364\n",
      "93/194, train_loss: 0.8433\n",
      "94/194, train_loss: 0.6425\n",
      "95/194, train_loss: 0.7721\n",
      "96/194, train_loss: 0.6776\n",
      "97/194, train_loss: 0.8559\n",
      "98/194, train_loss: 0.7924\n",
      "99/194, train_loss: 0.7577\n",
      "100/194, train_loss: 0.7299\n",
      "101/194, train_loss: 0.7948\n",
      "102/194, train_loss: 0.7361\n",
      "103/194, train_loss: 0.6867\n",
      "104/194, train_loss: 0.8745\n",
      "105/194, train_loss: 0.8813\n",
      "106/194, train_loss: 0.9099\n",
      "107/194, train_loss: 0.7859\n",
      "108/194, train_loss: 0.6690\n",
      "109/194, train_loss: 0.9017\n",
      "110/194, train_loss: 0.7476\n",
      "111/194, train_loss: 0.8645\n",
      "112/194, train_loss: 0.7195\n",
      "113/194, train_loss: 0.7530\n",
      "114/194, train_loss: 0.7739\n",
      "115/194, train_loss: 0.7372\n",
      "116/194, train_loss: 0.7345\n",
      "117/194, train_loss: 0.8266\n",
      "118/194, train_loss: 0.8032\n",
      "119/194, train_loss: 0.8376\n",
      "120/194, train_loss: 0.8712\n",
      "121/194, train_loss: 0.9196\n",
      "122/194, train_loss: 0.8269\n",
      "123/194, train_loss: 0.7938\n",
      "124/194, train_loss: 0.7041\n",
      "125/194, train_loss: 0.8542\n",
      "126/194, train_loss: 0.8308\n",
      "127/194, train_loss: 0.8954\n",
      "128/194, train_loss: 0.8000\n",
      "129/194, train_loss: 0.7551\n",
      "130/194, train_loss: 0.7511\n",
      "131/194, train_loss: 0.6752\n",
      "132/194, train_loss: 0.7591\n",
      "133/194, train_loss: 0.7087\n",
      "134/194, train_loss: 0.7859\n",
      "135/194, train_loss: 0.7004\n",
      "136/194, train_loss: 0.8237\n",
      "137/194, train_loss: 0.6302\n",
      "138/194, train_loss: 0.7135\n",
      "139/194, train_loss: 0.7583\n",
      "140/194, train_loss: 0.7581\n",
      "141/194, train_loss: 0.9060\n",
      "142/194, train_loss: 0.8862\n",
      "143/194, train_loss: 0.8554\n",
      "144/194, train_loss: 0.9085\n",
      "145/194, train_loss: 0.8922\n",
      "146/194, train_loss: 0.9164\n",
      "147/194, train_loss: 0.7394\n",
      "148/194, train_loss: 0.7645\n",
      "149/194, train_loss: 0.8049\n",
      "150/194, train_loss: 0.9657\n",
      "151/194, train_loss: 0.8757\n",
      "152/194, train_loss: 0.8638\n",
      "153/194, train_loss: 0.9671\n",
      "154/194, train_loss: 0.8680\n",
      "155/194, train_loss: 0.7363\n",
      "156/194, train_loss: 0.6739\n",
      "157/194, train_loss: 0.8353\n",
      "158/194, train_loss: 0.8720\n",
      "159/194, train_loss: 0.8804\n",
      "160/194, train_loss: 0.7561\n",
      "161/194, train_loss: 0.8683\n",
      "162/194, train_loss: 0.7366\n",
      "163/194, train_loss: 0.8638\n",
      "164/194, train_loss: 0.8976\n",
      "165/194, train_loss: 0.9127\n",
      "166/194, train_loss: 0.9270\n",
      "167/194, train_loss: 0.9334\n",
      "168/194, train_loss: 0.8520\n",
      "169/194, train_loss: 0.8395\n",
      "170/194, train_loss: 0.7812\n",
      "171/194, train_loss: 0.8281\n",
      "172/194, train_loss: 0.7562\n",
      "173/194, train_loss: 0.7861\n",
      "174/194, train_loss: 0.7136\n",
      "175/194, train_loss: 0.8317\n",
      "176/194, train_loss: 0.7754\n",
      "177/194, train_loss: 0.8825\n",
      "178/194, train_loss: 0.8176\n",
      "179/194, train_loss: 0.8599\n",
      "180/194, train_loss: 0.8351\n",
      "181/194, train_loss: 0.8515\n",
      "182/194, train_loss: 0.7034\n",
      "183/194, train_loss: 0.6115\n",
      "184/194, train_loss: 0.6127\n",
      "185/194, train_loss: 0.8742\n",
      "186/194, train_loss: 0.8383\n",
      "187/194, train_loss: 0.8080\n",
      "188/194, train_loss: 0.8389\n",
      "189/194, train_loss: 0.8732\n",
      "190/194, train_loss: 0.8228\n",
      "191/194, train_loss: 0.8260\n",
      "192/194, train_loss: 0.8853\n",
      "193/194, train_loss: 0.8502\n",
      "194/194, train_loss: 0.7705\n",
      "metric=0.3664277583981554, metric_tc=0.39495846691230935, metric_wt=0.4761038611953457, metric_et=0.22822095112254223\n",
      "metric=0.3664277583981554, metric_tc=0.39495846691230935, metric_wt=0.4761038611953457, metric_et=0.22822095112254223\n",
      "current epoch: 45 current epoch loss: 0.7948\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▋    | 45/80 [8:10:52<6:54:44, 710.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metric=0.3664277583981554, metric_tc=0.39495846691230935, metric_wt=0.4761038611953457, metric_et=0.22822095112254223\n",
      "0.3664277583981554\n",
      "current epoch: 45 current mean dice: 0.3664 tc: 0.3950 wt: 0.4761 et: 0.2282\n",
      "best mean dice: 0.3727 at epoch: 41\n",
      "\n",
      " | Global Training Round : 46 |\n",
      "\n",
      "user 0 selected\n",
      "local epoch 1\n",
      "1/194, train_loss: 0.8375\n",
      "2/194, train_loss: 0.7706\n",
      "3/194, train_loss: 0.7438\n",
      "4/194, train_loss: 0.8621\n",
      "5/194, train_loss: 0.8956\n",
      "6/194, train_loss: 0.6695\n",
      "7/194, train_loss: 0.8254\n",
      "8/194, train_loss: 0.7656\n",
      "9/194, train_loss: 0.8207\n",
      "10/194, train_loss: 0.7712\n",
      "11/194, train_loss: 0.7652\n",
      "12/194, train_loss: 0.8009\n",
      "13/194, train_loss: 0.6667\n",
      "14/194, train_loss: 0.8658\n",
      "15/194, train_loss: 0.8620\n",
      "16/194, train_loss: 0.7828\n",
      "17/194, train_loss: 0.6726\n",
      "18/194, train_loss: 0.7057\n",
      "19/194, train_loss: 0.7307\n",
      "20/194, train_loss: 0.7280\n",
      "21/194, train_loss: 0.8932\n",
      "22/194, train_loss: 0.9105\n",
      "23/194, train_loss: 0.7041\n",
      "24/194, train_loss: 0.8167\n",
      "25/194, train_loss: 0.9022\n",
      "26/194, train_loss: 0.8988\n",
      "27/194, train_loss: 0.8570\n",
      "28/194, train_loss: 0.6742\n",
      "29/194, train_loss: 0.8113\n",
      "30/194, train_loss: 0.8270\n",
      "31/194, train_loss: 0.8346\n",
      "32/194, train_loss: 0.7592\n",
      "33/194, train_loss: 0.7993\n",
      "34/194, train_loss: 0.7036\n",
      "35/194, train_loss: 0.5498\n",
      "36/194, train_loss: 0.8825\n",
      "37/194, train_loss: 0.7535\n",
      "38/194, train_loss: 0.5565\n",
      "39/194, train_loss: 0.6285\n",
      "40/194, train_loss: 0.7947\n",
      "41/194, train_loss: 0.8956\n",
      "42/194, train_loss: 0.7626\n",
      "43/194, train_loss: 0.7217\n",
      "44/194, train_loss: 0.7181\n",
      "45/194, train_loss: 0.8287\n",
      "46/194, train_loss: 0.8387\n",
      "47/194, train_loss: 0.6405\n",
      "48/194, train_loss: 0.8354\n",
      "49/194, train_loss: 0.7895\n",
      "50/194, train_loss: 0.9014\n",
      "51/194, train_loss: 0.7943\n",
      "52/194, train_loss: 0.7337\n",
      "53/194, train_loss: 0.8525\n",
      "54/194, train_loss: 0.8509\n",
      "55/194, train_loss: 0.8482\n",
      "56/194, train_loss: 0.6963\n",
      "57/194, train_loss: 0.7503\n",
      "58/194, train_loss: 0.9377\n",
      "59/194, train_loss: 0.8840\n",
      "60/194, train_loss: 0.8284\n",
      "61/194, train_loss: 0.7654\n",
      "62/194, train_loss: 0.7470\n",
      "63/194, train_loss: 0.7919\n",
      "64/194, train_loss: 0.6961\n",
      "65/194, train_loss: 0.8959\n",
      "66/194, train_loss: 0.8418\n",
      "67/194, train_loss: 0.8406\n",
      "68/194, train_loss: 0.7943\n",
      "69/194, train_loss: 0.8857\n",
      "70/194, train_loss: 0.8145\n",
      "71/194, train_loss: 0.8446\n",
      "72/194, train_loss: 0.8610\n",
      "73/194, train_loss: 0.6157\n",
      "74/194, train_loss: 0.7176\n",
      "75/194, train_loss: 0.6347\n",
      "76/194, train_loss: 0.8350\n",
      "77/194, train_loss: 0.8287\n",
      "78/194, train_loss: 0.8023\n",
      "79/194, train_loss: 0.6961\n",
      "80/194, train_loss: 0.6378\n",
      "81/194, train_loss: 0.8150\n",
      "82/194, train_loss: 0.8379\n",
      "83/194, train_loss: 0.8425\n",
      "84/194, train_loss: 0.7680\n",
      "85/194, train_loss: 0.7190\n",
      "86/194, train_loss: 0.7082\n",
      "87/194, train_loss: 0.8178\n",
      "88/194, train_loss: 0.6779\n",
      "89/194, train_loss: 0.6494\n",
      "90/194, train_loss: 0.9139\n",
      "91/194, train_loss: 0.7735\n",
      "92/194, train_loss: 0.8200\n",
      "93/194, train_loss: 0.7703\n",
      "94/194, train_loss: 0.7905\n",
      "95/194, train_loss: 0.7601\n",
      "96/194, train_loss: 0.6020\n",
      "97/194, train_loss: 0.7825\n",
      "98/194, train_loss: 0.8226\n",
      "99/194, train_loss: 0.7348\n",
      "100/194, train_loss: 0.8459\n",
      "101/194, train_loss: 0.7636\n",
      "102/194, train_loss: 0.8042\n",
      "103/194, train_loss: 0.8663\n",
      "104/194, train_loss: 0.8517\n",
      "105/194, train_loss: 0.7667\n",
      "106/194, train_loss: 0.8623\n",
      "107/194, train_loss: 0.8112\n",
      "108/194, train_loss: 0.7153\n",
      "109/194, train_loss: 0.8098\n",
      "110/194, train_loss: 0.7702\n",
      "111/194, train_loss: 0.7405\n",
      "112/194, train_loss: 0.9310\n",
      "113/194, train_loss: 0.8296\n",
      "114/194, train_loss: 0.8573\n",
      "115/194, train_loss: 0.7401\n",
      "116/194, train_loss: 0.7188\n",
      "117/194, train_loss: 0.7997\n",
      "118/194, train_loss: 0.8360\n",
      "119/194, train_loss: 0.8449\n",
      "120/194, train_loss: 0.6943\n",
      "121/194, train_loss: 0.8905\n",
      "122/194, train_loss: 0.9454\n",
      "123/194, train_loss: 0.8022\n",
      "124/194, train_loss: 0.9321\n",
      "125/194, train_loss: 0.7074\n",
      "126/194, train_loss: 0.7462\n",
      "127/194, train_loss: 0.8057\n",
      "128/194, train_loss: 0.8046\n",
      "129/194, train_loss: 0.6890\n",
      "130/194, train_loss: 0.8527\n",
      "131/194, train_loss: 0.8953\n",
      "132/194, train_loss: 0.7020\n",
      "133/194, train_loss: 0.8741\n",
      "134/194, train_loss: 0.6870\n",
      "135/194, train_loss: 0.7372\n",
      "136/194, train_loss: 0.8286\n",
      "137/194, train_loss: 0.8213\n",
      "138/194, train_loss: 0.6248\n",
      "139/194, train_loss: 0.7002\n",
      "140/194, train_loss: 0.7393\n",
      "141/194, train_loss: 0.8088\n",
      "142/194, train_loss: 0.7646\n",
      "143/194, train_loss: 0.8498\n",
      "144/194, train_loss: 0.9251\n",
      "145/194, train_loss: 0.7260\n",
      "146/194, train_loss: 0.7661\n",
      "147/194, train_loss: 0.6967\n",
      "148/194, train_loss: 0.8632\n",
      "149/194, train_loss: 0.6685\n",
      "150/194, train_loss: 0.8386\n",
      "151/194, train_loss: 0.9125\n",
      "152/194, train_loss: 0.8863\n",
      "153/194, train_loss: 0.8213\n",
      "154/194, train_loss: 0.8959\n",
      "155/194, train_loss: 0.7124\n",
      "156/194, train_loss: 0.7186\n",
      "157/194, train_loss: 0.8568\n",
      "158/194, train_loss: 0.7792\n",
      "159/194, train_loss: 0.7818\n",
      "160/194, train_loss: 0.8426\n",
      "161/194, train_loss: 0.8463\n",
      "162/194, train_loss: 0.7667\n",
      "163/194, train_loss: 0.8952\n",
      "164/194, train_loss: 0.8205\n",
      "165/194, train_loss: 0.8711\n",
      "166/194, train_loss: 0.7886\n",
      "167/194, train_loss: 0.6553\n",
      "168/194, train_loss: 0.8252\n",
      "169/194, train_loss: 0.6952\n",
      "170/194, train_loss: 0.9465\n",
      "171/194, train_loss: 0.7722\n",
      "172/194, train_loss: 0.7703\n",
      "173/194, train_loss: 0.8604\n",
      "174/194, train_loss: 0.8326\n",
      "175/194, train_loss: 0.8035\n",
      "176/194, train_loss: 0.9048\n",
      "177/194, train_loss: 0.7307\n",
      "178/194, train_loss: 0.7537\n",
      "179/194, train_loss: 0.7650\n",
      "180/194, train_loss: 0.7805\n",
      "181/194, train_loss: 0.7200\n",
      "182/194, train_loss: 0.5586\n",
      "183/194, train_loss: 0.7719\n",
      "184/194, train_loss: 0.9007\n",
      "185/194, train_loss: 0.8988\n",
      "186/194, train_loss: 0.8098\n",
      "187/194, train_loss: 0.8407\n",
      "188/194, train_loss: 0.9268\n",
      "189/194, train_loss: 0.8355\n",
      "190/194, train_loss: 0.8421\n",
      "191/194, train_loss: 0.8356\n",
      "192/194, train_loss: 0.7028\n",
      "193/194, train_loss: 0.7364\n",
      "194/194, train_loss: 0.8623\n",
      "metric=0.3388435027251641, metric_tc=0.35685694621255, metric_wt=0.4618718381971121, metric_et=0.19780171328845123\n",
      "metric=0.3388435027251641, metric_tc=0.35685694621255, metric_wt=0.4618718381971121, metric_et=0.19780171328845123\n",
      "current epoch: 46 current epoch loss: 0.7910\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▊    | 46/80 [8:22:52<6:44:27, 713.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metric=0.3388435027251641, metric_tc=0.35685694621255, metric_wt=0.4618718381971121, metric_et=0.19780171328845123\n",
      "0.3388435027251641\n",
      "current epoch: 46 current mean dice: 0.3388 tc: 0.3569 wt: 0.4619 et: 0.1978\n",
      "best mean dice: 0.3727 at epoch: 41\n",
      "\n",
      " | Global Training Round : 47 |\n",
      "\n",
      "user 0 selected\n",
      "local epoch 1\n",
      "1/194, train_loss: 0.7183\n",
      "2/194, train_loss: 0.8328\n",
      "3/194, train_loss: 0.8550\n",
      "4/194, train_loss: 0.8391\n",
      "5/194, train_loss: 0.8373\n",
      "6/194, train_loss: 0.8832\n",
      "7/194, train_loss: 0.7618\n",
      "8/194, train_loss: 0.8145\n",
      "9/194, train_loss: 0.7202\n",
      "10/194, train_loss: 0.7783\n",
      "11/194, train_loss: 0.9046\n",
      "12/194, train_loss: 0.6242\n",
      "13/194, train_loss: 0.6347\n",
      "14/194, train_loss: 0.6446\n",
      "15/194, train_loss: 0.8501\n",
      "16/194, train_loss: 0.7028\n",
      "17/194, train_loss: 0.7757\n",
      "18/194, train_loss: 0.7766\n",
      "19/194, train_loss: 0.7750\n",
      "20/194, train_loss: 0.7703\n",
      "21/194, train_loss: 0.7751\n",
      "22/194, train_loss: 0.6804\n",
      "23/194, train_loss: 0.6520\n",
      "24/194, train_loss: 0.6039\n",
      "25/194, train_loss: 0.7841\n",
      "26/194, train_loss: 0.8618\n",
      "27/194, train_loss: 0.8073\n",
      "28/194, train_loss: 0.7624\n",
      "29/194, train_loss: 0.9451\n",
      "30/194, train_loss: 0.7719\n",
      "31/194, train_loss: 0.7684\n",
      "32/194, train_loss: 0.8823\n",
      "33/194, train_loss: 0.8590\n",
      "34/194, train_loss: 0.7472\n",
      "35/194, train_loss: 0.8011\n",
      "36/194, train_loss: 0.8689\n",
      "37/194, train_loss: 0.7223\n",
      "38/194, train_loss: 0.7682\n",
      "39/194, train_loss: 0.6562\n",
      "40/194, train_loss: 0.6461\n",
      "41/194, train_loss: 0.9291\n",
      "42/194, train_loss: 0.9042\n",
      "43/194, train_loss: 0.7620\n",
      "44/194, train_loss: 0.7153\n",
      "45/194, train_loss: 0.8472\n",
      "46/194, train_loss: 0.6204\n",
      "47/194, train_loss: 0.5307\n",
      "48/194, train_loss: 0.9076\n",
      "49/194, train_loss: 0.8328\n",
      "50/194, train_loss: 0.8527\n",
      "51/194, train_loss: 0.8339\n",
      "52/194, train_loss: 0.9687\n",
      "53/194, train_loss: 0.8299\n",
      "54/194, train_loss: 0.7500\n",
      "55/194, train_loss: 0.6905\n",
      "56/194, train_loss: 0.5273\n",
      "57/194, train_loss: 0.9365\n",
      "58/194, train_loss: 0.8727\n",
      "59/194, train_loss: 0.7634\n",
      "60/194, train_loss: 0.7871\n",
      "61/194, train_loss: 0.7906\n",
      "62/194, train_loss: 0.7424\n",
      "63/194, train_loss: 0.6000\n",
      "64/194, train_loss: 0.6539\n",
      "65/194, train_loss: 0.6250\n",
      "66/194, train_loss: 0.7683\n",
      "67/194, train_loss: 0.8760\n",
      "68/194, train_loss: 0.7868\n",
      "69/194, train_loss: 0.7527\n",
      "70/194, train_loss: 0.8881\n",
      "71/194, train_loss: 0.7187\n",
      "72/194, train_loss: 0.9181\n",
      "73/194, train_loss: 0.8398\n",
      "74/194, train_loss: 0.6491\n",
      "75/194, train_loss: 0.8316\n",
      "76/194, train_loss: 0.6678\n",
      "77/194, train_loss: 0.7368\n",
      "78/194, train_loss: 0.5602\n",
      "79/194, train_loss: 0.7186\n",
      "80/194, train_loss: 0.8468\n",
      "81/194, train_loss: 0.8487\n",
      "82/194, train_loss: 0.8871\n",
      "83/194, train_loss: 0.6707\n",
      "84/194, train_loss: 0.8480\n",
      "85/194, train_loss: 0.8274\n",
      "86/194, train_loss: 0.8230\n",
      "87/194, train_loss: 0.9146\n",
      "88/194, train_loss: 0.8586\n",
      "89/194, train_loss: 0.8004\n",
      "90/194, train_loss: 0.7991\n",
      "91/194, train_loss: 0.6640\n",
      "92/194, train_loss: 0.7707\n",
      "93/194, train_loss: 0.8358\n",
      "94/194, train_loss: 0.7155\n",
      "95/194, train_loss: 0.7606\n",
      "96/194, train_loss: 0.7760\n",
      "97/194, train_loss: 0.7933\n",
      "98/194, train_loss: 0.8381\n",
      "99/194, train_loss: 0.8105\n",
      "100/194, train_loss: 0.8195\n",
      "101/194, train_loss: 0.9932\n",
      "102/194, train_loss: 0.7077\n",
      "103/194, train_loss: 0.8492\n",
      "104/194, train_loss: 0.8769\n",
      "105/194, train_loss: 0.8138\n",
      "106/194, train_loss: 0.8078\n",
      "107/194, train_loss: 0.7471\n",
      "108/194, train_loss: 0.7616\n",
      "109/194, train_loss: 0.6940\n",
      "110/194, train_loss: 0.8611\n",
      "111/194, train_loss: 0.8424\n",
      "112/194, train_loss: 0.6969\n",
      "113/194, train_loss: 0.5431\n",
      "114/194, train_loss: 0.8742\n",
      "115/194, train_loss: 0.7235\n",
      "116/194, train_loss: 0.8614\n",
      "117/194, train_loss: 0.8375\n",
      "118/194, train_loss: 0.8436\n",
      "119/194, train_loss: 0.8033\n",
      "120/194, train_loss: 0.7301\n",
      "121/194, train_loss: 0.8571\n",
      "122/194, train_loss: 0.8502\n",
      "123/194, train_loss: 0.8196\n",
      "124/194, train_loss: 0.9346\n",
      "125/194, train_loss: 0.8193\n",
      "126/194, train_loss: 0.7365\n",
      "127/194, train_loss: 0.7532\n",
      "128/194, train_loss: 0.7425\n",
      "129/194, train_loss: 0.7444\n",
      "130/194, train_loss: 0.7770\n",
      "131/194, train_loss: 0.7065\n",
      "132/194, train_loss: 0.8951\n",
      "133/194, train_loss: 0.6229\n",
      "134/194, train_loss: 0.8057\n",
      "135/194, train_loss: 0.6539\n",
      "136/194, train_loss: 0.7111\n",
      "137/194, train_loss: 0.8367\n",
      "138/194, train_loss: 0.8727\n",
      "139/194, train_loss: 0.8835\n",
      "140/194, train_loss: 0.6773\n",
      "141/194, train_loss: 0.6113\n",
      "142/194, train_loss: 0.8806\n",
      "143/194, train_loss: 0.7091\n",
      "144/194, train_loss: 0.9035\n",
      "145/194, train_loss: 0.8408\n",
      "146/194, train_loss: 0.9157\n",
      "147/194, train_loss: 0.8298\n",
      "148/194, train_loss: 0.7624\n",
      "149/194, train_loss: 0.8265\n",
      "150/194, train_loss: 0.7079\n",
      "151/194, train_loss: 0.7859\n",
      "152/194, train_loss: 0.9009\n",
      "153/194, train_loss: 0.7339\n",
      "154/194, train_loss: 0.8245\n",
      "155/194, train_loss: 0.8983\n",
      "156/194, train_loss: 0.9421\n",
      "157/194, train_loss: 0.8749\n",
      "158/194, train_loss: 0.8561\n",
      "159/194, train_loss: 0.7026\n",
      "160/194, train_loss: 0.8605\n",
      "161/194, train_loss: 0.8450\n",
      "162/194, train_loss: 0.8220\n",
      "163/194, train_loss: 0.8214\n",
      "164/194, train_loss: 0.8152\n",
      "165/194, train_loss: 0.8835\n",
      "166/194, train_loss: 0.6513\n",
      "167/194, train_loss: 0.7859\n",
      "168/194, train_loss: 0.8022\n",
      "169/194, train_loss: 0.6567\n",
      "170/194, train_loss: 0.8129\n",
      "171/194, train_loss: 0.7822\n",
      "172/194, train_loss: 0.7682\n",
      "173/194, train_loss: 0.7191\n",
      "174/194, train_loss: 0.8702\n",
      "175/194, train_loss: 0.8172\n",
      "176/194, train_loss: 0.9006\n",
      "177/194, train_loss: 0.8626\n",
      "178/194, train_loss: 0.7257\n",
      "179/194, train_loss: 0.6337\n",
      "180/194, train_loss: 0.9037\n",
      "181/194, train_loss: 0.8134\n",
      "182/194, train_loss: 0.5363\n",
      "183/194, train_loss: 0.7115\n",
      "184/194, train_loss: 0.7367\n",
      "185/194, train_loss: 0.9114\n",
      "186/194, train_loss: 0.8601\n",
      "187/194, train_loss: 0.8112\n",
      "188/194, train_loss: 0.7693\n",
      "189/194, train_loss: 0.8575\n",
      "190/194, train_loss: 0.8086\n",
      "191/194, train_loss: 0.8001\n",
      "192/194, train_loss: 0.7043\n",
      "193/194, train_loss: 0.8202\n",
      "194/194, train_loss: 0.8599\n",
      "metric=0.3582956151415904, metric_tc=0.38011777866631746, metric_wt=0.4826128811885913, metric_et=0.2121561928652227\n",
      "metric=0.3582956151415904, metric_tc=0.38011777866631746, metric_wt=0.4826128811885913, metric_et=0.2121561928652227\n",
      "current epoch: 47 current epoch loss: 0.7865\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▉    | 47/80 [8:34:36<6:31:01, 710.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metric=0.3582956151415904, metric_tc=0.38011777866631746, metric_wt=0.4826128811885913, metric_et=0.2121561928652227\n",
      "0.3582956151415904\n",
      "current epoch: 47 current mean dice: 0.3583 tc: 0.3801 wt: 0.4826 et: 0.2122\n",
      "best mean dice: 0.3727 at epoch: 41\n",
      "\n",
      " | Global Training Round : 48 |\n",
      "\n",
      "user 0 selected\n",
      "local epoch 1\n",
      "1/194, train_loss: 0.6466\n",
      "2/194, train_loss: 0.7080\n",
      "3/194, train_loss: 0.7927\n",
      "4/194, train_loss: 0.8425\n",
      "5/194, train_loss: 0.7580\n",
      "6/194, train_loss: 0.8192\n",
      "7/194, train_loss: 0.8512\n",
      "8/194, train_loss: 0.8683\n",
      "9/194, train_loss: 0.9044\n",
      "10/194, train_loss: 0.8099\n",
      "11/194, train_loss: 0.7688\n",
      "12/194, train_loss: 0.8832\n",
      "13/194, train_loss: 0.7421\n",
      "14/194, train_loss: 0.6597\n",
      "15/194, train_loss: 0.8101\n",
      "16/194, train_loss: 0.8065\n",
      "17/194, train_loss: 0.7565\n",
      "18/194, train_loss: 0.8071\n",
      "19/194, train_loss: 0.5616\n",
      "20/194, train_loss: 0.6735\n",
      "21/194, train_loss: 0.8142\n",
      "22/194, train_loss: 0.7832\n",
      "23/194, train_loss: 0.6011\n",
      "24/194, train_loss: 0.7855\n",
      "25/194, train_loss: 0.8332\n",
      "26/194, train_loss: 0.8804\n",
      "27/194, train_loss: 0.7497\n",
      "28/194, train_loss: 0.8826\n",
      "29/194, train_loss: 0.8611\n",
      "30/194, train_loss: 0.7345\n",
      "31/194, train_loss: 0.7598\n",
      "32/194, train_loss: 0.7163\n",
      "33/194, train_loss: 0.7909\n",
      "34/194, train_loss: 0.8554\n",
      "35/194, train_loss: 0.8461\n",
      "36/194, train_loss: 0.7603\n",
      "37/194, train_loss: 0.8251\n",
      "38/194, train_loss: 0.8618\n",
      "39/194, train_loss: 0.7804\n",
      "40/194, train_loss: 0.7836\n",
      "41/194, train_loss: 0.8803\n",
      "42/194, train_loss: 0.8905\n",
      "43/194, train_loss: 0.6865\n",
      "44/194, train_loss: 0.6892\n",
      "45/194, train_loss: 0.7010\n",
      "46/194, train_loss: 0.8318\n",
      "47/194, train_loss: 0.7342\n",
      "48/194, train_loss: 0.7578\n",
      "49/194, train_loss: 0.7109\n",
      "50/194, train_loss: 0.6747\n",
      "51/194, train_loss: 0.6734\n",
      "52/194, train_loss: 0.7837\n",
      "53/194, train_loss: 0.8329\n",
      "54/194, train_loss: 0.8742\n",
      "55/194, train_loss: 0.9343\n",
      "56/194, train_loss: 0.9380\n",
      "57/194, train_loss: 0.8472\n",
      "58/194, train_loss: 0.8854\n",
      "59/194, train_loss: 0.8497\n",
      "60/194, train_loss: 0.7649\n",
      "61/194, train_loss: 0.8785\n",
      "62/194, train_loss: 0.7703\n",
      "63/194, train_loss: 0.7892\n",
      "64/194, train_loss: 0.8173\n",
      "65/194, train_loss: 0.6840\n",
      "66/194, train_loss: 0.7310\n",
      "67/194, train_loss: 0.7999\n",
      "68/194, train_loss: 0.8590\n",
      "69/194, train_loss: 0.7646\n",
      "70/194, train_loss: 0.9079\n",
      "71/194, train_loss: 0.7834\n",
      "72/194, train_loss: 0.7660\n",
      "73/194, train_loss: 0.6383\n",
      "74/194, train_loss: 0.7118\n",
      "75/194, train_loss: 0.8114\n",
      "76/194, train_loss: 0.5740\n",
      "77/194, train_loss: 0.8689\n",
      "78/194, train_loss: 0.7471\n",
      "79/194, train_loss: 0.6606\n",
      "80/194, train_loss: 0.7214\n",
      "81/194, train_loss: 0.8285\n",
      "82/194, train_loss: 0.7007\n",
      "83/194, train_loss: 0.7800\n",
      "84/194, train_loss: 0.8984\n",
      "85/194, train_loss: 0.8349\n",
      "86/194, train_loss: 0.8526\n",
      "87/194, train_loss: 0.8883\n",
      "88/194, train_loss: 0.8311\n",
      "89/194, train_loss: 0.8576\n",
      "90/194, train_loss: 0.8150\n",
      "91/194, train_loss: 0.8823\n",
      "92/194, train_loss: 0.8261\n",
      "93/194, train_loss: 0.8089\n",
      "94/194, train_loss: 0.7682\n",
      "95/194, train_loss: 0.8249\n",
      "96/194, train_loss: 0.5691\n",
      "97/194, train_loss: 0.7728\n",
      "98/194, train_loss: 0.8914\n",
      "99/194, train_loss: 0.7328\n",
      "100/194, train_loss: 0.8307\n",
      "101/194, train_loss: 0.8377\n",
      "102/194, train_loss: 0.6295\n",
      "103/194, train_loss: 0.8359\n",
      "104/194, train_loss: 0.8962\n",
      "105/194, train_loss: 0.6682\n",
      "106/194, train_loss: 0.7270\n",
      "107/194, train_loss: 0.8558\n",
      "108/194, train_loss: 0.8158\n",
      "109/194, train_loss: 0.8057\n",
      "110/194, train_loss: 0.6670\n",
      "111/194, train_loss: 0.7731\n",
      "112/194, train_loss: 0.7330\n",
      "113/194, train_loss: 0.8766\n",
      "114/194, train_loss: 0.7756\n",
      "115/194, train_loss: 0.8205\n",
      "116/194, train_loss: 0.7165\n",
      "117/194, train_loss: 0.8745\n",
      "118/194, train_loss: 0.7961\n",
      "119/194, train_loss: 0.9318\n",
      "120/194, train_loss: 0.6852\n",
      "121/194, train_loss: 0.8893\n",
      "122/194, train_loss: 0.8744\n",
      "123/194, train_loss: 0.8631\n",
      "124/194, train_loss: 0.9524\n",
      "125/194, train_loss: 0.7921\n",
      "126/194, train_loss: 0.8139\n",
      "127/194, train_loss: 0.7757\n",
      "128/194, train_loss: 0.6207\n",
      "129/194, train_loss: 0.6925\n",
      "130/194, train_loss: 0.7246\n",
      "131/194, train_loss: 0.7094\n",
      "132/194, train_loss: 0.7821\n",
      "133/194, train_loss: 0.7518\n",
      "134/194, train_loss: 0.9536\n",
      "135/194, train_loss: 0.6925\n",
      "136/194, train_loss: 0.6764\n",
      "137/194, train_loss: 0.8332\n",
      "138/194, train_loss: 0.7704\n",
      "139/194, train_loss: 0.6449\n",
      "140/194, train_loss: 0.7625\n",
      "141/194, train_loss: 0.9524\n",
      "142/194, train_loss: 0.6992\n",
      "143/194, train_loss: 0.8671\n",
      "144/194, train_loss: 0.9760\n",
      "145/194, train_loss: 0.8492\n",
      "146/194, train_loss: 0.7287\n",
      "147/194, train_loss: 0.8240\n",
      "148/194, train_loss: 0.7638\n",
      "149/194, train_loss: 0.8806\n",
      "150/194, train_loss: 0.9515\n",
      "151/194, train_loss: 0.8385\n",
      "152/194, train_loss: 0.9416\n",
      "153/194, train_loss: 0.9293\n",
      "154/194, train_loss: 0.9630\n",
      "155/194, train_loss: 0.9343\n",
      "156/194, train_loss: 0.8936\n",
      "157/194, train_loss: 0.8010\n",
      "158/194, train_loss: 0.8452\n",
      "159/194, train_loss: 0.7707\n",
      "160/194, train_loss: 0.5782\n",
      "161/194, train_loss: 0.8153\n",
      "162/194, train_loss: 0.8601\n",
      "163/194, train_loss: 0.7312\n",
      "164/194, train_loss: 0.8866\n",
      "165/194, train_loss: 0.9292\n",
      "166/194, train_loss: 0.8479\n",
      "167/194, train_loss: 0.9092\n",
      "168/194, train_loss: 0.7572\n",
      "169/194, train_loss: 0.8929\n",
      "170/194, train_loss: 0.7611\n",
      "171/194, train_loss: 0.8084\n",
      "172/194, train_loss: 0.6448\n",
      "173/194, train_loss: 0.7648\n",
      "174/194, train_loss: 0.8849\n",
      "175/194, train_loss: 0.9127\n",
      "176/194, train_loss: 0.8024\n",
      "177/194, train_loss: 0.7841\n",
      "178/194, train_loss: 0.8799\n",
      "179/194, train_loss: 0.7667\n",
      "180/194, train_loss: 0.8295\n",
      "181/194, train_loss: 0.8228\n",
      "182/194, train_loss: 0.5814\n",
      "183/194, train_loss: 0.6333\n",
      "184/194, train_loss: 0.8850\n",
      "185/194, train_loss: 0.7393\n",
      "186/194, train_loss: 0.7301\n",
      "187/194, train_loss: 0.9684\n",
      "188/194, train_loss: 0.8201\n",
      "189/194, train_loss: 0.6976\n",
      "190/194, train_loss: 0.8319\n",
      "191/194, train_loss: 0.8504\n",
      "192/194, train_loss: 0.7127\n",
      "193/194, train_loss: 0.7200\n",
      "194/194, train_loss: 0.6737\n",
      "metric=0.34534028358757496, metric_tc=0.3608759604394436, metric_wt=0.47111265920102596, metric_et=0.2040322415996343\n",
      "metric=0.34534028358757496, metric_tc=0.3608759604394436, metric_wt=0.47111265920102596, metric_et=0.2040322415996343\n",
      "current epoch: 48 current epoch loss: 0.7949\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 48/80 [8:46:28<6:19:22, 711.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metric=0.34534028358757496, metric_tc=0.3608759604394436, metric_wt=0.47111265920102596, metric_et=0.2040322415996343\n",
      "0.34534028358757496\n",
      "current epoch: 48 current mean dice: 0.3453 tc: 0.3609 wt: 0.4711 et: 0.2040\n",
      "best mean dice: 0.3727 at epoch: 41\n",
      "\n",
      " | Global Training Round : 49 |\n",
      "\n",
      "user 0 selected\n",
      "local epoch 1\n",
      "1/194, train_loss: 0.8832\n",
      "2/194, train_loss: 0.7475\n",
      "3/194, train_loss: 0.7169\n",
      "4/194, train_loss: 0.7390\n",
      "5/194, train_loss: 0.7420\n",
      "6/194, train_loss: 0.8022\n",
      "7/194, train_loss: 0.7324\n",
      "8/194, train_loss: 0.7788\n",
      "9/194, train_loss: 0.6969\n",
      "10/194, train_loss: 0.6401\n",
      "11/194, train_loss: 0.8139\n",
      "12/194, train_loss: 0.5785\n",
      "13/194, train_loss: 0.8312\n",
      "14/194, train_loss: 0.7366\n",
      "15/194, train_loss: 0.6328\n",
      "16/194, train_loss: 0.5782\n",
      "17/194, train_loss: 0.6840\n",
      "18/194, train_loss: 0.7513\n",
      "19/194, train_loss: 0.7380\n",
      "20/194, train_loss: 0.7189\n",
      "21/194, train_loss: 0.8256\n",
      "22/194, train_loss: 0.9112\n",
      "23/194, train_loss: 0.7776\n",
      "24/194, train_loss: 0.8053\n",
      "25/194, train_loss: 0.9135\n",
      "26/194, train_loss: 0.9393\n",
      "27/194, train_loss: 0.8409\n",
      "28/194, train_loss: 0.7456\n",
      "29/194, train_loss: 0.8581\n",
      "30/194, train_loss: 0.7514\n",
      "31/194, train_loss: 0.7970\n",
      "32/194, train_loss: 0.8038\n",
      "33/194, train_loss: 0.8842\n",
      "34/194, train_loss: 0.8821\n",
      "35/194, train_loss: 0.8628\n",
      "36/194, train_loss: 0.7592\n",
      "37/194, train_loss: 0.6131\n",
      "38/194, train_loss: 0.8858\n",
      "39/194, train_loss: 0.6189\n",
      "40/194, train_loss: 0.6465\n",
      "41/194, train_loss: 0.7428\n",
      "42/194, train_loss: 0.6863\n",
      "43/194, train_loss: 0.8330\n",
      "44/194, train_loss: 0.7307\n",
      "45/194, train_loss: 0.9358\n",
      "46/194, train_loss: 0.7747\n",
      "47/194, train_loss: 0.7753\n",
      "48/194, train_loss: 0.6866\n",
      "49/194, train_loss: 0.7361\n",
      "50/194, train_loss: 0.7773\n",
      "51/194, train_loss: 0.6470\n",
      "52/194, train_loss: 0.8246\n",
      "53/194, train_loss: 0.7811\n",
      "54/194, train_loss: 0.8200\n",
      "55/194, train_loss: 0.8022\n",
      "56/194, train_loss: 0.8275\n",
      "57/194, train_loss: 0.8269\n",
      "58/194, train_loss: 0.7121\n",
      "59/194, train_loss: 0.8836\n",
      "60/194, train_loss: 0.8014\n",
      "61/194, train_loss: 0.7808\n",
      "62/194, train_loss: 0.8048\n",
      "63/194, train_loss: 0.7850\n",
      "64/194, train_loss: 0.6969\n",
      "65/194, train_loss: 0.8656\n",
      "66/194, train_loss: 0.7152\n",
      "67/194, train_loss: 0.5915\n",
      "68/194, train_loss: 0.8444\n",
      "69/194, train_loss: 0.8013\n",
      "70/194, train_loss: 0.7590\n",
      "71/194, train_loss: 0.7504\n",
      "72/194, train_loss: 0.8585\n",
      "73/194, train_loss: 0.8856\n",
      "74/194, train_loss: 0.9034\n",
      "75/194, train_loss: 0.6252\n",
      "76/194, train_loss: 0.8496\n",
      "77/194, train_loss: 0.8598\n",
      "78/194, train_loss: 0.9416\n",
      "79/194, train_loss: 0.8043\n",
      "80/194, train_loss: 0.7071\n",
      "81/194, train_loss: 0.8172\n",
      "82/194, train_loss: 0.8706\n",
      "83/194, train_loss: 0.8222\n",
      "84/194, train_loss: 0.9328\n",
      "85/194, train_loss: 0.8445\n",
      "86/194, train_loss: 0.8409\n",
      "87/194, train_loss: 0.8569\n",
      "88/194, train_loss: 0.8887\n",
      "89/194, train_loss: 0.8688\n",
      "90/194, train_loss: 0.8850\n",
      "91/194, train_loss: 0.8499\n",
      "92/194, train_loss: 0.8155\n",
      "93/194, train_loss: 0.4945\n",
      "94/194, train_loss: 0.7467\n",
      "95/194, train_loss: 0.6978\n",
      "96/194, train_loss: 0.7856\n",
      "97/194, train_loss: 0.8087\n",
      "98/194, train_loss: 0.8291\n",
      "99/194, train_loss: 0.7422\n",
      "100/194, train_loss: 0.8173\n",
      "101/194, train_loss: 0.6129\n",
      "102/194, train_loss: 0.8701\n",
      "103/194, train_loss: 0.7688\n",
      "104/194, train_loss: 0.7885\n",
      "105/194, train_loss: 0.7171\n",
      "106/194, train_loss: 0.7916\n",
      "107/194, train_loss: 0.7236\n",
      "108/194, train_loss: 0.6635\n",
      "109/194, train_loss: 0.8796\n",
      "110/194, train_loss: 0.6853\n",
      "111/194, train_loss: 0.7690\n",
      "112/194, train_loss: 0.9419\n",
      "113/194, train_loss: 0.8305\n",
      "114/194, train_loss: 0.8100\n",
      "115/194, train_loss: 0.8616\n",
      "116/194, train_loss: 0.8519\n",
      "117/194, train_loss: 0.7067\n",
      "118/194, train_loss: 0.7755\n",
      "119/194, train_loss: 0.8942\n",
      "120/194, train_loss: 0.7676\n",
      "121/194, train_loss: 0.6852\n",
      "122/194, train_loss: 0.8588\n",
      "123/194, train_loss: 0.7753\n",
      "124/194, train_loss: 0.7792\n",
      "125/194, train_loss: 0.8911\n",
      "126/194, train_loss: 0.6966\n",
      "127/194, train_loss: 0.7512\n",
      "128/194, train_loss: 0.7822\n",
      "129/194, train_loss: 0.8314\n",
      "130/194, train_loss: 0.7700\n",
      "131/194, train_loss: 0.8360\n",
      "132/194, train_loss: 0.8156\n",
      "133/194, train_loss: 0.8317\n",
      "134/194, train_loss: 0.6699\n",
      "135/194, train_loss: 0.8245\n",
      "136/194, train_loss: 0.6181\n",
      "137/194, train_loss: 0.6334\n",
      "138/194, train_loss: 0.7635\n",
      "139/194, train_loss: 0.7722\n",
      "140/194, train_loss: 0.7322\n",
      "141/194, train_loss: 0.9172\n",
      "142/194, train_loss: 0.9847\n",
      "143/194, train_loss: 0.8161\n",
      "144/194, train_loss: 0.8765\n",
      "145/194, train_loss: 0.6966\n",
      "146/194, train_loss: 0.8819\n",
      "147/194, train_loss: 0.7663\n",
      "148/194, train_loss: 0.8588\n",
      "149/194, train_loss: 0.9227\n",
      "150/194, train_loss: 0.9209\n",
      "151/194, train_loss: 0.9235\n",
      "152/194, train_loss: 0.7787\n",
      "153/194, train_loss: 0.9084\n",
      "154/194, train_loss: 0.9505\n",
      "155/194, train_loss: 0.6468\n",
      "156/194, train_loss: 0.7615\n",
      "157/194, train_loss: 0.8062\n",
      "158/194, train_loss: 0.8593\n",
      "159/194, train_loss: 0.7973\n",
      "160/194, train_loss: 0.9265\n",
      "161/194, train_loss: 0.7923\n",
      "162/194, train_loss: 0.7962\n",
      "163/194, train_loss: 0.9174\n",
      "164/194, train_loss: 0.8371\n",
      "165/194, train_loss: 0.7336\n",
      "166/194, train_loss: 0.8310\n",
      "167/194, train_loss: 0.8477\n",
      "168/194, train_loss: 0.7773\n",
      "169/194, train_loss: 0.6339\n",
      "170/194, train_loss: 0.6741\n",
      "171/194, train_loss: 0.7481\n",
      "172/194, train_loss: 0.7660\n",
      "173/194, train_loss: 0.8918\n",
      "174/194, train_loss: 0.7843\n",
      "175/194, train_loss: 0.7683\n",
      "176/194, train_loss: 0.8209\n",
      "177/194, train_loss: 0.8724\n",
      "178/194, train_loss: 0.8269\n",
      "179/194, train_loss: 0.7866\n",
      "180/194, train_loss: 0.7948\n",
      "181/194, train_loss: 0.6924\n",
      "182/194, train_loss: 0.8587\n",
      "183/194, train_loss: 0.8634\n",
      "184/194, train_loss: 0.7558\n",
      "185/194, train_loss: 0.8575\n",
      "186/194, train_loss: 0.8825\n",
      "187/194, train_loss: 0.8628\n",
      "188/194, train_loss: 0.7259\n",
      "189/194, train_loss: 0.7802\n",
      "190/194, train_loss: 0.7370\n",
      "191/194, train_loss: 0.9397\n",
      "192/194, train_loss: 0.8118\n",
      "193/194, train_loss: 0.9303\n",
      "194/194, train_loss: 0.9290\n",
      "metric=0.3645926012347142, metric_tc=0.3719005157860617, metric_wt=0.519640306631724, metric_et=0.20223697756106654\n",
      "metric=0.3645926012347142, metric_tc=0.3719005157860617, metric_wt=0.519640306631724, metric_et=0.20223697756106654\n",
      "current epoch: 49 current epoch loss: 0.7931\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████▏   | 49/80 [8:56:56<5:54:34, 686.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metric=0.3645926012347142, metric_tc=0.3719005157860617, metric_wt=0.519640306631724, metric_et=0.20223697756106654\n",
      "0.3645926012347142\n",
      "current epoch: 49 current mean dice: 0.3646 tc: 0.3719 wt: 0.5196 et: 0.2022\n",
      "best mean dice: 0.3727 at epoch: 41\n",
      "\n",
      " | Global Training Round : 50 |\n",
      "\n",
      "user 0 selected\n",
      "local epoch 1\n",
      "1/194, train_loss: 0.6807\n",
      "2/194, train_loss: 0.7445\n",
      "3/194, train_loss: 0.7424\n",
      "4/194, train_loss: 0.7988\n",
      "5/194, train_loss: 0.7530\n",
      "6/194, train_loss: 0.6589\n",
      "7/194, train_loss: 0.9009\n",
      "8/194, train_loss: 0.8621\n",
      "9/194, train_loss: 0.7324\n",
      "10/194, train_loss: 0.7990\n",
      "11/194, train_loss: 0.7848\n",
      "12/194, train_loss: 0.6012\n",
      "13/194, train_loss: 0.7428\n",
      "14/194, train_loss: 0.6701\n",
      "15/194, train_loss: 0.7432\n",
      "16/194, train_loss: 0.6881\n",
      "17/194, train_loss: 0.5353\n",
      "18/194, train_loss: 0.7273\n",
      "19/194, train_loss: 0.6611\n",
      "20/194, train_loss: 0.5907\n",
      "21/194, train_loss: 0.7856\n",
      "22/194, train_loss: 0.7459\n",
      "23/194, train_loss: 0.6609\n",
      "24/194, train_loss: 0.7959\n",
      "25/194, train_loss: 0.7198\n",
      "26/194, train_loss: 0.7410\n",
      "27/194, train_loss: 0.9403\n",
      "28/194, train_loss: 0.8719\n",
      "29/194, train_loss: 0.9173\n",
      "30/194, train_loss: 0.5450\n",
      "31/194, train_loss: 0.8046\n",
      "32/194, train_loss: 0.8572\n",
      "33/194, train_loss: 0.7486\n",
      "34/194, train_loss: 0.7283\n",
      "35/194, train_loss: 0.7624\n",
      "36/194, train_loss: 0.7850\n",
      "37/194, train_loss: 0.5830\n",
      "38/194, train_loss: 0.6348\n",
      "39/194, train_loss: 0.5382\n",
      "40/194, train_loss: 0.7299\n",
      "41/194, train_loss: 0.7104\n",
      "42/194, train_loss: 0.7761\n",
      "43/194, train_loss: 0.7597\n",
      "44/194, train_loss: 0.6484\n",
      "45/194, train_loss: 0.7777\n",
      "46/194, train_loss: 0.8083\n",
      "47/194, train_loss: 0.8794\n",
      "48/194, train_loss: 0.5933\n",
      "49/194, train_loss: 0.6488\n",
      "50/194, train_loss: 0.6223\n",
      "51/194, train_loss: 0.7571\n",
      "52/194, train_loss: 0.5977\n",
      "53/194, train_loss: 0.7024\n",
      "54/194, train_loss: 0.6637\n",
      "55/194, train_loss: 0.8612\n",
      "56/194, train_loss: 0.8291\n",
      "57/194, train_loss: 0.8970\n",
      "58/194, train_loss: 0.8633\n",
      "59/194, train_loss: 0.8951\n",
      "60/194, train_loss: 0.8876\n",
      "61/194, train_loss: 0.6209\n",
      "62/194, train_loss: 0.6714\n",
      "63/194, train_loss: 0.7634\n",
      "64/194, train_loss: 0.8715\n",
      "65/194, train_loss: 0.8235\n",
      "66/194, train_loss: 0.8713\n",
      "67/194, train_loss: 0.7783\n",
      "68/194, train_loss: 0.9314\n",
      "69/194, train_loss: 0.5304\n",
      "70/194, train_loss: 0.7212\n",
      "71/194, train_loss: 0.8529\n",
      "72/194, train_loss: 0.7145\n",
      "73/194, train_loss: 0.5986\n",
      "74/194, train_loss: 0.7451\n",
      "75/194, train_loss: 0.9500\n",
      "76/194, train_loss: 0.6907\n",
      "77/194, train_loss: 0.8505\n",
      "78/194, train_loss: 0.5793\n",
      "79/194, train_loss: 0.7528\n",
      "80/194, train_loss: 0.6559\n",
      "81/194, train_loss: 0.8825\n",
      "82/194, train_loss: 0.5635\n",
      "83/194, train_loss: 0.9310\n",
      "84/194, train_loss: 0.7335\n",
      "85/194, train_loss: 0.9211\n",
      "86/194, train_loss: 0.8586\n",
      "87/194, train_loss: 0.8377\n",
      "88/194, train_loss: 0.9070\n",
      "89/194, train_loss: 0.8621\n",
      "90/194, train_loss: 0.9001\n",
      "91/194, train_loss: 0.7653\n",
      "92/194, train_loss: 0.7729\n",
      "93/194, train_loss: 0.5765\n",
      "94/194, train_loss: 0.8941\n",
      "95/194, train_loss: 0.8315\n",
      "96/194, train_loss: 0.6176\n",
      "97/194, train_loss: 0.7515\n",
      "98/194, train_loss: 0.9139\n",
      "99/194, train_loss: 0.7158\n",
      "100/194, train_loss: 0.9258\n",
      "101/194, train_loss: 0.8732\n",
      "102/194, train_loss: 0.8533\n",
      "103/194, train_loss: 0.6967\n",
      "104/194, train_loss: 0.7405\n",
      "105/194, train_loss: 0.8386\n",
      "106/194, train_loss: 0.8629\n",
      "107/194, train_loss: 0.8584\n",
      "108/194, train_loss: 0.7712\n",
      "109/194, train_loss: 0.7102\n",
      "110/194, train_loss: 0.8454\n",
      "111/194, train_loss: 0.7444\n",
      "112/194, train_loss: 0.8905\n",
      "113/194, train_loss: 0.7164\n",
      "114/194, train_loss: 0.8970\n",
      "115/194, train_loss: 0.7477\n",
      "116/194, train_loss: 0.7366\n",
      "117/194, train_loss: 0.8687\n",
      "118/194, train_loss: 0.8508\n",
      "119/194, train_loss: 0.7354\n",
      "120/194, train_loss: 0.6576\n",
      "121/194, train_loss: 0.8107\n",
      "122/194, train_loss: 0.9120\n",
      "123/194, train_loss: 0.9553\n",
      "124/194, train_loss: 0.6834\n",
      "125/194, train_loss: 0.9493\n",
      "126/194, train_loss: 0.8536\n",
      "127/194, train_loss: 0.8774\n",
      "128/194, train_loss: 0.8955\n",
      "129/194, train_loss: 0.8790\n",
      "130/194, train_loss: 0.8102\n",
      "131/194, train_loss: 0.8511\n",
      "132/194, train_loss: 0.7907\n",
      "133/194, train_loss: 0.8281\n",
      "134/194, train_loss: 0.9126\n",
      "135/194, train_loss: 0.7907\n",
      "136/194, train_loss: 0.8552\n",
      "137/194, train_loss: 0.6468\n",
      "138/194, train_loss: 0.6080\n",
      "139/194, train_loss: 0.7320\n",
      "140/194, train_loss: 0.7789\n",
      "141/194, train_loss: 0.7036\n",
      "142/194, train_loss: 0.8978\n",
      "143/194, train_loss: 0.9219\n",
      "144/194, train_loss: 0.8662\n",
      "145/194, train_loss: 0.8351\n",
      "146/194, train_loss: 0.7315\n",
      "147/194, train_loss: 0.7780\n",
      "148/194, train_loss: 0.7877\n",
      "149/194, train_loss: 0.7008\n",
      "150/194, train_loss: 0.9135\n",
      "151/194, train_loss: 0.9248\n",
      "152/194, train_loss: 0.9278\n",
      "153/194, train_loss: 0.8460\n",
      "154/194, train_loss: 0.8450\n",
      "155/194, train_loss: 0.9156\n",
      "156/194, train_loss: 0.8487\n",
      "157/194, train_loss: 0.7980\n",
      "158/194, train_loss: 0.8939\n",
      "159/194, train_loss: 0.9117\n",
      "160/194, train_loss: 0.8578\n",
      "161/194, train_loss: 0.7307\n",
      "162/194, train_loss: 0.8518\n",
      "163/194, train_loss: 0.8005\n",
      "164/194, train_loss: 0.8991\n",
      "165/194, train_loss: 0.8908\n",
      "166/194, train_loss: 0.8646\n",
      "167/194, train_loss: 0.9180\n",
      "168/194, train_loss: 0.7783\n",
      "169/194, train_loss: 0.8502\n",
      "170/194, train_loss: 0.6381\n",
      "171/194, train_loss: 0.6908\n",
      "172/194, train_loss: 0.7651\n",
      "173/194, train_loss: 0.7022\n",
      "174/194, train_loss: 0.8004\n",
      "175/194, train_loss: 0.8047\n",
      "176/194, train_loss: 0.7209\n",
      "177/194, train_loss: 0.8726\n",
      "178/194, train_loss: 0.8073\n",
      "179/194, train_loss: 0.9279\n",
      "180/194, train_loss: 0.9098\n",
      "181/194, train_loss: 0.7666\n",
      "182/194, train_loss: 0.5343\n",
      "183/194, train_loss: 0.7949\n",
      "184/194, train_loss: 0.7863\n",
      "185/194, train_loss: 0.8248\n",
      "186/194, train_loss: 0.8407\n",
      "187/194, train_loss: 0.7495\n",
      "188/194, train_loss: 0.7995\n",
      "189/194, train_loss: 0.8494\n",
      "190/194, train_loss: 0.8146\n",
      "191/194, train_loss: 0.7485\n",
      "192/194, train_loss: 0.7113\n",
      "193/194, train_loss: 0.8481\n",
      "194/194, train_loss: 0.7625\n",
      "metric=0.3506780431295435, metric_tc=0.3683188925497234, metric_wt=0.481049466257294, metric_et=0.20266577896351615\n",
      "metric=0.3506780431295435, metric_tc=0.3683188925497234, metric_wt=0.481049466257294, metric_et=0.20266577896351615\n",
      "current epoch: 50 current epoch loss: 0.7830\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▎   | 50/80 [9:07:56<5:39:05, 678.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metric=0.3506780431295435, metric_tc=0.3683188925497234, metric_wt=0.481049466257294, metric_et=0.20266577896351615\n",
      "0.3506780431295435\n",
      "current epoch: 50 current mean dice: 0.3507 tc: 0.3683 wt: 0.4810 et: 0.2027\n",
      "best mean dice: 0.3727 at epoch: 41\n",
      "\n",
      " | Global Training Round : 51 |\n",
      "\n",
      "user 0 selected\n",
      "local epoch 1\n",
      "1/194, train_loss: 0.8434\n",
      "2/194, train_loss: 0.8469\n",
      "3/194, train_loss: 0.7303\n",
      "4/194, train_loss: 0.7289\n",
      "5/194, train_loss: 0.7100\n",
      "6/194, train_loss: 0.9179\n",
      "7/194, train_loss: 0.9252\n",
      "8/194, train_loss: 0.8740\n",
      "9/194, train_loss: 0.8899\n",
      "10/194, train_loss: 0.8208\n",
      "11/194, train_loss: 0.6078\n",
      "12/194, train_loss: 0.6846\n",
      "13/194, train_loss: 0.7965\n",
      "14/194, train_loss: 0.7106\n",
      "15/194, train_loss: 0.8389\n",
      "16/194, train_loss: 0.6234\n",
      "17/194, train_loss: 0.6571\n",
      "18/194, train_loss: 0.8014\n",
      "19/194, train_loss: 0.5584\n",
      "20/194, train_loss: 0.7156\n",
      "21/194, train_loss: 0.7166\n",
      "22/194, train_loss: 0.9063\n",
      "23/194, train_loss: 0.9123\n",
      "24/194, train_loss: 0.7761\n",
      "25/194, train_loss: 0.7255\n",
      "26/194, train_loss: 0.7366\n",
      "27/194, train_loss: 0.6917\n",
      "28/194, train_loss: 0.6529\n",
      "29/194, train_loss: 0.8379\n",
      "30/194, train_loss: 0.8333\n",
      "31/194, train_loss: 0.8995\n",
      "32/194, train_loss: 0.7506\n",
      "33/194, train_loss: 0.8708\n",
      "34/194, train_loss: 0.6740\n",
      "35/194, train_loss: 0.7288\n",
      "36/194, train_loss: 0.8499\n",
      "37/194, train_loss: 0.7153\n",
      "38/194, train_loss: 0.6983\n",
      "39/194, train_loss: 0.8576\n",
      "40/194, train_loss: 0.7330\n",
      "41/194, train_loss: 0.8389\n",
      "42/194, train_loss: 0.7250\n",
      "43/194, train_loss: 0.7929\n",
      "44/194, train_loss: 0.6974\n",
      "45/194, train_loss: 0.5560\n",
      "46/194, train_loss: 0.9129\n",
      "47/194, train_loss: 0.7273\n",
      "48/194, train_loss: 0.5385\n",
      "49/194, train_loss: 0.6836\n",
      "50/194, train_loss: 0.7264\n",
      "51/194, train_loss: 0.7592\n",
      "52/194, train_loss: 0.6679\n",
      "53/194, train_loss: 0.8932\n",
      "54/194, train_loss: 0.8452\n",
      "55/194, train_loss: 0.9236\n",
      "56/194, train_loss: 0.7201\n",
      "57/194, train_loss: 0.8268\n",
      "58/194, train_loss: 0.7954\n",
      "59/194, train_loss: 0.8928\n",
      "60/194, train_loss: 0.8637\n",
      "61/194, train_loss: 0.8451\n",
      "62/194, train_loss: 0.8514\n",
      "63/194, train_loss: 0.6049\n",
      "64/194, train_loss: 0.9258\n",
      "65/194, train_loss: 0.7364\n",
      "66/194, train_loss: 0.6809\n",
      "67/194, train_loss: 0.9086\n",
      "68/194, train_loss: 0.8154\n",
      "69/194, train_loss: 0.8987\n",
      "70/194, train_loss: 0.8649\n",
      "71/194, train_loss: 0.6679\n",
      "72/194, train_loss: 0.7227\n",
      "73/194, train_loss: 0.9548\n",
      "74/194, train_loss: 0.6982\n",
      "75/194, train_loss: 0.8353\n",
      "76/194, train_loss: 0.6508\n",
      "77/194, train_loss: 0.8429\n",
      "78/194, train_loss: 0.7736\n",
      "79/194, train_loss: 0.8260\n",
      "80/194, train_loss: 0.6371\n",
      "81/194, train_loss: 0.8173\n",
      "82/194, train_loss: 0.8665\n",
      "83/194, train_loss: 0.8770\n",
      "84/194, train_loss: 0.9052\n",
      "85/194, train_loss: 0.8353\n",
      "86/194, train_loss: 0.7069\n",
      "87/194, train_loss: 0.7400\n",
      "88/194, train_loss: 0.8073\n",
      "89/194, train_loss: 0.9442\n",
      "90/194, train_loss: 0.8244\n",
      "91/194, train_loss: 0.7351\n",
      "92/194, train_loss: 0.8000\n",
      "93/194, train_loss: 0.7494\n",
      "94/194, train_loss: 0.8069\n",
      "95/194, train_loss: 0.8244\n",
      "96/194, train_loss: 0.8182\n",
      "97/194, train_loss: 0.7221\n",
      "98/194, train_loss: 0.7318\n",
      "99/194, train_loss: 0.8747\n",
      "100/194, train_loss: 0.7043\n",
      "101/194, train_loss: 0.7887\n",
      "102/194, train_loss: 0.7948\n",
      "103/194, train_loss: 0.8779\n",
      "104/194, train_loss: 0.6466\n",
      "105/194, train_loss: 0.6813\n",
      "106/194, train_loss: 0.8995\n",
      "107/194, train_loss: 0.6485\n",
      "108/194, train_loss: 0.7732\n",
      "109/194, train_loss: 0.8421\n",
      "110/194, train_loss: 0.6773\n",
      "111/194, train_loss: 0.7486\n",
      "112/194, train_loss: 0.7194\n",
      "113/194, train_loss: 0.7932\n",
      "114/194, train_loss: 0.8561\n",
      "115/194, train_loss: 0.8013\n",
      "116/194, train_loss: 0.8654\n",
      "117/194, train_loss: 0.6254\n",
      "118/194, train_loss: 0.7620\n",
      "119/194, train_loss: 0.7706\n",
      "120/194, train_loss: 0.8234\n",
      "121/194, train_loss: 0.8463\n",
      "122/194, train_loss: 0.8385\n",
      "123/194, train_loss: 0.9241\n",
      "124/194, train_loss: 0.8223\n",
      "125/194, train_loss: 0.8933\n",
      "126/194, train_loss: 0.7992\n",
      "127/194, train_loss: 0.8805\n",
      "128/194, train_loss: 0.7326\n",
      "129/194, train_loss: 0.8480\n",
      "130/194, train_loss: 0.7311\n",
      "131/194, train_loss: 0.8227\n",
      "132/194, train_loss: 0.8514\n",
      "133/194, train_loss: 0.7288\n",
      "134/194, train_loss: 0.8475\n",
      "135/194, train_loss: 0.7558\n",
      "136/194, train_loss: 0.6457\n",
      "137/194, train_loss: 0.6003\n",
      "138/194, train_loss: 0.7758\n",
      "139/194, train_loss: 0.6057\n",
      "140/194, train_loss: 0.6718\n",
      "141/194, train_loss: 0.8499\n",
      "142/194, train_loss: 0.8303\n",
      "143/194, train_loss: 0.8457\n",
      "144/194, train_loss: 0.7770\n",
      "145/194, train_loss: 0.8170\n",
      "146/194, train_loss: 0.8533\n",
      "147/194, train_loss: 0.8166\n",
      "148/194, train_loss: 0.8478\n",
      "149/194, train_loss: 0.9177\n",
      "150/194, train_loss: 0.9472\n",
      "151/194, train_loss: 0.9600\n",
      "152/194, train_loss: 0.8692\n",
      "153/194, train_loss: 0.8561\n",
      "154/194, train_loss: 0.9283\n",
      "155/194, train_loss: 0.9171\n",
      "156/194, train_loss: 0.9326\n",
      "157/194, train_loss: 0.8465\n",
      "158/194, train_loss: 0.7860\n",
      "159/194, train_loss: 0.9345\n",
      "160/194, train_loss: 0.7884\n",
      "161/194, train_loss: 0.8904\n",
      "162/194, train_loss: 0.9370\n",
      "163/194, train_loss: 0.9589\n",
      "164/194, train_loss: 0.8935\n",
      "165/194, train_loss: 0.7852\n",
      "166/194, train_loss: 0.7513\n",
      "167/194, train_loss: 0.8001\n",
      "168/194, train_loss: 0.6994\n",
      "169/194, train_loss: 0.7759\n",
      "170/194, train_loss: 0.6772\n",
      "171/194, train_loss: 0.8435\n",
      "172/194, train_loss: 0.7415\n",
      "173/194, train_loss: 0.6855\n",
      "174/194, train_loss: 0.6967\n",
      "175/194, train_loss: 0.8920\n",
      "176/194, train_loss: 0.9021\n",
      "177/194, train_loss: 0.8433\n",
      "178/194, train_loss: 0.7356\n",
      "179/194, train_loss: 0.6472\n",
      "180/194, train_loss: 0.7014\n",
      "181/194, train_loss: 0.8680\n",
      "182/194, train_loss: 0.7665\n",
      "183/194, train_loss: 0.6901\n",
      "184/194, train_loss: 0.7203\n",
      "185/194, train_loss: 0.7965\n",
      "186/194, train_loss: 0.8335\n",
      "187/194, train_loss: 0.8554\n",
      "188/194, train_loss: 0.7733\n",
      "189/194, train_loss: 0.6779\n",
      "190/194, train_loss: 0.7767\n",
      "191/194, train_loss: 0.7707\n",
      "192/194, train_loss: 0.6641\n",
      "193/194, train_loss: 0.8449\n",
      "194/194, train_loss: 0.6872\n",
      "metric=0.36021283082664013, metric_tc=0.3725199659044544, metric_wt=0.49742567725479603, metric_et=0.21069284334468344\n",
      "metric=0.36021283082664013, metric_tc=0.3725199659044544, metric_wt=0.49742567725479603, metric_et=0.21069284334468344\n",
      "current epoch: 51 current epoch loss: 0.7886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 51/80 [9:19:31<5:30:15, 683.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metric=0.36021283082664013, metric_tc=0.3725199659044544, metric_wt=0.49742567725479603, metric_et=0.21069284334468344\n",
      "0.36021283082664013\n",
      "current epoch: 51 current mean dice: 0.3602 tc: 0.3725 wt: 0.4974 et: 0.2107\n",
      "best mean dice: 0.3727 at epoch: 41\n",
      "\n",
      " | Global Training Round : 52 |\n",
      "\n",
      "user 0 selected\n",
      "local epoch 1\n",
      "1/194, train_loss: 0.7716\n",
      "2/194, train_loss: 0.7600\n",
      "3/194, train_loss: 0.7028\n",
      "4/194, train_loss: 0.7608\n",
      "5/194, train_loss: 0.8601\n",
      "6/194, train_loss: 0.8886\n",
      "7/194, train_loss: 0.7804\n",
      "8/194, train_loss: 0.8747\n",
      "9/194, train_loss: 0.7723\n",
      "10/194, train_loss: 0.7411\n",
      "11/194, train_loss: 0.7901\n",
      "12/194, train_loss: 0.7767\n",
      "13/194, train_loss: 0.8947\n",
      "14/194, train_loss: 0.6724\n",
      "15/194, train_loss: 0.5941\n",
      "16/194, train_loss: 0.6718\n",
      "17/194, train_loss: 0.9159\n",
      "18/194, train_loss: 0.6090\n",
      "19/194, train_loss: 0.8960\n",
      "20/194, train_loss: 0.8189\n",
      "21/194, train_loss: 0.8648\n",
      "22/194, train_loss: 0.5416\n",
      "23/194, train_loss: 0.8201\n",
      "24/194, train_loss: 0.7959\n",
      "25/194, train_loss: 0.7864\n",
      "26/194, train_loss: 0.7451\n",
      "27/194, train_loss: 0.8318\n",
      "28/194, train_loss: 0.9325\n",
      "29/194, train_loss: 0.8732\n",
      "30/194, train_loss: 0.8013\n",
      "31/194, train_loss: 0.7842\n",
      "32/194, train_loss: 0.6788\n",
      "33/194, train_loss: 0.7783\n",
      "34/194, train_loss: 0.6850\n",
      "35/194, train_loss: 0.8187\n",
      "36/194, train_loss: 0.7379\n",
      "37/194, train_loss: 0.8932\n",
      "38/194, train_loss: 0.8036\n",
      "39/194, train_loss: 0.7567\n",
      "40/194, train_loss: 0.7804\n",
      "41/194, train_loss: 0.6039\n",
      "42/194, train_loss: 0.7676\n",
      "43/194, train_loss: 0.8165\n",
      "44/194, train_loss: 0.7271\n",
      "45/194, train_loss: 0.6615\n",
      "46/194, train_loss: 0.7519\n",
      "47/194, train_loss: 0.7520\n",
      "48/194, train_loss: 0.4641\n",
      "49/194, train_loss: 0.7346\n",
      "50/194, train_loss: 0.7685\n",
      "51/194, train_loss: 0.7006\n",
      "52/194, train_loss: 0.6544\n",
      "53/194, train_loss: 0.8468\n",
      "54/194, train_loss: 0.8913\n",
      "55/194, train_loss: 0.7885\n",
      "56/194, train_loss: 0.7214\n",
      "57/194, train_loss: 0.9032\n",
      "58/194, train_loss: 0.8775\n",
      "59/194, train_loss: 0.9061\n",
      "60/194, train_loss: 0.8299\n",
      "61/194, train_loss: 0.7216\n",
      "62/194, train_loss: 0.8732\n",
      "63/194, train_loss: 0.7170\n",
      "64/194, train_loss: 0.8066\n",
      "65/194, train_loss: 0.7978\n",
      "66/194, train_loss: 0.7702\n",
      "67/194, train_loss: 0.7370\n",
      "68/194, train_loss: 0.8714\n",
      "69/194, train_loss: 0.6708\n",
      "70/194, train_loss: 0.8327\n",
      "71/194, train_loss: 0.8637\n",
      "72/194, train_loss: 0.7699\n",
      "73/194, train_loss: 0.8282\n",
      "74/194, train_loss: 0.7243\n",
      "75/194, train_loss: 0.9006\n",
      "76/194, train_loss: 0.8529\n",
      "77/194, train_loss: 0.6845\n",
      "78/194, train_loss: 0.6899\n",
      "79/194, train_loss: 0.6676\n",
      "80/194, train_loss: 0.7348\n",
      "81/194, train_loss: 0.8047\n",
      "82/194, train_loss: 0.6943\n",
      "83/194, train_loss: 0.7920\n",
      "84/194, train_loss: 0.8376\n",
      "85/194, train_loss: 0.8334\n",
      "86/194, train_loss: 0.8542\n",
      "87/194, train_loss: 0.8046\n",
      "88/194, train_loss: 0.6726\n",
      "89/194, train_loss: 0.7389\n",
      "90/194, train_loss: 0.8813\n",
      "91/194, train_loss: 0.7699\n",
      "92/194, train_loss: 0.8344\n",
      "93/194, train_loss: 0.7811\n",
      "94/194, train_loss: 0.7734\n",
      "95/194, train_loss: 0.7546\n",
      "96/194, train_loss: 0.7609\n",
      "97/194, train_loss: 0.8482\n",
      "98/194, train_loss: 0.7665\n",
      "99/194, train_loss: 0.8107\n",
      "100/194, train_loss: 0.7637\n",
      "101/194, train_loss: 0.6970\n",
      "102/194, train_loss: 0.7054\n",
      "103/194, train_loss: 0.8509\n",
      "104/194, train_loss: 0.8352\n",
      "105/194, train_loss: 0.7749\n",
      "106/194, train_loss: 0.8103\n",
      "107/194, train_loss: 0.8743\n",
      "108/194, train_loss: 0.8706\n",
      "109/194, train_loss: 0.6276\n",
      "110/194, train_loss: 0.7192\n",
      "111/194, train_loss: 0.7108\n",
      "112/194, train_loss: 0.6456\n",
      "113/194, train_loss: 0.8654\n",
      "114/194, train_loss: 0.8020\n",
      "115/194, train_loss: 0.9177\n",
      "116/194, train_loss: 0.8014\n",
      "117/194, train_loss: 0.7850\n",
      "118/194, train_loss: 0.7662\n",
      "119/194, train_loss: 0.7675\n",
      "120/194, train_loss: 0.7771\n",
      "121/194, train_loss: 0.7992\n",
      "122/194, train_loss: 0.6712\n",
      "123/194, train_loss: 0.9795\n",
      "124/194, train_loss: 0.7346\n",
      "125/194, train_loss: 0.8284\n",
      "126/194, train_loss: 0.5819\n",
      "127/194, train_loss: 0.8730\n",
      "128/194, train_loss: 0.8741\n",
      "129/194, train_loss: 0.8471\n",
      "130/194, train_loss: 0.8391\n",
      "131/194, train_loss: 0.7726\n",
      "132/194, train_loss: 0.7737\n",
      "133/194, train_loss: 0.6687\n",
      "134/194, train_loss: 0.8025\n",
      "135/194, train_loss: 0.8120\n",
      "136/194, train_loss: 0.7732\n",
      "137/194, train_loss: 0.7037\n",
      "138/194, train_loss: 0.8314\n",
      "139/194, train_loss: 0.6664\n",
      "140/194, train_loss: 0.7395\n",
      "141/194, train_loss: 0.9662\n",
      "142/194, train_loss: 0.8976\n",
      "143/194, train_loss: 0.8888\n",
      "144/194, train_loss: 0.9596\n",
      "145/194, train_loss: 0.7920\n",
      "146/194, train_loss: 0.7912\n",
      "147/194, train_loss: 0.8504\n",
      "148/194, train_loss: 0.8969\n",
      "149/194, train_loss: 0.7521\n",
      "150/194, train_loss: 0.9019\n",
      "151/194, train_loss: 0.7652\n",
      "152/194, train_loss: 0.9913\n",
      "153/194, train_loss: 0.8668\n",
      "154/194, train_loss: 0.9180\n",
      "155/194, train_loss: 0.8579\n",
      "156/194, train_loss: 0.8313\n",
      "157/194, train_loss: 0.8483\n",
      "158/194, train_loss: 0.7713\n",
      "159/194, train_loss: 0.6345\n",
      "160/194, train_loss: 0.8176\n",
      "161/194, train_loss: 0.9229\n",
      "162/194, train_loss: 0.8629\n",
      "163/194, train_loss: 0.9466\n",
      "164/194, train_loss: 0.9179\n",
      "165/194, train_loss: 0.7034\n",
      "166/194, train_loss: 0.6694\n",
      "167/194, train_loss: 0.8853\n",
      "168/194, train_loss: 0.8201\n",
      "169/194, train_loss: 0.8042\n",
      "170/194, train_loss: 0.7615\n",
      "171/194, train_loss: 0.6710\n",
      "172/194, train_loss: 0.7720\n",
      "173/194, train_loss: 0.8293\n",
      "174/194, train_loss: 0.6986\n",
      "175/194, train_loss: 0.8454\n",
      "176/194, train_loss: 0.7087\n",
      "177/194, train_loss: 0.8540\n",
      "178/194, train_loss: 0.8125\n",
      "179/194, train_loss: 0.8571\n",
      "180/194, train_loss: 0.6978\n",
      "181/194, train_loss: 0.8474\n",
      "182/194, train_loss: 0.7170\n",
      "183/194, train_loss: 0.8096\n",
      "184/194, train_loss: 0.7525\n",
      "185/194, train_loss: 0.8622\n",
      "186/194, train_loss: 0.7908\n",
      "187/194, train_loss: 0.7732\n",
      "188/194, train_loss: 0.8858\n",
      "189/194, train_loss: 0.8302\n",
      "190/194, train_loss: 0.7893\n",
      "191/194, train_loss: 0.9174\n",
      "192/194, train_loss: 0.7919\n",
      "193/194, train_loss: 0.6571\n",
      "194/194, train_loss: 0.8513\n",
      "metric=0.3740657242015004, metric_tc=0.39607124372075003, metric_wt=0.5037130390604337, metric_et=0.22241289634257555\n",
      "metric=0.3740657242015004, metric_tc=0.39607124372075003, metric_wt=0.5037130390604337, metric_et=0.22241289634257555\n",
      "current epoch: 52 current epoch loss: 0.7897\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 52/80 [9:34:01<5:45:04, 739.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metric=0.3740657242015004, metric_tc=0.39607124372075003, metric_wt=0.5037130390604337, metric_et=0.22241289634257555\n",
      "0.3740657242015004\n",
      "saved new best metric model\n",
      "current epoch: 52 current mean dice: 0.3741 tc: 0.3961 wt: 0.5037 et: 0.2224\n",
      "best mean dice: 0.3741 at epoch: 52\n",
      "\n",
      " | Global Training Round : 53 |\n",
      "\n",
      "user 0 selected\n",
      "local epoch 1\n",
      "1/194, train_loss: 0.8105\n",
      "2/194, train_loss: 0.6396\n",
      "3/194, train_loss: 0.6857\n",
      "4/194, train_loss: 0.7779\n",
      "5/194, train_loss: 0.7877\n",
      "6/194, train_loss: 0.8196\n",
      "7/194, train_loss: 0.7387\n",
      "8/194, train_loss: 0.6977\n",
      "9/194, train_loss: 0.8459\n",
      "10/194, train_loss: 0.8688\n",
      "11/194, train_loss: 0.8402\n",
      "12/194, train_loss: 0.6465\n",
      "13/194, train_loss: 0.7541\n",
      "14/194, train_loss: 0.7857\n",
      "15/194, train_loss: 0.8140\n",
      "16/194, train_loss: 0.5990\n",
      "17/194, train_loss: 0.8053\n",
      "18/194, train_loss: 0.8599\n",
      "19/194, train_loss: 0.9297\n",
      "20/194, train_loss: 0.6135\n",
      "21/194, train_loss: 0.7822\n",
      "22/194, train_loss: 0.8605\n",
      "23/194, train_loss: 0.7912\n",
      "24/194, train_loss: 0.7744\n",
      "25/194, train_loss: 0.6600\n",
      "26/194, train_loss: 0.9446\n",
      "27/194, train_loss: 0.9363\n",
      "28/194, train_loss: 0.6694\n",
      "29/194, train_loss: 0.8364\n",
      "30/194, train_loss: 0.6640\n",
      "31/194, train_loss: 0.7381\n",
      "32/194, train_loss: 0.9710\n",
      "33/194, train_loss: 0.8743\n",
      "34/194, train_loss: 0.8285\n",
      "35/194, train_loss: 0.9106\n",
      "36/194, train_loss: 0.5069\n",
      "37/194, train_loss: 0.8155\n",
      "38/194, train_loss: 0.8454\n",
      "39/194, train_loss: 0.7357\n",
      "40/194, train_loss: 0.9080\n",
      "41/194, train_loss: 0.9567\n",
      "42/194, train_loss: 0.8616\n",
      "43/194, train_loss: 0.7407\n",
      "44/194, train_loss: 0.7156\n",
      "45/194, train_loss: 0.8297\n",
      "46/194, train_loss: 0.6434\n",
      "47/194, train_loss: 0.5971\n",
      "48/194, train_loss: 0.6636\n",
      "49/194, train_loss: 0.7389\n",
      "50/194, train_loss: 0.7085\n",
      "51/194, train_loss: 0.8531\n",
      "52/194, train_loss: 0.6542\n",
      "53/194, train_loss: 0.7149\n",
      "54/194, train_loss: 0.8934\n",
      "55/194, train_loss: 0.8968\n",
      "56/194, train_loss: 0.8261\n",
      "57/194, train_loss: 0.8432\n",
      "58/194, train_loss: 0.8984\n",
      "59/194, train_loss: 0.7757\n",
      "60/194, train_loss: 0.7067\n",
      "61/194, train_loss: 0.7794\n",
      "62/194, train_loss: 0.8611\n",
      "63/194, train_loss: 0.8036\n",
      "64/194, train_loss: 0.7741\n",
      "65/194, train_loss: 0.6388\n",
      "66/194, train_loss: 0.8060\n",
      "67/194, train_loss: 0.7301\n",
      "68/194, train_loss: 0.7925\n",
      "69/194, train_loss: 0.9444\n",
      "70/194, train_loss: 0.7929\n",
      "71/194, train_loss: 0.8418\n",
      "72/194, train_loss: 0.8665\n",
      "73/194, train_loss: 0.7114\n",
      "74/194, train_loss: 0.8503\n",
      "75/194, train_loss: 0.7956\n",
      "76/194, train_loss: 0.9174\n",
      "77/194, train_loss: 0.7194\n",
      "78/194, train_loss: 0.7700\n",
      "79/194, train_loss: 0.7136\n",
      "80/194, train_loss: 0.6262\n",
      "81/194, train_loss: 0.6671\n",
      "82/194, train_loss: 0.8285\n",
      "83/194, train_loss: 0.7459\n",
      "84/194, train_loss: 0.8135\n",
      "85/194, train_loss: 0.8959\n",
      "86/194, train_loss: 0.7231\n",
      "87/194, train_loss: 0.8713\n",
      "88/194, train_loss: 0.8681\n",
      "89/194, train_loss: 0.6357\n",
      "90/194, train_loss: 0.9232\n",
      "91/194, train_loss: 0.8739\n",
      "92/194, train_loss: 0.8204\n",
      "93/194, train_loss: 0.6946\n",
      "94/194, train_loss: 0.7546\n",
      "95/194, train_loss: 0.8278\n",
      "96/194, train_loss: 0.8521\n",
      "97/194, train_loss: 0.9163\n",
      "98/194, train_loss: 0.7365\n",
      "99/194, train_loss: 0.6713\n",
      "100/194, train_loss: 0.8850\n",
      "101/194, train_loss: 0.7465\n",
      "102/194, train_loss: 0.8555\n",
      "103/194, train_loss: 0.8771\n",
      "104/194, train_loss: 0.8866\n",
      "105/194, train_loss: 0.8659\n",
      "106/194, train_loss: 0.7517\n",
      "107/194, train_loss: 0.7033\n",
      "108/194, train_loss: 0.8367\n",
      "109/194, train_loss: 0.6806\n",
      "110/194, train_loss: 0.7630\n",
      "111/194, train_loss: 0.6713\n",
      "112/194, train_loss: 0.7521\n",
      "113/194, train_loss: 0.7972\n",
      "114/194, train_loss: 0.9884\n",
      "115/194, train_loss: 0.7901\n",
      "116/194, train_loss: 0.7059\n",
      "117/194, train_loss: 0.8409\n",
      "118/194, train_loss: 0.8046\n",
      "119/194, train_loss: 0.7391\n",
      "120/194, train_loss: 0.7396\n",
      "121/194, train_loss: 0.8450\n",
      "122/194, train_loss: 0.7221\n",
      "123/194, train_loss: 0.9028\n",
      "124/194, train_loss: 0.8650\n",
      "125/194, train_loss: 0.8243\n",
      "126/194, train_loss: 0.6332\n",
      "127/194, train_loss: 0.8059\n",
      "128/194, train_loss: 0.8342\n",
      "129/194, train_loss: 0.7885\n",
      "130/194, train_loss: 0.8742\n",
      "131/194, train_loss: 0.6638\n",
      "132/194, train_loss: 0.7962\n",
      "133/194, train_loss: 0.6948\n",
      "134/194, train_loss: 0.8683\n",
      "135/194, train_loss: 0.6929\n",
      "136/194, train_loss: 0.8620\n",
      "137/194, train_loss: 0.7562\n",
      "138/194, train_loss: 0.8037\n",
      "139/194, train_loss: 0.8130\n",
      "140/194, train_loss: 0.6925\n",
      "141/194, train_loss: 0.8386\n",
      "142/194, train_loss: 0.7250\n",
      "143/194, train_loss: 0.7980\n",
      "144/194, train_loss: 0.8317\n",
      "145/194, train_loss: 0.9163\n",
      "146/194, train_loss: 0.7659\n",
      "147/194, train_loss: 0.6884\n",
      "148/194, train_loss: 0.8098\n",
      "149/194, train_loss: 0.8106\n",
      "150/194, train_loss: 0.9394\n",
      "151/194, train_loss: 0.8799\n",
      "152/194, train_loss: 0.8982\n",
      "153/194, train_loss: 0.8514\n",
      "154/194, train_loss: 0.7332\n",
      "155/194, train_loss: 0.9267\n",
      "156/194, train_loss: 0.8364\n",
      "157/194, train_loss: 0.8945\n",
      "158/194, train_loss: 0.7580\n",
      "159/194, train_loss: 0.8987\n",
      "160/194, train_loss: 0.7878\n",
      "161/194, train_loss: 0.9450\n",
      "162/194, train_loss: 0.6365\n",
      "163/194, train_loss: 0.8636\n",
      "164/194, train_loss: 0.6922\n",
      "165/194, train_loss: 0.8467\n",
      "166/194, train_loss: 0.9093\n",
      "167/194, train_loss: 0.7695\n",
      "168/194, train_loss: 0.8506\n",
      "169/194, train_loss: 0.6950\n",
      "170/194, train_loss: 0.8258\n",
      "171/194, train_loss: 0.6585\n",
      "172/194, train_loss: 0.8169\n",
      "173/194, train_loss: 0.6942\n",
      "174/194, train_loss: 0.6806\n",
      "175/194, train_loss: 0.8389\n",
      "176/194, train_loss: 0.7375\n",
      "177/194, train_loss: 0.8805\n",
      "178/194, train_loss: 0.7240\n",
      "179/194, train_loss: 0.6462\n",
      "180/194, train_loss: 0.8029\n",
      "181/194, train_loss: 0.5841\n",
      "182/194, train_loss: 0.7758\n",
      "183/194, train_loss: 0.7048\n",
      "184/194, train_loss: 0.7153\n",
      "185/194, train_loss: 0.8588\n",
      "186/194, train_loss: 0.8887\n",
      "187/194, train_loss: 0.9058\n",
      "188/194, train_loss: 0.7842\n",
      "189/194, train_loss: 0.9364\n",
      "190/194, train_loss: 0.7456\n",
      "191/194, train_loss: 0.8727\n",
      "192/194, train_loss: 0.8576\n",
      "193/194, train_loss: 0.7298\n",
      "194/194, train_loss: 0.8488\n",
      "metric=0.3657102274398009, metric_tc=0.39249214188506204, metric_wt=0.48431695190568763, metric_et=0.22032158515260866\n",
      "metric=0.3657102274398009, metric_tc=0.39249214188506204, metric_wt=0.48431695190568763, metric_et=0.22032158515260866\n",
      "current epoch: 53 current epoch loss: 0.7911\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▋   | 53/80 [9:49:33<5:58:42, 797.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metric=0.3657102274398009, metric_tc=0.39249214188506204, metric_wt=0.48431695190568763, metric_et=0.22032158515260866\n",
      "0.3657102274398009\n",
      "current epoch: 53 current mean dice: 0.3657 tc: 0.3925 wt: 0.4843 et: 0.2203\n",
      "best mean dice: 0.3741 at epoch: 52\n",
      "\n",
      " | Global Training Round : 54 |\n",
      "\n",
      "user 0 selected\n",
      "local epoch 1\n",
      "1/194, train_loss: 0.7812\n",
      "2/194, train_loss: 0.8766\n",
      "3/194, train_loss: 0.8606\n",
      "4/194, train_loss: 0.6412\n",
      "5/194, train_loss: 0.8217\n",
      "6/194, train_loss: 0.7915\n",
      "7/194, train_loss: 0.6643\n",
      "8/194, train_loss: 0.7880\n",
      "9/194, train_loss: 0.5810\n",
      "10/194, train_loss: 0.7379\n",
      "11/194, train_loss: 0.6036\n",
      "12/194, train_loss: 0.6600\n",
      "13/194, train_loss: 0.7420\n",
      "14/194, train_loss: 0.8191\n",
      "15/194, train_loss: 0.6623\n",
      "16/194, train_loss: 0.7279\n",
      "17/194, train_loss: 0.6601\n",
      "18/194, train_loss: 0.6853\n",
      "19/194, train_loss: 0.9050\n",
      "20/194, train_loss: 0.7124\n",
      "21/194, train_loss: 0.6456\n",
      "22/194, train_loss: 0.7743\n",
      "23/194, train_loss: 0.7175\n",
      "24/194, train_loss: 0.8097\n",
      "25/194, train_loss: 0.8094\n",
      "26/194, train_loss: 0.7497\n",
      "27/194, train_loss: 0.8599\n",
      "28/194, train_loss: 0.8785\n",
      "29/194, train_loss: 0.7084\n",
      "30/194, train_loss: 0.7824\n",
      "31/194, train_loss: 0.8586\n",
      "32/194, train_loss: 0.7886\n",
      "33/194, train_loss: 0.7426\n",
      "34/194, train_loss: 0.7387\n",
      "35/194, train_loss: 0.8124\n",
      "36/194, train_loss: 0.8372\n",
      "37/194, train_loss: 0.8510\n",
      "38/194, train_loss: 0.5916\n",
      "39/194, train_loss: 0.7529\n",
      "40/194, train_loss: 0.6794\n",
      "41/194, train_loss: 0.8630\n",
      "42/194, train_loss: 0.5386\n",
      "43/194, train_loss: 0.6214\n",
      "44/194, train_loss: 0.8133\n",
      "45/194, train_loss: 0.8689\n",
      "46/194, train_loss: 0.8807\n",
      "47/194, train_loss: 0.7602\n",
      "48/194, train_loss: 0.7976\n",
      "49/194, train_loss: 0.6651\n",
      "50/194, train_loss: 0.7155\n",
      "51/194, train_loss: 0.7054\n",
      "52/194, train_loss: 0.7337\n",
      "53/194, train_loss: 0.7864\n",
      "54/194, train_loss: 0.8018\n",
      "55/194, train_loss: 0.7045\n",
      "56/194, train_loss: 0.8342\n",
      "57/194, train_loss: 0.9015\n",
      "58/194, train_loss: 0.8295\n",
      "59/194, train_loss: 0.9229\n",
      "60/194, train_loss: 0.7259\n",
      "61/194, train_loss: 0.6166\n",
      "62/194, train_loss: 0.7059\n",
      "63/194, train_loss: 0.6690\n",
      "64/194, train_loss: 0.6990\n",
      "65/194, train_loss: 0.8126\n",
      "66/194, train_loss: 0.5493\n",
      "67/194, train_loss: 0.7521\n",
      "68/194, train_loss: 0.7769\n",
      "69/194, train_loss: 0.8937\n",
      "70/194, train_loss: 0.7644\n",
      "71/194, train_loss: 0.7391\n",
      "72/194, train_loss: 0.8501\n",
      "73/194, train_loss: 0.9052\n",
      "74/194, train_loss: 0.8130\n",
      "75/194, train_loss: 0.7477\n",
      "76/194, train_loss: 0.8953\n",
      "77/194, train_loss: 0.6849\n",
      "78/194, train_loss: 0.7460\n",
      "79/194, train_loss: 0.7181\n",
      "80/194, train_loss: 0.8828\n",
      "81/194, train_loss: 0.8760\n",
      "82/194, train_loss: 0.7304\n",
      "83/194, train_loss: 0.7978\n",
      "84/194, train_loss: 0.6822\n",
      "85/194, train_loss: 0.8086\n",
      "86/194, train_loss: 0.9269\n",
      "87/194, train_loss: 0.9191\n",
      "88/194, train_loss: 0.8760\n",
      "89/194, train_loss: 0.8307\n",
      "90/194, train_loss: 0.8411\n",
      "91/194, train_loss: 0.9382\n",
      "92/194, train_loss: 0.8632\n",
      "93/194, train_loss: 0.8395\n",
      "94/194, train_loss: 0.8361\n",
      "95/194, train_loss: 0.7515\n",
      "96/194, train_loss: 0.8365\n",
      "97/194, train_loss: 0.8271\n",
      "98/194, train_loss: 0.6417\n",
      "99/194, train_loss: 0.7683\n",
      "100/194, train_loss: 0.6176\n",
      "101/194, train_loss: 0.8117\n",
      "102/194, train_loss: 0.8834\n",
      "103/194, train_loss: 0.8219\n",
      "104/194, train_loss: 0.6252\n",
      "105/194, train_loss: 0.8033\n",
      "106/194, train_loss: 0.7866\n",
      "107/194, train_loss: 0.8113\n",
      "108/194, train_loss: 0.8461\n",
      "109/194, train_loss: 0.8130\n",
      "110/194, train_loss: 0.7674\n",
      "111/194, train_loss: 0.7821\n",
      "112/194, train_loss: 0.7897\n",
      "113/194, train_loss: 0.7786\n",
      "114/194, train_loss: 0.8000\n",
      "115/194, train_loss: 0.9109\n",
      "116/194, train_loss: 0.8801\n",
      "117/194, train_loss: 0.8139\n",
      "118/194, train_loss: 0.8364\n",
      "119/194, train_loss: 0.8189\n",
      "120/194, train_loss: 0.8249\n",
      "121/194, train_loss: 0.8829\n",
      "122/194, train_loss: 0.9172\n",
      "123/194, train_loss: 0.8370\n",
      "124/194, train_loss: 0.7766\n",
      "125/194, train_loss: 0.8078\n",
      "126/194, train_loss: 0.8437\n",
      "127/194, train_loss: 0.8667\n",
      "128/194, train_loss: 0.8647\n",
      "129/194, train_loss: 0.8601\n",
      "130/194, train_loss: 0.8040\n",
      "131/194, train_loss: 0.7657\n",
      "132/194, train_loss: 0.7705\n",
      "133/194, train_loss: 0.7889\n",
      "134/194, train_loss: 0.8020\n",
      "135/194, train_loss: 0.7764\n",
      "136/194, train_loss: 0.8321\n",
      "137/194, train_loss: 0.7500\n",
      "138/194, train_loss: 0.7977\n",
      "139/194, train_loss: 0.6849\n",
      "140/194, train_loss: 0.5740\n",
      "141/194, train_loss: 0.7953\n",
      "142/194, train_loss: 0.8386\n",
      "143/194, train_loss: 0.9144\n",
      "144/194, train_loss: 0.7134\n",
      "145/194, train_loss: 0.7617\n",
      "146/194, train_loss: 0.7642\n",
      "147/194, train_loss: 0.9093\n",
      "148/194, train_loss: 0.9939\n",
      "149/194, train_loss: 0.8940\n",
      "150/194, train_loss: 0.7962\n",
      "151/194, train_loss: 0.7989\n",
      "152/194, train_loss: 0.7889\n",
      "153/194, train_loss: 0.8392\n",
      "154/194, train_loss: 0.8610\n",
      "155/194, train_loss: 0.6576\n",
      "156/194, train_loss: 0.9012\n",
      "157/194, train_loss: 0.8228\n",
      "158/194, train_loss: 0.7255\n",
      "159/194, train_loss: 0.9608\n",
      "160/194, train_loss: 0.7444\n",
      "161/194, train_loss: 0.7641\n",
      "162/194, train_loss: 0.7983\n",
      "163/194, train_loss: 0.8133\n",
      "164/194, train_loss: 0.8110\n",
      "165/194, train_loss: 0.8525\n",
      "166/194, train_loss: 0.8008\n",
      "167/194, train_loss: 0.8228\n",
      "168/194, train_loss: 0.6311\n",
      "169/194, train_loss: 0.7306\n",
      "170/194, train_loss: 0.8266\n",
      "171/194, train_loss: 0.6979\n",
      "172/194, train_loss: 0.7412\n",
      "173/194, train_loss: 0.7286\n",
      "174/194, train_loss: 0.7063\n",
      "175/194, train_loss: 0.8712\n",
      "176/194, train_loss: 0.8284\n",
      "177/194, train_loss: 0.7523\n",
      "178/194, train_loss: 0.8070\n",
      "179/194, train_loss: 0.7786\n",
      "180/194, train_loss: 0.6138\n",
      "181/194, train_loss: 0.6975\n",
      "182/194, train_loss: 0.7915\n",
      "183/194, train_loss: 0.6990\n",
      "184/194, train_loss: 0.6401\n",
      "185/194, train_loss: 0.8335\n",
      "186/194, train_loss: 0.9002\n",
      "187/194, train_loss: 0.8373\n",
      "188/194, train_loss: 0.8763\n",
      "189/194, train_loss: 0.6887\n",
      "190/194, train_loss: 0.7533\n",
      "191/194, train_loss: 0.8095\n",
      "192/194, train_loss: 0.7494\n",
      "193/194, train_loss: 0.8630\n",
      "194/194, train_loss: 0.8619\n",
      "metric=0.32930992140124243, metric_tc=0.34008956359078485, metric_wt=0.4499067769696315, metric_et=0.19793342837753394\n",
      "metric=0.32930992140124243, metric_tc=0.34008956359078485, metric_wt=0.4499067769696315, metric_et=0.19793342837753394\n",
      "current epoch: 54 current epoch loss: 0.7839\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 54/80 [10:03:29<5:50:26, 808.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metric=0.32930992140124243, metric_tc=0.34008956359078485, metric_wt=0.4499067769696315, metric_et=0.19793342837753394\n",
      "0.32930992140124243\n",
      "current epoch: 54 current mean dice: 0.3293 tc: 0.3401 wt: 0.4499 et: 0.1979\n",
      "best mean dice: 0.3741 at epoch: 52\n",
      "\n",
      " | Global Training Round : 55 |\n",
      "\n",
      "user 0 selected\n",
      "local epoch 1\n",
      "1/194, train_loss: 0.6890\n",
      "2/194, train_loss: 0.8888\n",
      "3/194, train_loss: 0.8947\n",
      "4/194, train_loss: 0.7522\n",
      "5/194, train_loss: 0.7073\n",
      "6/194, train_loss: 0.8524\n",
      "7/194, train_loss: 0.7988\n",
      "8/194, train_loss: 0.9150\n",
      "9/194, train_loss: 0.6834\n",
      "10/194, train_loss: 0.8737\n",
      "11/194, train_loss: 0.7477\n",
      "12/194, train_loss: 0.8551\n",
      "13/194, train_loss: 0.7685\n",
      "14/194, train_loss: 0.6842\n",
      "15/194, train_loss: 0.7154\n",
      "16/194, train_loss: 0.6918\n",
      "17/194, train_loss: 0.8564\n",
      "18/194, train_loss: 0.8155\n",
      "19/194, train_loss: 0.7967\n",
      "20/194, train_loss: 0.6841\n",
      "21/194, train_loss: 0.8162\n",
      "22/194, train_loss: 0.7594\n",
      "23/194, train_loss: 0.6206\n",
      "24/194, train_loss: 0.7315\n",
      "25/194, train_loss: 0.8179\n",
      "26/194, train_loss: 0.6682\n",
      "27/194, train_loss: 0.7457\n",
      "28/194, train_loss: 0.8871\n",
      "29/194, train_loss: 0.7920\n",
      "30/194, train_loss: 0.9195\n",
      "31/194, train_loss: 0.8745\n",
      "32/194, train_loss: 0.8493\n",
      "33/194, train_loss: 0.6675\n",
      "34/194, train_loss: 0.8357\n",
      "35/194, train_loss: 0.7631\n",
      "36/194, train_loss: 0.7620\n",
      "37/194, train_loss: 0.6456\n",
      "38/194, train_loss: 0.7686\n",
      "39/194, train_loss: 0.5754\n",
      "40/194, train_loss: 0.6695\n",
      "41/194, train_loss: 0.9111\n",
      "42/194, train_loss: 0.5453\n",
      "43/194, train_loss: 0.6928\n",
      "44/194, train_loss: 0.8073\n",
      "45/194, train_loss: 0.7320\n",
      "46/194, train_loss: 0.9320\n",
      "47/194, train_loss: 0.7374\n",
      "48/194, train_loss: 0.7107\n",
      "49/194, train_loss: 0.6415\n",
      "50/194, train_loss: 0.6165\n",
      "51/194, train_loss: 0.7932\n",
      "52/194, train_loss: 0.7198\n",
      "53/194, train_loss: 0.8866\n",
      "54/194, train_loss: 0.9240\n",
      "55/194, train_loss: 0.6953\n",
      "56/194, train_loss: 0.9850\n",
      "57/194, train_loss: 0.8762\n",
      "58/194, train_loss: 0.8807\n",
      "59/194, train_loss: 0.7733\n",
      "60/194, train_loss: 0.7830\n",
      "61/194, train_loss: 0.7826\n",
      "62/194, train_loss: 0.8536\n",
      "63/194, train_loss: 0.7363\n",
      "64/194, train_loss: 0.6660\n",
      "65/194, train_loss: 0.7602\n",
      "66/194, train_loss: 0.8846\n",
      "67/194, train_loss: 0.7489\n",
      "68/194, train_loss: 0.6299\n",
      "69/194, train_loss: 0.7278\n",
      "70/194, train_loss: 0.8456\n",
      "71/194, train_loss: 0.6990\n",
      "72/194, train_loss: 0.8075\n",
      "73/194, train_loss: 0.5120\n",
      "74/194, train_loss: 0.7946\n",
      "75/194, train_loss: 0.5713\n",
      "76/194, train_loss: 0.5473\n",
      "77/194, train_loss: 0.5758\n",
      "78/194, train_loss: 0.7358\n",
      "79/194, train_loss: 0.6634\n",
      "80/194, train_loss: 0.5637\n",
      "81/194, train_loss: 0.8978\n",
      "82/194, train_loss: 0.8343\n",
      "83/194, train_loss: 0.8735\n",
      "84/194, train_loss: 0.8412\n",
      "85/194, train_loss: 0.7468\n",
      "86/194, train_loss: 0.9030\n",
      "87/194, train_loss: 0.7786\n",
      "88/194, train_loss: 0.8849\n",
      "89/194, train_loss: 0.8867\n",
      "90/194, train_loss: 0.6163\n",
      "91/194, train_loss: 0.8405\n",
      "92/194, train_loss: 0.7289\n",
      "93/194, train_loss: 0.6462\n",
      "94/194, train_loss: 0.7774\n",
      "95/194, train_loss: 0.6639\n",
      "96/194, train_loss: 0.7286\n",
      "97/194, train_loss: 0.7424\n",
      "98/194, train_loss: 0.8265\n",
      "99/194, train_loss: 0.7081\n",
      "100/194, train_loss: 0.7123\n",
      "101/194, train_loss: 0.8747\n",
      "102/194, train_loss: 0.7240\n",
      "103/194, train_loss: 0.8104\n",
      "104/194, train_loss: 0.8762\n",
      "105/194, train_loss: 0.8197\n",
      "106/194, train_loss: 0.7788\n",
      "107/194, train_loss: 0.7836\n",
      "108/194, train_loss: 0.7083\n",
      "109/194, train_loss: 0.9097\n",
      "110/194, train_loss: 0.6565\n",
      "111/194, train_loss: 0.7188\n",
      "112/194, train_loss: 0.6155\n",
      "113/194, train_loss: 0.7754\n",
      "114/194, train_loss: 0.7929\n",
      "115/194, train_loss: 0.8588\n",
      "116/194, train_loss: 0.7845\n",
      "117/194, train_loss: 0.8131\n",
      "118/194, train_loss: 0.7358\n",
      "119/194, train_loss: 0.9161\n",
      "120/194, train_loss: 0.7059\n",
      "121/194, train_loss: 0.8923\n",
      "122/194, train_loss: 0.9368\n",
      "123/194, train_loss: 0.8194\n",
      "124/194, train_loss: 0.9356\n",
      "125/194, train_loss: 0.8635\n",
      "126/194, train_loss: 0.8508\n",
      "127/194, train_loss: 0.8006\n",
      "128/194, train_loss: 0.7211\n",
      "129/194, train_loss: 0.8263\n",
      "130/194, train_loss: 0.8170\n",
      "131/194, train_loss: 0.8838\n",
      "132/194, train_loss: 0.8501\n",
      "133/194, train_loss: 0.8507\n",
      "134/194, train_loss: 0.7492\n",
      "135/194, train_loss: 0.7135\n",
      "136/194, train_loss: 0.6929\n",
      "137/194, train_loss: 0.5497\n",
      "138/194, train_loss: 0.7118\n",
      "139/194, train_loss: 0.6721\n",
      "140/194, train_loss: 0.8353\n",
      "141/194, train_loss: 0.8657\n",
      "142/194, train_loss: 0.9118\n",
      "143/194, train_loss: 0.8705\n",
      "144/194, train_loss: 0.7666\n",
      "145/194, train_loss: 0.7254\n",
      "146/194, train_loss: 0.8151\n",
      "147/194, train_loss: 0.9159\n",
      "148/194, train_loss: 0.8123\n",
      "149/194, train_loss: 0.9414\n",
      "150/194, train_loss: 0.8705\n",
      "151/194, train_loss: 0.9435\n",
      "152/194, train_loss: 0.9167\n",
      "153/194, train_loss: 0.8484\n",
      "154/194, train_loss: 0.7667\n",
      "155/194, train_loss: 0.8523\n",
      "156/194, train_loss: 0.7640\n",
      "157/194, train_loss: 0.8659\n",
      "158/194, train_loss: 0.9077\n",
      "159/194, train_loss: 0.9851\n",
      "160/194, train_loss: 0.8432\n",
      "161/194, train_loss: 0.9135\n",
      "162/194, train_loss: 0.9131\n",
      "163/194, train_loss: 0.9284\n",
      "164/194, train_loss: 0.8433\n",
      "165/194, train_loss: 0.8773\n",
      "166/194, train_loss: 0.7747\n",
      "167/194, train_loss: 0.8427\n",
      "168/194, train_loss: 0.7853\n",
      "169/194, train_loss: 0.7178\n",
      "170/194, train_loss: 0.8083\n",
      "171/194, train_loss: 0.6421\n",
      "172/194, train_loss: 0.9188\n",
      "173/194, train_loss: 0.8028\n",
      "174/194, train_loss: 0.8229\n",
      "175/194, train_loss: 0.8190\n",
      "176/194, train_loss: 0.5297\n",
      "177/194, train_loss: 0.8115\n",
      "178/194, train_loss: 0.9103\n",
      "179/194, train_loss: 0.7884\n",
      "180/194, train_loss: 0.9000\n",
      "181/194, train_loss: 0.8919\n",
      "182/194, train_loss: 0.6265\n",
      "183/194, train_loss: 0.7321\n",
      "184/194, train_loss: 0.7741\n",
      "185/194, train_loss: 0.8478\n",
      "186/194, train_loss: 0.8826\n",
      "187/194, train_loss: 0.8301\n",
      "188/194, train_loss: 0.7960\n",
      "189/194, train_loss: 0.8543\n",
      "190/194, train_loss: 0.8343\n",
      "191/194, train_loss: 0.8402\n",
      "192/194, train_loss: 0.8561\n",
      "193/194, train_loss: 0.7348\n",
      "194/194, train_loss: 0.7648\n",
      "metric=0.3845666681105892, metric_tc=0.4089067913591862, metric_wt=0.5180056598037481, metric_et=0.22678754470931986\n",
      "metric=0.3845666681105892, metric_tc=0.4089067913591862, metric_wt=0.5180056598037481, metric_et=0.22678754470931986\n",
      "current epoch: 55 current epoch loss: 0.7869\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▉   | 55/80 [10:16:02<5:29:59, 791.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metric=0.3845666681105892, metric_tc=0.4089067913591862, metric_wt=0.5180056598037481, metric_et=0.22678754470931986\n",
      "0.3845666681105892\n",
      "saved new best metric model\n",
      "current epoch: 55 current mean dice: 0.3846 tc: 0.4089 wt: 0.5180 et: 0.2268\n",
      "best mean dice: 0.3846 at epoch: 55\n",
      "\n",
      " | Global Training Round : 56 |\n",
      "\n",
      "user 0 selected\n",
      "local epoch 1\n",
      "1/194, train_loss: 0.7858\n",
      "2/194, train_loss: 0.6550\n",
      "3/194, train_loss: 0.8865\n",
      "4/194, train_loss: 0.8409\n",
      "5/194, train_loss: 0.7972\n",
      "6/194, train_loss: 0.8874\n",
      "7/194, train_loss: 0.6533\n",
      "8/194, train_loss: 0.7484\n",
      "9/194, train_loss: 0.7537\n",
      "10/194, train_loss: 0.8886\n",
      "11/194, train_loss: 0.7613\n",
      "12/194, train_loss: 0.9513\n",
      "13/194, train_loss: 0.8922\n",
      "14/194, train_loss: 0.7211\n",
      "15/194, train_loss: 0.7304\n",
      "16/194, train_loss: 0.6311\n",
      "17/194, train_loss: 0.7810\n",
      "18/194, train_loss: 0.6523\n",
      "19/194, train_loss: 0.8114\n",
      "20/194, train_loss: 0.6552\n",
      "21/194, train_loss: 0.7420\n",
      "22/194, train_loss: 0.7949\n",
      "23/194, train_loss: 0.9583\n",
      "24/194, train_loss: 0.8277\n",
      "25/194, train_loss: 0.8433\n",
      "26/194, train_loss: 0.7954\n",
      "27/194, train_loss: 0.7968\n",
      "28/194, train_loss: 0.8028\n",
      "29/194, train_loss: 0.7764\n",
      "30/194, train_loss: 0.8466\n",
      "31/194, train_loss: 0.8508\n",
      "32/194, train_loss: 0.8650\n",
      "33/194, train_loss: 0.8260\n",
      "34/194, train_loss: 0.7726\n",
      "35/194, train_loss: 0.7982\n",
      "36/194, train_loss: 0.8062\n",
      "37/194, train_loss: 0.6996\n",
      "38/194, train_loss: 0.6615\n",
      "39/194, train_loss: 0.6329\n",
      "40/194, train_loss: 0.7087\n",
      "41/194, train_loss: 0.6548\n",
      "42/194, train_loss: 0.8822\n",
      "43/194, train_loss: 0.7439\n",
      "44/194, train_loss: 0.8981\n",
      "45/194, train_loss: 0.9498\n",
      "46/194, train_loss: 0.6060\n",
      "47/194, train_loss: 0.9035\n",
      "48/194, train_loss: 0.7524\n",
      "49/194, train_loss: 0.7884\n",
      "50/194, train_loss: 0.6094\n",
      "51/194, train_loss: 0.6415\n",
      "52/194, train_loss: 0.5351\n",
      "53/194, train_loss: 0.7386\n",
      "54/194, train_loss: 0.7794\n",
      "55/194, train_loss: 0.8043\n",
      "56/194, train_loss: 0.9296\n",
      "57/194, train_loss: 0.8027\n",
      "58/194, train_loss: 0.8903\n",
      "59/194, train_loss: 0.7887\n",
      "60/194, train_loss: 0.8024\n",
      "61/194, train_loss: 0.7998\n",
      "62/194, train_loss: 0.7023\n",
      "63/194, train_loss: 0.8557\n",
      "64/194, train_loss: 0.6986\n",
      "65/194, train_loss: 0.7594\n",
      "66/194, train_loss: 0.8033\n",
      "67/194, train_loss: 0.8781\n",
      "68/194, train_loss: 0.8334\n",
      "69/194, train_loss: 0.7359\n",
      "70/194, train_loss: 0.8273\n",
      "71/194, train_loss: 0.8675\n",
      "72/194, train_loss: 0.6532\n",
      "73/194, train_loss: 0.8313\n",
      "74/194, train_loss: 0.8478\n",
      "75/194, train_loss: 0.7428\n",
      "76/194, train_loss: 0.5847\n",
      "77/194, train_loss: 0.4906\n",
      "78/194, train_loss: 0.8316\n",
      "79/194, train_loss: 0.6359\n",
      "80/194, train_loss: 0.5845\n",
      "81/194, train_loss: 0.8873\n",
      "82/194, train_loss: 0.7017\n",
      "83/194, train_loss: 0.7471\n",
      "84/194, train_loss: 0.7904\n",
      "85/194, train_loss: 0.8957\n",
      "86/194, train_loss: 0.9275\n",
      "87/194, train_loss: 0.7906\n",
      "88/194, train_loss: 0.8021\n",
      "89/194, train_loss: 0.9220\n",
      "90/194, train_loss: 0.7884\n",
      "91/194, train_loss: 0.6826\n",
      "92/194, train_loss: 0.7371\n",
      "93/194, train_loss: 0.7485\n",
      "94/194, train_loss: 0.7240\n",
      "95/194, train_loss: 0.8808\n",
      "96/194, train_loss: 0.6414\n",
      "97/194, train_loss: 0.8508\n",
      "98/194, train_loss: 0.8107\n",
      "99/194, train_loss: 0.6821\n",
      "100/194, train_loss: 0.7563\n",
      "101/194, train_loss: 0.8534\n",
      "102/194, train_loss: 0.8685\n",
      "103/194, train_loss: 0.8271\n",
      "104/194, train_loss: 0.8879\n",
      "105/194, train_loss: 0.6504\n",
      "106/194, train_loss: 0.7424\n",
      "107/194, train_loss: 0.7940\n",
      "108/194, train_loss: 0.7227\n",
      "109/194, train_loss: 0.7280\n",
      "110/194, train_loss: 0.6088\n",
      "111/194, train_loss: 0.7463\n",
      "112/194, train_loss: 0.8612\n",
      "113/194, train_loss: 0.8359\n",
      "114/194, train_loss: 0.6973\n",
      "115/194, train_loss: 0.8253\n",
      "116/194, train_loss: 0.7832\n",
      "117/194, train_loss: 0.8068\n",
      "118/194, train_loss: 0.8808\n",
      "119/194, train_loss: 0.7074\n",
      "120/194, train_loss: 0.7476\n",
      "121/194, train_loss: 0.7237\n",
      "122/194, train_loss: 0.9303\n",
      "123/194, train_loss: 0.8962\n",
      "124/194, train_loss: 0.8960\n",
      "125/194, train_loss: 0.8498\n",
      "126/194, train_loss: 0.8958\n",
      "127/194, train_loss: 0.8409\n",
      "128/194, train_loss: 0.6812\n",
      "129/194, train_loss: 0.8927\n",
      "130/194, train_loss: 0.8407\n",
      "131/194, train_loss: 0.7467\n",
      "132/194, train_loss: 0.7658\n",
      "133/194, train_loss: 0.7185\n",
      "134/194, train_loss: 0.7602\n",
      "135/194, train_loss: 0.7899\n",
      "136/194, train_loss: 0.8012\n",
      "137/194, train_loss: 0.8284\n",
      "138/194, train_loss: 0.7986\n",
      "139/194, train_loss: 0.7986\n",
      "140/194, train_loss: 0.6618\n",
      "141/194, train_loss: 0.8686\n",
      "142/194, train_loss: 0.7307\n",
      "143/194, train_loss: 0.7916\n",
      "144/194, train_loss: 0.6332\n",
      "145/194, train_loss: 0.8899\n",
      "146/194, train_loss: 0.8492\n",
      "147/194, train_loss: 0.7490\n",
      "148/194, train_loss: 0.6092\n",
      "149/194, train_loss: 0.8769\n",
      "150/194, train_loss: 0.8335\n",
      "151/194, train_loss: 0.7841\n",
      "152/194, train_loss: 0.8723\n",
      "153/194, train_loss: 0.8852\n",
      "154/194, train_loss: 0.7981\n",
      "155/194, train_loss: 0.8642\n",
      "156/194, train_loss: 0.7993\n",
      "157/194, train_loss: 0.9097\n",
      "158/194, train_loss: 0.7916\n",
      "159/194, train_loss: 0.8725\n",
      "160/194, train_loss: 0.9089\n",
      "161/194, train_loss: 0.7351\n",
      "162/194, train_loss: 0.7992\n",
      "163/194, train_loss: 0.8575\n",
      "164/194, train_loss: 0.7380\n",
      "165/194, train_loss: 0.8387\n",
      "166/194, train_loss: 0.8794\n",
      "167/194, train_loss: 0.6750\n",
      "168/194, train_loss: 0.6288\n",
      "169/194, train_loss: 0.8478\n",
      "170/194, train_loss: 0.7000\n",
      "171/194, train_loss: 0.7292\n",
      "172/194, train_loss: 0.7105\n",
      "173/194, train_loss: 0.7699\n",
      "174/194, train_loss: 0.7090\n",
      "175/194, train_loss: 0.9100\n",
      "176/194, train_loss: 0.6627\n",
      "177/194, train_loss: 0.6325\n",
      "178/194, train_loss: 0.7907\n",
      "179/194, train_loss: 0.7250\n",
      "180/194, train_loss: 0.6362\n",
      "181/194, train_loss: 0.5850\n",
      "182/194, train_loss: 0.6724\n",
      "183/194, train_loss: 0.8177\n",
      "184/194, train_loss: 0.7334\n",
      "185/194, train_loss: 0.8534\n",
      "186/194, train_loss: 0.7825\n",
      "187/194, train_loss: 0.7411\n",
      "188/194, train_loss: 0.8836\n",
      "189/194, train_loss: 0.6275\n",
      "190/194, train_loss: 0.4916\n",
      "191/194, train_loss: 0.8677\n",
      "192/194, train_loss: 0.7294\n",
      "193/194, train_loss: 0.7584\n",
      "194/194, train_loss: 0.7336\n",
      "metric=0.36963412817567587, metric_tc=0.38480839288483065, metric_wt=0.4994701234002908, metric_et=0.22462386121818176\n",
      "metric=0.36963412817567587, metric_tc=0.38480839288483065, metric_wt=0.4994701234002908, metric_et=0.22462386121818176\n",
      "current epoch: 56 current epoch loss: 0.7772\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 56/80 [10:29:20<5:17:29, 793.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metric=0.36963412817567587, metric_tc=0.38480839288483065, metric_wt=0.4994701234002908, metric_et=0.22462386121818176\n",
      "0.36963412817567587\n",
      "current epoch: 56 current mean dice: 0.3696 tc: 0.3848 wt: 0.4995 et: 0.2246\n",
      "best mean dice: 0.3846 at epoch: 55\n",
      "\n",
      " | Global Training Round : 57 |\n",
      "\n",
      "user 0 selected\n",
      "local epoch 1\n",
      "1/194, train_loss: 0.6476\n",
      "2/194, train_loss: 0.7369\n",
      "3/194, train_loss: 0.9113\n",
      "4/194, train_loss: 0.6797\n",
      "5/194, train_loss: 0.8323\n",
      "6/194, train_loss: 0.7996\n",
      "7/194, train_loss: 0.7580\n",
      "8/194, train_loss: 0.4859\n",
      "9/194, train_loss: 0.7332\n",
      "10/194, train_loss: 0.7485\n",
      "11/194, train_loss: 0.6861\n",
      "12/194, train_loss: 0.7671\n",
      "13/194, train_loss: 0.5822\n",
      "14/194, train_loss: 0.8611\n",
      "15/194, train_loss: 0.5394\n",
      "16/194, train_loss: 0.7018\n",
      "17/194, train_loss: 0.7655\n",
      "18/194, train_loss: 0.7505\n",
      "19/194, train_loss: 0.8353\n",
      "20/194, train_loss: 0.9422\n",
      "21/194, train_loss: 0.7956\n",
      "22/194, train_loss: 0.7380\n",
      "23/194, train_loss: 0.6893\n",
      "24/194, train_loss: 0.7175\n",
      "25/194, train_loss: 0.5977\n",
      "26/194, train_loss: 0.5523\n",
      "27/194, train_loss: 0.9344\n",
      "28/194, train_loss: 0.6593\n",
      "29/194, train_loss: 0.9005\n",
      "30/194, train_loss: 0.8813\n",
      "31/194, train_loss: 0.8948\n",
      "32/194, train_loss: 0.7172\n",
      "33/194, train_loss: 0.9089\n",
      "34/194, train_loss: 0.7957\n",
      "35/194, train_loss: 0.8817\n",
      "36/194, train_loss: 0.9090\n",
      "37/194, train_loss: 0.8813\n",
      "38/194, train_loss: 0.7595\n",
      "39/194, train_loss: 0.8395\n",
      "40/194, train_loss: 0.6714\n",
      "41/194, train_loss: 0.6531\n",
      "42/194, train_loss: 0.7551\n",
      "43/194, train_loss: 0.7758\n",
      "44/194, train_loss: 0.7737\n",
      "45/194, train_loss: 0.7797\n",
      "46/194, train_loss: 0.8142\n",
      "47/194, train_loss: 0.7969\n",
      "48/194, train_loss: 0.7579\n",
      "49/194, train_loss: 0.5554\n",
      "50/194, train_loss: 0.6217\n",
      "51/194, train_loss: 0.6076\n",
      "52/194, train_loss: 0.9831\n",
      "53/194, train_loss: 0.8434\n",
      "54/194, train_loss: 0.4916\n",
      "55/194, train_loss: 0.7256\n",
      "56/194, train_loss: 0.8504\n",
      "57/194, train_loss: 0.8564\n",
      "58/194, train_loss: 0.8762\n",
      "59/194, train_loss: 0.7360\n",
      "60/194, train_loss: 0.8751\n",
      "61/194, train_loss: 0.7254\n",
      "62/194, train_loss: 0.7473\n",
      "63/194, train_loss: 0.6465\n",
      "64/194, train_loss: 0.7850\n",
      "65/194, train_loss: 0.7628\n",
      "66/194, train_loss: 0.7210\n",
      "67/194, train_loss: 0.6353\n",
      "68/194, train_loss: 0.9218\n",
      "69/194, train_loss: 0.9126\n",
      "70/194, train_loss: 0.7699\n",
      "71/194, train_loss: 0.7713\n",
      "72/194, train_loss: 0.6545\n",
      "73/194, train_loss: 0.7206\n",
      "74/194, train_loss: 0.7792\n",
      "75/194, train_loss: 0.7375\n",
      "76/194, train_loss: 0.8895\n",
      "77/194, train_loss: 0.7447\n",
      "78/194, train_loss: 0.7831\n",
      "79/194, train_loss: 0.7423\n",
      "80/194, train_loss: 0.6313\n",
      "81/194, train_loss: 0.7858\n",
      "82/194, train_loss: 0.7817\n",
      "83/194, train_loss: 0.7814\n",
      "84/194, train_loss: 0.7316\n",
      "85/194, train_loss: 0.9358\n",
      "86/194, train_loss: 0.8604\n",
      "87/194, train_loss: 0.8478\n",
      "88/194, train_loss: 0.8467\n",
      "89/194, train_loss: 0.8558\n",
      "90/194, train_loss: 0.8323\n",
      "91/194, train_loss: 0.7910\n",
      "92/194, train_loss: 0.6693\n",
      "93/194, train_loss: 0.7108\n",
      "94/194, train_loss: 0.5535\n",
      "95/194, train_loss: 0.6967\n",
      "96/194, train_loss: 0.3755\n",
      "97/194, train_loss: 0.7816\n",
      "98/194, train_loss: 0.6886\n",
      "99/194, train_loss: 0.7416\n",
      "100/194, train_loss: 0.7549\n",
      "101/194, train_loss: 0.7423\n",
      "102/194, train_loss: 0.9368\n",
      "103/194, train_loss: 0.5999\n",
      "104/194, train_loss: 0.8710\n",
      "105/194, train_loss: 0.7512\n",
      "106/194, train_loss: 0.7971\n",
      "107/194, train_loss: 0.8495\n",
      "108/194, train_loss: 0.7059\n",
      "109/194, train_loss: 0.7487\n",
      "110/194, train_loss: 0.7297\n",
      "111/194, train_loss: 0.7456\n",
      "112/194, train_loss: 0.7075\n",
      "113/194, train_loss: 0.8444\n",
      "114/194, train_loss: 0.8824\n",
      "115/194, train_loss: 0.6319\n",
      "116/194, train_loss: 0.8600\n",
      "117/194, train_loss: 0.8292\n",
      "118/194, train_loss: 0.7369\n",
      "119/194, train_loss: 0.7662\n",
      "120/194, train_loss: 0.8674\n",
      "121/194, train_loss: 0.7691\n",
      "122/194, train_loss: 0.8787\n",
      "123/194, train_loss: 0.5771\n",
      "124/194, train_loss: 0.8634\n",
      "125/194, train_loss: 0.7318\n",
      "126/194, train_loss: 0.7030\n",
      "127/194, train_loss: 0.9265\n",
      "128/194, train_loss: 0.7356\n",
      "129/194, train_loss: 0.8484\n",
      "130/194, train_loss: 0.7602\n",
      "131/194, train_loss: 0.7881\n",
      "132/194, train_loss: 0.6424\n",
      "133/194, train_loss: 0.8017\n",
      "134/194, train_loss: 0.8557\n",
      "135/194, train_loss: 0.6373\n",
      "136/194, train_loss: 0.7777\n",
      "137/194, train_loss: 0.7717\n",
      "138/194, train_loss: 0.8244\n",
      "139/194, train_loss: 0.5867\n",
      "140/194, train_loss: 0.4725\n",
      "141/194, train_loss: 0.9285\n",
      "142/194, train_loss: 0.9047\n",
      "143/194, train_loss: 0.6571\n",
      "144/194, train_loss: 0.7937\n",
      "145/194, train_loss: 0.8231\n",
      "146/194, train_loss: 0.8245\n",
      "147/194, train_loss: 0.6594\n",
      "148/194, train_loss: 0.7796\n",
      "149/194, train_loss: 0.8452\n",
      "150/194, train_loss: 0.8079\n",
      "151/194, train_loss: 0.9273\n",
      "152/194, train_loss: 0.7947\n",
      "153/194, train_loss: 0.6936\n",
      "154/194, train_loss: 0.9206\n",
      "155/194, train_loss: 0.9286\n",
      "156/194, train_loss: 0.8473\n",
      "157/194, train_loss: 0.8357\n",
      "158/194, train_loss: 0.7140\n",
      "159/194, train_loss: 0.8218\n",
      "160/194, train_loss: 0.6438\n",
      "161/194, train_loss: 0.8166\n",
      "162/194, train_loss: 0.7949\n",
      "163/194, train_loss: 0.7188\n",
      "164/194, train_loss: 0.9141\n",
      "165/194, train_loss: 0.7724\n",
      "166/194, train_loss: 0.6523\n",
      "167/194, train_loss: 0.8278\n",
      "168/194, train_loss: 0.8752\n",
      "169/194, train_loss: 0.6719\n",
      "170/194, train_loss: 0.7685\n",
      "171/194, train_loss: 0.7924\n",
      "172/194, train_loss: 0.7627\n",
      "173/194, train_loss: 0.6662\n",
      "174/194, train_loss: 0.8766\n",
      "175/194, train_loss: 0.7608\n",
      "176/194, train_loss: 0.8025\n",
      "177/194, train_loss: 0.8322\n",
      "178/194, train_loss: 0.8433\n",
      "179/194, train_loss: 0.9027\n",
      "180/194, train_loss: 0.8960\n",
      "181/194, train_loss: 0.7246\n",
      "182/194, train_loss: 0.7807\n",
      "183/194, train_loss: 0.7326\n",
      "184/194, train_loss: 0.5689\n",
      "185/194, train_loss: 0.7718\n",
      "186/194, train_loss: 0.9896\n",
      "187/194, train_loss: 0.7355\n",
      "188/194, train_loss: 0.7318\n",
      "189/194, train_loss: 0.6871\n",
      "190/194, train_loss: 0.8510\n",
      "191/194, train_loss: 0.9392\n",
      "192/194, train_loss: 0.9309\n",
      "193/194, train_loss: 0.8028\n",
      "194/194, train_loss: 0.7306\n",
      "metric=0.36708947767814, metric_tc=0.39191402634605765, metric_wt=0.49128117846945923, metric_et=0.21807323667841652\n",
      "metric=0.36708947767814, metric_tc=0.39191402634605765, metric_wt=0.49128117846945923, metric_et=0.21807323667841652\n",
      "current epoch: 57 current epoch loss: 0.7699\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████▏  | 57/80 [10:40:13<4:48:07, 751.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metric=0.36708947767814, metric_tc=0.39191402634605765, metric_wt=0.49128117846945923, metric_et=0.21807323667841652\n",
      "0.36708947767814\n",
      "current epoch: 57 current mean dice: 0.3671 tc: 0.3919 wt: 0.4913 et: 0.2181\n",
      "best mean dice: 0.3846 at epoch: 55\n",
      "\n",
      " | Global Training Round : 58 |\n",
      "\n",
      "user 0 selected\n",
      "local epoch 1\n",
      "1/194, train_loss: 0.8261\n",
      "2/194, train_loss: 0.7752\n",
      "3/194, train_loss: 0.7641\n",
      "4/194, train_loss: 0.6550\n",
      "5/194, train_loss: 0.6810\n",
      "6/194, train_loss: 0.8610\n",
      "7/194, train_loss: 0.7902\n",
      "8/194, train_loss: 0.8531\n",
      "9/194, train_loss: 0.8327\n",
      "10/194, train_loss: 0.6934\n",
      "11/194, train_loss: 0.6883\n",
      "12/194, train_loss: 0.7460\n",
      "13/194, train_loss: 0.6945\n",
      "14/194, train_loss: 0.9377\n",
      "15/194, train_loss: 0.9125\n",
      "16/194, train_loss: 0.9023\n",
      "17/194, train_loss: 0.7411\n",
      "18/194, train_loss: 0.7828\n",
      "19/194, train_loss: 0.9153\n",
      "20/194, train_loss: 0.6500\n",
      "21/194, train_loss: 0.6869\n",
      "22/194, train_loss: 0.7764\n",
      "23/194, train_loss: 0.8464\n",
      "24/194, train_loss: 0.7021\n",
      "25/194, train_loss: 0.7337\n",
      "26/194, train_loss: 0.8254\n",
      "27/194, train_loss: 0.8384\n",
      "28/194, train_loss: 0.6337\n",
      "29/194, train_loss: 0.6496\n",
      "30/194, train_loss: 0.7212\n",
      "31/194, train_loss: 0.8419\n",
      "32/194, train_loss: 0.6538\n",
      "33/194, train_loss: 0.6782\n",
      "34/194, train_loss: 0.6968\n",
      "35/194, train_loss: 0.7287\n",
      "36/194, train_loss: 0.7945\n",
      "37/194, train_loss: 0.6829\n",
      "38/194, train_loss: 0.6431\n",
      "39/194, train_loss: 0.5860\n",
      "40/194, train_loss: 0.7294\n",
      "41/194, train_loss: 0.8790\n",
      "42/194, train_loss: 0.6271\n",
      "43/194, train_loss: 0.8770\n",
      "44/194, train_loss: 0.7951\n",
      "45/194, train_loss: 0.5733\n",
      "46/194, train_loss: 0.7782\n",
      "47/194, train_loss: 0.7451\n",
      "48/194, train_loss: 0.6757\n",
      "49/194, train_loss: 0.8063\n",
      "50/194, train_loss: 0.5933\n",
      "51/194, train_loss: 0.7742\n",
      "52/194, train_loss: 0.6693\n",
      "53/194, train_loss: 0.8282\n",
      "54/194, train_loss: 0.5982\n",
      "55/194, train_loss: 0.9231\n",
      "56/194, train_loss: 0.8205\n",
      "57/194, train_loss: 0.7839\n",
      "58/194, train_loss: 0.8418\n",
      "59/194, train_loss: 0.7666\n",
      "60/194, train_loss: 0.9318\n",
      "61/194, train_loss: 0.7319\n",
      "62/194, train_loss: 0.6788\n",
      "63/194, train_loss: 0.6298\n",
      "64/194, train_loss: 0.7730\n",
      "65/194, train_loss: 0.7551\n",
      "66/194, train_loss: 0.7275\n",
      "67/194, train_loss: 0.6094\n",
      "68/194, train_loss: 0.9093\n",
      "69/194, train_loss: 0.8675\n",
      "70/194, train_loss: 0.7328\n",
      "71/194, train_loss: 0.7603\n",
      "72/194, train_loss: 0.8019\n",
      "73/194, train_loss: 0.6592\n",
      "74/194, train_loss: 0.6767\n",
      "75/194, train_loss: 0.9012\n",
      "76/194, train_loss: 0.8461\n",
      "77/194, train_loss: 0.7540\n",
      "78/194, train_loss: 0.7643\n",
      "79/194, train_loss: 0.7081\n",
      "80/194, train_loss: 0.8265\n",
      "81/194, train_loss: 0.8122\n",
      "82/194, train_loss: 0.7565\n",
      "83/194, train_loss: 0.8639\n",
      "84/194, train_loss: 0.8373\n",
      "85/194, train_loss: 0.6137\n",
      "86/194, train_loss: 0.8804\n",
      "87/194, train_loss: 0.8394\n",
      "88/194, train_loss: 0.6558\n",
      "89/194, train_loss: 0.8016\n",
      "90/194, train_loss: 0.7280\n",
      "91/194, train_loss: 0.8779\n",
      "92/194, train_loss: 0.8931\n",
      "93/194, train_loss: 0.7774\n",
      "94/194, train_loss: 0.6802\n",
      "95/194, train_loss: 0.7317\n",
      "96/194, train_loss: 0.7891\n",
      "97/194, train_loss: 0.7946\n",
      "98/194, train_loss: 0.5548\n",
      "99/194, train_loss: 0.8141\n",
      "100/194, train_loss: 0.7900\n",
      "101/194, train_loss: 0.8228\n",
      "102/194, train_loss: 0.7592\n",
      "103/194, train_loss: 0.7384\n",
      "104/194, train_loss: 0.8006\n",
      "105/194, train_loss: 0.8316\n",
      "106/194, train_loss: 0.8289\n",
      "107/194, train_loss: 0.7259\n",
      "108/194, train_loss: 0.7443\n",
      "109/194, train_loss: 0.7513\n",
      "110/194, train_loss: 0.8376\n",
      "111/194, train_loss: 0.7766\n",
      "112/194, train_loss: 0.4340\n",
      "113/194, train_loss: 0.8115\n",
      "114/194, train_loss: 0.7623\n",
      "115/194, train_loss: 0.8599\n",
      "116/194, train_loss: 0.8906\n",
      "117/194, train_loss: 0.6980\n",
      "118/194, train_loss: 0.8941\n",
      "119/194, train_loss: 0.7842\n",
      "120/194, train_loss: 0.6235\n",
      "121/194, train_loss: 0.9003\n",
      "122/194, train_loss: 0.9401\n",
      "123/194, train_loss: 0.9127\n",
      "124/194, train_loss: 0.9151\n",
      "125/194, train_loss: 0.8786\n",
      "126/194, train_loss: 0.9009\n",
      "127/194, train_loss: 0.8252\n",
      "128/194, train_loss: 0.8730\n",
      "129/194, train_loss: 0.7861\n",
      "130/194, train_loss: 0.8387\n",
      "131/194, train_loss: 0.7634\n",
      "132/194, train_loss: 0.7525\n",
      "133/194, train_loss: 0.7565\n",
      "134/194, train_loss: 0.7153\n",
      "135/194, train_loss: 0.6585\n",
      "136/194, train_loss: 0.7080\n",
      "137/194, train_loss: 0.7881\n",
      "138/194, train_loss: 0.6203\n",
      "139/194, train_loss: 0.8370\n",
      "140/194, train_loss: 0.6315\n",
      "141/194, train_loss: 0.8547\n",
      "142/194, train_loss: 0.8174\n",
      "143/194, train_loss: 0.7927\n",
      "144/194, train_loss: 0.8437\n",
      "145/194, train_loss: 0.7902\n",
      "146/194, train_loss: 0.8199\n",
      "147/194, train_loss: 0.7578\n",
      "148/194, train_loss: 0.8458\n",
      "149/194, train_loss: 0.9141\n",
      "150/194, train_loss: 0.7574\n",
      "151/194, train_loss: 0.9030\n",
      "152/194, train_loss: 0.8668\n",
      "153/194, train_loss: 0.9341\n",
      "154/194, train_loss: 0.9925\n",
      "155/194, train_loss: 0.9415\n",
      "156/194, train_loss: 0.7594\n",
      "157/194, train_loss: 0.7216\n",
      "158/194, train_loss: 0.8746\n",
      "159/194, train_loss: 0.8094\n",
      "160/194, train_loss: 0.8442\n",
      "161/194, train_loss: 0.8448\n",
      "162/194, train_loss: 0.8624\n",
      "163/194, train_loss: 0.9376\n",
      "164/194, train_loss: 0.9449\n",
      "165/194, train_loss: 0.8451\n",
      "166/194, train_loss: 0.8371\n",
      "167/194, train_loss: 0.8731\n",
      "168/194, train_loss: 0.8222\n",
      "169/194, train_loss: 0.7371\n",
      "170/194, train_loss: 0.6515\n",
      "171/194, train_loss: 0.7892\n",
      "172/194, train_loss: 0.9051\n",
      "173/194, train_loss: 0.8101\n",
      "174/194, train_loss: 0.7484\n",
      "175/194, train_loss: 0.7395\n",
      "176/194, train_loss: 0.6614\n",
      "177/194, train_loss: 0.8240\n",
      "178/194, train_loss: 0.8691\n",
      "179/194, train_loss: 0.6920\n",
      "180/194, train_loss: 0.8948\n",
      "181/194, train_loss: 0.6392\n",
      "182/194, train_loss: 0.6308\n",
      "183/194, train_loss: 0.5675\n",
      "184/194, train_loss: 0.7020\n",
      "185/194, train_loss: 0.8142\n",
      "186/194, train_loss: 0.7677\n",
      "187/194, train_loss: 0.7177\n",
      "188/194, train_loss: 0.7809\n",
      "189/194, train_loss: 0.7952\n",
      "190/194, train_loss: 0.8902\n",
      "191/194, train_loss: 0.8388\n",
      "192/194, train_loss: 0.7207\n",
      "193/194, train_loss: 0.6522\n",
      "194/194, train_loss: 0.5338\n",
      "metric=0.39128343388438225, metric_tc=0.4077576892450452, metric_wt=0.5439026057720184, metric_et=0.22219001156433174\n",
      "metric=0.39128343388438225, metric_tc=0.4077576892450452, metric_wt=0.5439026057720184, metric_et=0.22219001156433174\n",
      "current epoch: 58 current epoch loss: 0.7763\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▎  | 58/80 [10:50:59<4:23:56, 719.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metric=0.39128343388438225, metric_tc=0.4077576892450452, metric_wt=0.5439026057720184, metric_et=0.22219001156433174\n",
      "0.39128343388438225\n",
      "saved new best metric model\n",
      "current epoch: 58 current mean dice: 0.3913 tc: 0.4078 wt: 0.5439 et: 0.2222\n",
      "best mean dice: 0.3913 at epoch: 58\n",
      "\n",
      " | Global Training Round : 59 |\n",
      "\n",
      "user 0 selected\n",
      "local epoch 1\n",
      "1/194, train_loss: 0.7648\n",
      "2/194, train_loss: 0.7384\n",
      "3/194, train_loss: 0.6643\n",
      "4/194, train_loss: 0.7556\n",
      "5/194, train_loss: 0.8849\n",
      "6/194, train_loss: 0.9183\n",
      "7/194, train_loss: 0.8089\n",
      "8/194, train_loss: 0.8206\n",
      "9/194, train_loss: 0.8974\n",
      "10/194, train_loss: 0.7960\n",
      "11/194, train_loss: 0.7080\n",
      "12/194, train_loss: 0.8795\n",
      "13/194, train_loss: 0.8556\n",
      "14/194, train_loss: 0.7098\n",
      "15/194, train_loss: 0.9146\n",
      "16/194, train_loss: 0.6977\n",
      "17/194, train_loss: 0.8045\n",
      "18/194, train_loss: 0.7558\n",
      "19/194, train_loss: 0.7236\n",
      "20/194, train_loss: 0.8365\n",
      "21/194, train_loss: 0.7692\n",
      "22/194, train_loss: 0.7169\n",
      "23/194, train_loss: 0.7348\n",
      "24/194, train_loss: 0.6511\n",
      "25/194, train_loss: 0.7969\n",
      "26/194, train_loss: 0.8118\n",
      "27/194, train_loss: 0.8031\n",
      "28/194, train_loss: 0.7489\n",
      "29/194, train_loss: 0.5966\n",
      "30/194, train_loss: 0.8758\n",
      "31/194, train_loss: 0.7481\n",
      "32/194, train_loss: 0.7576\n",
      "33/194, train_loss: 0.6640\n",
      "34/194, train_loss: 0.7239\n",
      "35/194, train_loss: 0.7464\n",
      "36/194, train_loss: 0.8707\n",
      "37/194, train_loss: 0.6626\n",
      "38/194, train_loss: 0.8385\n",
      "39/194, train_loss: 0.6504\n",
      "40/194, train_loss: 0.5939\n",
      "41/194, train_loss: 0.8158\n",
      "42/194, train_loss: 0.8506\n",
      "43/194, train_loss: 0.6527\n",
      "44/194, train_loss: 0.6104\n",
      "45/194, train_loss: 0.6297\n",
      "46/194, train_loss: 0.6613\n",
      "47/194, train_loss: 0.6591\n",
      "48/194, train_loss: 0.6450\n",
      "49/194, train_loss: 0.7958\n",
      "50/194, train_loss: 0.7949\n",
      "51/194, train_loss: 0.7884\n",
      "52/194, train_loss: 0.7296\n",
      "53/194, train_loss: 0.7408\n",
      "54/194, train_loss: 0.8707\n",
      "55/194, train_loss: 0.8694\n",
      "56/194, train_loss: 0.7695\n",
      "57/194, train_loss: 0.7365\n",
      "58/194, train_loss: 0.8453\n",
      "59/194, train_loss: 0.9029\n",
      "60/194, train_loss: 0.8898\n",
      "61/194, train_loss: 0.6689\n",
      "62/194, train_loss: 0.7626\n",
      "63/194, train_loss: 0.7731\n",
      "64/194, train_loss: 0.6312\n",
      "65/194, train_loss: 0.8689\n",
      "66/194, train_loss: 0.8042\n",
      "67/194, train_loss: 0.8804\n",
      "68/194, train_loss: 0.7779\n",
      "69/194, train_loss: 0.7190\n",
      "70/194, train_loss: 0.7880\n",
      "71/194, train_loss: 0.7393\n",
      "72/194, train_loss: 0.7587\n",
      "73/194, train_loss: 0.6233\n",
      "74/194, train_loss: 0.5614\n",
      "75/194, train_loss: 0.6492\n",
      "76/194, train_loss: 0.7664\n",
      "77/194, train_loss: 0.7529\n",
      "78/194, train_loss: 0.6087\n",
      "79/194, train_loss: 0.7789\n",
      "80/194, train_loss: 0.7255\n",
      "81/194, train_loss: 0.8301\n",
      "82/194, train_loss: 0.8311\n",
      "83/194, train_loss: 0.8005\n",
      "84/194, train_loss: 0.6848\n",
      "85/194, train_loss: 0.8037\n",
      "86/194, train_loss: 0.8333\n",
      "87/194, train_loss: 0.9250\n",
      "88/194, train_loss: 0.9134\n",
      "89/194, train_loss: 0.8344\n",
      "90/194, train_loss: 0.8097\n",
      "91/194, train_loss: 0.8161\n",
      "92/194, train_loss: 0.8640\n",
      "93/194, train_loss: 0.6513\n",
      "94/194, train_loss: 0.5081\n",
      "95/194, train_loss: 0.8325\n",
      "96/194, train_loss: 0.7619\n",
      "97/194, train_loss: 0.7411\n",
      "98/194, train_loss: 0.6971\n",
      "99/194, train_loss: 0.7618\n",
      "100/194, train_loss: 0.8330\n",
      "101/194, train_loss: 0.7197\n",
      "102/194, train_loss: 0.9606\n",
      "103/194, train_loss: 0.7651\n",
      "104/194, train_loss: 0.6856\n",
      "105/194, train_loss: 0.6996\n",
      "106/194, train_loss: 0.6107\n",
      "107/194, train_loss: 0.6386\n",
      "108/194, train_loss: 0.6637\n",
      "109/194, train_loss: 0.8143\n",
      "110/194, train_loss: 0.6845\n",
      "111/194, train_loss: 0.5782\n",
      "112/194, train_loss: 0.9092\n",
      "113/194, train_loss: 0.6106\n",
      "114/194, train_loss: 0.8526\n",
      "115/194, train_loss: 0.8713\n",
      "116/194, train_loss: 0.7901\n",
      "117/194, train_loss: 0.8817\n",
      "118/194, train_loss: 0.7548\n",
      "119/194, train_loss: 0.7504\n",
      "120/194, train_loss: 0.8196\n",
      "121/194, train_loss: 0.9184\n",
      "122/194, train_loss: 0.8544\n",
      "123/194, train_loss: 0.8979\n",
      "124/194, train_loss: 0.7832\n",
      "125/194, train_loss: 0.8073\n",
      "126/194, train_loss: 0.8688\n",
      "127/194, train_loss: 0.7966\n",
      "128/194, train_loss: 0.8754\n",
      "129/194, train_loss: 0.8586\n",
      "130/194, train_loss: 0.9101\n",
      "131/194, train_loss: 0.8735\n",
      "132/194, train_loss: 0.8167\n",
      "133/194, train_loss: 0.7977\n",
      "134/194, train_loss: 0.7143\n",
      "135/194, train_loss: 0.7910\n",
      "136/194, train_loss: 0.7024\n",
      "137/194, train_loss: 0.6618\n",
      "138/194, train_loss: 0.7751\n",
      "139/194, train_loss: 0.6674\n",
      "140/194, train_loss: 0.7430\n",
      "141/194, train_loss: 0.9435\n",
      "142/194, train_loss: 0.7350\n",
      "143/194, train_loss: 0.9282\n",
      "144/194, train_loss: 0.9121\n",
      "145/194, train_loss: 0.8621\n",
      "146/194, train_loss: 0.8458\n",
      "147/194, train_loss: 0.7340\n",
      "148/194, train_loss: 0.7546\n",
      "149/194, train_loss: 0.8750\n",
      "150/194, train_loss: 0.6329\n",
      "151/194, train_loss: 0.9092\n",
      "152/194, train_loss: 0.8358\n",
      "153/194, train_loss: 0.9399\n",
      "154/194, train_loss: 0.7877\n",
      "155/194, train_loss: 0.9222\n",
      "156/194, train_loss: 0.9177\n",
      "157/194, train_loss: 0.7852\n",
      "158/194, train_loss: 0.8147\n",
      "159/194, train_loss: 0.9004\n",
      "160/194, train_loss: 0.8466\n",
      "161/194, train_loss: 0.8755\n",
      "162/194, train_loss: 0.7408\n",
      "163/194, train_loss: 0.9702\n",
      "164/194, train_loss: 0.9191\n",
      "165/194, train_loss: 0.8791\n",
      "166/194, train_loss: 0.8508\n",
      "167/194, train_loss: 0.8939\n",
      "168/194, train_loss: 0.7574\n",
      "169/194, train_loss: 0.8074\n",
      "170/194, train_loss: 0.6936\n",
      "171/194, train_loss: 0.7590\n",
      "172/194, train_loss: 0.5507\n",
      "173/194, train_loss: 0.7883\n",
      "174/194, train_loss: 0.8384\n",
      "175/194, train_loss: 0.7514\n",
      "176/194, train_loss: 0.8710\n",
      "177/194, train_loss: 0.6311\n",
      "178/194, train_loss: 0.8794\n",
      "179/194, train_loss: 0.7640\n",
      "180/194, train_loss: 0.8269\n",
      "181/194, train_loss: 0.6461\n",
      "182/194, train_loss: 0.8438\n",
      "183/194, train_loss: 0.6871\n",
      "184/194, train_loss: 0.6543\n",
      "185/194, train_loss: 0.8630\n",
      "186/194, train_loss: 0.8675\n",
      "187/194, train_loss: 0.7801\n",
      "188/194, train_loss: 0.7399\n",
      "189/194, train_loss: 0.8859\n",
      "190/194, train_loss: 0.8740\n",
      "191/194, train_loss: 0.7016\n",
      "192/194, train_loss: 0.8357\n",
      "193/194, train_loss: 0.6724\n",
      "194/194, train_loss: 0.9137\n",
      "metric=0.39140310262640315, metric_tc=0.4125402740513285, metric_wt=0.5355109181255102, metric_et=0.22615812066942453\n",
      "metric=0.39140310262640315, metric_tc=0.4125402740513285, metric_wt=0.5355109181255102, metric_et=0.22615812066942453\n",
      "current epoch: 59 current epoch loss: 0.7804\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 59/80 [11:00:55<3:58:59, 682.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metric=0.39140310262640315, metric_tc=0.4125402740513285, metric_wt=0.5355109181255102, metric_et=0.22615812066942453\n",
      "0.39140310262640315\n",
      "saved new best metric model\n",
      "current epoch: 59 current mean dice: 0.3914 tc: 0.4125 wt: 0.5355 et: 0.2262\n",
      "best mean dice: 0.3914 at epoch: 59\n",
      "\n",
      " | Global Training Round : 60 |\n",
      "\n",
      "user 0 selected\n",
      "local epoch 1\n",
      "1/194, train_loss: 0.7310\n",
      "2/194, train_loss: 0.5494\n",
      "3/194, train_loss: 0.8015\n",
      "4/194, train_loss: 0.5505\n",
      "5/194, train_loss: 0.8420\n",
      "6/194, train_loss: 0.7812\n",
      "7/194, train_loss: 0.8431\n",
      "8/194, train_loss: 0.8973\n",
      "9/194, train_loss: 0.8506\n",
      "10/194, train_loss: 0.8393\n",
      "11/194, train_loss: 0.6042\n",
      "12/194, train_loss: 0.7746\n",
      "13/194, train_loss: 0.6592\n",
      "14/194, train_loss: 0.5709\n",
      "15/194, train_loss: 0.8925\n",
      "16/194, train_loss: 0.9137\n",
      "17/194, train_loss: 0.7468\n",
      "18/194, train_loss: 0.8135\n",
      "19/194, train_loss: 0.7344\n",
      "20/194, train_loss: 0.8564\n",
      "21/194, train_loss: 0.7462\n",
      "22/194, train_loss: 0.6531\n",
      "23/194, train_loss: 0.6748\n",
      "24/194, train_loss: 0.6905\n",
      "25/194, train_loss: 0.7849\n",
      "26/194, train_loss: 0.7239\n",
      "27/194, train_loss: 0.7571\n",
      "28/194, train_loss: 0.8942\n",
      "29/194, train_loss: 0.8794\n",
      "30/194, train_loss: 0.8623\n",
      "31/194, train_loss: 0.8845\n",
      "32/194, train_loss: 0.7213\n",
      "33/194, train_loss: 0.6733\n",
      "34/194, train_loss: 0.7895\n",
      "35/194, train_loss: 0.7174\n",
      "36/194, train_loss: 0.6643\n",
      "37/194, train_loss: 0.8187\n",
      "38/194, train_loss: 0.6139\n",
      "39/194, train_loss: 0.8652\n",
      "40/194, train_loss: 0.7210\n",
      "41/194, train_loss: 0.7108\n",
      "42/194, train_loss: 0.7893\n",
      "43/194, train_loss: 0.8524\n",
      "44/194, train_loss: 0.7815\n",
      "45/194, train_loss: 0.7296\n",
      "46/194, train_loss: 0.7886\n",
      "47/194, train_loss: 0.7655\n",
      "48/194, train_loss: 0.6978\n",
      "49/194, train_loss: 0.6289\n",
      "50/194, train_loss: 0.7412\n",
      "51/194, train_loss: 0.7325\n",
      "52/194, train_loss: 0.8896\n",
      "53/194, train_loss: 0.7741\n",
      "54/194, train_loss: 0.8026\n",
      "55/194, train_loss: 0.7889\n",
      "56/194, train_loss: 0.8078\n",
      "57/194, train_loss: 0.8111\n",
      "58/194, train_loss: 0.8443\n",
      "59/194, train_loss: 0.8955\n",
      "60/194, train_loss: 0.8039\n",
      "61/194, train_loss: 0.7626\n",
      "62/194, train_loss: 0.8713\n",
      "63/194, train_loss: 0.7549\n",
      "64/194, train_loss: 0.6014\n",
      "65/194, train_loss: 0.8833\n",
      "66/194, train_loss: 0.8600\n",
      "67/194, train_loss: 0.8709\n",
      "68/194, train_loss: 0.7904\n",
      "69/194, train_loss: 0.7574\n",
      "70/194, train_loss: 0.7318\n",
      "71/194, train_loss: 0.7991\n",
      "72/194, train_loss: 0.7311\n",
      "73/194, train_loss: 0.5642\n",
      "74/194, train_loss: 0.6064\n",
      "75/194, train_loss: 0.4594\n",
      "76/194, train_loss: 0.6984\n",
      "77/194, train_loss: 0.7163\n",
      "78/194, train_loss: 0.7179\n",
      "79/194, train_loss: 0.7650\n",
      "80/194, train_loss: 0.7317\n",
      "81/194, train_loss: 0.9245\n",
      "82/194, train_loss: 0.8877\n",
      "83/194, train_loss: 0.7356\n",
      "84/194, train_loss: 0.7994\n",
      "85/194, train_loss: 0.8667\n",
      "86/194, train_loss: 0.8054\n",
      "87/194, train_loss: 0.6982\n",
      "88/194, train_loss: 0.9160\n",
      "89/194, train_loss: 0.8133\n",
      "90/194, train_loss: 0.6568\n",
      "91/194, train_loss: 0.7076\n",
      "92/194, train_loss: 0.8337\n",
      "93/194, train_loss: 0.6998\n",
      "94/194, train_loss: 0.8246\n",
      "95/194, train_loss: 0.9366\n",
      "96/194, train_loss: 0.7489\n",
      "97/194, train_loss: 0.8633\n",
      "98/194, train_loss: 0.8113\n",
      "99/194, train_loss: 0.7680\n",
      "100/194, train_loss: 0.7044\n",
      "101/194, train_loss: 0.7039\n",
      "102/194, train_loss: 0.9161\n",
      "103/194, train_loss: 0.5724\n",
      "104/194, train_loss: 0.8968\n",
      "105/194, train_loss: 0.9176\n",
      "106/194, train_loss: 0.6893\n",
      "107/194, train_loss: 0.7244\n",
      "108/194, train_loss: 0.8422\n",
      "109/194, train_loss: 0.7909\n",
      "110/194, train_loss: 0.8387\n",
      "111/194, train_loss: 0.7928\n",
      "112/194, train_loss: 0.7365\n",
      "113/194, train_loss: 0.7510\n",
      "114/194, train_loss: 0.7420\n",
      "115/194, train_loss: 0.8115\n",
      "116/194, train_loss: 0.7822\n",
      "117/194, train_loss: 0.7735\n",
      "118/194, train_loss: 0.7618\n",
      "119/194, train_loss: 0.6697\n",
      "120/194, train_loss: 0.8520\n",
      "121/194, train_loss: 0.7447\n",
      "122/194, train_loss: 0.6494\n",
      "123/194, train_loss: 0.9001\n",
      "124/194, train_loss: 0.8218\n",
      "125/194, train_loss: 0.8344\n",
      "126/194, train_loss: 0.7468\n",
      "127/194, train_loss: 0.8732\n",
      "128/194, train_loss: 0.7291\n",
      "129/194, train_loss: 0.8943\n",
      "130/194, train_loss: 0.6750\n",
      "131/194, train_loss: 0.6218\n",
      "132/194, train_loss: 0.8394\n",
      "133/194, train_loss: 0.8610\n",
      "134/194, train_loss: 0.7532\n",
      "135/194, train_loss: 0.6947\n",
      "136/194, train_loss: 0.6788\n",
      "137/194, train_loss: 0.7313\n",
      "138/194, train_loss: 0.6371\n",
      "139/194, train_loss: 0.7292\n",
      "140/194, train_loss: 0.6518\n",
      "141/194, train_loss: 0.7723\n",
      "142/194, train_loss: 0.8349\n",
      "143/194, train_loss: 0.8077\n",
      "144/194, train_loss: 0.8650\n",
      "145/194, train_loss: 0.8425\n",
      "146/194, train_loss: 0.8014\n",
      "147/194, train_loss: 0.9301\n",
      "148/194, train_loss: 0.8662\n",
      "149/194, train_loss: 0.9122\n",
      "150/194, train_loss: 0.8775\n",
      "151/194, train_loss: 0.8677\n",
      "152/194, train_loss: 0.8072\n",
      "153/194, train_loss: 0.7999\n",
      "154/194, train_loss: 0.9198\n",
      "155/194, train_loss: 0.5848\n",
      "156/194, train_loss: 0.7365\n",
      "157/194, train_loss: 0.7359\n",
      "158/194, train_loss: 0.9474\n",
      "159/194, train_loss: 0.7482\n",
      "160/194, train_loss: 0.9593\n",
      "161/194, train_loss: 0.9906\n",
      "162/194, train_loss: 0.8466\n",
      "163/194, train_loss: 0.9057\n",
      "164/194, train_loss: 0.6049\n",
      "165/194, train_loss: 0.7906\n",
      "166/194, train_loss: 0.7383\n",
      "167/194, train_loss: 0.5411\n",
      "168/194, train_loss: 0.8513\n",
      "169/194, train_loss: 0.8641\n",
      "170/194, train_loss: 0.8361\n",
      "171/194, train_loss: 0.7927\n",
      "172/194, train_loss: 0.9030\n",
      "173/194, train_loss: 0.7298\n",
      "174/194, train_loss: 0.7688\n",
      "175/194, train_loss: 0.7888\n",
      "176/194, train_loss: 0.8533\n",
      "177/194, train_loss: 0.7764\n",
      "178/194, train_loss: 0.8503\n",
      "179/194, train_loss: 0.7412\n",
      "180/194, train_loss: 0.7110\n",
      "181/194, train_loss: 0.7169\n",
      "182/194, train_loss: 0.6571\n",
      "183/194, train_loss: 0.9137\n",
      "184/194, train_loss: 0.7234\n",
      "185/194, train_loss: 0.9077\n",
      "186/194, train_loss: 0.8513\n",
      "187/194, train_loss: 0.9410\n",
      "188/194, train_loss: 0.7343\n",
      "189/194, train_loss: 0.7443\n",
      "190/194, train_loss: 0.7780\n",
      "191/194, train_loss: 0.7633\n",
      "192/194, train_loss: 0.8635\n",
      "193/194, train_loss: 0.7949\n",
      "194/194, train_loss: 0.8465\n",
      "metric=0.366568633976082, metric_tc=0.38539723322416347, metric_wt=0.5011071662108103, metric_et=0.21320149783665934\n",
      "metric=0.366568633976082, metric_tc=0.38539723322416347, metric_wt=0.5011071662108103, metric_et=0.21320149783665934\n",
      "current epoch: 60 current epoch loss: 0.7787\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 60/80 [11:10:13<3:35:09, 645.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metric=0.366568633976082, metric_tc=0.38539723322416347, metric_wt=0.5011071662108103, metric_et=0.21320149783665934\n",
      "0.366568633976082\n",
      "current epoch: 60 current mean dice: 0.3666 tc: 0.3854 wt: 0.5011 et: 0.2132\n",
      "best mean dice: 0.3914 at epoch: 59\n",
      "\n",
      " | Global Training Round : 61 |\n",
      "\n",
      "user 0 selected\n",
      "local epoch 1\n",
      "1/194, train_loss: 0.7946\n",
      "2/194, train_loss: 0.5651\n",
      "3/194, train_loss: 0.9269\n",
      "4/194, train_loss: 0.6071\n",
      "5/194, train_loss: 0.7043\n",
      "6/194, train_loss: 0.8760\n",
      "7/194, train_loss: 0.7538\n",
      "8/194, train_loss: 0.7650\n",
      "9/194, train_loss: 0.8493\n",
      "10/194, train_loss: 0.6054\n",
      "11/194, train_loss: 0.8265\n",
      "12/194, train_loss: 0.8341\n",
      "13/194, train_loss: 0.7790\n",
      "14/194, train_loss: 0.5706\n",
      "15/194, train_loss: 0.8358\n",
      "16/194, train_loss: 0.7807\n",
      "17/194, train_loss: 0.7801\n",
      "18/194, train_loss: 0.8302\n",
      "19/194, train_loss: 0.6728\n",
      "20/194, train_loss: 0.8384\n",
      "21/194, train_loss: 0.6830\n",
      "22/194, train_loss: 0.8302\n",
      "23/194, train_loss: 0.7427\n",
      "24/194, train_loss: 0.7078\n",
      "25/194, train_loss: 0.7319\n",
      "26/194, train_loss: 0.7423\n",
      "27/194, train_loss: 0.7820\n",
      "28/194, train_loss: 0.8023\n",
      "29/194, train_loss: 0.7289\n",
      "30/194, train_loss: 0.5246\n",
      "31/194, train_loss: 0.7473\n",
      "32/194, train_loss: 0.8690\n",
      "33/194, train_loss: 0.8625\n",
      "34/194, train_loss: 0.7138\n",
      "35/194, train_loss: 0.7972\n",
      "36/194, train_loss: 0.9645\n",
      "37/194, train_loss: 0.7748\n",
      "38/194, train_loss: 0.7138\n",
      "39/194, train_loss: 0.7877\n",
      "40/194, train_loss: 0.6218\n",
      "41/194, train_loss: 0.8706\n",
      "42/194, train_loss: 0.9649\n",
      "43/194, train_loss: 0.9186\n",
      "44/194, train_loss: 0.7845\n",
      "45/194, train_loss: 0.8466\n",
      "46/194, train_loss: 0.8105\n",
      "47/194, train_loss: 0.5837\n",
      "48/194, train_loss: 0.7886\n",
      "49/194, train_loss: 0.6785\n",
      "50/194, train_loss: 0.7623\n",
      "51/194, train_loss: 0.8807\n",
      "52/194, train_loss: 0.6370\n",
      "53/194, train_loss: 0.7766\n",
      "54/194, train_loss: 0.7333\n",
      "55/194, train_loss: 0.9040\n",
      "56/194, train_loss: 0.7331\n",
      "57/194, train_loss: 0.8873\n",
      "58/194, train_loss: 0.7252\n",
      "59/194, train_loss: 0.9585\n",
      "60/194, train_loss: 0.8843\n",
      "61/194, train_loss: 0.8222\n",
      "62/194, train_loss: 0.8422\n",
      "63/194, train_loss: 0.8329\n",
      "64/194, train_loss: 0.8383\n",
      "65/194, train_loss: 0.7872\n",
      "66/194, train_loss: 0.9126\n",
      "67/194, train_loss: 0.8562\n",
      "68/194, train_loss: 0.7118\n",
      "69/194, train_loss: 0.8833\n",
      "70/194, train_loss: 0.7522\n",
      "71/194, train_loss: 0.7543\n",
      "72/194, train_loss: 0.8603\n",
      "73/194, train_loss: 0.8188\n",
      "74/194, train_loss: 0.6638\n",
      "75/194, train_loss: 0.7423\n",
      "76/194, train_loss: 0.7641\n",
      "77/194, train_loss: 0.7535\n",
      "78/194, train_loss: 0.8840\n",
      "79/194, train_loss: 0.6862\n",
      "80/194, train_loss: 0.6564\n",
      "81/194, train_loss: 0.7886\n",
      "82/194, train_loss: 0.8086\n",
      "83/194, train_loss: 0.7989\n",
      "84/194, train_loss: 0.7988\n",
      "85/194, train_loss: 0.8213\n",
      "86/194, train_loss: 0.7411\n",
      "87/194, train_loss: 0.8371\n",
      "88/194, train_loss: 0.7444\n",
      "89/194, train_loss: 0.6885\n",
      "90/194, train_loss: 0.6906\n",
      "91/194, train_loss: 0.7959\n",
      "92/194, train_loss: 0.7684\n",
      "93/194, train_loss: 0.7380\n",
      "94/194, train_loss: 0.8121\n",
      "95/194, train_loss: 0.7334\n",
      "96/194, train_loss: 0.8207\n",
      "97/194, train_loss: 0.8024\n",
      "98/194, train_loss: 0.8323\n",
      "99/194, train_loss: 0.8327\n",
      "100/194, train_loss: 0.9316\n",
      "101/194, train_loss: 0.7635\n",
      "102/194, train_loss: 0.8852\n",
      "103/194, train_loss: 0.8298\n",
      "104/194, train_loss: 0.6383\n",
      "105/194, train_loss: 0.6689\n",
      "106/194, train_loss: 0.6733\n",
      "107/194, train_loss: 0.8142\n",
      "108/194, train_loss: 0.6380\n",
      "109/194, train_loss: 0.7446\n",
      "110/194, train_loss: 0.6963\n",
      "111/194, train_loss: 0.7307\n",
      "112/194, train_loss: 0.7261\n",
      "113/194, train_loss: 0.7539\n",
      "114/194, train_loss: 0.7588\n",
      "115/194, train_loss: 0.8229\n",
      "116/194, train_loss: 0.7573\n",
      "117/194, train_loss: 0.6429\n",
      "118/194, train_loss: 0.7869\n",
      "119/194, train_loss: 0.7377\n",
      "120/194, train_loss: 0.6735\n",
      "121/194, train_loss: 0.8508\n",
      "122/194, train_loss: 0.7629\n",
      "123/194, train_loss: 0.7577\n",
      "124/194, train_loss: 0.8012\n",
      "125/194, train_loss: 0.5186\n",
      "126/194, train_loss: 0.8047\n",
      "127/194, train_loss: 0.8727\n",
      "128/194, train_loss: 0.6539\n",
      "129/194, train_loss: 0.7665\n",
      "130/194, train_loss: 0.7658\n",
      "131/194, train_loss: 0.7898\n",
      "132/194, train_loss: 0.8539\n",
      "133/194, train_loss: 0.8423\n",
      "134/194, train_loss: 0.6830\n",
      "135/194, train_loss: 0.9850\n",
      "136/194, train_loss: 0.8636\n",
      "137/194, train_loss: 0.8747\n",
      "138/194, train_loss: 0.9593\n",
      "139/194, train_loss: 0.7330\n",
      "140/194, train_loss: 0.7252\n",
      "141/194, train_loss: 0.7806\n",
      "142/194, train_loss: 0.8253\n",
      "143/194, train_loss: 0.8553\n",
      "144/194, train_loss: 0.8732\n",
      "145/194, train_loss: 0.6437\n",
      "146/194, train_loss: 0.9230\n",
      "147/194, train_loss: 0.6858\n",
      "148/194, train_loss: 0.8034\n",
      "149/194, train_loss: 0.9340\n",
      "150/194, train_loss: 0.7449\n",
      "151/194, train_loss: 0.9440\n",
      "152/194, train_loss: 0.9081\n",
      "153/194, train_loss: 0.7645\n",
      "154/194, train_loss: 0.8468\n",
      "155/194, train_loss: 0.7782\n",
      "156/194, train_loss: 0.8071\n",
      "157/194, train_loss: 0.6932\n",
      "158/194, train_loss: 0.7692\n",
      "159/194, train_loss: 0.8635\n",
      "160/194, train_loss: 0.5131\n",
      "161/194, train_loss: 0.8219\n",
      "162/194, train_loss: 0.8111\n",
      "163/194, train_loss: 0.8229\n",
      "164/194, train_loss: 0.7618\n",
      "165/194, train_loss: 0.7642\n",
      "166/194, train_loss: 0.7637\n",
      "167/194, train_loss: 0.8929\n",
      "168/194, train_loss: 0.8833\n",
      "169/194, train_loss: 0.7548\n",
      "170/194, train_loss: 0.6760\n",
      "171/194, train_loss: 0.7045\n",
      "172/194, train_loss: 0.7773\n",
      "173/194, train_loss: 0.7603\n",
      "174/194, train_loss: 0.6778\n",
      "175/194, train_loss: 0.7176\n",
      "176/194, train_loss: 0.8494\n",
      "177/194, train_loss: 0.8824\n",
      "178/194, train_loss: 0.7275\n",
      "179/194, train_loss: 0.7540\n",
      "180/194, train_loss: 0.6254\n",
      "181/194, train_loss: 0.8651\n",
      "182/194, train_loss: 0.6665\n",
      "183/194, train_loss: 0.6668\n",
      "184/194, train_loss: 0.7390\n",
      "185/194, train_loss: 0.8778\n",
      "186/194, train_loss: 0.7268\n",
      "187/194, train_loss: 0.9004\n",
      "188/194, train_loss: 0.8195\n",
      "189/194, train_loss: 0.8939\n",
      "190/194, train_loss: 0.7762\n",
      "191/194, train_loss: 0.8634\n",
      "192/194, train_loss: 0.8644\n",
      "193/194, train_loss: 0.7487\n",
      "194/194, train_loss: 0.9286\n",
      "metric=0.3769080936908722, metric_tc=0.40587809557716054, metric_wt=0.4966975847880046, metric_et=0.22814860264770687\n",
      "metric=0.3769080936908722, metric_tc=0.40587809557716054, metric_wt=0.4966975847880046, metric_et=0.22814860264770687\n",
      "current epoch: 61 current epoch loss: 0.7804\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▋  | 61/80 [11:19:55<3:18:19, 626.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metric=0.3769080936908722, metric_tc=0.40587809557716054, metric_wt=0.4966975847880046, metric_et=0.22814860264770687\n",
      "0.3769080936908722\n",
      "current epoch: 61 current mean dice: 0.3769 tc: 0.4059 wt: 0.4967 et: 0.2281\n",
      "best mean dice: 0.3914 at epoch: 59\n",
      "\n",
      " | Global Training Round : 62 |\n",
      "\n",
      "user 0 selected\n",
      "local epoch 1\n",
      "1/194, train_loss: 0.7614\n",
      "2/194, train_loss: 0.7643\n",
      "3/194, train_loss: 0.8140\n",
      "4/194, train_loss: 0.5804\n",
      "5/194, train_loss: 0.8954\n",
      "6/194, train_loss: 0.7837\n",
      "7/194, train_loss: 0.6515\n",
      "8/194, train_loss: 0.7388\n",
      "9/194, train_loss: 0.8359\n",
      "10/194, train_loss: 0.9126\n",
      "11/194, train_loss: 0.7937\n",
      "12/194, train_loss: 0.8391\n",
      "13/194, train_loss: 0.6393\n",
      "14/194, train_loss: 0.8683\n",
      "15/194, train_loss: 0.6886\n",
      "16/194, train_loss: 0.6049\n",
      "17/194, train_loss: 0.7062\n",
      "18/194, train_loss: 0.7970\n",
      "19/194, train_loss: 0.7804\n",
      "20/194, train_loss: 0.7468\n",
      "21/194, train_loss: 0.6774\n",
      "22/194, train_loss: 0.6981\n",
      "23/194, train_loss: 0.6932\n",
      "24/194, train_loss: 0.6315\n",
      "25/194, train_loss: 0.8899\n",
      "26/194, train_loss: 0.5852\n",
      "27/194, train_loss: 0.7533\n",
      "28/194, train_loss: 0.8684\n",
      "29/194, train_loss: 0.7523\n",
      "30/194, train_loss: 0.6634\n",
      "31/194, train_loss: 0.5574\n",
      "32/194, train_loss: 0.5838\n",
      "33/194, train_loss: 0.6810\n",
      "34/194, train_loss: 0.8218\n",
      "35/194, train_loss: 0.6899\n",
      "36/194, train_loss: 0.7901\n",
      "37/194, train_loss: 0.8190\n",
      "38/194, train_loss: 0.7781\n",
      "39/194, train_loss: 0.8307\n",
      "40/194, train_loss: 0.7470\n",
      "41/194, train_loss: 0.8090\n",
      "42/194, train_loss: 0.7502\n",
      "43/194, train_loss: 0.8726\n",
      "44/194, train_loss: 0.6884\n",
      "45/194, train_loss: 0.7302\n",
      "46/194, train_loss: 0.7007\n",
      "47/194, train_loss: 0.8539\n",
      "48/194, train_loss: 0.7338\n",
      "49/194, train_loss: 0.5770\n",
      "50/194, train_loss: 0.7724\n",
      "51/194, train_loss: 0.7273\n",
      "52/194, train_loss: 0.6005\n",
      "53/194, train_loss: 0.7087\n",
      "54/194, train_loss: 0.7956\n",
      "55/194, train_loss: 0.7310\n",
      "56/194, train_loss: 0.8112\n",
      "57/194, train_loss: 0.6206\n",
      "58/194, train_loss: 0.7416\n",
      "59/194, train_loss: 0.7990\n",
      "60/194, train_loss: 0.7352\n",
      "61/194, train_loss: 0.8294\n",
      "62/194, train_loss: 0.8651\n",
      "63/194, train_loss: 0.7738\n",
      "64/194, train_loss: 0.7227\n",
      "65/194, train_loss: 0.8049\n",
      "66/194, train_loss: 0.6874\n",
      "67/194, train_loss: 0.7228\n",
      "68/194, train_loss: 0.7477\n",
      "69/194, train_loss: 0.6623\n",
      "70/194, train_loss: 0.7793\n",
      "71/194, train_loss: 0.8236\n",
      "72/194, train_loss: 0.9129\n",
      "73/194, train_loss: 0.6963\n",
      "74/194, train_loss: 0.7885\n",
      "75/194, train_loss: 0.7844\n",
      "76/194, train_loss: 0.7424\n",
      "77/194, train_loss: 0.7251\n",
      "78/194, train_loss: 0.7341\n",
      "79/194, train_loss: 0.6932\n",
      "80/194, train_loss: 0.9744\n",
      "81/194, train_loss: 0.7141\n",
      "82/194, train_loss: 0.7603\n",
      "83/194, train_loss: 0.7960\n",
      "84/194, train_loss: 0.6988\n",
      "85/194, train_loss: 0.7508\n",
      "86/194, train_loss: 0.9377\n",
      "87/194, train_loss: 0.8051\n",
      "88/194, train_loss: 0.7186\n",
      "89/194, train_loss: 0.7803\n",
      "90/194, train_loss: 0.9072\n",
      "91/194, train_loss: 0.7044\n",
      "92/194, train_loss: 0.7340\n",
      "93/194, train_loss: 0.7432\n",
      "94/194, train_loss: 0.7641\n",
      "95/194, train_loss: 0.6806\n",
      "96/194, train_loss: 0.8340\n",
      "97/194, train_loss: 0.7169\n",
      "98/194, train_loss: 0.7873\n",
      "99/194, train_loss: 0.9151\n",
      "100/194, train_loss: 0.7880\n",
      "101/194, train_loss: 0.8640\n",
      "102/194, train_loss: 0.8033\n",
      "103/194, train_loss: 0.5647\n",
      "104/194, train_loss: 0.7693\n",
      "105/194, train_loss: 0.6741\n",
      "106/194, train_loss: 0.4723\n",
      "107/194, train_loss: 0.8366\n",
      "108/194, train_loss: 0.7737\n",
      "109/194, train_loss: 0.6822\n",
      "110/194, train_loss: 0.7775\n",
      "111/194, train_loss: 0.6521\n",
      "112/194, train_loss: 0.6515\n",
      "113/194, train_loss: 0.8764\n",
      "114/194, train_loss: 0.8303\n",
      "115/194, train_loss: 0.7313\n",
      "116/194, train_loss: 0.7887\n",
      "117/194, train_loss: 0.7721\n",
      "118/194, train_loss: 0.8204\n",
      "119/194, train_loss: 0.9126\n",
      "120/194, train_loss: 0.8650\n",
      "121/194, train_loss: 0.8692\n",
      "122/194, train_loss: 0.7802\n",
      "123/194, train_loss: 0.6107\n",
      "124/194, train_loss: 0.9244\n",
      "125/194, train_loss: 0.9347\n",
      "126/194, train_loss: 0.8643\n",
      "127/194, train_loss: 0.7848\n",
      "128/194, train_loss: 0.8292\n",
      "129/194, train_loss: 0.8529\n",
      "130/194, train_loss: 0.8189\n",
      "131/194, train_loss: 0.5139\n",
      "132/194, train_loss: 0.8236\n",
      "133/194, train_loss: 0.8270\n",
      "134/194, train_loss: 0.8580\n",
      "135/194, train_loss: 0.8617\n",
      "136/194, train_loss: 0.7099\n",
      "137/194, train_loss: 0.7973\n",
      "138/194, train_loss: 0.8993\n",
      "139/194, train_loss: 0.8611\n",
      "140/194, train_loss: 0.7183\n",
      "141/194, train_loss: 0.9457\n",
      "142/194, train_loss: 0.8434\n",
      "143/194, train_loss: 0.8373\n",
      "144/194, train_loss: 0.8183\n",
      "145/194, train_loss: 0.7284\n",
      "146/194, train_loss: 0.8505\n",
      "147/194, train_loss: 0.8344\n",
      "148/194, train_loss: 0.7630\n",
      "149/194, train_loss: 0.8220\n",
      "150/194, train_loss: 0.8208\n",
      "151/194, train_loss: 0.9117\n",
      "152/194, train_loss: 0.8491\n",
      "153/194, train_loss: 0.8087\n",
      "154/194, train_loss: 0.7217\n",
      "155/194, train_loss: 0.9249\n",
      "156/194, train_loss: 0.8483\n",
      "157/194, train_loss: 0.7808\n",
      "158/194, train_loss: 0.8569\n",
      "159/194, train_loss: 0.8094\n",
      "160/194, train_loss: 0.7941\n",
      "161/194, train_loss: 0.8242\n",
      "162/194, train_loss: 0.8375\n",
      "163/194, train_loss: 0.8600\n",
      "164/194, train_loss: 0.7118\n",
      "165/194, train_loss: 0.8618\n",
      "166/194, train_loss: 0.7406\n",
      "167/194, train_loss: 0.7334\n",
      "168/194, train_loss: 0.8650\n",
      "169/194, train_loss: 0.7570\n",
      "170/194, train_loss: 0.6971\n",
      "171/194, train_loss: 0.7550\n",
      "172/194, train_loss: 0.7913\n",
      "173/194, train_loss: 0.7978\n",
      "174/194, train_loss: 0.8476\n",
      "175/194, train_loss: 0.7045\n",
      "176/194, train_loss: 0.7303\n",
      "177/194, train_loss: 0.7406\n",
      "178/194, train_loss: 0.8412\n",
      "179/194, train_loss: 0.8682\n",
      "180/194, train_loss: 0.7164\n",
      "181/194, train_loss: 0.7314\n",
      "182/194, train_loss: 0.7018\n",
      "183/194, train_loss: 0.8007\n",
      "184/194, train_loss: 0.6476\n",
      "185/194, train_loss: 0.8294\n",
      "186/194, train_loss: 0.8496\n",
      "187/194, train_loss: 0.8101\n",
      "188/194, train_loss: 0.7488\n",
      "189/194, train_loss: 0.9686\n",
      "190/194, train_loss: 0.8635\n",
      "191/194, train_loss: 0.8741\n",
      "192/194, train_loss: 0.9559\n",
      "193/194, train_loss: 0.7518\n",
      "194/194, train_loss: 0.8824\n",
      "metric=0.342343266432484, metric_tc=0.3660971629433334, metric_wt=0.45922035599748295, metric_et=0.2017122775238628\n",
      "metric=0.342343266432484, metric_tc=0.3660971629433334, metric_wt=0.45922035599748295, metric_et=0.2017122775238628\n",
      "current epoch: 62 current epoch loss: 0.7753\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 62/80 [11:29:40<3:04:09, 613.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metric=0.342343266432484, metric_tc=0.3660971629433334, metric_wt=0.45922035599748295, metric_et=0.2017122775238628\n",
      "0.342343266432484\n",
      "current epoch: 62 current mean dice: 0.3423 tc: 0.3661 wt: 0.4592 et: 0.2017\n",
      "best mean dice: 0.3914 at epoch: 59\n",
      "\n",
      " | Global Training Round : 63 |\n",
      "\n",
      "user 0 selected\n",
      "local epoch 1\n",
      "1/194, train_loss: 0.7947\n",
      "2/194, train_loss: 0.8243\n",
      "3/194, train_loss: 0.6489\n",
      "4/194, train_loss: 0.7877\n",
      "5/194, train_loss: 0.8969\n",
      "6/194, train_loss: 0.8060\n",
      "7/194, train_loss: 0.8727\n",
      "8/194, train_loss: 0.7694\n",
      "9/194, train_loss: 0.5537\n",
      "10/194, train_loss: 0.6773\n",
      "11/194, train_loss: 0.8685\n",
      "12/194, train_loss: 0.6994\n",
      "13/194, train_loss: 0.7767\n",
      "14/194, train_loss: 0.8404\n",
      "15/194, train_loss: 0.6635\n",
      "16/194, train_loss: 0.6910\n",
      "17/194, train_loss: 0.7109\n",
      "18/194, train_loss: 0.6999\n",
      "19/194, train_loss: 0.7483\n",
      "20/194, train_loss: 0.6007\n",
      "21/194, train_loss: 0.6994\n",
      "22/194, train_loss: 0.7646\n",
      "23/194, train_loss: 0.8336\n",
      "24/194, train_loss: 0.6923\n",
      "25/194, train_loss: 0.8368\n",
      "26/194, train_loss: 0.7874\n",
      "27/194, train_loss: 0.9393\n",
      "28/194, train_loss: 0.7791\n",
      "29/194, train_loss: 0.8603\n",
      "30/194, train_loss: 0.8069\n",
      "31/194, train_loss: 0.8360\n",
      "32/194, train_loss: 0.6386\n",
      "33/194, train_loss: 0.7801\n",
      "34/194, train_loss: 0.8901\n",
      "35/194, train_loss: 0.9357\n",
      "36/194, train_loss: 0.8028\n",
      "37/194, train_loss: 0.7444\n",
      "38/194, train_loss: 0.6808\n",
      "39/194, train_loss: 0.7264\n",
      "40/194, train_loss: 0.6718\n",
      "41/194, train_loss: 0.8848\n",
      "42/194, train_loss: 0.7489\n",
      "43/194, train_loss: 0.8640\n",
      "44/194, train_loss: 0.7521\n",
      "45/194, train_loss: 0.6397\n",
      "46/194, train_loss: 0.8587\n",
      "47/194, train_loss: 0.7439\n",
      "48/194, train_loss: 0.6803\n",
      "49/194, train_loss: 0.7101\n",
      "50/194, train_loss: 0.6765\n",
      "51/194, train_loss: 0.6605\n",
      "52/194, train_loss: 0.7522\n",
      "53/194, train_loss: 0.8606\n",
      "54/194, train_loss: 0.7445\n",
      "55/194, train_loss: 0.8921\n",
      "56/194, train_loss: 0.7020\n",
      "57/194, train_loss: 0.7867\n",
      "58/194, train_loss: 0.8683\n",
      "59/194, train_loss: 0.7722\n",
      "60/194, train_loss: 0.8143\n",
      "61/194, train_loss: 0.7961\n",
      "62/194, train_loss: 0.6379\n",
      "63/194, train_loss: 0.6146\n",
      "64/194, train_loss: 0.7063\n",
      "65/194, train_loss: 0.7534\n",
      "66/194, train_loss: 0.8664\n",
      "67/194, train_loss: 0.8837\n",
      "68/194, train_loss: 0.6856\n",
      "69/194, train_loss: 0.6528\n",
      "70/194, train_loss: 0.7754\n",
      "71/194, train_loss: 0.8587\n",
      "72/194, train_loss: 0.8901\n",
      "73/194, train_loss: 0.6850\n",
      "74/194, train_loss: 0.7715\n",
      "75/194, train_loss: 0.7397\n",
      "76/194, train_loss: 0.7296\n",
      "77/194, train_loss: 0.8004\n",
      "78/194, train_loss: 0.9396\n",
      "79/194, train_loss: 0.7627\n",
      "80/194, train_loss: 0.6229\n",
      "81/194, train_loss: 0.8758\n",
      "82/194, train_loss: 0.6647\n",
      "83/194, train_loss: 0.7573\n",
      "84/194, train_loss: 0.8127\n",
      "85/194, train_loss: 0.6930\n",
      "86/194, train_loss: 0.7221\n",
      "87/194, train_loss: 0.8389\n",
      "88/194, train_loss: 0.8386\n",
      "89/194, train_loss: 0.8711\n",
      "90/194, train_loss: 0.6663\n",
      "91/194, train_loss: 0.8462\n",
      "92/194, train_loss: 0.8505\n",
      "93/194, train_loss: 0.7286\n",
      "94/194, train_loss: 0.8375\n",
      "95/194, train_loss: 0.7374\n",
      "96/194, train_loss: 0.7655\n",
      "97/194, train_loss: 0.8233\n",
      "98/194, train_loss: 0.7697\n",
      "99/194, train_loss: 0.6727\n",
      "100/194, train_loss: 0.8570\n",
      "101/194, train_loss: 0.8177\n",
      "102/194, train_loss: 0.8167\n",
      "103/194, train_loss: 0.9524\n",
      "104/194, train_loss: 0.8218\n",
      "105/194, train_loss: 0.7481\n",
      "106/194, train_loss: 0.9142\n",
      "107/194, train_loss: 0.6445\n",
      "108/194, train_loss: 0.6399\n",
      "109/194, train_loss: 0.8288\n",
      "110/194, train_loss: 0.7953\n",
      "111/194, train_loss: 0.8269\n",
      "112/194, train_loss: 0.8599\n",
      "113/194, train_loss: 0.7612\n",
      "114/194, train_loss: 0.7487\n",
      "115/194, train_loss: 0.8341\n",
      "116/194, train_loss: 0.7173\n",
      "117/194, train_loss: 0.8965\n",
      "118/194, train_loss: 0.7118\n",
      "119/194, train_loss: 0.6574\n",
      "120/194, train_loss: 0.8909\n",
      "121/194, train_loss: 0.6425\n",
      "122/194, train_loss: 0.7336\n",
      "123/194, train_loss: 0.7565\n",
      "124/194, train_loss: 0.7781\n",
      "125/194, train_loss: 0.9067\n",
      "126/194, train_loss: 0.8262\n",
      "127/194, train_loss: 0.7853\n",
      "128/194, train_loss: 0.9411\n",
      "129/194, train_loss: 0.6935\n",
      "130/194, train_loss: 0.7238\n",
      "131/194, train_loss: 0.8667\n",
      "132/194, train_loss: 0.8273\n",
      "133/194, train_loss: 0.8123\n",
      "134/194, train_loss: 0.5813\n",
      "135/194, train_loss: 0.8945\n",
      "136/194, train_loss: 0.8172\n",
      "137/194, train_loss: 0.7607\n",
      "138/194, train_loss: 0.6228\n",
      "139/194, train_loss: 0.5194\n",
      "140/194, train_loss: 0.5928\n",
      "141/194, train_loss: 0.6865\n",
      "142/194, train_loss: 0.8130\n",
      "143/194, train_loss: 0.8067\n",
      "144/194, train_loss: 0.8512\n",
      "145/194, train_loss: 0.7638\n",
      "146/194, train_loss: 0.7770\n",
      "147/194, train_loss: 0.9356\n",
      "148/194, train_loss: 0.9251\n",
      "149/194, train_loss: 0.8812\n",
      "150/194, train_loss: 0.9353\n",
      "151/194, train_loss: 0.8775\n",
      "152/194, train_loss: 0.9022\n",
      "153/194, train_loss: 0.9144\n",
      "154/194, train_loss: 0.9648\n",
      "155/194, train_loss: 0.8736\n",
      "156/194, train_loss: 0.8804\n",
      "157/194, train_loss: 0.8126\n",
      "158/194, train_loss: 0.8815\n",
      "159/194, train_loss: 0.9109\n",
      "160/194, train_loss: 0.8819\n",
      "161/194, train_loss: 0.8605\n",
      "162/194, train_loss: 0.7971\n",
      "163/194, train_loss: 0.8311\n",
      "164/194, train_loss: 0.7917\n",
      "165/194, train_loss: 0.9533\n",
      "166/194, train_loss: 0.8690\n",
      "167/194, train_loss: 0.6737\n",
      "168/194, train_loss: 0.6856\n",
      "169/194, train_loss: 0.7622\n",
      "170/194, train_loss: 0.7342\n",
      "171/194, train_loss: 0.8069\n",
      "172/194, train_loss: 0.8036\n",
      "173/194, train_loss: 0.8630\n",
      "174/194, train_loss: 0.8163\n",
      "175/194, train_loss: 0.6511\n",
      "176/194, train_loss: 0.7028\n",
      "177/194, train_loss: 0.6790\n",
      "178/194, train_loss: 0.6949\n",
      "179/194, train_loss: 0.5792\n",
      "180/194, train_loss: 0.6861\n",
      "181/194, train_loss: 0.7350\n",
      "182/194, train_loss: 0.8347\n",
      "183/194, train_loss: 0.5547\n",
      "184/194, train_loss: 0.7049\n",
      "185/194, train_loss: 0.8477\n",
      "186/194, train_loss: 0.8714\n",
      "187/194, train_loss: 0.7421\n",
      "188/194, train_loss: 0.8395\n",
      "189/194, train_loss: 0.8435\n",
      "190/194, train_loss: 0.8399\n",
      "191/194, train_loss: 0.8303\n",
      "192/194, train_loss: 0.8887\n",
      "193/194, train_loss: 0.8779\n",
      "194/194, train_loss: 0.8607\n",
      "metric=0.39053297881036997, metric_tc=0.416862631837527, metric_wt=0.5162192328522602, metric_et=0.23851708772902688\n",
      "metric=0.39053297881036997, metric_tc=0.416862631837527, metric_wt=0.5162192328522602, metric_et=0.23851708772902688\n",
      "current epoch: 63 current epoch loss: 0.7815\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████▉  | 63/80 [11:39:35<2:52:20, 608.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metric=0.39053297881036997, metric_tc=0.416862631837527, metric_wt=0.5162192328522602, metric_et=0.23851708772902688\n",
      "0.39053297881036997\n",
      "current epoch: 63 current mean dice: 0.3905 tc: 0.4169 wt: 0.5162 et: 0.2385\n",
      "best mean dice: 0.3914 at epoch: 59\n",
      "\n",
      " | Global Training Round : 64 |\n",
      "\n",
      "user 0 selected\n",
      "local epoch 1\n",
      "1/194, train_loss: 0.9364\n",
      "2/194, train_loss: 0.6299\n",
      "3/194, train_loss: 0.7328\n",
      "4/194, train_loss: 0.8270\n",
      "5/194, train_loss: 0.7944\n",
      "6/194, train_loss: 0.8347\n",
      "7/194, train_loss: 0.8605\n",
      "8/194, train_loss: 0.7734\n",
      "9/194, train_loss: 0.8367\n",
      "10/194, train_loss: 0.6740\n",
      "11/194, train_loss: 0.8911\n",
      "12/194, train_loss: 0.8000\n",
      "13/194, train_loss: 0.8433\n",
      "14/194, train_loss: 0.7169\n",
      "15/194, train_loss: 0.7410\n",
      "16/194, train_loss: 0.7135\n",
      "17/194, train_loss: 0.8450\n",
      "18/194, train_loss: 0.8773\n",
      "19/194, train_loss: 0.7009\n",
      "20/194, train_loss: 0.6954\n",
      "21/194, train_loss: 0.8080\n",
      "22/194, train_loss: 0.8672\n",
      "23/194, train_loss: 0.6652\n",
      "24/194, train_loss: 0.8150\n",
      "25/194, train_loss: 0.7703\n",
      "26/194, train_loss: 0.8168\n",
      "27/194, train_loss: 0.7107\n",
      "28/194, train_loss: 0.8122\n",
      "29/194, train_loss: 0.8304\n",
      "30/194, train_loss: 0.8943\n",
      "31/194, train_loss: 0.7534\n",
      "32/194, train_loss: 0.7314\n",
      "33/194, train_loss: 0.7953\n",
      "34/194, train_loss: 0.6971\n",
      "35/194, train_loss: 0.9038\n",
      "36/194, train_loss: 0.7656\n",
      "37/194, train_loss: 0.7130\n",
      "38/194, train_loss: 0.7863\n",
      "39/194, train_loss: 0.8821\n",
      "40/194, train_loss: 0.8096\n",
      "41/194, train_loss: 0.6221\n",
      "42/194, train_loss: 0.6543\n",
      "43/194, train_loss: 0.7948\n",
      "44/194, train_loss: 0.7610\n",
      "45/194, train_loss: 0.7024\n",
      "46/194, train_loss: 0.8280\n",
      "47/194, train_loss: 0.6964\n",
      "48/194, train_loss: 0.6878\n",
      "49/194, train_loss: 0.9168\n",
      "50/194, train_loss: 0.8751\n",
      "51/194, train_loss: 0.7014\n",
      "52/194, train_loss: 0.7052\n",
      "53/194, train_loss: 0.6435\n",
      "54/194, train_loss: 0.8339\n",
      "55/194, train_loss: 0.6358\n",
      "56/194, train_loss: 0.6179\n",
      "57/194, train_loss: 0.7683\n",
      "58/194, train_loss: 0.8114\n",
      "59/194, train_loss: 0.7151\n",
      "60/194, train_loss: 0.9209\n",
      "61/194, train_loss: 0.7531\n",
      "62/194, train_loss: 0.7563\n",
      "63/194, train_loss: 0.6343\n",
      "64/194, train_loss: 0.6719\n",
      "65/194, train_loss: 0.7871\n",
      "66/194, train_loss: 0.7101\n",
      "67/194, train_loss: 0.7400\n",
      "68/194, train_loss: 0.7764\n",
      "69/194, train_loss: 0.7820\n",
      "70/194, train_loss: 0.7358\n",
      "71/194, train_loss: 0.7709\n",
      "72/194, train_loss: 0.8920\n",
      "73/194, train_loss: 0.7148\n",
      "74/194, train_loss: 0.8296\n",
      "75/194, train_loss: 0.7561\n",
      "76/194, train_loss: 0.7766\n",
      "77/194, train_loss: 0.5707\n",
      "78/194, train_loss: 0.6419\n",
      "79/194, train_loss: 0.8048\n",
      "80/194, train_loss: 0.6952\n",
      "81/194, train_loss: 0.7996\n",
      "82/194, train_loss: 0.7208\n",
      "83/194, train_loss: 0.8244\n",
      "84/194, train_loss: 0.8123\n",
      "85/194, train_loss: 0.8005\n",
      "86/194, train_loss: 0.7748\n",
      "87/194, train_loss: 0.8764\n",
      "88/194, train_loss: 0.9034\n",
      "89/194, train_loss: 0.7504\n",
      "90/194, train_loss: 0.7267\n",
      "91/194, train_loss: 0.9164\n",
      "92/194, train_loss: 0.6323\n",
      "93/194, train_loss: 0.5131\n",
      "94/194, train_loss: 0.7990\n",
      "95/194, train_loss: 0.7846\n",
      "96/194, train_loss: 0.7784\n",
      "97/194, train_loss: 0.8452\n",
      "98/194, train_loss: 0.8947\n",
      "99/194, train_loss: 0.7873\n",
      "100/194, train_loss: 0.8526\n",
      "101/194, train_loss: 0.8711\n",
      "102/194, train_loss: 0.7462\n",
      "103/194, train_loss: 0.9112\n",
      "104/194, train_loss: 0.8700\n",
      "105/194, train_loss: 0.7209\n",
      "106/194, train_loss: 0.7585\n",
      "107/194, train_loss: 0.8440\n",
      "108/194, train_loss: 0.7493\n",
      "109/194, train_loss: 0.6726\n",
      "110/194, train_loss: 0.5890\n",
      "111/194, train_loss: 0.8230\n",
      "112/194, train_loss: 0.7104\n",
      "113/194, train_loss: 0.8153\n",
      "114/194, train_loss: 0.6362\n",
      "115/194, train_loss: 0.7758\n",
      "116/194, train_loss: 0.7244\n",
      "117/194, train_loss: 0.8263\n",
      "118/194, train_loss: 0.8183\n",
      "119/194, train_loss: 0.8867\n",
      "120/194, train_loss: 0.6853\n",
      "121/194, train_loss: 0.6674\n",
      "122/194, train_loss: 0.7390\n",
      "123/194, train_loss: 0.7902\n",
      "124/194, train_loss: 0.9130\n",
      "125/194, train_loss: 0.7504\n",
      "126/194, train_loss: 0.7725\n",
      "127/194, train_loss: 0.9176\n",
      "128/194, train_loss: 0.8134\n",
      "129/194, train_loss: 0.7722\n",
      "130/194, train_loss: 0.7981\n",
      "131/194, train_loss: 0.8238\n",
      "132/194, train_loss: 0.9239\n",
      "133/194, train_loss: 0.5793\n",
      "134/194, train_loss: 0.7685\n",
      "135/194, train_loss: 0.5164\n",
      "136/194, train_loss: 0.6057\n",
      "137/194, train_loss: 0.6974\n",
      "138/194, train_loss: 0.8790\n",
      "139/194, train_loss: 0.6870\n",
      "140/194, train_loss: 0.7238\n",
      "141/194, train_loss: 0.8272\n",
      "142/194, train_loss: 0.7661\n",
      "143/194, train_loss: 0.6725\n",
      "144/194, train_loss: 0.8958\n",
      "145/194, train_loss: 0.8389\n",
      "146/194, train_loss: 0.7529\n",
      "147/194, train_loss: 0.9431\n",
      "148/194, train_loss: 0.8294\n",
      "149/194, train_loss: 0.8828\n",
      "150/194, train_loss: 0.7619\n",
      "151/194, train_loss: 0.8172\n",
      "152/194, train_loss: 0.8544\n",
      "153/194, train_loss: 0.8218\n",
      "154/194, train_loss: 0.9000\n",
      "155/194, train_loss: 0.9018\n",
      "156/194, train_loss: 0.8439\n",
      "157/194, train_loss: 0.8422\n",
      "158/194, train_loss: 0.8697\n",
      "159/194, train_loss: 0.8617\n",
      "160/194, train_loss: 0.7912\n",
      "161/194, train_loss: 0.8575\n",
      "162/194, train_loss: 0.8810\n",
      "163/194, train_loss: 0.8663\n",
      "164/194, train_loss: 0.8199\n",
      "165/194, train_loss: 0.9254\n",
      "166/194, train_loss: 0.8769\n",
      "167/194, train_loss: 0.7751\n",
      "168/194, train_loss: 0.8245\n",
      "169/194, train_loss: 0.5557\n",
      "170/194, train_loss: 0.7905\n",
      "171/194, train_loss: 0.8379\n",
      "172/194, train_loss: 0.6784\n",
      "173/194, train_loss: 0.6997\n",
      "174/194, train_loss: 0.6419\n",
      "175/194, train_loss: 0.9428\n",
      "176/194, train_loss: 0.5137\n",
      "177/194, train_loss: 0.8454\n",
      "178/194, train_loss: 0.7429\n",
      "179/194, train_loss: 0.9022\n",
      "180/194, train_loss: 0.7603\n",
      "181/194, train_loss: 0.8907\n",
      "182/194, train_loss: 0.6332\n",
      "183/194, train_loss: 0.7637\n",
      "184/194, train_loss: 0.7220\n",
      "185/194, train_loss: 0.8259\n",
      "186/194, train_loss: 0.8791\n",
      "187/194, train_loss: 0.8815\n",
      "188/194, train_loss: 0.8334\n",
      "189/194, train_loss: 0.7431\n",
      "190/194, train_loss: 0.8760\n",
      "191/194, train_loss: 0.8397\n",
      "192/194, train_loss: 0.6927\n",
      "193/194, train_loss: 0.7948\n",
      "194/194, train_loss: 0.7002\n",
      "metric=0.380642452587684, metric_tc=0.4076259483893712, metric_wt=0.5093984119594097, metric_et=0.2249030024977401\n",
      "metric=0.380642452587684, metric_tc=0.4076259483893712, metric_wt=0.5093984119594097, metric_et=0.2249030024977401\n",
      "current epoch: 64 current epoch loss: 0.7789\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 64/80 [11:50:15<2:44:45, 617.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metric=0.380642452587684, metric_tc=0.4076259483893712, metric_wt=0.5093984119594097, metric_et=0.2249030024977401\n",
      "0.380642452587684\n",
      "current epoch: 64 current mean dice: 0.3806 tc: 0.4076 wt: 0.5094 et: 0.2249\n",
      "best mean dice: 0.3914 at epoch: 59\n",
      "\n",
      " | Global Training Round : 65 |\n",
      "\n",
      "user 0 selected\n",
      "local epoch 1\n",
      "1/194, train_loss: 0.8503\n",
      "2/194, train_loss: 0.7584\n",
      "3/194, train_loss: 0.7276\n",
      "4/194, train_loss: 0.6854\n",
      "5/194, train_loss: 0.7459\n",
      "6/194, train_loss: 0.7649\n",
      "7/194, train_loss: 0.7383\n",
      "8/194, train_loss: 0.7758\n",
      "9/194, train_loss: 0.8273\n",
      "10/194, train_loss: 0.6672\n",
      "11/194, train_loss: 0.6460\n",
      "12/194, train_loss: 0.7368\n",
      "13/194, train_loss: 0.8023\n",
      "14/194, train_loss: 0.8261\n",
      "15/194, train_loss: 0.7108\n",
      "16/194, train_loss: 0.8116\n",
      "17/194, train_loss: 0.6682\n",
      "18/194, train_loss: 0.8066\n",
      "19/194, train_loss: 0.7784\n",
      "20/194, train_loss: 0.9030\n",
      "21/194, train_loss: 0.7829\n",
      "22/194, train_loss: 0.6786\n",
      "23/194, train_loss: 0.7788\n",
      "24/194, train_loss: 0.8024\n",
      "25/194, train_loss: 0.7777\n",
      "26/194, train_loss: 0.7441\n",
      "27/194, train_loss: 0.8775\n",
      "28/194, train_loss: 0.7294\n",
      "29/194, train_loss: 0.6716\n",
      "30/194, train_loss: 0.6996\n",
      "31/194, train_loss: 0.8328\n",
      "32/194, train_loss: 0.8142\n",
      "33/194, train_loss: 0.8674\n",
      "34/194, train_loss: 0.8815\n",
      "35/194, train_loss: 0.8907\n",
      "36/194, train_loss: 0.8276\n",
      "37/194, train_loss: 0.6545\n",
      "38/194, train_loss: 0.7521\n",
      "39/194, train_loss: 0.6276\n",
      "40/194, train_loss: 0.7794\n",
      "41/194, train_loss: 0.7562\n",
      "42/194, train_loss: 0.7356\n",
      "43/194, train_loss: 0.8042\n",
      "44/194, train_loss: 0.7955\n",
      "45/194, train_loss: 0.7044\n",
      "46/194, train_loss: 0.7206\n",
      "47/194, train_loss: 0.8644\n",
      "48/194, train_loss: 0.6293\n",
      "49/194, train_loss: 0.7369\n",
      "50/194, train_loss: 0.7461\n",
      "51/194, train_loss: 0.8762\n",
      "52/194, train_loss: 0.4729\n",
      "53/194, train_loss: 0.7941\n",
      "54/194, train_loss: 0.7034\n",
      "55/194, train_loss: 0.6769\n",
      "56/194, train_loss: 0.8838\n",
      "57/194, train_loss: 0.8428\n",
      "58/194, train_loss: 0.7767\n",
      "59/194, train_loss: 0.8600\n",
      "60/194, train_loss: 0.9292\n",
      "61/194, train_loss: 0.7607\n",
      "62/194, train_loss: 0.6041\n",
      "63/194, train_loss: 0.6979\n",
      "64/194, train_loss: 0.7368\n",
      "65/194, train_loss: 0.7069\n",
      "66/194, train_loss: 0.7836\n",
      "67/194, train_loss: 0.8517\n",
      "68/194, train_loss: 0.5799\n",
      "69/194, train_loss: 0.7646\n",
      "70/194, train_loss: 0.6784\n",
      "71/194, train_loss: 0.8513\n",
      "72/194, train_loss: 0.5670\n",
      "73/194, train_loss: 0.6699\n",
      "74/194, train_loss: 0.7712\n",
      "75/194, train_loss: 0.7657\n",
      "76/194, train_loss: 0.7588\n",
      "77/194, train_loss: 0.7264\n",
      "78/194, train_loss: 0.8098\n",
      "79/194, train_loss: 0.7365\n",
      "80/194, train_loss: 0.6478\n",
      "81/194, train_loss: 0.6650\n",
      "82/194, train_loss: 0.8289\n",
      "83/194, train_loss: 0.8624\n",
      "84/194, train_loss: 0.8717\n",
      "85/194, train_loss: 0.9132\n",
      "86/194, train_loss: 0.9618\n",
      "87/194, train_loss: 0.8855\n",
      "88/194, train_loss: 0.8813\n",
      "89/194, train_loss: 0.9110\n",
      "90/194, train_loss: 0.7252\n",
      "91/194, train_loss: 0.6736\n",
      "92/194, train_loss: 0.7208\n",
      "93/194, train_loss: 0.6425\n",
      "94/194, train_loss: 0.8061\n",
      "95/194, train_loss: 0.7456\n",
      "96/194, train_loss: 0.6518\n",
      "97/194, train_loss: 0.6635\n",
      "98/194, train_loss: 0.7594\n",
      "99/194, train_loss: 0.6046\n",
      "100/194, train_loss: 0.8331\n",
      "101/194, train_loss: 0.7772\n",
      "102/194, train_loss: 0.8631\n",
      "103/194, train_loss: 0.7065\n",
      "104/194, train_loss: 0.7814\n",
      "105/194, train_loss: 0.7603\n",
      "106/194, train_loss: 0.6080\n",
      "107/194, train_loss: 0.4991\n",
      "108/194, train_loss: 0.7468\n",
      "109/194, train_loss: 0.7342\n",
      "110/194, train_loss: 0.7305\n",
      "111/194, train_loss: 0.8430\n",
      "112/194, train_loss: 0.6929\n",
      "113/194, train_loss: 0.7869\n",
      "114/194, train_loss: 0.7050\n",
      "115/194, train_loss: 0.6600\n",
      "116/194, train_loss: 0.6241\n",
      "117/194, train_loss: 0.8953\n",
      "118/194, train_loss: 0.8076\n",
      "119/194, train_loss: 0.7917\n",
      "120/194, train_loss: 0.7875\n",
      "121/194, train_loss: 0.8034\n",
      "122/194, train_loss: 0.8949\n",
      "123/194, train_loss: 0.7507\n",
      "124/194, train_loss: 0.8963\n",
      "125/194, train_loss: 0.8009\n",
      "126/194, train_loss: 0.8316\n",
      "127/194, train_loss: 0.7513\n",
      "128/194, train_loss: 0.7744\n",
      "129/194, train_loss: 0.7510\n",
      "130/194, train_loss: 0.8517\n",
      "131/194, train_loss: 0.8492\n",
      "132/194, train_loss: 0.7813\n",
      "133/194, train_loss: 0.7255\n",
      "134/194, train_loss: 0.7800\n",
      "135/194, train_loss: 0.7185\n",
      "136/194, train_loss: 0.8187\n",
      "137/194, train_loss: 0.8814\n",
      "138/194, train_loss: 0.6672\n",
      "139/194, train_loss: 0.5674\n",
      "140/194, train_loss: 0.8010\n",
      "141/194, train_loss: 0.7376\n",
      "142/194, train_loss: 0.8878\n",
      "143/194, train_loss: 0.7544\n",
      "144/194, train_loss: 0.8356\n",
      "145/194, train_loss: 0.7789\n",
      "146/194, train_loss: 0.7102\n",
      "147/194, train_loss: 0.8112\n",
      "148/194, train_loss: 0.8116\n",
      "149/194, train_loss: 0.8735\n",
      "150/194, train_loss: 0.7269\n",
      "151/194, train_loss: 0.9645\n",
      "152/194, train_loss: 0.8181\n",
      "153/194, train_loss: 0.7630\n",
      "154/194, train_loss: 0.9239\n",
      "155/194, train_loss: 0.9380\n",
      "156/194, train_loss: 0.9266\n",
      "157/194, train_loss: 0.8253\n",
      "158/194, train_loss: 0.7603\n",
      "159/194, train_loss: 0.8604\n",
      "160/194, train_loss: 0.8050\n",
      "161/194, train_loss: 0.8931\n",
      "162/194, train_loss: 0.8569\n",
      "163/194, train_loss: 0.9145\n",
      "164/194, train_loss: 0.8029\n",
      "165/194, train_loss: 0.8238\n",
      "166/194, train_loss: 0.9112\n",
      "167/194, train_loss: 0.7638\n",
      "168/194, train_loss: 0.8244\n",
      "169/194, train_loss: 0.8437\n",
      "170/194, train_loss: 0.7391\n",
      "171/194, train_loss: 0.7798\n",
      "172/194, train_loss: 0.8727\n",
      "173/194, train_loss: 0.6458\n",
      "174/194, train_loss: 0.7115\n",
      "175/194, train_loss: 0.7852\n",
      "176/194, train_loss: 0.8842\n",
      "177/194, train_loss: 0.9091\n",
      "178/194, train_loss: 0.7531\n",
      "179/194, train_loss: 0.9433\n",
      "180/194, train_loss: 0.8592\n",
      "181/194, train_loss: 0.7207\n",
      "182/194, train_loss: 0.7936\n",
      "183/194, train_loss: 0.8807\n",
      "184/194, train_loss: 0.7031\n",
      "185/194, train_loss: 0.7915\n",
      "186/194, train_loss: 0.8351\n",
      "187/194, train_loss: 0.7993\n",
      "188/194, train_loss: 0.8342\n",
      "189/194, train_loss: 0.8620\n",
      "190/194, train_loss: 0.8934\n",
      "191/194, train_loss: 0.8266\n",
      "192/194, train_loss: 0.7951\n",
      "193/194, train_loss: 0.7140\n",
      "194/194, train_loss: 0.8945\n",
      "metric=0.3817622633650899, metric_tc=0.3949622803678115, metric_wt=0.5335915486017863, metric_et=0.21673296058240035\n",
      "metric=0.3817622633650899, metric_tc=0.3949622803678115, metric_wt=0.5335915486017863, metric_et=0.21673296058240035\n",
      "current epoch: 65 current epoch loss: 0.7781\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████▏ | 65/80 [12:00:27<2:34:00, 616.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metric=0.3817622633650899, metric_tc=0.3949622803678115, metric_wt=0.5335915486017863, metric_et=0.21673296058240035\n",
      "0.3817622633650899\n",
      "current epoch: 65 current mean dice: 0.3818 tc: 0.3950 wt: 0.5336 et: 0.2167\n",
      "best mean dice: 0.3914 at epoch: 59\n",
      "\n",
      " | Global Training Round : 66 |\n",
      "\n",
      "user 0 selected\n",
      "local epoch 1\n",
      "1/194, train_loss: 0.7697\n",
      "2/194, train_loss: 0.5822\n",
      "3/194, train_loss: 0.8348\n",
      "4/194, train_loss: 0.7118\n",
      "5/194, train_loss: 0.7487\n",
      "6/194, train_loss: 0.7774\n",
      "7/194, train_loss: 0.8059\n",
      "8/194, train_loss: 0.9683\n",
      "9/194, train_loss: 0.8009\n",
      "10/194, train_loss: 0.8578\n",
      "11/194, train_loss: 0.6514\n",
      "12/194, train_loss: 0.6750\n",
      "13/194, train_loss: 0.7522\n",
      "14/194, train_loss: 0.7024\n",
      "15/194, train_loss: 0.6730\n",
      "16/194, train_loss: 0.5752\n",
      "17/194, train_loss: 0.9054\n",
      "18/194, train_loss: 0.8654\n",
      "19/194, train_loss: 0.7324\n",
      "20/194, train_loss: 0.8956\n",
      "21/194, train_loss: 0.7179\n",
      "22/194, train_loss: 0.6179\n",
      "23/194, train_loss: 0.6896\n",
      "24/194, train_loss: 0.6176\n",
      "25/194, train_loss: 0.8797\n",
      "26/194, train_loss: 0.6067\n",
      "27/194, train_loss: 0.9224\n",
      "28/194, train_loss: 0.8787\n",
      "29/194, train_loss: 0.7803\n",
      "30/194, train_loss: 0.7256\n",
      "31/194, train_loss: 0.9118\n",
      "32/194, train_loss: 0.7168\n",
      "33/194, train_loss: 0.7796\n",
      "34/194, train_loss: 0.7750\n",
      "35/194, train_loss: 0.7042\n",
      "36/194, train_loss: 0.7289\n",
      "37/194, train_loss: 0.8046\n",
      "38/194, train_loss: 0.7240\n",
      "39/194, train_loss: 0.8217\n",
      "40/194, train_loss: 0.7319\n",
      "41/194, train_loss: 0.8005\n",
      "42/194, train_loss: 0.6798\n",
      "43/194, train_loss: 0.7469\n",
      "44/194, train_loss: 0.8446\n",
      "45/194, train_loss: 0.7538\n",
      "46/194, train_loss: 0.8756\n",
      "47/194, train_loss: 0.5121\n",
      "48/194, train_loss: 0.8134\n",
      "49/194, train_loss: 0.6184\n",
      "50/194, train_loss: 0.6714\n",
      "51/194, train_loss: 0.6898\n",
      "52/194, train_loss: 0.6896\n",
      "53/194, train_loss: 0.8002\n",
      "54/194, train_loss: 0.6666\n",
      "55/194, train_loss: 0.6818\n",
      "56/194, train_loss: 0.6890\n",
      "57/194, train_loss: 0.9326\n",
      "58/194, train_loss: 0.8506\n",
      "59/194, train_loss: 0.8750\n",
      "60/194, train_loss: 0.8913\n",
      "61/194, train_loss: 0.6965\n",
      "62/194, train_loss: 0.7234\n",
      "63/194, train_loss: 0.8093\n",
      "64/194, train_loss: 0.6405\n",
      "65/194, train_loss: 0.6938\n",
      "66/194, train_loss: 0.6447\n",
      "67/194, train_loss: 0.8019\n",
      "68/194, train_loss: 0.7319\n",
      "69/194, train_loss: 0.9270\n",
      "70/194, train_loss: 0.6469\n",
      "71/194, train_loss: 0.9475\n",
      "72/194, train_loss: 0.8340\n",
      "73/194, train_loss: 0.7203\n",
      "74/194, train_loss: 0.7082\n",
      "75/194, train_loss: 0.7758\n",
      "76/194, train_loss: 0.7634\n",
      "77/194, train_loss: 0.7002\n",
      "78/194, train_loss: 0.6392\n",
      "79/194, train_loss: 0.6541\n",
      "80/194, train_loss: 0.6311\n",
      "81/194, train_loss: 0.8075\n",
      "82/194, train_loss: 0.7818\n",
      "83/194, train_loss: 0.8298\n",
      "84/194, train_loss: 0.7926\n",
      "85/194, train_loss: 0.7907\n",
      "86/194, train_loss: 0.8331\n",
      "87/194, train_loss: 0.8274\n",
      "88/194, train_loss: 0.7994\n",
      "89/194, train_loss: 0.7605\n",
      "90/194, train_loss: 0.6215\n",
      "91/194, train_loss: 0.6786\n",
      "92/194, train_loss: 0.7065\n",
      "93/194, train_loss: 0.8146\n",
      "94/194, train_loss: 0.6960\n",
      "95/194, train_loss: 0.7181\n",
      "96/194, train_loss: 0.8004\n",
      "97/194, train_loss: 0.7512\n",
      "98/194, train_loss: 0.8137\n",
      "99/194, train_loss: 0.6955\n",
      "100/194, train_loss: 0.8092\n",
      "101/194, train_loss: 0.9018\n",
      "102/194, train_loss: 0.6681\n",
      "103/194, train_loss: 0.7298\n",
      "104/194, train_loss: 0.8010\n",
      "105/194, train_loss: 0.8882\n",
      "106/194, train_loss: 0.8989\n",
      "107/194, train_loss: 0.7892\n",
      "108/194, train_loss: 0.7935\n",
      "109/194, train_loss: 0.7084\n",
      "110/194, train_loss: 0.8517\n",
      "111/194, train_loss: 0.6201\n",
      "112/194, train_loss: 0.9060\n",
      "113/194, train_loss: 0.7582\n",
      "114/194, train_loss: 0.6653\n",
      "115/194, train_loss: 0.7869\n",
      "116/194, train_loss: 0.5462\n",
      "117/194, train_loss: 0.6921\n",
      "118/194, train_loss: 0.6884\n",
      "119/194, train_loss: 0.8198\n",
      "120/194, train_loss: 0.6236\n",
      "121/194, train_loss: 0.8041\n",
      "122/194, train_loss: 0.6184\n",
      "123/194, train_loss: 0.6378\n",
      "124/194, train_loss: 0.9339\n",
      "125/194, train_loss: 0.6960\n",
      "126/194, train_loss: 0.9074\n",
      "127/194, train_loss: 0.6110\n",
      "128/194, train_loss: 0.7410\n",
      "129/194, train_loss: 0.7104\n",
      "130/194, train_loss: 0.7727\n",
      "131/194, train_loss: 0.8182\n",
      "132/194, train_loss: 0.6489\n",
      "133/194, train_loss: 0.7974\n",
      "134/194, train_loss: 0.7967\n",
      "135/194, train_loss: 0.8155\n",
      "136/194, train_loss: 0.9110\n",
      "137/194, train_loss: 0.8504\n",
      "138/194, train_loss: 0.5411\n",
      "139/194, train_loss: 0.7580\n",
      "140/194, train_loss: 0.4709\n",
      "141/194, train_loss: 0.8710\n",
      "142/194, train_loss: 0.8350\n",
      "143/194, train_loss: 0.8540\n",
      "144/194, train_loss: 0.9467\n",
      "145/194, train_loss: 0.8433\n",
      "146/194, train_loss: 0.8025\n",
      "147/194, train_loss: 0.8244\n",
      "148/194, train_loss: 0.7339\n",
      "149/194, train_loss: 0.7725\n",
      "150/194, train_loss: 0.7990\n",
      "151/194, train_loss: 0.8065\n",
      "152/194, train_loss: 0.8438\n",
      "153/194, train_loss: 0.9248\n",
      "154/194, train_loss: 0.9580\n",
      "155/194, train_loss: 0.8889\n",
      "156/194, train_loss: 0.8606\n",
      "157/194, train_loss: 0.9797\n",
      "158/194, train_loss: 0.7849\n",
      "159/194, train_loss: 0.6738\n",
      "160/194, train_loss: 0.7074\n",
      "161/194, train_loss: 0.8388\n",
      "162/194, train_loss: 0.8315\n",
      "163/194, train_loss: 0.7740\n",
      "164/194, train_loss: 0.8728\n",
      "165/194, train_loss: 0.7759\n",
      "166/194, train_loss: 0.9495\n",
      "167/194, train_loss: 0.9248\n",
      "168/194, train_loss: 0.8501\n",
      "169/194, train_loss: 0.7427\n",
      "170/194, train_loss: 0.8727\n",
      "171/194, train_loss: 0.7694\n",
      "172/194, train_loss: 0.7127\n",
      "173/194, train_loss: 0.8662\n",
      "174/194, train_loss: 0.8078\n",
      "175/194, train_loss: 0.8540\n",
      "176/194, train_loss: 0.7183\n",
      "177/194, train_loss: 0.7220\n",
      "178/194, train_loss: 0.7319\n",
      "179/194, train_loss: 0.7239\n",
      "180/194, train_loss: 0.7122\n",
      "181/194, train_loss: 0.7677\n",
      "182/194, train_loss: 0.7516\n",
      "183/194, train_loss: 0.8036\n",
      "184/194, train_loss: 0.8362\n",
      "185/194, train_loss: 0.8600\n",
      "186/194, train_loss: 0.8901\n",
      "187/194, train_loss: 0.7671\n",
      "188/194, train_loss: 0.7630\n",
      "189/194, train_loss: 0.7577\n",
      "190/194, train_loss: 0.8192\n",
      "191/194, train_loss: 0.7437\n",
      "192/194, train_loss: 0.8731\n",
      "193/194, train_loss: 0.8133\n",
      "194/194, train_loss: 0.9117\n",
      "metric=0.3518170217672984, metric_tc=0.35798447268704575, metric_wt=0.5021626322219769, metric_et=0.1953039529422919\n",
      "metric=0.3518170217672984, metric_tc=0.35798447268704575, metric_wt=0.5021626322219769, metric_et=0.1953039529422919\n",
      "current epoch: 66 current epoch loss: 0.7712\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▎ | 66/80 [12:10:52<2:24:23, 618.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metric=0.3518170217672984, metric_tc=0.35798447268704575, metric_wt=0.5021626322219769, metric_et=0.1953039529422919\n",
      "0.3518170217672984\n",
      "current epoch: 66 current mean dice: 0.3518 tc: 0.3580 wt: 0.5022 et: 0.1953\n",
      "best mean dice: 0.3914 at epoch: 59\n",
      "\n",
      " | Global Training Round : 67 |\n",
      "\n",
      "user 0 selected\n",
      "local epoch 1\n",
      "1/194, train_loss: 0.5795\n",
      "2/194, train_loss: 0.9141\n",
      "3/194, train_loss: 0.7714\n",
      "4/194, train_loss: 0.7078\n",
      "5/194, train_loss: 0.8533\n",
      "6/194, train_loss: 0.6165\n",
      "7/194, train_loss: 0.7334\n",
      "8/194, train_loss: 0.6805\n",
      "9/194, train_loss: 0.7718\n",
      "10/194, train_loss: 0.7799\n",
      "11/194, train_loss: 0.7559\n",
      "12/194, train_loss: 0.6080\n",
      "13/194, train_loss: 0.6005\n",
      "14/194, train_loss: 0.5758\n",
      "15/194, train_loss: 0.8057\n",
      "16/194, train_loss: 0.7045\n",
      "17/194, train_loss: 0.7196\n",
      "18/194, train_loss: 0.8621\n",
      "19/194, train_loss: 0.7625\n",
      "20/194, train_loss: 0.6621\n",
      "21/194, train_loss: 0.8035\n",
      "22/194, train_loss: 0.5739\n",
      "23/194, train_loss: 0.7241\n",
      "24/194, train_loss: 0.7796\n",
      "25/194, train_loss: 0.7908\n",
      "26/194, train_loss: 0.7646\n",
      "27/194, train_loss: 0.7964\n",
      "28/194, train_loss: 0.8901\n",
      "29/194, train_loss: 0.7531\n",
      "30/194, train_loss: 0.7846\n",
      "31/194, train_loss: 0.7514\n",
      "32/194, train_loss: 0.8483\n",
      "33/194, train_loss: 0.5700\n",
      "34/194, train_loss: 0.6823\n",
      "35/194, train_loss: 0.7031\n",
      "36/194, train_loss: 0.9391\n",
      "37/194, train_loss: 0.7031\n",
      "38/194, train_loss: 0.7376\n",
      "39/194, train_loss: 0.6098\n",
      "40/194, train_loss: 0.7756\n",
      "41/194, train_loss: 0.9160\n",
      "42/194, train_loss: 0.4480\n",
      "43/194, train_loss: 0.5961\n",
      "44/194, train_loss: 0.8401\n",
      "45/194, train_loss: 0.4771\n",
      "46/194, train_loss: 0.7977\n",
      "47/194, train_loss: 0.7664\n",
      "48/194, train_loss: 0.6093\n",
      "49/194, train_loss: 0.7538\n",
      "50/194, train_loss: 0.7238\n",
      "51/194, train_loss: 0.7584\n",
      "52/194, train_loss: 0.6978\n",
      "53/194, train_loss: 0.8789\n",
      "54/194, train_loss: 0.8272\n",
      "55/194, train_loss: 0.7186\n",
      "56/194, train_loss: 0.8021\n",
      "57/194, train_loss: 0.6923\n",
      "58/194, train_loss: 0.7150\n",
      "59/194, train_loss: 0.8475\n",
      "60/194, train_loss: 0.8141\n",
      "61/194, train_loss: 0.8234\n",
      "62/194, train_loss: 0.6415\n",
      "63/194, train_loss: 0.6234\n",
      "64/194, train_loss: 0.7159\n",
      "65/194, train_loss: 0.7677\n",
      "66/194, train_loss: 0.6884\n",
      "67/194, train_loss: 0.7746\n",
      "68/194, train_loss: 0.7450\n",
      "69/194, train_loss: 0.9105\n",
      "70/194, train_loss: 0.9140\n",
      "71/194, train_loss: 0.9323\n",
      "72/194, train_loss: 0.7039\n",
      "73/194, train_loss: 0.6999\n",
      "74/194, train_loss: 0.7490\n",
      "75/194, train_loss: 0.6759\n",
      "76/194, train_loss: 0.7315\n",
      "77/194, train_loss: 0.7647\n",
      "78/194, train_loss: 0.6634\n",
      "79/194, train_loss: 0.7924\n",
      "80/194, train_loss: 0.6296\n",
      "81/194, train_loss: 0.8423\n",
      "82/194, train_loss: 0.6244\n",
      "83/194, train_loss: 0.8066\n",
      "84/194, train_loss: 0.8129\n",
      "85/194, train_loss: 0.7666\n",
      "86/194, train_loss: 0.7859\n",
      "87/194, train_loss: 0.7449\n",
      "88/194, train_loss: 0.8510\n",
      "89/194, train_loss: 0.8384\n",
      "90/194, train_loss: 0.7401\n",
      "91/194, train_loss: 0.7557\n",
      "92/194, train_loss: 0.8079\n",
      "93/194, train_loss: 0.8782\n",
      "94/194, train_loss: 0.7099\n",
      "95/194, train_loss: 0.7041\n",
      "96/194, train_loss: 0.7690\n",
      "97/194, train_loss: 0.8134\n",
      "98/194, train_loss: 0.7888\n",
      "99/194, train_loss: 0.8531\n",
      "100/194, train_loss: 0.8776\n",
      "101/194, train_loss: 0.7138\n",
      "102/194, train_loss: 0.7385\n",
      "103/194, train_loss: 0.8915\n",
      "104/194, train_loss: 0.8932\n",
      "105/194, train_loss: 0.8355\n",
      "106/194, train_loss: 0.7910\n",
      "107/194, train_loss: 0.6687\n",
      "108/194, train_loss: 0.7954\n",
      "109/194, train_loss: 0.6912\n",
      "110/194, train_loss: 0.9198\n",
      "111/194, train_loss: 0.8433\n",
      "112/194, train_loss: 0.8474\n",
      "113/194, train_loss: 0.8339\n",
      "114/194, train_loss: 0.9429\n",
      "115/194, train_loss: 0.8767\n",
      "116/194, train_loss: 0.7823\n",
      "117/194, train_loss: 0.6500\n",
      "118/194, train_loss: 0.6927\n",
      "119/194, train_loss: 0.6328\n",
      "120/194, train_loss: 0.8090\n",
      "121/194, train_loss: 0.8794\n",
      "122/194, train_loss: 0.8104\n",
      "123/194, train_loss: 0.8473\n",
      "124/194, train_loss: 0.6728\n",
      "125/194, train_loss: 0.7321\n",
      "126/194, train_loss: 0.7490\n",
      "127/194, train_loss: 0.9427\n",
      "128/194, train_loss: 0.9259\n",
      "129/194, train_loss: 0.8018\n",
      "130/194, train_loss: 0.6912\n",
      "131/194, train_loss: 0.7934\n",
      "132/194, train_loss: 0.7787\n",
      "133/194, train_loss: 0.6892\n",
      "134/194, train_loss: 0.7779\n",
      "135/194, train_loss: 0.8314\n",
      "136/194, train_loss: 0.8395\n",
      "137/194, train_loss: 0.7731\n",
      "138/194, train_loss: 0.6691\n",
      "139/194, train_loss: 0.6700\n",
      "140/194, train_loss: 0.6569\n",
      "141/194, train_loss: 0.8844\n",
      "142/194, train_loss: 0.7961\n",
      "143/194, train_loss: 0.8158\n",
      "144/194, train_loss: 0.7434\n",
      "145/194, train_loss: 0.8609\n",
      "146/194, train_loss: 0.7279\n",
      "147/194, train_loss: 0.8900\n",
      "148/194, train_loss: 0.7439\n",
      "149/194, train_loss: 0.7595\n",
      "150/194, train_loss: 0.7829\n",
      "151/194, train_loss: 0.8254\n",
      "152/194, train_loss: 0.7806\n",
      "153/194, train_loss: 0.8742\n",
      "154/194, train_loss: 0.8301\n",
      "155/194, train_loss: 0.8218\n",
      "156/194, train_loss: 0.8776\n",
      "157/194, train_loss: 0.8310\n",
      "158/194, train_loss: 0.7452\n",
      "159/194, train_loss: 0.7897\n",
      "160/194, train_loss: 0.8299\n",
      "161/194, train_loss: 0.8174\n",
      "162/194, train_loss: 0.8673\n",
      "163/194, train_loss: 0.9028\n",
      "164/194, train_loss: 0.9172\n",
      "165/194, train_loss: 0.8003\n",
      "166/194, train_loss: 0.9303\n",
      "167/194, train_loss: 0.7679\n",
      "168/194, train_loss: 0.8750\n",
      "169/194, train_loss: 0.8677\n",
      "170/194, train_loss: 0.7658\n",
      "171/194, train_loss: 0.7438\n",
      "172/194, train_loss: 0.6701\n",
      "173/194, train_loss: 0.7629\n",
      "174/194, train_loss: 0.6285\n",
      "175/194, train_loss: 0.9332\n",
      "176/194, train_loss: 0.8848\n",
      "177/194, train_loss: 0.7478\n",
      "178/194, train_loss: 0.8736\n",
      "179/194, train_loss: 0.5760\n",
      "180/194, train_loss: 0.7861\n",
      "181/194, train_loss: 0.7310\n",
      "182/194, train_loss: 0.8276\n",
      "183/194, train_loss: 0.7869\n",
      "184/194, train_loss: 0.8978\n",
      "185/194, train_loss: 0.7653\n",
      "186/194, train_loss: 0.7308\n",
      "187/194, train_loss: 0.8928\n",
      "188/194, train_loss: 0.9083\n",
      "189/194, train_loss: 0.9010\n",
      "190/194, train_loss: 0.8585\n",
      "191/194, train_loss: 0.8051\n",
      "192/194, train_loss: 0.9258\n",
      "193/194, train_loss: 0.8688\n",
      "194/194, train_loss: 0.8485\n",
      "metric=0.360396939329803, metric_tc=0.3698154032851259, metric_wt=0.5051869445790848, metric_et=0.2061884691550707\n",
      "metric=0.360396939329803, metric_tc=0.3698154032851259, metric_wt=0.5051869445790848, metric_et=0.2061884691550707\n",
      "current epoch: 67 current epoch loss: 0.7748\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 67/80 [12:21:22<2:14:48, 622.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metric=0.360396939329803, metric_tc=0.3698154032851259, metric_wt=0.5051869445790848, metric_et=0.2061884691550707\n",
      "0.360396939329803\n",
      "current epoch: 67 current mean dice: 0.3604 tc: 0.3698 wt: 0.5052 et: 0.2062\n",
      "best mean dice: 0.3914 at epoch: 59\n",
      "\n",
      " | Global Training Round : 68 |\n",
      "\n",
      "user 0 selected\n",
      "local epoch 1\n",
      "1/194, train_loss: 0.7068\n",
      "2/194, train_loss: 0.7821\n",
      "3/194, train_loss: 0.8282\n",
      "4/194, train_loss: 0.7841\n",
      "5/194, train_loss: 0.8305\n",
      "6/194, train_loss: 0.6604\n",
      "7/194, train_loss: 0.7542\n",
      "8/194, train_loss: 0.7653\n",
      "9/194, train_loss: 0.8640\n",
      "10/194, train_loss: 0.8372\n",
      "11/194, train_loss: 0.7562\n",
      "12/194, train_loss: 0.7768\n",
      "13/194, train_loss: 0.7507\n",
      "14/194, train_loss: 0.7386\n",
      "15/194, train_loss: 0.8756\n",
      "16/194, train_loss: 0.5994\n",
      "17/194, train_loss: 0.7983\n",
      "18/194, train_loss: 0.8038\n",
      "19/194, train_loss: 0.8212\n",
      "20/194, train_loss: 0.7645\n",
      "21/194, train_loss: 0.9126\n",
      "22/194, train_loss: 0.7833\n",
      "23/194, train_loss: 0.7623\n",
      "24/194, train_loss: 0.7442\n",
      "25/194, train_loss: 0.6559\n",
      "26/194, train_loss: 0.9305\n",
      "27/194, train_loss: 0.8924\n",
      "28/194, train_loss: 0.7762\n",
      "29/194, train_loss: 0.6106\n",
      "30/194, train_loss: 0.6328\n",
      "31/194, train_loss: 0.8912\n",
      "32/194, train_loss: 0.8121\n",
      "33/194, train_loss: 0.5271\n",
      "34/194, train_loss: 0.7993\n",
      "35/194, train_loss: 0.6183\n",
      "36/194, train_loss: 0.8081\n",
      "37/194, train_loss: 0.6903\n",
      "38/194, train_loss: 0.6154\n",
      "39/194, train_loss: 0.6514\n",
      "40/194, train_loss: 0.5398\n",
      "41/194, train_loss: 0.7233\n",
      "42/194, train_loss: 0.8860\n",
      "43/194, train_loss: 0.8278\n",
      "44/194, train_loss: 0.8097\n",
      "45/194, train_loss: 0.7894\n",
      "46/194, train_loss: 0.7567\n",
      "47/194, train_loss: 0.7663\n",
      "48/194, train_loss: 0.7560\n",
      "49/194, train_loss: 0.8476\n",
      "50/194, train_loss: 0.6940\n",
      "51/194, train_loss: 0.7018\n",
      "52/194, train_loss: 0.7233\n",
      "53/194, train_loss: 0.6750\n",
      "54/194, train_loss: 0.8039\n",
      "55/194, train_loss: 0.7360\n",
      "56/194, train_loss: 0.8775\n",
      "57/194, train_loss: 0.8480\n",
      "58/194, train_loss: 0.8649\n",
      "59/194, train_loss: 0.9137\n",
      "60/194, train_loss: 0.7918\n",
      "61/194, train_loss: 0.7365\n",
      "62/194, train_loss: 0.8387\n",
      "63/194, train_loss: 0.7510\n",
      "64/194, train_loss: 0.7102\n",
      "65/194, train_loss: 0.9241\n",
      "66/194, train_loss: 0.8289\n",
      "67/194, train_loss: 0.7639\n",
      "68/194, train_loss: 0.7280\n",
      "69/194, train_loss: 0.8375\n",
      "70/194, train_loss: 0.7865\n",
      "71/194, train_loss: 0.8352\n",
      "72/194, train_loss: 0.6930\n",
      "73/194, train_loss: 0.7686\n",
      "74/194, train_loss: 0.7043\n",
      "75/194, train_loss: 0.7758\n",
      "76/194, train_loss: 0.7602\n",
      "77/194, train_loss: 0.6464\n",
      "78/194, train_loss: 0.8474\n",
      "79/194, train_loss: 0.8128\n",
      "80/194, train_loss: 0.6830\n",
      "81/194, train_loss: 0.7920\n",
      "82/194, train_loss: 0.8003\n",
      "83/194, train_loss: 0.8476\n",
      "84/194, train_loss: 0.8345\n",
      "85/194, train_loss: 0.7668\n",
      "86/194, train_loss: 0.7602\n",
      "87/194, train_loss: 0.5871\n",
      "88/194, train_loss: 0.6982\n",
      "89/194, train_loss: 0.6416\n",
      "90/194, train_loss: 0.8874\n",
      "91/194, train_loss: 0.7244\n",
      "92/194, train_loss: 0.8474\n",
      "93/194, train_loss: 0.7431\n",
      "94/194, train_loss: 0.8286\n",
      "95/194, train_loss: 0.7706\n",
      "96/194, train_loss: 0.6418\n",
      "97/194, train_loss: 0.7138\n",
      "98/194, train_loss: 0.7392\n",
      "99/194, train_loss: 0.8759\n",
      "100/194, train_loss: 0.7451\n",
      "101/194, train_loss: 0.8187\n",
      "102/194, train_loss: 0.6874\n",
      "103/194, train_loss: 0.8148\n",
      "104/194, train_loss: 0.8272\n",
      "105/194, train_loss: 0.7164\n",
      "106/194, train_loss: 0.7660\n",
      "107/194, train_loss: 0.7138\n",
      "108/194, train_loss: 0.6949\n",
      "109/194, train_loss: 0.6917\n",
      "110/194, train_loss: 0.7170\n",
      "111/194, train_loss: 0.6317\n",
      "112/194, train_loss: 0.6961\n",
      "113/194, train_loss: 0.8250\n",
      "114/194, train_loss: 0.6822\n",
      "115/194, train_loss: 0.7485\n",
      "116/194, train_loss: 0.6406\n",
      "117/194, train_loss: 0.8662\n",
      "118/194, train_loss: 0.7065\n",
      "119/194, train_loss: 0.7329\n",
      "120/194, train_loss: 0.5766\n",
      "121/194, train_loss: 0.9414\n",
      "122/194, train_loss: 0.7031\n",
      "123/194, train_loss: 0.9111\n",
      "124/194, train_loss: 0.5293\n",
      "125/194, train_loss: 0.7469\n",
      "126/194, train_loss: 0.7888\n",
      "127/194, train_loss: 0.6003\n",
      "128/194, train_loss: 0.7960\n",
      "129/194, train_loss: 0.8724\n",
      "130/194, train_loss: 0.7748\n",
      "131/194, train_loss: 0.7721\n",
      "132/194, train_loss: 0.7794\n",
      "133/194, train_loss: 0.7649\n",
      "134/194, train_loss: 0.9005\n",
      "135/194, train_loss: 0.6739\n",
      "136/194, train_loss: 0.8166\n",
      "137/194, train_loss: 0.7797\n",
      "138/194, train_loss: 0.9072\n",
      "139/194, train_loss: 0.7375\n",
      "140/194, train_loss: 0.7703\n",
      "141/194, train_loss: 0.8439\n",
      "142/194, train_loss: 0.7566\n",
      "143/194, train_loss: 0.8845\n",
      "144/194, train_loss: 0.7751\n",
      "145/194, train_loss: 0.7696\n",
      "146/194, train_loss: 0.7703\n",
      "147/194, train_loss: 0.6551\n",
      "148/194, train_loss: 0.8575\n",
      "149/194, train_loss: 0.9883\n",
      "150/194, train_loss: 0.7228\n",
      "151/194, train_loss: 0.7784\n",
      "152/194, train_loss: 0.7276\n",
      "153/194, train_loss: 0.8441\n",
      "154/194, train_loss: 0.8150\n",
      "155/194, train_loss: 0.8034\n",
      "156/194, train_loss: 0.8770\n",
      "157/194, train_loss: 0.6742\n",
      "158/194, train_loss: 0.7862\n",
      "159/194, train_loss: 0.8304\n",
      "160/194, train_loss: 0.8787\n",
      "161/194, train_loss: 0.8633\n",
      "162/194, train_loss: 0.8859\n",
      "163/194, train_loss: 0.8200\n",
      "164/194, train_loss: 0.8574\n",
      "165/194, train_loss: 0.6724\n",
      "166/194, train_loss: 0.7863\n",
      "167/194, train_loss: 0.6834\n",
      "168/194, train_loss: 0.9092\n",
      "169/194, train_loss: 0.5412\n",
      "170/194, train_loss: 0.8266\n",
      "171/194, train_loss: 0.8542\n",
      "172/194, train_loss: 0.7829\n",
      "173/194, train_loss: 0.7804\n",
      "174/194, train_loss: 0.7979\n",
      "175/194, train_loss: 0.6781\n",
      "176/194, train_loss: 0.6784\n",
      "177/194, train_loss: 0.7210\n",
      "178/194, train_loss: 0.8056\n",
      "179/194, train_loss: 0.8640\n",
      "180/194, train_loss: 0.8975\n",
      "181/194, train_loss: 0.7327\n",
      "182/194, train_loss: 0.6294\n",
      "183/194, train_loss: 0.6137\n",
      "184/194, train_loss: 0.7285\n",
      "185/194, train_loss: 0.7976\n",
      "186/194, train_loss: 0.7088\n",
      "187/194, train_loss: 0.8473\n",
      "188/194, train_loss: 0.8460\n",
      "189/194, train_loss: 0.7936\n",
      "190/194, train_loss: 0.7651\n",
      "191/194, train_loss: 0.7545\n",
      "192/194, train_loss: 0.9334\n",
      "193/194, train_loss: 0.7452\n",
      "194/194, train_loss: 0.9296\n",
      "metric=0.39408023344973725, metric_tc=0.4246221063658595, metric_wt=0.5189583878964186, metric_et=0.23866020461233953\n",
      "metric=0.39408023344973725, metric_tc=0.4246221063658595, metric_wt=0.5189583878964186, metric_et=0.23866020461233953\n",
      "current epoch: 68 current epoch loss: 0.7696\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 68/80 [12:32:03<2:05:33, 627.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metric=0.39408023344973725, metric_tc=0.4246221063658595, metric_wt=0.5189583878964186, metric_et=0.23866020461233953\n",
      "0.39408023344973725\n",
      "saved new best metric model\n",
      "current epoch: 68 current mean dice: 0.3941 tc: 0.4246 wt: 0.5190 et: 0.2387\n",
      "best mean dice: 0.3941 at epoch: 68\n",
      "\n",
      " | Global Training Round : 69 |\n",
      "\n",
      "user 0 selected\n",
      "local epoch 1\n",
      "1/194, train_loss: 0.8198\n",
      "2/194, train_loss: 0.8279\n",
      "3/194, train_loss: 0.7474\n",
      "4/194, train_loss: 0.8940\n",
      "5/194, train_loss: 0.6201\n",
      "6/194, train_loss: 0.6819\n",
      "7/194, train_loss: 0.7693\n",
      "8/194, train_loss: 0.8106\n",
      "9/194, train_loss: 0.7090\n",
      "10/194, train_loss: 0.7373\n",
      "11/194, train_loss: 0.7695\n",
      "12/194, train_loss: 0.8051\n",
      "13/194, train_loss: 0.8508\n",
      "14/194, train_loss: 0.8805\n",
      "15/194, train_loss: 0.7081\n",
      "16/194, train_loss: 0.7865\n",
      "17/194, train_loss: 0.8586\n",
      "18/194, train_loss: 0.6333\n",
      "19/194, train_loss: 0.7234\n",
      "20/194, train_loss: 0.9157\n",
      "21/194, train_loss: 0.8004\n",
      "22/194, train_loss: 0.6632\n",
      "23/194, train_loss: 0.7863\n",
      "24/194, train_loss: 0.6505\n",
      "25/194, train_loss: 0.8648\n",
      "26/194, train_loss: 0.7420\n",
      "27/194, train_loss: 0.8175\n",
      "28/194, train_loss: 0.7715\n",
      "29/194, train_loss: 0.7391\n",
      "30/194, train_loss: 0.8604\n",
      "31/194, train_loss: 0.8145\n",
      "32/194, train_loss: 0.8220\n",
      "33/194, train_loss: 0.6416\n",
      "34/194, train_loss: 0.8235\n",
      "35/194, train_loss: 0.8558\n",
      "36/194, train_loss: 0.7770\n",
      "37/194, train_loss: 0.6660\n",
      "38/194, train_loss: 0.6099\n",
      "39/194, train_loss: 0.4183\n",
      "40/194, train_loss: 0.5227\n",
      "41/194, train_loss: 0.7665\n",
      "42/194, train_loss: 0.6899\n",
      "43/194, train_loss: 0.7002\n",
      "44/194, train_loss: 0.7782\n",
      "45/194, train_loss: 0.7512\n",
      "46/194, train_loss: 0.7648\n",
      "47/194, train_loss: 0.6302\n",
      "48/194, train_loss: 0.6295\n",
      "49/194, train_loss: 0.7247\n",
      "50/194, train_loss: 0.6310\n",
      "51/194, train_loss: 0.8577\n",
      "52/194, train_loss: 0.6063\n",
      "53/194, train_loss: 0.7838\n",
      "54/194, train_loss: 0.8831\n",
      "55/194, train_loss: 0.6432\n",
      "56/194, train_loss: 0.8918\n",
      "57/194, train_loss: 0.9097\n",
      "58/194, train_loss: 0.9063\n",
      "59/194, train_loss: 0.7885\n",
      "60/194, train_loss: 0.7523\n",
      "61/194, train_loss: 0.8359\n",
      "62/194, train_loss: 0.7380\n",
      "63/194, train_loss: 0.5418\n",
      "64/194, train_loss: 0.7190\n",
      "65/194, train_loss: 0.6758\n",
      "66/194, train_loss: 0.7331\n",
      "67/194, train_loss: 0.6217\n",
      "68/194, train_loss: 0.8132\n",
      "69/194, train_loss: 0.7184\n",
      "70/194, train_loss: 0.8428\n",
      "71/194, train_loss: 0.7218\n",
      "72/194, train_loss: 0.5913\n",
      "73/194, train_loss: 0.7305\n",
      "74/194, train_loss: 0.7556\n",
      "75/194, train_loss: 0.6776\n",
      "76/194, train_loss: 0.6446\n",
      "77/194, train_loss: 0.6613\n",
      "78/194, train_loss: 0.6174\n",
      "79/194, train_loss: 0.7708\n",
      "80/194, train_loss: 0.6671\n",
      "81/194, train_loss: 0.6381\n",
      "82/194, train_loss: 0.9473\n",
      "83/194, train_loss: 0.8337\n",
      "84/194, train_loss: 0.8189\n",
      "85/194, train_loss: 0.9368\n",
      "86/194, train_loss: 0.8552\n",
      "87/194, train_loss: 0.7431\n",
      "88/194, train_loss: 0.9220\n",
      "89/194, train_loss: 0.9098\n",
      "90/194, train_loss: 0.7698\n",
      "91/194, train_loss: 0.7611\n",
      "92/194, train_loss: 0.6897\n",
      "93/194, train_loss: 0.7421\n",
      "94/194, train_loss: 0.7129\n",
      "95/194, train_loss: 0.8138\n",
      "96/194, train_loss: 0.7815\n",
      "97/194, train_loss: 0.6334\n",
      "98/194, train_loss: 0.8321\n",
      "99/194, train_loss: 0.8810\n",
      "100/194, train_loss: 0.6617\n",
      "101/194, train_loss: 0.8190\n",
      "102/194, train_loss: 0.7690\n",
      "103/194, train_loss: 0.7901\n",
      "104/194, train_loss: 0.8527\n",
      "105/194, train_loss: 0.8344\n",
      "106/194, train_loss: 0.6402\n",
      "107/194, train_loss: 0.7022\n",
      "108/194, train_loss: 0.7460\n",
      "109/194, train_loss: 0.6504\n",
      "110/194, train_loss: 0.6549\n",
      "111/194, train_loss: 0.6888\n",
      "112/194, train_loss: 0.7002\n",
      "113/194, train_loss: 0.8796\n",
      "114/194, train_loss: 0.8014\n",
      "115/194, train_loss: 0.8286\n",
      "116/194, train_loss: 0.7617\n",
      "117/194, train_loss: 0.8377\n",
      "118/194, train_loss: 0.8161\n",
      "119/194, train_loss: 0.8968\n",
      "120/194, train_loss: 0.7064\n",
      "121/194, train_loss: 0.7891\n",
      "122/194, train_loss: 0.8544\n",
      "123/194, train_loss: 0.8966\n",
      "124/194, train_loss: 0.8764\n",
      "125/194, train_loss: 0.8708\n",
      "126/194, train_loss: 0.8054\n",
      "127/194, train_loss: 0.8050\n",
      "128/194, train_loss: 0.8079\n",
      "129/194, train_loss: 0.7913\n",
      "130/194, train_loss: 0.8056\n",
      "131/194, train_loss: 0.6457\n",
      "132/194, train_loss: 0.7426\n",
      "133/194, train_loss: 0.6714\n",
      "134/194, train_loss: 0.7218\n",
      "135/194, train_loss: 0.8492\n",
      "136/194, train_loss: 0.8441\n",
      "137/194, train_loss: 0.8716\n",
      "138/194, train_loss: 0.8029\n",
      "139/194, train_loss: 0.8351\n",
      "140/194, train_loss: 0.9120\n",
      "141/194, train_loss: 0.8426\n",
      "142/194, train_loss: 0.7182\n",
      "143/194, train_loss: 0.8573\n",
      "144/194, train_loss: 0.8237\n",
      "145/194, train_loss: 0.7667\n",
      "146/194, train_loss: 0.6928\n",
      "147/194, train_loss: 0.7623\n",
      "148/194, train_loss: 0.8938\n",
      "149/194, train_loss: 0.7925\n",
      "150/194, train_loss: 0.8775\n",
      "151/194, train_loss: 0.7711\n",
      "152/194, train_loss: 0.8482\n",
      "153/194, train_loss: 0.9184\n",
      "154/194, train_loss: 0.9618\n",
      "155/194, train_loss: 0.8714\n",
      "156/194, train_loss: 0.6044\n",
      "157/194, train_loss: 0.5706\n",
      "158/194, train_loss: 0.7787\n",
      "159/194, train_loss: 0.8559\n",
      "160/194, train_loss: 0.6842\n",
      "161/194, train_loss: 0.8413\n",
      "162/194, train_loss: 0.7816\n",
      "163/194, train_loss: 0.9278\n",
      "164/194, train_loss: 0.8667\n",
      "165/194, train_loss: 0.7265\n",
      "166/194, train_loss: 0.8606\n",
      "167/194, train_loss: 0.8057\n",
      "168/194, train_loss: 0.8737\n",
      "169/194, train_loss: 0.7362\n",
      "170/194, train_loss: 0.8986\n",
      "171/194, train_loss: 0.9102\n",
      "172/194, train_loss: 0.6153\n",
      "173/194, train_loss: 0.8196\n",
      "174/194, train_loss: 0.9212\n",
      "175/194, train_loss: 0.7544\n",
      "176/194, train_loss: 0.8071\n",
      "177/194, train_loss: 0.8204\n",
      "178/194, train_loss: 0.8046\n",
      "179/194, train_loss: 0.8412\n",
      "180/194, train_loss: 0.6651\n",
      "181/194, train_loss: 0.8500\n",
      "182/194, train_loss: 0.8547\n",
      "183/194, train_loss: 0.6420\n",
      "184/194, train_loss: 0.6363\n",
      "185/194, train_loss: 0.7103\n",
      "186/194, train_loss: 0.7122\n",
      "187/194, train_loss: 0.9162\n",
      "188/194, train_loss: 0.7724\n",
      "189/194, train_loss: 0.8161\n",
      "190/194, train_loss: 0.9018\n",
      "191/194, train_loss: 0.8538\n",
      "192/194, train_loss: 0.8243\n",
      "193/194, train_loss: 0.7815\n",
      "194/194, train_loss: 0.7201\n",
      "metric=0.30359618614117306, metric_tc=0.3010978967261811, metric_wt=0.4496644881243507, metric_et=0.16002616034044573\n",
      "metric=0.30359618614117306, metric_tc=0.3010978967261811, metric_wt=0.4496644881243507, metric_et=0.16002616034044573\n",
      "current epoch: 69 current epoch loss: 0.7731\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▋ | 69/80 [12:42:59<1:56:36, 636.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metric=0.30359618614117306, metric_tc=0.3010978967261811, metric_wt=0.4496644881243507, metric_et=0.16002616034044573\n",
      "0.30359618614117306\n",
      "current epoch: 69 current mean dice: 0.3036 tc: 0.3011 wt: 0.4497 et: 0.1600\n",
      "best mean dice: 0.3941 at epoch: 68\n",
      "\n",
      " | Global Training Round : 70 |\n",
      "\n",
      "user 0 selected\n",
      "local epoch 1\n",
      "1/194, train_loss: 0.6233\n",
      "2/194, train_loss: 0.7626\n",
      "3/194, train_loss: 0.6611\n",
      "4/194, train_loss: 0.8638\n",
      "5/194, train_loss: 0.8571\n",
      "6/194, train_loss: 0.6791\n",
      "7/194, train_loss: 0.5884\n",
      "8/194, train_loss: 0.7198\n",
      "9/194, train_loss: 0.7835\n",
      "10/194, train_loss: 0.7648\n",
      "11/194, train_loss: 0.6801\n",
      "12/194, train_loss: 0.5237\n",
      "13/194, train_loss: 0.5706\n",
      "14/194, train_loss: 0.5670\n",
      "15/194, train_loss: 0.6207\n",
      "16/194, train_loss: 0.9206\n",
      "17/194, train_loss: 0.7725\n",
      "18/194, train_loss: 0.8080\n",
      "19/194, train_loss: 0.7963\n",
      "20/194, train_loss: 0.7291\n",
      "21/194, train_loss: 0.6481\n",
      "22/194, train_loss: 0.7526\n",
      "23/194, train_loss: 0.7741\n",
      "24/194, train_loss: 0.8528\n",
      "25/194, train_loss: 0.6755\n",
      "26/194, train_loss: 0.6621\n",
      "27/194, train_loss: 0.8325\n",
      "28/194, train_loss: 0.7282\n",
      "29/194, train_loss: 0.9121\n",
      "30/194, train_loss: 0.9172\n",
      "31/194, train_loss: 0.6773\n",
      "32/194, train_loss: 0.7210\n",
      "33/194, train_loss: 0.7787\n",
      "34/194, train_loss: 0.7629\n",
      "35/194, train_loss: 0.8759\n",
      "36/194, train_loss: 0.7921\n",
      "37/194, train_loss: 0.7148\n",
      "38/194, train_loss: 0.5248\n",
      "39/194, train_loss: 0.7499\n",
      "40/194, train_loss: 0.9024\n",
      "41/194, train_loss: 0.6380\n",
      "42/194, train_loss: 0.7202\n",
      "43/194, train_loss: 0.8781\n",
      "44/194, train_loss: 0.7521\n",
      "45/194, train_loss: 0.6312\n",
      "46/194, train_loss: 0.5783\n",
      "47/194, train_loss: 0.7932\n",
      "48/194, train_loss: 0.6589\n",
      "49/194, train_loss: 0.8965\n",
      "50/194, train_loss: 0.8348\n",
      "51/194, train_loss: 0.6730\n",
      "52/194, train_loss: 0.7667\n",
      "53/194, train_loss: 0.7593\n",
      "54/194, train_loss: 0.9125\n",
      "55/194, train_loss: 0.6722\n",
      "56/194, train_loss: 0.7034\n",
      "57/194, train_loss: 0.7929\n",
      "58/194, train_loss: 0.8902\n",
      "59/194, train_loss: 0.7278\n",
      "60/194, train_loss: 0.6915\n",
      "61/194, train_loss: 0.8070\n",
      "62/194, train_loss: 0.7726\n",
      "63/194, train_loss: 0.8034\n",
      "64/194, train_loss: 0.7885\n",
      "65/194, train_loss: 0.8937\n",
      "66/194, train_loss: 0.8312\n",
      "67/194, train_loss: 0.6214\n",
      "68/194, train_loss: 0.7328\n",
      "69/194, train_loss: 0.7366\n",
      "70/194, train_loss: 0.7554\n",
      "71/194, train_loss: 0.6500\n",
      "72/194, train_loss: 0.6213\n",
      "73/194, train_loss: 0.7158\n",
      "74/194, train_loss: 0.8472\n",
      "75/194, train_loss: 0.7685\n",
      "76/194, train_loss: 0.8022\n",
      "77/194, train_loss: 0.7950\n",
      "78/194, train_loss: 0.8181\n",
      "79/194, train_loss: 0.6461\n",
      "80/194, train_loss: 0.7087\n",
      "81/194, train_loss: 0.8041\n",
      "82/194, train_loss: 0.6275\n",
      "83/194, train_loss: 0.7806\n",
      "84/194, train_loss: 0.7616\n",
      "85/194, train_loss: 0.8527\n",
      "86/194, train_loss: 0.9259\n",
      "87/194, train_loss: 0.6910\n",
      "88/194, train_loss: 0.6958\n",
      "89/194, train_loss: 0.7901\n",
      "90/194, train_loss: 0.7521\n",
      "91/194, train_loss: 0.7562\n",
      "92/194, train_loss: 0.7951\n",
      "93/194, train_loss: 0.7742\n",
      "94/194, train_loss: 0.7738\n",
      "95/194, train_loss: 0.6573\n",
      "96/194, train_loss: 0.8196\n",
      "97/194, train_loss: 0.7474\n",
      "98/194, train_loss: 0.7374\n",
      "99/194, train_loss: 0.9535\n",
      "100/194, train_loss: 0.6653\n",
      "101/194, train_loss: 0.8688\n",
      "102/194, train_loss: 0.8393\n",
      "103/194, train_loss: 0.8842\n",
      "104/194, train_loss: 0.8557\n",
      "105/194, train_loss: 0.7493\n",
      "106/194, train_loss: 0.9382\n",
      "107/194, train_loss: 0.7615\n",
      "108/194, train_loss: 0.6859\n",
      "109/194, train_loss: 0.6932\n",
      "110/194, train_loss: 0.8174\n",
      "111/194, train_loss: 0.6549\n",
      "112/194, train_loss: 0.7012\n",
      "113/194, train_loss: 0.8058\n",
      "114/194, train_loss: 0.7384\n",
      "115/194, train_loss: 0.6669\n",
      "116/194, train_loss: 0.6241\n",
      "117/194, train_loss: 0.7175\n",
      "118/194, train_loss: 0.7801\n",
      "119/194, train_loss: 0.8839\n",
      "120/194, train_loss: 0.6322\n",
      "121/194, train_loss: 0.7697\n",
      "122/194, train_loss: 0.7865\n",
      "123/194, train_loss: 0.8682\n",
      "124/194, train_loss: 0.9548\n",
      "125/194, train_loss: 0.8618\n",
      "126/194, train_loss: 0.8899\n",
      "127/194, train_loss: 0.8058\n",
      "128/194, train_loss: 0.6981\n",
      "129/194, train_loss: 0.7410\n",
      "130/194, train_loss: 0.8036\n",
      "131/194, train_loss: 0.7181\n",
      "132/194, train_loss: 0.7722\n",
      "133/194, train_loss: 0.6055\n",
      "134/194, train_loss: 0.7407\n",
      "135/194, train_loss: 0.7649\n",
      "136/194, train_loss: 0.7511\n",
      "137/194, train_loss: 0.6687\n",
      "138/194, train_loss: 0.7209\n",
      "139/194, train_loss: 0.6270\n",
      "140/194, train_loss: 0.7498\n",
      "141/194, train_loss: 0.7172\n",
      "142/194, train_loss: 0.6926\n",
      "143/194, train_loss: 0.7581\n",
      "144/194, train_loss: 0.7458\n",
      "145/194, train_loss: 0.7656\n",
      "146/194, train_loss: 0.8140\n",
      "147/194, train_loss: 0.6949\n",
      "148/194, train_loss: 0.7952\n",
      "149/194, train_loss: 0.8712\n",
      "150/194, train_loss: 0.8119\n",
      "151/194, train_loss: 0.9216\n",
      "152/194, train_loss: 0.8834\n",
      "153/194, train_loss: 0.8575\n",
      "154/194, train_loss: 0.8474\n",
      "155/194, train_loss: 0.8664\n",
      "156/194, train_loss: 0.9018\n",
      "157/194, train_loss: 0.9383\n",
      "158/194, train_loss: 0.8022\n",
      "159/194, train_loss: 0.8582\n",
      "160/194, train_loss: 0.8845\n",
      "161/194, train_loss: 0.7412\n",
      "162/194, train_loss: 0.8340\n",
      "163/194, train_loss: 0.8947\n",
      "164/194, train_loss: 0.8880\n",
      "165/194, train_loss: 0.8795\n",
      "166/194, train_loss: 0.9400\n",
      "167/194, train_loss: 0.8442\n",
      "168/194, train_loss: 0.7808\n",
      "169/194, train_loss: 0.8052\n",
      "170/194, train_loss: 0.6468\n",
      "171/194, train_loss: 0.7976\n",
      "172/194, train_loss: 0.7057\n",
      "173/194, train_loss: 0.6741\n",
      "174/194, train_loss: 0.6529\n",
      "175/194, train_loss: 0.7841\n",
      "176/194, train_loss: 0.5252\n",
      "177/194, train_loss: 0.8173\n",
      "178/194, train_loss: 0.7964\n",
      "179/194, train_loss: 0.7678\n",
      "180/194, train_loss: 0.9639\n",
      "181/194, train_loss: 0.6381\n",
      "182/194, train_loss: 0.6976\n",
      "183/194, train_loss: 0.8262\n",
      "184/194, train_loss: 0.7827\n",
      "185/194, train_loss: 0.8393\n",
      "186/194, train_loss: 0.7250\n",
      "187/194, train_loss: 0.8080\n",
      "188/194, train_loss: 0.8903\n",
      "189/194, train_loss: 0.8692\n",
      "190/194, train_loss: 0.8022\n",
      "191/194, train_loss: 0.5663\n",
      "192/194, train_loss: 0.6132\n",
      "193/194, train_loss: 0.7235\n",
      "194/194, train_loss: 0.6763\n",
      "metric=0.3638621149584651, metric_tc=0.384863858576864, metric_wt=0.49551338019470376, metric_et=0.211209117124478\n",
      "metric=0.3638621149584651, metric_tc=0.384863858576864, metric_wt=0.49551338019470376, metric_et=0.211209117124478\n",
      "current epoch: 70 current epoch loss: 0.7640\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 70/80 [12:53:46<1:46:34, 639.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metric=0.3638621149584651, metric_tc=0.384863858576864, metric_wt=0.49551338019470376, metric_et=0.211209117124478\n",
      "0.3638621149584651\n",
      "current epoch: 70 current mean dice: 0.3639 tc: 0.3849 wt: 0.4955 et: 0.2112\n",
      "best mean dice: 0.3941 at epoch: 68\n",
      "\n",
      " | Global Training Round : 71 |\n",
      "\n",
      "user 0 selected\n",
      "local epoch 1\n",
      "1/194, train_loss: 0.6758\n",
      "2/194, train_loss: 0.6698\n",
      "3/194, train_loss: 0.8313\n",
      "4/194, train_loss: 0.5924\n",
      "5/194, train_loss: 0.8643\n",
      "6/194, train_loss: 0.7355\n",
      "7/194, train_loss: 0.6952\n",
      "8/194, train_loss: 0.7835\n",
      "9/194, train_loss: 0.9262\n",
      "10/194, train_loss: 0.8402\n",
      "11/194, train_loss: 0.8839\n",
      "12/194, train_loss: 0.6018\n",
      "13/194, train_loss: 0.7742\n",
      "14/194, train_loss: 0.6353\n",
      "15/194, train_loss: 0.7467\n",
      "16/194, train_loss: 0.6413\n",
      "17/194, train_loss: 0.8008\n",
      "18/194, train_loss: 0.8195\n",
      "19/194, train_loss: 0.8082\n",
      "20/194, train_loss: 0.6955\n",
      "21/194, train_loss: 0.8557\n",
      "22/194, train_loss: 0.6220\n",
      "23/194, train_loss: 0.6644\n",
      "24/194, train_loss: 0.7730\n",
      "25/194, train_loss: 0.7990\n",
      "26/194, train_loss: 0.8179\n",
      "27/194, train_loss: 0.8709\n",
      "28/194, train_loss: 0.7013\n",
      "29/194, train_loss: 0.7240\n",
      "30/194, train_loss: 0.7689\n",
      "31/194, train_loss: 0.6944\n",
      "32/194, train_loss: 0.6966\n",
      "33/194, train_loss: 0.5960\n",
      "34/194, train_loss: 0.9526\n",
      "35/194, train_loss: 0.8540\n",
      "36/194, train_loss: 0.7351\n",
      "37/194, train_loss: 0.5015\n",
      "38/194, train_loss: 0.6561\n",
      "39/194, train_loss: 0.6393\n",
      "40/194, train_loss: 0.7857\n",
      "41/194, train_loss: 0.8572\n",
      "42/194, train_loss: 0.6625\n",
      "43/194, train_loss: 0.7436\n",
      "44/194, train_loss: 0.4441\n",
      "45/194, train_loss: 0.8532\n",
      "46/194, train_loss: 0.6696\n",
      "47/194, train_loss: 0.8829\n",
      "48/194, train_loss: 0.8179\n",
      "49/194, train_loss: 0.5772\n",
      "50/194, train_loss: 0.8586\n",
      "51/194, train_loss: 0.8651\n",
      "52/194, train_loss: 0.6671\n",
      "53/194, train_loss: 0.8476\n",
      "54/194, train_loss: 0.9157\n",
      "55/194, train_loss: 0.7505\n",
      "56/194, train_loss: 0.7292\n",
      "57/194, train_loss: 0.8867\n",
      "58/194, train_loss: 0.8535\n",
      "59/194, train_loss: 0.8831\n",
      "60/194, train_loss: 0.9246\n",
      "61/194, train_loss: 0.6199\n",
      "62/194, train_loss: 0.8951\n",
      "63/194, train_loss: 0.6179\n",
      "64/194, train_loss: 0.7325\n",
      "65/194, train_loss: 0.6947\n",
      "66/194, train_loss: 0.6714\n",
      "67/194, train_loss: 0.8533\n",
      "68/194, train_loss: 0.7778\n",
      "69/194, train_loss: 0.7263\n",
      "70/194, train_loss: 0.8411\n",
      "71/194, train_loss: 0.5497\n",
      "72/194, train_loss: 0.7672\n",
      "73/194, train_loss: 0.7853\n",
      "74/194, train_loss: 0.9029\n",
      "75/194, train_loss: 0.8286\n",
      "76/194, train_loss: 0.7718\n",
      "77/194, train_loss: 0.8501\n",
      "78/194, train_loss: 0.5832\n",
      "79/194, train_loss: 0.5166\n",
      "80/194, train_loss: 0.6233\n",
      "81/194, train_loss: 0.7674\n",
      "82/194, train_loss: 0.7195\n",
      "83/194, train_loss: 0.8664\n",
      "84/194, train_loss: 0.8370\n",
      "85/194, train_loss: 0.6436\n",
      "86/194, train_loss: 0.8736\n",
      "87/194, train_loss: 0.6878\n",
      "88/194, train_loss: 0.7751\n",
      "89/194, train_loss: 0.5965\n",
      "90/194, train_loss: 0.8132\n",
      "91/194, train_loss: 0.9020\n",
      "92/194, train_loss: 0.6644\n",
      "93/194, train_loss: 0.7350\n",
      "94/194, train_loss: 0.6552\n",
      "95/194, train_loss: 0.6050\n",
      "96/194, train_loss: 0.9065\n",
      "97/194, train_loss: 0.9066\n",
      "98/194, train_loss: 0.7620\n",
      "99/194, train_loss: 0.7127\n",
      "100/194, train_loss: 0.7400\n",
      "101/194, train_loss: 0.8957\n",
      "102/194, train_loss: 0.8491\n",
      "103/194, train_loss: 0.7623\n",
      "104/194, train_loss: 0.7511\n",
      "105/194, train_loss: 0.6579\n",
      "106/194, train_loss: 0.7536\n",
      "107/194, train_loss: 0.8016\n",
      "108/194, train_loss: 0.6767\n",
      "109/194, train_loss: 0.8570\n",
      "110/194, train_loss: 0.7190\n",
      "111/194, train_loss: 0.7902\n",
      "112/194, train_loss: 0.9034\n",
      "113/194, train_loss: 0.7864\n",
      "114/194, train_loss: 0.7392\n",
      "115/194, train_loss: 0.7557\n",
      "116/194, train_loss: 0.6566\n",
      "117/194, train_loss: 0.8440\n",
      "118/194, train_loss: 0.7638\n",
      "119/194, train_loss: 0.8084\n",
      "120/194, train_loss: 0.7235\n",
      "121/194, train_loss: 0.9385\n",
      "122/194, train_loss: 0.9291\n",
      "123/194, train_loss: 0.7887\n",
      "124/194, train_loss: 0.8695\n",
      "125/194, train_loss: 0.8106\n",
      "126/194, train_loss: 0.8189\n",
      "127/194, train_loss: 0.7645\n",
      "128/194, train_loss: 0.7894\n",
      "129/194, train_loss: 0.8365\n",
      "130/194, train_loss: 0.8439\n",
      "131/194, train_loss: 0.7399\n",
      "132/194, train_loss: 0.8296\n",
      "133/194, train_loss: 0.5548\n",
      "134/194, train_loss: 0.7981\n",
      "135/194, train_loss: 0.6563\n",
      "136/194, train_loss: 0.6459\n",
      "137/194, train_loss: 0.7189\n",
      "138/194, train_loss: 0.8062\n",
      "139/194, train_loss: 0.6752\n",
      "140/194, train_loss: 0.5366\n",
      "141/194, train_loss: 0.9557\n",
      "142/194, train_loss: 0.7504\n",
      "143/194, train_loss: 0.8061\n",
      "144/194, train_loss: 0.5895\n",
      "145/194, train_loss: 0.7561\n",
      "146/194, train_loss: 0.8125\n",
      "147/194, train_loss: 0.7487\n",
      "148/194, train_loss: 0.7073\n",
      "149/194, train_loss: 0.8731\n",
      "150/194, train_loss: 0.8586\n",
      "151/194, train_loss: 0.9299\n",
      "152/194, train_loss: 0.7600\n",
      "153/194, train_loss: 0.8398\n",
      "154/194, train_loss: 0.8662\n",
      "155/194, train_loss: 0.8234\n",
      "156/194, train_loss: 0.7727\n",
      "157/194, train_loss: 0.7979\n",
      "158/194, train_loss: 0.9150\n",
      "159/194, train_loss: 0.8373\n",
      "160/194, train_loss: 0.8122\n",
      "161/194, train_loss: 0.7441\n",
      "162/194, train_loss: 0.8966\n",
      "163/194, train_loss: 0.7162\n",
      "164/194, train_loss: 0.7706\n",
      "165/194, train_loss: 0.8151\n",
      "166/194, train_loss: 0.8951\n",
      "167/194, train_loss: 0.8578\n",
      "168/194, train_loss: 0.8482\n",
      "169/194, train_loss: 0.9248\n",
      "170/194, train_loss: 0.7437\n",
      "171/194, train_loss: 0.9357\n",
      "172/194, train_loss: 0.7441\n",
      "173/194, train_loss: 0.7838\n",
      "174/194, train_loss: 0.7590\n",
      "175/194, train_loss: 0.7587\n",
      "176/194, train_loss: 0.7725\n",
      "177/194, train_loss: 0.9056\n",
      "178/194, train_loss: 0.8928\n",
      "179/194, train_loss: 0.7353\n",
      "180/194, train_loss: 0.6735\n",
      "181/194, train_loss: 0.7746\n",
      "182/194, train_loss: 0.5718\n",
      "183/194, train_loss: 0.8856\n",
      "184/194, train_loss: 0.6402\n",
      "185/194, train_loss: 0.8021\n",
      "186/194, train_loss: 0.7124\n",
      "187/194, train_loss: 0.7991\n",
      "188/194, train_loss: 0.8796\n",
      "189/194, train_loss: 0.8325\n",
      "190/194, train_loss: 0.7001\n",
      "191/194, train_loss: 0.8060\n",
      "192/194, train_loss: 0.8310\n",
      "193/194, train_loss: 0.9764\n",
      "194/194, train_loss: 0.8631\n",
      "metric=0.4132914099221428, metric_tc=0.44100518710911274, metric_wt=0.5520510952919722, metric_et=0.24681793168808022\n",
      "metric=0.4132914099221428, metric_tc=0.44100518710911274, metric_wt=0.5520510952919722, metric_et=0.24681793168808022\n",
      "current epoch: 71 current epoch loss: 0.7706\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▉ | 71/80 [13:04:30<1:36:07, 640.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metric=0.4132914099221428, metric_tc=0.44100518710911274, metric_wt=0.5520510952919722, metric_et=0.24681793168808022\n",
      "0.4132914099221428\n",
      "saved new best metric model\n",
      "current epoch: 71 current mean dice: 0.4133 tc: 0.4410 wt: 0.5521 et: 0.2468\n",
      "best mean dice: 0.4133 at epoch: 71\n",
      "\n",
      " | Global Training Round : 72 |\n",
      "\n",
      "user 0 selected\n",
      "local epoch 1\n",
      "1/194, train_loss: 0.7910\n",
      "2/194, train_loss: 0.8956\n",
      "3/194, train_loss: 0.6468\n",
      "4/194, train_loss: 0.7136\n",
      "5/194, train_loss: 0.5733\n",
      "6/194, train_loss: 0.9422\n",
      "7/194, train_loss: 0.8957\n",
      "8/194, train_loss: 0.8026\n",
      "9/194, train_loss: 0.7008\n",
      "10/194, train_loss: 0.7558\n",
      "11/194, train_loss: 0.5880\n",
      "12/194, train_loss: 0.7270\n",
      "13/194, train_loss: 0.7889\n",
      "14/194, train_loss: 0.8388\n",
      "15/194, train_loss: 0.6138\n",
      "16/194, train_loss: 0.6476\n",
      "17/194, train_loss: 0.7849\n",
      "18/194, train_loss: 0.6344\n",
      "19/194, train_loss: 0.6197\n",
      "20/194, train_loss: 0.8502\n",
      "21/194, train_loss: 0.6660\n",
      "22/194, train_loss: 0.8105\n",
      "23/194, train_loss: 0.7001\n",
      "24/194, train_loss: 0.7264\n",
      "25/194, train_loss: 0.7606\n",
      "26/194, train_loss: 0.8247\n",
      "27/194, train_loss: 0.7634\n",
      "28/194, train_loss: 0.6765\n",
      "29/194, train_loss: 0.8230\n",
      "30/194, train_loss: 0.7197\n",
      "31/194, train_loss: 0.8822\n",
      "32/194, train_loss: 0.6980\n",
      "33/194, train_loss: 0.8010\n",
      "34/194, train_loss: 0.8346\n",
      "35/194, train_loss: 0.7386\n",
      "36/194, train_loss: 0.7998\n",
      "37/194, train_loss: 0.6128\n",
      "38/194, train_loss: 0.8248\n",
      "39/194, train_loss: 0.6489\n",
      "40/194, train_loss: 0.7496\n",
      "41/194, train_loss: 0.6204\n",
      "42/194, train_loss: 0.8446\n",
      "43/194, train_loss: 0.8005\n",
      "44/194, train_loss: 0.5937\n",
      "45/194, train_loss: 0.7358\n",
      "46/194, train_loss: 0.7873\n",
      "47/194, train_loss: 0.7611\n",
      "48/194, train_loss: 0.8033\n",
      "49/194, train_loss: 0.9036\n",
      "50/194, train_loss: 0.8503\n",
      "51/194, train_loss: 0.7471\n",
      "52/194, train_loss: 0.6366\n",
      "53/194, train_loss: 0.8048\n",
      "54/194, train_loss: 0.7336\n",
      "55/194, train_loss: 0.6537\n",
      "56/194, train_loss: 0.7993\n",
      "57/194, train_loss: 0.9272\n",
      "58/194, train_loss: 0.9140\n",
      "59/194, train_loss: 0.8060\n",
      "60/194, train_loss: 0.9447\n",
      "61/194, train_loss: 0.7536\n",
      "62/194, train_loss: 0.5305\n",
      "63/194, train_loss: 0.7720\n",
      "64/194, train_loss: 0.6957\n",
      "65/194, train_loss: 0.8525\n",
      "66/194, train_loss: 0.8285\n",
      "67/194, train_loss: 0.6674\n",
      "68/194, train_loss: 0.7292\n",
      "69/194, train_loss: 0.9027\n",
      "70/194, train_loss: 0.8727\n",
      "71/194, train_loss: 0.7472\n",
      "72/194, train_loss: 0.7032\n",
      "73/194, train_loss: 0.6071\n",
      "74/194, train_loss: 0.7635\n",
      "75/194, train_loss: 0.6486\n",
      "76/194, train_loss: 0.7354\n",
      "77/194, train_loss: 0.8368\n",
      "78/194, train_loss: 0.6435\n",
      "79/194, train_loss: 0.7648\n",
      "80/194, train_loss: 0.7183\n",
      "81/194, train_loss: 0.6697\n",
      "82/194, train_loss: 0.8508\n",
      "83/194, train_loss: 0.8458\n",
      "84/194, train_loss: 0.6825\n",
      "85/194, train_loss: 0.9814\n",
      "86/194, train_loss: 0.7517\n",
      "87/194, train_loss: 0.8306\n",
      "88/194, train_loss: 0.9251\n",
      "89/194, train_loss: 0.8755\n",
      "90/194, train_loss: 0.8140\n",
      "91/194, train_loss: 0.6901\n",
      "92/194, train_loss: 0.9015\n",
      "93/194, train_loss: 0.6878\n",
      "94/194, train_loss: 0.8235\n",
      "95/194, train_loss: 0.5991\n",
      "96/194, train_loss: 0.6776\n",
      "97/194, train_loss: 0.7293\n",
      "98/194, train_loss: 0.6666\n",
      "99/194, train_loss: 0.6460\n",
      "100/194, train_loss: 0.7560\n",
      "101/194, train_loss: 0.8160\n",
      "102/194, train_loss: 0.8387\n",
      "103/194, train_loss: 0.8676\n",
      "104/194, train_loss: 0.7276\n",
      "105/194, train_loss: 0.7306\n",
      "106/194, train_loss: 0.8151\n",
      "107/194, train_loss: 0.8396\n",
      "108/194, train_loss: 0.7863\n",
      "109/194, train_loss: 0.7239\n",
      "110/194, train_loss: 0.6734\n",
      "111/194, train_loss: 0.7796\n",
      "112/194, train_loss: 0.6348\n",
      "113/194, train_loss: 0.6820\n",
      "114/194, train_loss: 0.6015\n",
      "115/194, train_loss: 0.8494\n",
      "116/194, train_loss: 0.7803\n",
      "117/194, train_loss: 0.6229\n",
      "118/194, train_loss: 0.9333\n",
      "119/194, train_loss: 0.6417\n",
      "120/194, train_loss: 0.8262\n",
      "121/194, train_loss: 0.9331\n",
      "122/194, train_loss: 0.9729\n",
      "123/194, train_loss: 0.8940\n",
      "124/194, train_loss: 0.7874\n",
      "125/194, train_loss: 0.7857\n",
      "126/194, train_loss: 0.9040\n",
      "127/194, train_loss: 0.6840\n",
      "128/194, train_loss: 0.7139\n",
      "129/194, train_loss: 0.7503\n",
      "130/194, train_loss: 0.7146\n",
      "131/194, train_loss: 0.8181\n",
      "132/194, train_loss: 0.7378\n",
      "133/194, train_loss: 0.8303\n",
      "134/194, train_loss: 0.7741\n",
      "135/194, train_loss: 0.7356\n",
      "136/194, train_loss: 0.8853\n",
      "137/194, train_loss: 0.9347\n",
      "138/194, train_loss: 0.8173\n",
      "139/194, train_loss: 0.7107\n",
      "140/194, train_loss: 0.6503\n",
      "141/194, train_loss: 0.9155\n",
      "142/194, train_loss: 0.7642\n",
      "143/194, train_loss: 0.8181\n",
      "144/194, train_loss: 0.8729\n",
      "145/194, train_loss: 0.6813\n",
      "146/194, train_loss: 0.6727\n",
      "147/194, train_loss: 0.8719\n",
      "148/194, train_loss: 0.7209\n",
      "149/194, train_loss: 0.8477\n",
      "150/194, train_loss: 0.8357\n",
      "151/194, train_loss: 0.8330\n",
      "152/194, train_loss: 0.8740\n",
      "153/194, train_loss: 0.8056\n",
      "154/194, train_loss: 0.7708\n",
      "155/194, train_loss: 0.7508\n",
      "156/194, train_loss: 0.9285\n",
      "157/194, train_loss: 0.8639\n",
      "158/194, train_loss: 0.7015\n",
      "159/194, train_loss: 0.8141\n",
      "160/194, train_loss: 0.8056\n",
      "161/194, train_loss: 0.7678\n",
      "162/194, train_loss: 0.8553\n",
      "163/194, train_loss: 0.7733\n",
      "164/194, train_loss: 0.8629\n",
      "165/194, train_loss: 0.7577\n",
      "166/194, train_loss: 0.7222\n",
      "167/194, train_loss: 0.8711\n",
      "168/194, train_loss: 0.9570\n",
      "169/194, train_loss: 0.7671\n",
      "170/194, train_loss: 0.7278\n",
      "171/194, train_loss: 0.8722\n",
      "172/194, train_loss: 0.8214\n",
      "173/194, train_loss: 0.6181\n",
      "174/194, train_loss: 0.8942\n",
      "175/194, train_loss: 0.7309\n",
      "176/194, train_loss: 0.8464\n",
      "177/194, train_loss: 0.8437\n",
      "178/194, train_loss: 0.7139\n",
      "179/194, train_loss: 0.7772\n",
      "180/194, train_loss: 0.8919\n",
      "181/194, train_loss: 0.6937\n",
      "182/194, train_loss: 0.6698\n",
      "183/194, train_loss: 0.6200\n",
      "184/194, train_loss: 0.8932\n",
      "185/194, train_loss: 0.7855\n",
      "186/194, train_loss: 0.8503\n",
      "187/194, train_loss: 0.8980\n",
      "188/194, train_loss: 0.8536\n",
      "189/194, train_loss: 0.8536\n",
      "190/194, train_loss: 0.8180\n",
      "191/194, train_loss: 0.8179\n",
      "192/194, train_loss: 0.8634\n",
      "193/194, train_loss: 0.6358\n",
      "194/194, train_loss: 0.8302\n",
      "metric=0.34782576747238636, metric_tc=0.3674717831114928, metric_wt=0.460144084567825, metric_et=0.21586143015883863\n",
      "metric=0.34782576747238636, metric_tc=0.3674717831114928, metric_wt=0.460144084567825, metric_et=0.21586143015883863\n",
      "current epoch: 72 current epoch loss: 0.7744\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 72/80 [13:15:35<1:26:24, 648.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metric=0.34782576747238636, metric_tc=0.3674717831114928, metric_wt=0.460144084567825, metric_et=0.21586143015883863\n",
      "0.34782576747238636\n",
      "current epoch: 72 current mean dice: 0.3478 tc: 0.3675 wt: 0.4601 et: 0.2159\n",
      "best mean dice: 0.4133 at epoch: 71\n",
      "\n",
      " | Global Training Round : 73 |\n",
      "\n",
      "user 0 selected\n",
      "local epoch 1\n",
      "1/194, train_loss: 0.6493\n",
      "2/194, train_loss: 0.7918\n",
      "3/194, train_loss: 0.8481\n",
      "4/194, train_loss: 0.5803\n",
      "5/194, train_loss: 0.7847\n",
      "6/194, train_loss: 0.7734\n",
      "7/194, train_loss: 0.8670\n",
      "8/194, train_loss: 0.8188\n",
      "9/194, train_loss: 0.6160\n",
      "10/194, train_loss: 0.8199\n",
      "11/194, train_loss: 0.7657\n",
      "12/194, train_loss: 0.6544\n",
      "13/194, train_loss: 0.8414\n",
      "14/194, train_loss: 0.8989\n",
      "15/194, train_loss: 0.7811\n",
      "16/194, train_loss: 0.6224\n",
      "17/194, train_loss: 0.8051\n",
      "18/194, train_loss: 0.7372\n",
      "19/194, train_loss: 0.8228\n",
      "20/194, train_loss: 0.8687\n",
      "21/194, train_loss: 0.6538\n",
      "22/194, train_loss: 0.8089\n",
      "23/194, train_loss: 0.8265\n",
      "24/194, train_loss: 0.7610\n",
      "25/194, train_loss: 0.8180\n",
      "26/194, train_loss: 0.7890\n",
      "27/194, train_loss: 0.8109\n",
      "28/194, train_loss: 0.8793\n",
      "29/194, train_loss: 0.8334\n",
      "30/194, train_loss: 0.5278\n",
      "31/194, train_loss: 0.8026\n",
      "32/194, train_loss: 0.7474\n",
      "33/194, train_loss: 0.8099\n",
      "34/194, train_loss: 0.8344\n",
      "35/194, train_loss: 0.8422\n",
      "36/194, train_loss: 0.8140\n",
      "37/194, train_loss: 0.5798\n",
      "38/194, train_loss: 0.6312\n",
      "39/194, train_loss: 0.5669\n",
      "40/194, train_loss: 0.7235\n",
      "41/194, train_loss: 0.6250\n",
      "42/194, train_loss: 0.8739\n",
      "43/194, train_loss: 0.5662\n",
      "44/194, train_loss: 0.8564\n",
      "45/194, train_loss: 0.7445\n",
      "46/194, train_loss: 0.6326\n",
      "47/194, train_loss: 0.7871\n",
      "48/194, train_loss: 0.7385\n",
      "49/194, train_loss: 0.6496\n",
      "50/194, train_loss: 0.3981\n",
      "51/194, train_loss: 0.7204\n",
      "52/194, train_loss: 0.5630\n",
      "53/194, train_loss: 0.8931\n",
      "54/194, train_loss: 0.7562\n",
      "55/194, train_loss: 0.8122\n",
      "56/194, train_loss: 0.8602\n",
      "57/194, train_loss: 0.8478\n",
      "58/194, train_loss: 0.8194\n",
      "59/194, train_loss: 0.8733\n",
      "60/194, train_loss: 0.8651\n",
      "61/194, train_loss: 0.6465\n",
      "62/194, train_loss: 0.7395\n",
      "63/194, train_loss: 0.6684\n",
      "64/194, train_loss: 0.4888\n",
      "65/194, train_loss: 0.7883\n",
      "66/194, train_loss: 0.6880\n",
      "67/194, train_loss: 0.8419\n",
      "68/194, train_loss: 0.5862\n",
      "69/194, train_loss: 0.8722\n",
      "70/194, train_loss: 0.7825\n",
      "71/194, train_loss: 0.9239\n",
      "72/194, train_loss: 0.7590\n",
      "73/194, train_loss: 0.7714\n",
      "74/194, train_loss: 0.7225\n",
      "75/194, train_loss: 0.8900\n",
      "76/194, train_loss: 0.6993\n",
      "77/194, train_loss: 0.8960\n",
      "78/194, train_loss: 0.7679\n",
      "79/194, train_loss: 0.5899\n",
      "80/194, train_loss: 0.6571\n",
      "81/194, train_loss: 0.7021\n",
      "82/194, train_loss: 0.8543\n",
      "83/194, train_loss: 0.7254\n",
      "84/194, train_loss: 0.8045\n",
      "85/194, train_loss: 0.7844\n",
      "86/194, train_loss: 0.8017\n",
      "87/194, train_loss: 0.9038\n",
      "88/194, train_loss: 0.8443\n",
      "89/194, train_loss: 0.8065\n",
      "90/194, train_loss: 0.7348\n",
      "91/194, train_loss: 0.8122\n",
      "92/194, train_loss: 0.6803\n",
      "93/194, train_loss: 0.7166\n",
      "94/194, train_loss: 0.8508\n",
      "95/194, train_loss: 0.7218\n",
      "96/194, train_loss: 0.8214\n",
      "97/194, train_loss: 0.8211\n",
      "98/194, train_loss: 0.7256\n",
      "99/194, train_loss: 0.7542\n",
      "100/194, train_loss: 0.7844\n",
      "101/194, train_loss: 0.7483\n",
      "102/194, train_loss: 0.8109\n",
      "103/194, train_loss: 0.7201\n",
      "104/194, train_loss: 0.7219\n",
      "105/194, train_loss: 0.6355\n",
      "106/194, train_loss: 0.8639\n",
      "107/194, train_loss: 0.7328\n",
      "108/194, train_loss: 0.7067\n",
      "109/194, train_loss: 0.8680\n",
      "110/194, train_loss: 0.6419\n",
      "111/194, train_loss: 0.8561\n",
      "112/194, train_loss: 0.6073\n",
      "113/194, train_loss: 0.7562\n",
      "114/194, train_loss: 0.7734\n",
      "115/194, train_loss: 0.8194\n",
      "116/194, train_loss: 0.7204\n",
      "117/194, train_loss: 0.7650\n",
      "118/194, train_loss: 0.7993\n",
      "119/194, train_loss: 0.7986\n",
      "120/194, train_loss: 0.6965\n",
      "121/194, train_loss: 0.6187\n",
      "122/194, train_loss: 0.8531\n",
      "123/194, train_loss: 0.6578\n",
      "124/194, train_loss: 0.9031\n",
      "125/194, train_loss: 0.7308\n",
      "126/194, train_loss: 0.8025\n",
      "127/194, train_loss: 0.8464\n",
      "128/194, train_loss: 0.7050\n",
      "129/194, train_loss: 0.7775\n",
      "130/194, train_loss: 0.7845\n",
      "131/194, train_loss: 0.6951\n",
      "132/194, train_loss: 0.6954\n",
      "133/194, train_loss: 0.9258\n",
      "134/194, train_loss: 0.7390\n",
      "135/194, train_loss: 0.6670\n",
      "136/194, train_loss: 0.6974\n",
      "137/194, train_loss: 0.8586\n",
      "138/194, train_loss: 0.6844\n",
      "139/194, train_loss: 0.7346\n",
      "140/194, train_loss: 0.8339\n",
      "141/194, train_loss: 0.6712\n",
      "142/194, train_loss: 0.8659\n",
      "143/194, train_loss: 0.9692\n",
      "144/194, train_loss: 0.6035\n",
      "145/194, train_loss: 0.5924\n",
      "146/194, train_loss: 0.8527\n",
      "147/194, train_loss: 0.7827\n",
      "148/194, train_loss: 0.7535\n",
      "149/194, train_loss: 0.7622\n",
      "150/194, train_loss: 0.8765\n",
      "151/194, train_loss: 0.8766\n",
      "152/194, train_loss: 0.8092\n",
      "153/194, train_loss: 0.8780\n",
      "154/194, train_loss: 0.7844\n",
      "155/194, train_loss: 0.8595\n",
      "156/194, train_loss: 0.8372\n",
      "157/194, train_loss: 0.6547\n",
      "158/194, train_loss: 0.8165\n",
      "159/194, train_loss: 0.6944\n",
      "160/194, train_loss: 0.9125\n",
      "161/194, train_loss: 0.8326\n",
      "162/194, train_loss: 0.7850\n",
      "163/194, train_loss: 0.8675\n",
      "164/194, train_loss: 0.8360\n",
      "165/194, train_loss: 0.6754\n",
      "166/194, train_loss: 0.7345\n",
      "167/194, train_loss: 0.8256\n",
      "168/194, train_loss: 0.9146\n",
      "169/194, train_loss: 0.5836\n",
      "170/194, train_loss: 0.6847\n",
      "171/194, train_loss: 0.9557\n",
      "172/194, train_loss: 0.8419\n",
      "173/194, train_loss: 0.8204\n",
      "174/194, train_loss: 0.8039\n",
      "175/194, train_loss: 0.8488\n",
      "176/194, train_loss: 0.7159\n",
      "177/194, train_loss: 0.7321\n",
      "178/194, train_loss: 0.7833\n",
      "179/194, train_loss: 0.7632\n",
      "180/194, train_loss: 0.6982\n",
      "181/194, train_loss: 0.6243\n",
      "182/194, train_loss: 0.6726\n",
      "183/194, train_loss: 0.6084\n",
      "184/194, train_loss: 0.5296\n",
      "185/194, train_loss: 0.8599\n",
      "186/194, train_loss: 0.8786\n",
      "187/194, train_loss: 0.7374\n",
      "188/194, train_loss: 0.8204\n",
      "189/194, train_loss: 0.8776\n",
      "190/194, train_loss: 0.7574\n",
      "191/194, train_loss: 0.9572\n",
      "192/194, train_loss: 0.8036\n",
      "193/194, train_loss: 0.8810\n",
      "194/194, train_loss: 0.8253\n",
      "metric=0.3715726736312111, metric_tc=0.3890830526749293, metric_wt=0.5062944777309895, metric_et=0.2193404872280856\n",
      "metric=0.3715726736312111, metric_tc=0.3890830526749293, metric_wt=0.5062944777309895, metric_et=0.2193404872280856\n",
      "current epoch: 73 current epoch loss: 0.7647\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████▏| 73/80 [13:25:57<1:14:41, 640.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metric=0.3715726736312111, metric_tc=0.3890830526749293, metric_wt=0.5062944777309895, metric_et=0.2193404872280856\n",
      "0.3715726736312111\n",
      "current epoch: 73 current mean dice: 0.3716 tc: 0.3891 wt: 0.5063 et: 0.2193\n",
      "best mean dice: 0.4133 at epoch: 71\n",
      "\n",
      " | Global Training Round : 74 |\n",
      "\n",
      "user 0 selected\n",
      "local epoch 1\n",
      "1/194, train_loss: 0.5049\n",
      "2/194, train_loss: 0.8949\n",
      "3/194, train_loss: 0.8704\n",
      "4/194, train_loss: 0.5370\n",
      "5/194, train_loss: 0.7040\n",
      "6/194, train_loss: 0.7935\n",
      "7/194, train_loss: 0.5721\n",
      "8/194, train_loss: 0.8879\n",
      "9/194, train_loss: 0.6694\n",
      "10/194, train_loss: 0.6524\n",
      "11/194, train_loss: 0.7222\n",
      "12/194, train_loss: 0.7106\n",
      "13/194, train_loss: 0.6581\n",
      "14/194, train_loss: 0.7589\n",
      "15/194, train_loss: 0.9456\n",
      "16/194, train_loss: 0.8473\n",
      "17/194, train_loss: 0.7788\n",
      "18/194, train_loss: 0.7008\n",
      "19/194, train_loss: 0.8782\n",
      "20/194, train_loss: 0.8436\n",
      "21/194, train_loss: 0.7477\n",
      "22/194, train_loss: 0.6621\n",
      "23/194, train_loss: 0.6017\n",
      "24/194, train_loss: 0.9278\n",
      "25/194, train_loss: 0.7172\n",
      "26/194, train_loss: 0.7556\n",
      "27/194, train_loss: 0.5601\n",
      "28/194, train_loss: 0.7633\n",
      "29/194, train_loss: 0.7594\n",
      "30/194, train_loss: 0.7177\n",
      "31/194, train_loss: 0.7326\n",
      "32/194, train_loss: 0.6760\n",
      "33/194, train_loss: 0.8242\n",
      "34/194, train_loss: 0.8155\n",
      "35/194, train_loss: 0.8825\n",
      "36/194, train_loss: 0.9403\n",
      "37/194, train_loss: 0.7272\n",
      "38/194, train_loss: 0.5257\n",
      "39/194, train_loss: 0.5415\n",
      "40/194, train_loss: 0.6208\n",
      "41/194, train_loss: 0.7498\n",
      "42/194, train_loss: 0.4370\n",
      "43/194, train_loss: 0.8340\n",
      "44/194, train_loss: 0.8531\n",
      "45/194, train_loss: 0.8024\n",
      "46/194, train_loss: 0.7629\n",
      "47/194, train_loss: 0.7248\n",
      "48/194, train_loss: 0.6303\n",
      "49/194, train_loss: 0.5553\n",
      "50/194, train_loss: 0.9099\n",
      "51/194, train_loss: 0.7790\n",
      "52/194, train_loss: 0.6664\n",
      "53/194, train_loss: 0.8423\n",
      "54/194, train_loss: 0.7986\n",
      "55/194, train_loss: 0.6699\n",
      "56/194, train_loss: 0.7505\n",
      "57/194, train_loss: 0.7739\n",
      "58/194, train_loss: 0.8272\n",
      "59/194, train_loss: 0.8416\n",
      "60/194, train_loss: 0.8946\n",
      "61/194, train_loss: 0.8863\n",
      "62/194, train_loss: 0.8186\n",
      "63/194, train_loss: 0.7259\n",
      "64/194, train_loss: 0.6945\n",
      "65/194, train_loss: 0.7551\n",
      "66/194, train_loss: 0.7657\n",
      "67/194, train_loss: 0.8417\n",
      "68/194, train_loss: 0.7781\n",
      "69/194, train_loss: 0.6936\n",
      "70/194, train_loss: 0.6792\n",
      "71/194, train_loss: 0.7260\n",
      "72/194, train_loss: 0.7766\n",
      "73/194, train_loss: 0.6676\n",
      "74/194, train_loss: 0.7630\n",
      "75/194, train_loss: 0.7597\n",
      "76/194, train_loss: 0.7585\n",
      "77/194, train_loss: 0.6185\n",
      "78/194, train_loss: 0.7826\n",
      "79/194, train_loss: 0.7195\n",
      "80/194, train_loss: 0.4510\n",
      "81/194, train_loss: 0.8105\n",
      "82/194, train_loss: 0.8486\n",
      "83/194, train_loss: 0.8088\n",
      "84/194, train_loss: 0.8050\n",
      "85/194, train_loss: 0.9034\n",
      "86/194, train_loss: 0.8086\n",
      "87/194, train_loss: 0.7756\n",
      "88/194, train_loss: 0.6514\n",
      "89/194, train_loss: 0.8250\n",
      "90/194, train_loss: 0.7417\n",
      "91/194, train_loss: 0.7890\n",
      "92/194, train_loss: 0.8801\n",
      "93/194, train_loss: 0.8888\n",
      "94/194, train_loss: 0.7126\n",
      "95/194, train_loss: 0.8671\n",
      "96/194, train_loss: 0.6178\n",
      "97/194, train_loss: 0.7202\n",
      "98/194, train_loss: 0.7015\n",
      "99/194, train_loss: 0.6846\n",
      "100/194, train_loss: 0.8166\n",
      "101/194, train_loss: 0.8370\n",
      "102/194, train_loss: 0.6802\n",
      "103/194, train_loss: 0.8597\n",
      "104/194, train_loss: 0.7824\n",
      "105/194, train_loss: 0.5536\n",
      "106/194, train_loss: 0.6081\n",
      "107/194, train_loss: 0.5209\n",
      "108/194, train_loss: 0.7518\n",
      "109/194, train_loss: 0.7027\n",
      "110/194, train_loss: 0.6684\n",
      "111/194, train_loss: 0.6025\n",
      "112/194, train_loss: 0.6745\n",
      "113/194, train_loss: 0.7845\n",
      "114/194, train_loss: 0.7097\n",
      "115/194, train_loss: 0.6573\n",
      "116/194, train_loss: 0.7486\n",
      "117/194, train_loss: 0.8203\n",
      "118/194, train_loss: 0.7507\n",
      "119/194, train_loss: 0.7584\n",
      "120/194, train_loss: 0.7197\n",
      "121/194, train_loss: 0.8992\n",
      "122/194, train_loss: 0.8339\n",
      "123/194, train_loss: 0.8780\n",
      "124/194, train_loss: 0.8752\n",
      "125/194, train_loss: 0.8783\n",
      "126/194, train_loss: 0.8844\n",
      "127/194, train_loss: 0.9768\n",
      "128/194, train_loss: 0.7619\n",
      "129/194, train_loss: 0.7954\n",
      "130/194, train_loss: 0.7577\n",
      "131/194, train_loss: 0.6933\n",
      "132/194, train_loss: 0.6395\n",
      "133/194, train_loss: 0.6678\n",
      "134/194, train_loss: 0.6890\n",
      "135/194, train_loss: 0.7197\n",
      "136/194, train_loss: 0.7026\n",
      "137/194, train_loss: 0.7049\n",
      "138/194, train_loss: 0.5068\n",
      "139/194, train_loss: 0.6199\n",
      "140/194, train_loss: 0.7162\n",
      "141/194, train_loss: 0.8769\n",
      "142/194, train_loss: 0.7860\n",
      "143/194, train_loss: 0.8779\n",
      "144/194, train_loss: 0.8772\n",
      "145/194, train_loss: 0.7610\n",
      "146/194, train_loss: 0.8117\n",
      "147/194, train_loss: 0.7687\n",
      "148/194, train_loss: 0.6656\n",
      "149/194, train_loss: 0.6827\n",
      "150/194, train_loss: 0.8292\n",
      "151/194, train_loss: 0.8057\n",
      "152/194, train_loss: 0.8190\n",
      "153/194, train_loss: 0.8808\n",
      "154/194, train_loss: 0.8042\n",
      "155/194, train_loss: 0.7981\n",
      "156/194, train_loss: 0.9005\n",
      "157/194, train_loss: 0.8423\n",
      "158/194, train_loss: 0.9756\n",
      "159/194, train_loss: 0.7617\n",
      "160/194, train_loss: 0.8542\n",
      "161/194, train_loss: 0.8685\n",
      "162/194, train_loss: 0.8651\n",
      "163/194, train_loss: 0.9265\n",
      "164/194, train_loss: 0.7809\n",
      "165/194, train_loss: 0.7159\n",
      "166/194, train_loss: 0.8306\n",
      "167/194, train_loss: 0.5406\n",
      "168/194, train_loss: 0.8935\n",
      "169/194, train_loss: 0.6721\n",
      "170/194, train_loss: 0.8106\n",
      "171/194, train_loss: 0.6787\n",
      "172/194, train_loss: 0.7813\n",
      "173/194, train_loss: 0.8446\n",
      "174/194, train_loss: 0.6668\n",
      "175/194, train_loss: 0.7706\n",
      "176/194, train_loss: 0.8052\n",
      "177/194, train_loss: 0.6958\n",
      "178/194, train_loss: 0.7598\n",
      "179/194, train_loss: 0.7353\n",
      "180/194, train_loss: 0.8901\n",
      "181/194, train_loss: 0.6826\n",
      "182/194, train_loss: 0.8394\n",
      "183/194, train_loss: 0.6305\n",
      "184/194, train_loss: 0.8369\n",
      "185/194, train_loss: 0.8385\n",
      "186/194, train_loss: 0.8734\n",
      "187/194, train_loss: 0.9216\n",
      "188/194, train_loss: 0.6475\n",
      "189/194, train_loss: 0.8322\n",
      "190/194, train_loss: 0.9304\n",
      "191/194, train_loss: 0.9440\n",
      "192/194, train_loss: 0.9188\n",
      "193/194, train_loss: 0.6288\n",
      "194/194, train_loss: 0.8986\n",
      "metric=0.36345293559134007, metric_tc=0.3726347141588728, metric_wt=0.5003744739418229, metric_et=0.2173496154913058\n",
      "metric=0.36345293559134007, metric_tc=0.3726347141588728, metric_wt=0.5003744739418229, metric_et=0.2173496154913058\n",
      "current epoch: 74 current epoch loss: 0.7607\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▎| 74/80 [13:37:20<1:05:17, 652.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metric=0.36345293559134007, metric_tc=0.3726347141588728, metric_wt=0.5003744739418229, metric_et=0.2173496154913058\n",
      "0.36345293559134007\n",
      "current epoch: 74 current mean dice: 0.3635 tc: 0.3726 wt: 0.5004 et: 0.2173\n",
      "best mean dice: 0.4133 at epoch: 71\n",
      "\n",
      " | Global Training Round : 75 |\n",
      "\n",
      "user 0 selected\n",
      "local epoch 1\n",
      "1/194, train_loss: 0.5973\n",
      "2/194, train_loss: 0.6230\n",
      "3/194, train_loss: 0.6442\n",
      "4/194, train_loss: 0.6667\n",
      "5/194, train_loss: 0.7239\n",
      "6/194, train_loss: 0.7968\n",
      "7/194, train_loss: 0.8529\n",
      "8/194, train_loss: 0.7942\n",
      "9/194, train_loss: 0.7533\n",
      "10/194, train_loss: 0.7583\n",
      "11/194, train_loss: 0.6059\n",
      "12/194, train_loss: 0.6998\n",
      "13/194, train_loss: 0.6060\n",
      "14/194, train_loss: 0.6804\n",
      "15/194, train_loss: 0.6407\n",
      "16/194, train_loss: 0.8172\n",
      "17/194, train_loss: 0.6292\n",
      "18/194, train_loss: 0.8883\n",
      "19/194, train_loss: 0.7541\n",
      "20/194, train_loss: 0.8596\n",
      "21/194, train_loss: 0.7302\n",
      "22/194, train_loss: 0.8407\n",
      "23/194, train_loss: 0.8045\n",
      "24/194, train_loss: 0.5510\n",
      "25/194, train_loss: 0.9007\n",
      "26/194, train_loss: 0.6123\n",
      "27/194, train_loss: 0.6861\n",
      "28/194, train_loss: 0.8945\n",
      "29/194, train_loss: 0.7069\n",
      "30/194, train_loss: 0.6258\n",
      "31/194, train_loss: 0.7680\n",
      "32/194, train_loss: 0.9059\n",
      "33/194, train_loss: 0.6827\n",
      "34/194, train_loss: 0.8373\n",
      "35/194, train_loss: 0.8030\n",
      "36/194, train_loss: 0.7585\n",
      "37/194, train_loss: 0.7136\n",
      "38/194, train_loss: 0.6488\n",
      "39/194, train_loss: 0.5284\n",
      "40/194, train_loss: 0.5844\n",
      "41/194, train_loss: 0.6140\n",
      "42/194, train_loss: 0.8631\n",
      "43/194, train_loss: 0.7664\n",
      "44/194, train_loss: 0.6037\n",
      "45/194, train_loss: 0.7623\n",
      "46/194, train_loss: 0.7274\n",
      "47/194, train_loss: 0.8511\n",
      "48/194, train_loss: 0.8018\n",
      "49/194, train_loss: 0.8156\n",
      "50/194, train_loss: 0.7222\n",
      "51/194, train_loss: 0.8891\n",
      "52/194, train_loss: 0.6529\n",
      "53/194, train_loss: 0.8311\n",
      "54/194, train_loss: 0.6231\n",
      "55/194, train_loss: 0.7456\n",
      "56/194, train_loss: 0.8397\n",
      "57/194, train_loss: 0.8722\n",
      "58/194, train_loss: 0.9265\n",
      "59/194, train_loss: 0.7441\n",
      "60/194, train_loss: 0.5624\n",
      "61/194, train_loss: 0.8317\n",
      "62/194, train_loss: 0.7873\n",
      "63/194, train_loss: 0.7627\n",
      "64/194, train_loss: 0.7022\n",
      "65/194, train_loss: 0.7272\n",
      "66/194, train_loss: 0.8636\n",
      "67/194, train_loss: 0.7335\n",
      "68/194, train_loss: 0.7143\n",
      "69/194, train_loss: 0.7260\n",
      "70/194, train_loss: 0.8572\n",
      "71/194, train_loss: 0.7448\n",
      "72/194, train_loss: 0.5918\n",
      "73/194, train_loss: 0.6861\n",
      "74/194, train_loss: 0.7403\n",
      "75/194, train_loss: 0.8567\n",
      "76/194, train_loss: 0.5720\n",
      "77/194, train_loss: 0.6935\n",
      "78/194, train_loss: 0.4441\n",
      "79/194, train_loss: 0.7649\n",
      "80/194, train_loss: 0.8310\n",
      "81/194, train_loss: 0.8520\n",
      "82/194, train_loss: 0.6847\n",
      "83/194, train_loss: 0.8068\n",
      "84/194, train_loss: 0.8169\n",
      "85/194, train_loss: 0.7701\n",
      "86/194, train_loss: 0.7132\n",
      "87/194, train_loss: 0.7182\n",
      "88/194, train_loss: 0.9408\n",
      "89/194, train_loss: 0.7618\n",
      "90/194, train_loss: 0.7825\n",
      "91/194, train_loss: 0.8566\n",
      "92/194, train_loss: 0.8485\n",
      "93/194, train_loss: 0.6241\n",
      "94/194, train_loss: 0.9181\n",
      "95/194, train_loss: 0.5311\n",
      "96/194, train_loss: 0.7888\n",
      "97/194, train_loss: 0.7477\n",
      "98/194, train_loss: 0.7445\n",
      "99/194, train_loss: 0.6613\n",
      "100/194, train_loss: 0.7548\n",
      "101/194, train_loss: 0.7071\n",
      "102/194, train_loss: 0.7878\n",
      "103/194, train_loss: 0.8783\n",
      "104/194, train_loss: 0.7440\n",
      "105/194, train_loss: 0.7693\n",
      "106/194, train_loss: 0.6143\n",
      "107/194, train_loss: 0.8751\n",
      "108/194, train_loss: 0.6328\n",
      "109/194, train_loss: 0.6751\n",
      "110/194, train_loss: 0.7769\n",
      "111/194, train_loss: 0.6047\n",
      "112/194, train_loss: 0.7761\n",
      "113/194, train_loss: 0.8047\n",
      "114/194, train_loss: 0.7720\n",
      "115/194, train_loss: 0.7018\n",
      "116/194, train_loss: 0.6721\n",
      "117/194, train_loss: 0.8218\n",
      "118/194, train_loss: 0.5497\n",
      "119/194, train_loss: 0.7593\n",
      "120/194, train_loss: 0.8171\n",
      "121/194, train_loss: 0.8326\n",
      "122/194, train_loss: 0.8126\n",
      "123/194, train_loss: 0.8280\n",
      "124/194, train_loss: 0.7599\n",
      "125/194, train_loss: 0.9175\n",
      "126/194, train_loss: 0.7657\n",
      "127/194, train_loss: 0.8575\n",
      "128/194, train_loss: 0.8766\n",
      "129/194, train_loss: 0.7875\n",
      "130/194, train_loss: 0.9159\n",
      "131/194, train_loss: 0.7796\n",
      "132/194, train_loss: 0.9022\n",
      "133/194, train_loss: 0.8523\n",
      "134/194, train_loss: 0.8118\n",
      "135/194, train_loss: 0.8180\n",
      "136/194, train_loss: 0.8623\n",
      "137/194, train_loss: 0.6584\n",
      "138/194, train_loss: 0.7302\n",
      "139/194, train_loss: 0.6268\n",
      "140/194, train_loss: 0.4807\n",
      "141/194, train_loss: 0.8717\n",
      "142/194, train_loss: 0.6969\n",
      "143/194, train_loss: 0.7091\n",
      "144/194, train_loss: 0.9351\n",
      "145/194, train_loss: 0.7232\n",
      "146/194, train_loss: 0.8130\n",
      "147/194, train_loss: 0.7503\n",
      "148/194, train_loss: 0.7697\n",
      "149/194, train_loss: 0.8322\n",
      "150/194, train_loss: 0.7757\n",
      "151/194, train_loss: 0.9156\n",
      "152/194, train_loss: 0.8545\n",
      "153/194, train_loss: 0.7985\n",
      "154/194, train_loss: 0.8981\n",
      "155/194, train_loss: 0.8336\n",
      "156/194, train_loss: 0.8086\n",
      "157/194, train_loss: 0.7905\n",
      "158/194, train_loss: 0.8476\n",
      "159/194, train_loss: 0.7668\n",
      "160/194, train_loss: 0.7984\n",
      "161/194, train_loss: 0.9044\n",
      "162/194, train_loss: 0.8877\n",
      "163/194, train_loss: 0.9083\n",
      "164/194, train_loss: 0.7185\n",
      "165/194, train_loss: 0.9683\n",
      "166/194, train_loss: 0.7230\n",
      "167/194, train_loss: 0.9600\n",
      "168/194, train_loss: 0.9104\n",
      "169/194, train_loss: 0.6897\n",
      "170/194, train_loss: 0.7753\n",
      "171/194, train_loss: 0.7332\n",
      "172/194, train_loss: 0.5375\n",
      "173/194, train_loss: 0.7808\n",
      "174/194, train_loss: 0.8976\n",
      "175/194, train_loss: 0.6610\n",
      "176/194, train_loss: 0.6860\n",
      "177/194, train_loss: 0.8039\n",
      "178/194, train_loss: 0.5484\n",
      "179/194, train_loss: 0.8565\n",
      "180/194, train_loss: 0.5329\n",
      "181/194, train_loss: 0.8105\n",
      "182/194, train_loss: 0.7927\n",
      "183/194, train_loss: 0.7489\n",
      "184/194, train_loss: 0.6441\n",
      "185/194, train_loss: 0.8369\n",
      "186/194, train_loss: 0.7538\n",
      "187/194, train_loss: 0.8405\n",
      "188/194, train_loss: 0.7735\n",
      "189/194, train_loss: 0.9332\n",
      "190/194, train_loss: 0.7602\n",
      "191/194, train_loss: 0.8251\n",
      "192/194, train_loss: 0.6998\n",
      "193/194, train_loss: 0.7055\n",
      "194/194, train_loss: 0.8813\n",
      "metric=0.3539700300122301, metric_tc=0.3737095147371292, metric_wt=0.4728919503589471, metric_et=0.21530862036161125\n",
      "metric=0.3539700300122301, metric_tc=0.3737095147371292, metric_wt=0.4728919503589471, metric_et=0.21530862036161125\n",
      "current epoch: 75 current epoch loss: 0.7600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 75/80 [13:48:21<54:37, 655.60s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metric=0.3539700300122301, metric_tc=0.3737095147371292, metric_wt=0.4728919503589471, metric_et=0.21530862036161125\n",
      "0.3539700300122301\n",
      "current epoch: 75 current mean dice: 0.3540 tc: 0.3737 wt: 0.4729 et: 0.2153\n",
      "best mean dice: 0.4133 at epoch: 71\n",
      "\n",
      " | Global Training Round : 76 |\n",
      "\n",
      "user 0 selected\n",
      "local epoch 1\n",
      "1/194, train_loss: 0.7250\n",
      "2/194, train_loss: 0.7202\n",
      "3/194, train_loss: 0.8008\n",
      "4/194, train_loss: 0.6666\n",
      "5/194, train_loss: 0.8180\n",
      "6/194, train_loss: 0.7615\n",
      "7/194, train_loss: 0.7798\n",
      "8/194, train_loss: 0.6123\n",
      "9/194, train_loss: 0.6500\n",
      "10/194, train_loss: 0.5158\n",
      "11/194, train_loss: 0.6741\n",
      "12/194, train_loss: 0.5693\n",
      "13/194, train_loss: 0.7349\n",
      "14/194, train_loss: 0.7838\n",
      "15/194, train_loss: 0.6557\n",
      "16/194, train_loss: 0.6462\n",
      "17/194, train_loss: 0.7622\n",
      "18/194, train_loss: 0.8573\n",
      "19/194, train_loss: 0.5943\n",
      "20/194, train_loss: 0.8927\n",
      "21/194, train_loss: 0.8668\n",
      "22/194, train_loss: 0.8439\n",
      "23/194, train_loss: 0.8241\n",
      "24/194, train_loss: 0.7817\n",
      "25/194, train_loss: 0.7207\n",
      "26/194, train_loss: 0.7580\n",
      "27/194, train_loss: 0.7317\n",
      "28/194, train_loss: 0.8032\n",
      "29/194, train_loss: 0.7593\n",
      "30/194, train_loss: 0.8663\n",
      "31/194, train_loss: 0.8103\n",
      "32/194, train_loss: 0.9270\n",
      "33/194, train_loss: 0.8296\n",
      "34/194, train_loss: 0.8021\n",
      "35/194, train_loss: 0.8324\n",
      "36/194, train_loss: 0.8561\n",
      "37/194, train_loss: 0.7303\n",
      "38/194, train_loss: 0.4034\n",
      "39/194, train_loss: 0.7195\n",
      "40/194, train_loss: 0.9153\n",
      "41/194, train_loss: 0.6772\n",
      "42/194, train_loss: 0.8051\n",
      "43/194, train_loss: 0.6033\n",
      "44/194, train_loss: 0.5188\n",
      "45/194, train_loss: 0.8121\n",
      "46/194, train_loss: 0.5531\n",
      "47/194, train_loss: 0.7508\n",
      "48/194, train_loss: 0.8178\n",
      "49/194, train_loss: 0.7009\n",
      "50/194, train_loss: 0.6834\n",
      "51/194, train_loss: 0.8752\n",
      "52/194, train_loss: 0.7830\n",
      "53/194, train_loss: 0.5879\n",
      "54/194, train_loss: 0.6524\n",
      "55/194, train_loss: 0.7231\n",
      "56/194, train_loss: 0.7813\n",
      "57/194, train_loss: 0.7901\n",
      "58/194, train_loss: 0.8306\n",
      "59/194, train_loss: 0.8762\n",
      "60/194, train_loss: 0.8406\n",
      "61/194, train_loss: 0.6463\n",
      "62/194, train_loss: 0.7991\n",
      "63/194, train_loss: 0.6760\n",
      "64/194, train_loss: 0.7911\n",
      "65/194, train_loss: 0.6274\n",
      "66/194, train_loss: 0.6379\n",
      "67/194, train_loss: 0.6244\n",
      "68/194, train_loss: 0.8378\n",
      "69/194, train_loss: 0.7189\n",
      "70/194, train_loss: 0.8439\n",
      "71/194, train_loss: 0.7816\n",
      "72/194, train_loss: 0.8516\n",
      "73/194, train_loss: 0.8043\n",
      "74/194, train_loss: 0.6956\n",
      "75/194, train_loss: 0.5997\n",
      "76/194, train_loss: 0.8109\n",
      "77/194, train_loss: 0.7153\n",
      "78/194, train_loss: 0.6512\n",
      "79/194, train_loss: 0.8156\n",
      "80/194, train_loss: 0.7241\n",
      "81/194, train_loss: 0.7340\n",
      "82/194, train_loss: 0.6938\n",
      "83/194, train_loss: 0.7676\n",
      "84/194, train_loss: 0.7990\n",
      "85/194, train_loss: 0.7496\n",
      "86/194, train_loss: 0.8210\n",
      "87/194, train_loss: 0.8330\n",
      "88/194, train_loss: 0.8785\n",
      "89/194, train_loss: 0.8597\n",
      "90/194, train_loss: 0.8596\n",
      "91/194, train_loss: 0.7332\n",
      "92/194, train_loss: 0.8403\n",
      "93/194, train_loss: 0.8544\n",
      "94/194, train_loss: 0.8484\n",
      "95/194, train_loss: 0.6896\n",
      "96/194, train_loss: 0.9072\n",
      "97/194, train_loss: 0.9041\n",
      "98/194, train_loss: 0.7041\n",
      "99/194, train_loss: 0.6536\n",
      "100/194, train_loss: 0.7795\n",
      "101/194, train_loss: 0.8266\n",
      "102/194, train_loss: 0.7221\n",
      "103/194, train_loss: 0.8829\n",
      "104/194, train_loss: 0.7728\n",
      "105/194, train_loss: 0.8573\n",
      "106/194, train_loss: 0.6325\n",
      "107/194, train_loss: 0.6919\n",
      "108/194, train_loss: 0.8216\n",
      "109/194, train_loss: 0.7377\n",
      "110/194, train_loss: 0.6179\n",
      "111/194, train_loss: 0.5759\n",
      "112/194, train_loss: 0.6262\n",
      "113/194, train_loss: 0.6605\n",
      "114/194, train_loss: 0.7270\n",
      "115/194, train_loss: 0.6777\n",
      "116/194, train_loss: 0.7833\n",
      "117/194, train_loss: 0.6494\n",
      "118/194, train_loss: 0.8493\n",
      "119/194, train_loss: 0.8572\n",
      "120/194, train_loss: 0.7730\n",
      "121/194, train_loss: 0.8850\n",
      "122/194, train_loss: 0.8586\n",
      "123/194, train_loss: 0.5686\n",
      "124/194, train_loss: 0.8140\n",
      "125/194, train_loss: 0.6836\n",
      "126/194, train_loss: 0.8691\n",
      "127/194, train_loss: 0.8174\n",
      "128/194, train_loss: 0.7171\n",
      "129/194, train_loss: 0.6703\n",
      "130/194, train_loss: 0.7552\n",
      "131/194, train_loss: 0.8714\n",
      "132/194, train_loss: 0.7752\n",
      "133/194, train_loss: 0.7654\n",
      "134/194, train_loss: 0.6361\n",
      "135/194, train_loss: 0.8045\n",
      "136/194, train_loss: 0.6818\n",
      "137/194, train_loss: 0.7927\n",
      "138/194, train_loss: 0.6388\n",
      "139/194, train_loss: 0.8893\n",
      "140/194, train_loss: 0.6614\n",
      "141/194, train_loss: 0.6422\n",
      "142/194, train_loss: 0.7385\n",
      "143/194, train_loss: 0.9269\n",
      "144/194, train_loss: 0.6585\n",
      "145/194, train_loss: 0.9192\n",
      "146/194, train_loss: 0.8307\n",
      "147/194, train_loss: 0.7046\n",
      "148/194, train_loss: 0.7009\n",
      "149/194, train_loss: 0.8251\n",
      "150/194, train_loss: 0.7568\n",
      "151/194, train_loss: 0.7353\n",
      "152/194, train_loss: 0.9048\n",
      "153/194, train_loss: 0.9032\n",
      "154/194, train_loss: 0.6919\n",
      "155/194, train_loss: 0.8403\n",
      "156/194, train_loss: 0.9339\n",
      "157/194, train_loss: 0.7875\n",
      "158/194, train_loss: 0.9101\n",
      "159/194, train_loss: 0.7552\n",
      "160/194, train_loss: 0.7817\n",
      "161/194, train_loss: 0.8519\n",
      "162/194, train_loss: 0.8458\n",
      "163/194, train_loss: 0.7182\n",
      "164/194, train_loss: 0.7973\n",
      "165/194, train_loss: 0.7917\n",
      "166/194, train_loss: 0.7714\n",
      "167/194, train_loss: 0.8690\n",
      "168/194, train_loss: 0.7415\n",
      "169/194, train_loss: 0.8478\n",
      "170/194, train_loss: 0.7296\n",
      "171/194, train_loss: 0.8065\n",
      "172/194, train_loss: 0.5776\n",
      "173/194, train_loss: 0.9000\n",
      "174/194, train_loss: 0.9212\n",
      "175/194, train_loss: 0.8048\n",
      "176/194, train_loss: 0.9026\n",
      "177/194, train_loss: 0.7804\n",
      "178/194, train_loss: 0.7179\n",
      "179/194, train_loss: 0.5964\n",
      "180/194, train_loss: 0.8838\n",
      "181/194, train_loss: 0.7113\n",
      "182/194, train_loss: 0.6749\n",
      "183/194, train_loss: 0.7181\n",
      "184/194, train_loss: 0.5383\n",
      "185/194, train_loss: 0.8288\n",
      "186/194, train_loss: 0.8447\n",
      "187/194, train_loss: 0.8008\n",
      "188/194, train_loss: 0.8755\n",
      "189/194, train_loss: 0.8863\n",
      "190/194, train_loss: 0.8595\n",
      "191/194, train_loss: 0.8319\n",
      "192/194, train_loss: 0.7491\n",
      "193/194, train_loss: 0.8648\n",
      "194/194, train_loss: 0.8749\n",
      "metric=0.3889104438324769, metric_tc=0.4229086296012004, metric_wt=0.5089231015493473, metric_et=0.23489961066904166\n",
      "metric=0.3889104438324769, metric_tc=0.4229086296012004, metric_wt=0.5089231015493473, metric_et=0.23489961066904166\n",
      "current epoch: 76 current epoch loss: 0.7628\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 76/80 [13:58:47<43:05, 646.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metric=0.3889104438324769, metric_tc=0.4229086296012004, metric_wt=0.5089231015493473, metric_et=0.23489961066904166\n",
      "0.3889104438324769\n",
      "current epoch: 76 current mean dice: 0.3889 tc: 0.4229 wt: 0.5089 et: 0.2349\n",
      "best mean dice: 0.4133 at epoch: 71\n",
      "\n",
      " | Global Training Round : 77 |\n",
      "\n",
      "user 0 selected\n",
      "local epoch 1\n",
      "1/194, train_loss: 0.7879\n",
      "2/194, train_loss: 0.8820\n",
      "3/194, train_loss: 0.7589\n",
      "4/194, train_loss: 0.7500\n",
      "5/194, train_loss: 0.7907\n",
      "6/194, train_loss: 0.8548\n",
      "7/194, train_loss: 0.8207\n",
      "8/194, train_loss: 0.7625\n",
      "9/194, train_loss: 0.7765\n",
      "10/194, train_loss: 0.6729\n",
      "11/194, train_loss: 0.7157\n",
      "12/194, train_loss: 0.8538\n",
      "13/194, train_loss: 0.8858\n",
      "14/194, train_loss: 0.5966\n",
      "15/194, train_loss: 0.6993\n",
      "16/194, train_loss: 0.5927\n",
      "17/194, train_loss: 0.6416\n",
      "18/194, train_loss: 0.8457\n",
      "19/194, train_loss: 0.7732\n",
      "20/194, train_loss: 0.8508\n",
      "21/194, train_loss: 0.6337\n",
      "22/194, train_loss: 0.8246\n",
      "23/194, train_loss: 0.6637\n",
      "24/194, train_loss: 0.7835\n",
      "25/194, train_loss: 0.8577\n",
      "26/194, train_loss: 0.7665\n",
      "27/194, train_loss: 0.7649\n",
      "28/194, train_loss: 0.7621\n",
      "29/194, train_loss: 0.8450\n",
      "30/194, train_loss: 0.7511\n",
      "31/194, train_loss: 0.8490\n",
      "32/194, train_loss: 0.8527\n",
      "33/194, train_loss: 0.8519\n",
      "34/194, train_loss: 0.6244\n",
      "35/194, train_loss: 0.8775\n",
      "36/194, train_loss: 0.9051\n",
      "37/194, train_loss: 0.8365\n",
      "38/194, train_loss: 0.6889\n",
      "39/194, train_loss: 0.7855\n",
      "40/194, train_loss: 0.5420\n",
      "41/194, train_loss: 0.7990\n",
      "42/194, train_loss: 0.7070\n",
      "43/194, train_loss: 0.7876\n",
      "44/194, train_loss: 0.4987\n",
      "45/194, train_loss: 0.8283\n",
      "46/194, train_loss: 0.7105\n",
      "47/194, train_loss: 0.6833\n",
      "48/194, train_loss: 0.6481\n",
      "49/194, train_loss: 0.8619\n",
      "50/194, train_loss: 0.8503\n",
      "51/194, train_loss: 0.9657\n",
      "52/194, train_loss: 0.7127\n",
      "53/194, train_loss: 0.7458\n",
      "54/194, train_loss: 0.6386\n",
      "55/194, train_loss: 0.5955\n",
      "56/194, train_loss: 0.6769\n",
      "57/194, train_loss: 0.7863\n",
      "58/194, train_loss: 0.6878\n",
      "59/194, train_loss: 0.8407\n",
      "60/194, train_loss: 0.7879\n",
      "61/194, train_loss: 0.7899\n",
      "62/194, train_loss: 0.6795\n",
      "63/194, train_loss: 0.6595\n",
      "64/194, train_loss: 0.6753\n",
      "65/194, train_loss: 0.7245\n",
      "66/194, train_loss: 0.8061\n",
      "67/194, train_loss: 0.7471\n",
      "68/194, train_loss: 0.6587\n",
      "69/194, train_loss: 0.6955\n",
      "70/194, train_loss: 0.6346\n",
      "71/194, train_loss: 0.7656\n",
      "72/194, train_loss: 0.7404\n",
      "73/194, train_loss: 0.8147\n",
      "74/194, train_loss: 0.6689\n",
      "75/194, train_loss: 0.7554\n",
      "76/194, train_loss: 0.8054\n",
      "77/194, train_loss: 0.6819\n",
      "78/194, train_loss: 0.7196\n",
      "79/194, train_loss: 0.6051\n",
      "80/194, train_loss: 0.5332\n",
      "81/194, train_loss: 0.6826\n",
      "82/194, train_loss: 0.7393\n",
      "83/194, train_loss: 0.8222\n",
      "84/194, train_loss: 0.6690\n",
      "85/194, train_loss: 0.8478\n",
      "86/194, train_loss: 0.7873\n",
      "87/194, train_loss: 0.6912\n",
      "88/194, train_loss: 0.7558\n",
      "89/194, train_loss: 0.7681\n",
      "90/194, train_loss: 0.8031\n",
      "91/194, train_loss: 0.7146\n",
      "92/194, train_loss: 0.6519\n",
      "93/194, train_loss: 0.8667\n",
      "94/194, train_loss: 0.9291\n",
      "95/194, train_loss: 0.5844\n",
      "96/194, train_loss: 0.8008\n",
      "97/194, train_loss: 0.7057\n",
      "98/194, train_loss: 0.8437\n",
      "99/194, train_loss: 0.7917\n",
      "100/194, train_loss: 0.8192\n",
      "101/194, train_loss: 0.8468\n",
      "102/194, train_loss: 0.8667\n",
      "103/194, train_loss: 0.7565\n",
      "104/194, train_loss: 0.8004\n",
      "105/194, train_loss: 0.7210\n",
      "106/194, train_loss: 0.6828\n",
      "107/194, train_loss: 0.8070\n",
      "108/194, train_loss: 0.7539\n",
      "109/194, train_loss: 0.6795\n",
      "110/194, train_loss: 0.7285\n",
      "111/194, train_loss: 0.6283\n",
      "112/194, train_loss: 0.7761\n",
      "113/194, train_loss: 0.8924\n",
      "114/194, train_loss: 0.5467\n",
      "115/194, train_loss: 0.6271\n",
      "116/194, train_loss: 0.7306\n",
      "117/194, train_loss: 0.5721\n",
      "118/194, train_loss: 0.7363\n",
      "119/194, train_loss: 0.7179\n",
      "120/194, train_loss: 0.8088\n",
      "121/194, train_loss: 0.7480\n",
      "122/194, train_loss: 0.6832\n",
      "123/194, train_loss: 0.8056\n",
      "124/194, train_loss: 0.7605\n",
      "125/194, train_loss: 0.8508\n",
      "126/194, train_loss: 0.7789\n",
      "127/194, train_loss: 0.9199\n",
      "128/194, train_loss: 0.4929\n",
      "129/194, train_loss: 0.6279\n",
      "130/194, train_loss: 0.8537\n",
      "131/194, train_loss: 0.8724\n",
      "132/194, train_loss: 0.7629\n",
      "133/194, train_loss: 0.8873\n",
      "134/194, train_loss: 0.6625\n",
      "135/194, train_loss: 0.7709\n",
      "136/194, train_loss: 0.7033\n",
      "137/194, train_loss: 0.6580\n",
      "138/194, train_loss: 0.5066\n",
      "139/194, train_loss: 0.5480\n",
      "140/194, train_loss: 0.4558\n",
      "141/194, train_loss: 0.7152\n",
      "142/194, train_loss: 0.8627\n",
      "143/194, train_loss: 0.9233\n",
      "144/194, train_loss: 0.6619\n",
      "145/194, train_loss: 0.8934\n",
      "146/194, train_loss: 0.8954\n",
      "147/194, train_loss: 0.6619\n",
      "148/194, train_loss: 0.7159\n",
      "149/194, train_loss: 0.8851\n",
      "150/194, train_loss: 0.9084\n",
      "151/194, train_loss: 0.7541\n",
      "152/194, train_loss: 0.7520\n",
      "153/194, train_loss: 0.7199\n",
      "154/194, train_loss: 0.7181\n",
      "155/194, train_loss: 0.8123\n",
      "156/194, train_loss: 0.9693\n",
      "157/194, train_loss: 0.8905\n",
      "158/194, train_loss: 0.8408\n",
      "159/194, train_loss: 0.8196\n",
      "160/194, train_loss: 0.9006\n",
      "161/194, train_loss: 0.9252\n",
      "162/194, train_loss: 0.7129\n",
      "163/194, train_loss: 0.7971\n",
      "164/194, train_loss: 0.9145\n",
      "165/194, train_loss: 0.8445\n",
      "166/194, train_loss: 0.6818\n",
      "167/194, train_loss: 0.7761\n",
      "168/194, train_loss: 0.8537\n",
      "169/194, train_loss: 0.7974\n",
      "170/194, train_loss: 0.7392\n",
      "171/194, train_loss: 0.7581\n",
      "172/194, train_loss: 0.7626\n",
      "173/194, train_loss: 0.7182\n",
      "174/194, train_loss: 0.8363\n",
      "175/194, train_loss: 0.7109\n",
      "176/194, train_loss: 0.7681\n",
      "177/194, train_loss: 0.8364\n",
      "178/194, train_loss: 0.8321\n",
      "179/194, train_loss: 0.5772\n",
      "180/194, train_loss: 0.8193\n",
      "181/194, train_loss: 0.7069\n",
      "182/194, train_loss: 0.6134\n",
      "183/194, train_loss: 0.6519\n",
      "184/194, train_loss: 0.8596\n",
      "185/194, train_loss: 0.6659\n",
      "186/194, train_loss: 0.8087\n",
      "187/194, train_loss: 0.7827\n",
      "188/194, train_loss: 0.9211\n",
      "189/194, train_loss: 0.8765\n",
      "190/194, train_loss: 0.9334\n",
      "191/194, train_loss: 0.6727\n",
      "192/194, train_loss: 0.8209\n",
      "193/194, train_loss: 0.7585\n",
      "194/194, train_loss: 0.8621\n",
      "metric=0.365028068733712, metric_tc=0.38842478891213733, metric_wt=0.48396966854731244, metric_et=0.22268975184609494\n",
      "metric=0.365028068733712, metric_tc=0.38842478891213733, metric_wt=0.48396966854731244, metric_et=0.22268975184609494\n",
      "current epoch: 77 current epoch loss: 0.7575\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▋| 77/80 [14:09:40<32:25, 648.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metric=0.365028068733712, metric_tc=0.38842478891213733, metric_wt=0.48396966854731244, metric_et=0.22268975184609494\n",
      "0.365028068733712\n",
      "current epoch: 77 current mean dice: 0.3650 tc: 0.3884 wt: 0.4840 et: 0.2227\n",
      "best mean dice: 0.4133 at epoch: 71\n",
      "\n",
      " | Global Training Round : 78 |\n",
      "\n",
      "user 0 selected\n",
      "local epoch 1\n",
      "1/194, train_loss: 0.6323\n",
      "2/194, train_loss: 0.7275\n",
      "3/194, train_loss: 0.6173\n",
      "4/194, train_loss: 0.8493\n",
      "5/194, train_loss: 0.8443\n",
      "6/194, train_loss: 0.8512\n",
      "7/194, train_loss: 0.8232\n",
      "8/194, train_loss: 0.8020\n",
      "9/194, train_loss: 0.7192\n",
      "10/194, train_loss: 0.7988\n",
      "11/194, train_loss: 0.7798\n",
      "12/194, train_loss: 0.7979\n",
      "13/194, train_loss: 0.7921\n",
      "14/194, train_loss: 0.8157\n",
      "15/194, train_loss: 0.8261\n",
      "16/194, train_loss: 0.5075\n",
      "17/194, train_loss: 0.8014\n",
      "18/194, train_loss: 0.6754\n",
      "19/194, train_loss: 0.9186\n",
      "20/194, train_loss: 0.8549\n",
      "21/194, train_loss: 0.7068\n",
      "22/194, train_loss: 0.7590\n",
      "23/194, train_loss: 0.9134\n",
      "24/194, train_loss: 0.7809\n",
      "25/194, train_loss: 0.7301\n",
      "26/194, train_loss: 0.6219\n",
      "27/194, train_loss: 0.7882\n",
      "28/194, train_loss: 0.8723\n",
      "29/194, train_loss: 0.8863\n",
      "30/194, train_loss: 0.6696\n",
      "31/194, train_loss: 0.7792\n",
      "32/194, train_loss: 0.8445\n",
      "33/194, train_loss: 0.6973\n",
      "34/194, train_loss: 0.8322\n",
      "35/194, train_loss: 0.7557\n",
      "36/194, train_loss: 0.8322\n",
      "37/194, train_loss: 0.5966\n",
      "38/194, train_loss: 0.7119\n",
      "39/194, train_loss: 0.5660\n",
      "40/194, train_loss: 0.6986\n",
      "41/194, train_loss: 0.6812\n",
      "42/194, train_loss: 0.6403\n",
      "43/194, train_loss: 0.8249\n",
      "44/194, train_loss: 0.8013\n",
      "45/194, train_loss: 0.6859\n",
      "46/194, train_loss: 0.6583\n",
      "47/194, train_loss: 0.7513\n",
      "48/194, train_loss: 0.5932\n",
      "49/194, train_loss: 0.7320\n",
      "50/194, train_loss: 0.7089\n",
      "51/194, train_loss: 0.6770\n",
      "52/194, train_loss: 0.8203\n",
      "53/194, train_loss: 0.6609\n",
      "54/194, train_loss: 0.7830\n",
      "55/194, train_loss: 0.6722\n",
      "56/194, train_loss: 0.6903\n",
      "57/194, train_loss: 0.7468\n",
      "58/194, train_loss: 0.8040\n",
      "59/194, train_loss: 0.7977\n",
      "60/194, train_loss: 0.9207\n",
      "61/194, train_loss: 0.7393\n",
      "62/194, train_loss: 0.9052\n",
      "63/194, train_loss: 0.8503\n",
      "64/194, train_loss: 0.7397\n",
      "65/194, train_loss: 0.6829\n",
      "66/194, train_loss: 0.7199\n",
      "67/194, train_loss: 0.7999\n",
      "68/194, train_loss: 0.8112\n",
      "69/194, train_loss: 0.5369\n",
      "70/194, train_loss: 0.8998\n",
      "71/194, train_loss: 0.7527\n",
      "72/194, train_loss: 0.7981\n",
      "73/194, train_loss: 0.8117\n",
      "74/194, train_loss: 0.7774\n",
      "75/194, train_loss: 0.6093\n",
      "76/194, train_loss: 0.6125\n",
      "77/194, train_loss: 0.5852\n",
      "78/194, train_loss: 0.5648\n",
      "79/194, train_loss: 0.8746\n",
      "80/194, train_loss: 0.7704\n",
      "81/194, train_loss: 0.8818\n",
      "82/194, train_loss: 0.6794\n",
      "83/194, train_loss: 0.6851\n",
      "84/194, train_loss: 0.8226\n",
      "85/194, train_loss: 0.8158\n",
      "86/194, train_loss: 0.7263\n",
      "87/194, train_loss: 0.8401\n",
      "88/194, train_loss: 0.6970\n",
      "89/194, train_loss: 0.7329\n",
      "90/194, train_loss: 0.8832\n",
      "91/194, train_loss: 0.7776\n",
      "92/194, train_loss: 0.8089\n",
      "93/194, train_loss: 0.8845\n",
      "94/194, train_loss: 0.8077\n",
      "95/194, train_loss: 0.7670\n",
      "96/194, train_loss: 0.8499\n",
      "97/194, train_loss: 0.7828\n",
      "98/194, train_loss: 0.7562\n",
      "99/194, train_loss: 0.7228\n",
      "100/194, train_loss: 0.6028\n",
      "101/194, train_loss: 0.7996\n",
      "102/194, train_loss: 0.7753\n",
      "103/194, train_loss: 0.6870\n",
      "104/194, train_loss: 0.7408\n",
      "105/194, train_loss: 0.8787\n",
      "106/194, train_loss: 0.7100\n",
      "107/194, train_loss: 0.7039\n",
      "108/194, train_loss: 0.8075\n",
      "109/194, train_loss: 0.8674\n",
      "110/194, train_loss: 0.7217\n",
      "111/194, train_loss: 0.7473\n",
      "112/194, train_loss: 0.6599\n",
      "113/194, train_loss: 0.6720\n",
      "114/194, train_loss: 0.7603\n",
      "115/194, train_loss: 0.6406\n",
      "116/194, train_loss: 0.7924\n",
      "117/194, train_loss: 0.7054\n",
      "118/194, train_loss: 0.8420\n",
      "119/194, train_loss: 0.7786\n",
      "120/194, train_loss: 0.7407\n",
      "121/194, train_loss: 0.8684\n",
      "122/194, train_loss: 0.7539\n",
      "123/194, train_loss: 0.9201\n",
      "124/194, train_loss: 0.8440\n",
      "125/194, train_loss: 0.8495\n",
      "126/194, train_loss: 0.8426\n",
      "127/194, train_loss: 0.8547\n",
      "128/194, train_loss: 0.7460\n",
      "129/194, train_loss: 0.7270\n",
      "130/194, train_loss: 0.6129\n",
      "131/194, train_loss: 0.5389\n",
      "132/194, train_loss: 0.7946\n",
      "133/194, train_loss: 0.6522\n",
      "134/194, train_loss: 0.7620\n",
      "135/194, train_loss: 0.6929\n",
      "136/194, train_loss: 0.7414\n",
      "137/194, train_loss: 0.6395\n",
      "138/194, train_loss: 0.6395\n",
      "139/194, train_loss: 0.8028\n",
      "140/194, train_loss: 0.6916\n",
      "141/194, train_loss: 0.9063\n",
      "142/194, train_loss: 0.5915\n",
      "143/194, train_loss: 0.7151\n",
      "144/194, train_loss: 0.7022\n",
      "145/194, train_loss: 0.6699\n",
      "146/194, train_loss: 0.7327\n",
      "147/194, train_loss: 0.7758\n",
      "148/194, train_loss: 0.6654\n",
      "149/194, train_loss: 0.8851\n",
      "150/194, train_loss: 0.7144\n",
      "151/194, train_loss: 0.9130\n",
      "152/194, train_loss: 0.8899\n",
      "153/194, train_loss: 0.8261\n",
      "154/194, train_loss: 0.8879\n",
      "155/194, train_loss: 0.8878\n",
      "156/194, train_loss: 0.6028\n",
      "157/194, train_loss: 0.9833\n",
      "158/194, train_loss: 0.8160\n",
      "159/194, train_loss: 0.7730\n",
      "160/194, train_loss: 0.9138\n",
      "161/194, train_loss: 0.7865\n",
      "162/194, train_loss: 0.8040\n",
      "163/194, train_loss: 0.8522\n",
      "164/194, train_loss: 0.8481\n",
      "165/194, train_loss: 0.8258\n",
      "166/194, train_loss: 0.7108\n",
      "167/194, train_loss: 0.8750\n",
      "168/194, train_loss: 0.8208\n",
      "169/194, train_loss: 0.8447\n",
      "170/194, train_loss: 0.7511\n",
      "171/194, train_loss: 0.8301\n",
      "172/194, train_loss: 0.8157\n",
      "173/194, train_loss: 0.7803\n",
      "174/194, train_loss: 0.5806\n",
      "175/194, train_loss: 0.7889\n",
      "176/194, train_loss: 0.7986\n",
      "177/194, train_loss: 0.7673\n",
      "178/194, train_loss: 0.6827\n",
      "179/194, train_loss: 0.8500\n",
      "180/194, train_loss: 0.8158\n",
      "181/194, train_loss: 0.6721\n",
      "182/194, train_loss: 0.5802\n",
      "183/194, train_loss: 0.6126\n",
      "184/194, train_loss: 0.6665\n",
      "185/194, train_loss: 0.7926\n",
      "186/194, train_loss: 0.7612\n",
      "187/194, train_loss: 0.8375\n",
      "188/194, train_loss: 0.7501\n",
      "189/194, train_loss: 0.8477\n",
      "190/194, train_loss: 0.8794\n",
      "191/194, train_loss: 0.8193\n",
      "192/194, train_loss: 0.8184\n",
      "193/194, train_loss: 0.9048\n",
      "194/194, train_loss: 0.7600\n",
      "metric=0.39927226801713306, metric_tc=0.42807494631658, metric_wt=0.5278447276602188, metric_et=0.24189711928678057\n",
      "metric=0.39927226801713306, metric_tc=0.42807494631658, metric_wt=0.5278447276602188, metric_et=0.24189711928678057\n",
      "current epoch: 78 current epoch loss: 0.7623\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 78/80 [14:20:31<21:38, 649.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metric=0.39927226801713306, metric_tc=0.42807494631658, metric_wt=0.5278447276602188, metric_et=0.24189711928678057\n",
      "0.39927226801713306\n",
      "current epoch: 78 current mean dice: 0.3993 tc: 0.4281 wt: 0.5278 et: 0.2419\n",
      "best mean dice: 0.4133 at epoch: 71\n",
      "\n",
      " | Global Training Round : 79 |\n",
      "\n",
      "user 0 selected\n",
      "local epoch 1\n",
      "1/194, train_loss: 0.7700\n",
      "2/194, train_loss: 0.8841\n",
      "3/194, train_loss: 0.5558\n",
      "4/194, train_loss: 0.6042\n",
      "5/194, train_loss: 0.8014\n",
      "6/194, train_loss: 0.8111\n",
      "7/194, train_loss: 0.6500\n",
      "8/194, train_loss: 0.7903\n",
      "9/194, train_loss: 0.7950\n",
      "10/194, train_loss: 0.6459\n",
      "11/194, train_loss: 0.6153\n",
      "12/194, train_loss: 0.8122\n",
      "13/194, train_loss: 0.7381\n",
      "14/194, train_loss: 0.6246\n",
      "15/194, train_loss: 0.5830\n",
      "16/194, train_loss: 0.6655\n",
      "17/194, train_loss: 0.8687\n",
      "18/194, train_loss: 0.7798\n",
      "19/194, train_loss: 0.6264\n",
      "20/194, train_loss: 0.8140\n",
      "21/194, train_loss: 0.7375\n",
      "22/194, train_loss: 0.8915\n",
      "23/194, train_loss: 0.8686\n",
      "24/194, train_loss: 0.7184\n",
      "25/194, train_loss: 0.6665\n",
      "26/194, train_loss: 0.7995\n",
      "27/194, train_loss: 0.7742\n",
      "28/194, train_loss: 0.7478\n",
      "29/194, train_loss: 0.7603\n",
      "30/194, train_loss: 0.6525\n",
      "31/194, train_loss: 0.8128\n",
      "32/194, train_loss: 0.9110\n",
      "33/194, train_loss: 0.7485\n",
      "34/194, train_loss: 0.8070\n",
      "35/194, train_loss: 0.7828\n",
      "36/194, train_loss: 0.8829\n",
      "37/194, train_loss: 0.5970\n",
      "38/194, train_loss: 0.5195\n",
      "39/194, train_loss: 0.8081\n",
      "40/194, train_loss: 0.7310\n",
      "41/194, train_loss: 0.4967\n",
      "42/194, train_loss: 0.7491\n",
      "43/194, train_loss: 0.6732\n",
      "44/194, train_loss: 0.4863\n",
      "45/194, train_loss: 0.7917\n",
      "46/194, train_loss: 0.6233\n",
      "47/194, train_loss: 0.8178\n",
      "48/194, train_loss: 0.7025\n",
      "49/194, train_loss: 0.7249\n",
      "50/194, train_loss: 0.6547\n",
      "51/194, train_loss: 0.6425\n",
      "52/194, train_loss: 0.8932\n",
      "53/194, train_loss: 0.8938\n",
      "54/194, train_loss: 0.8538\n",
      "55/194, train_loss: 0.7247\n",
      "56/194, train_loss: 0.7995\n",
      "57/194, train_loss: 0.8426\n",
      "58/194, train_loss: 0.8771\n",
      "59/194, train_loss: 0.8886\n",
      "60/194, train_loss: 0.8549\n",
      "61/194, train_loss: 0.5277\n",
      "62/194, train_loss: 0.8072\n",
      "63/194, train_loss: 0.7869\n",
      "64/194, train_loss: 0.6328\n",
      "65/194, train_loss: 0.6755\n",
      "66/194, train_loss: 0.5476\n",
      "67/194, train_loss: 0.7205\n",
      "68/194, train_loss: 0.5891\n",
      "69/194, train_loss: 0.8590\n",
      "70/194, train_loss: 0.6940\n",
      "71/194, train_loss: 0.5494\n",
      "72/194, train_loss: 0.8633\n",
      "73/194, train_loss: 0.7649\n",
      "74/194, train_loss: 0.6792\n",
      "75/194, train_loss: 0.9259\n",
      "76/194, train_loss: 0.6980\n",
      "77/194, train_loss: 0.6916\n",
      "78/194, train_loss: 0.6748\n",
      "79/194, train_loss: 0.7851\n",
      "80/194, train_loss: 0.5542\n",
      "81/194, train_loss: 0.8226\n",
      "82/194, train_loss: 0.9184\n",
      "83/194, train_loss: 0.7576\n",
      "84/194, train_loss: 0.8221\n",
      "85/194, train_loss: 0.7646\n",
      "86/194, train_loss: 0.6030\n",
      "87/194, train_loss: 0.8467\n",
      "88/194, train_loss: 0.8259\n",
      "89/194, train_loss: 0.6868\n",
      "90/194, train_loss: 0.6564\n",
      "91/194, train_loss: 0.7454\n",
      "92/194, train_loss: 0.8570\n",
      "93/194, train_loss: 0.6512\n",
      "94/194, train_loss: 0.6258\n",
      "95/194, train_loss: 0.6689\n",
      "96/194, train_loss: 0.8783\n",
      "97/194, train_loss: 0.8714\n",
      "98/194, train_loss: 0.7211\n",
      "99/194, train_loss: 0.7671\n",
      "100/194, train_loss: 0.8129\n",
      "101/194, train_loss: 0.7847\n",
      "102/194, train_loss: 0.8273\n",
      "103/194, train_loss: 0.8608\n",
      "104/194, train_loss: 0.9213\n",
      "105/194, train_loss: 0.6553\n",
      "106/194, train_loss: 0.5944\n",
      "107/194, train_loss: 0.8472\n",
      "108/194, train_loss: 0.7661\n",
      "109/194, train_loss: 0.7204\n",
      "110/194, train_loss: 0.6724\n",
      "111/194, train_loss: 0.7548\n",
      "112/194, train_loss: 0.6722\n",
      "113/194, train_loss: 0.7919\n",
      "114/194, train_loss: 0.8125\n",
      "115/194, train_loss: 0.7554\n",
      "116/194, train_loss: 0.4872\n",
      "117/194, train_loss: 0.8757\n",
      "118/194, train_loss: 0.8877\n",
      "119/194, train_loss: 0.7004\n",
      "120/194, train_loss: 0.8267\n",
      "121/194, train_loss: 0.9356\n",
      "122/194, train_loss: 0.8878\n",
      "123/194, train_loss: 0.9235\n",
      "124/194, train_loss: 0.6288\n",
      "125/194, train_loss: 0.8787\n",
      "126/194, train_loss: 0.8971\n",
      "127/194, train_loss: 0.6489\n",
      "128/194, train_loss: 0.7348\n",
      "129/194, train_loss: 0.8610\n",
      "130/194, train_loss: 0.8878\n",
      "131/194, train_loss: 0.7310\n",
      "132/194, train_loss: 0.8718\n",
      "133/194, train_loss: 0.8313\n",
      "134/194, train_loss: 0.7264\n",
      "135/194, train_loss: 0.6883\n",
      "136/194, train_loss: 0.6081\n",
      "137/194, train_loss: 0.6641\n",
      "138/194, train_loss: 0.6889\n",
      "139/194, train_loss: 0.8792\n",
      "140/194, train_loss: 0.7484\n",
      "141/194, train_loss: 0.8141\n",
      "142/194, train_loss: 0.8273\n",
      "143/194, train_loss: 0.8378\n",
      "144/194, train_loss: 0.9003\n",
      "145/194, train_loss: 0.7778\n",
      "146/194, train_loss: 0.7564\n",
      "147/194, train_loss: 0.8798\n",
      "148/194, train_loss: 0.7342\n",
      "149/194, train_loss: 0.8909\n",
      "150/194, train_loss: 0.8054\n",
      "151/194, train_loss: 0.8156\n",
      "152/194, train_loss: 0.7481\n",
      "153/194, train_loss: 0.8808\n",
      "154/194, train_loss: 0.8268\n",
      "155/194, train_loss: 0.8108\n",
      "156/194, train_loss: 0.8781\n",
      "157/194, train_loss: 0.9070\n",
      "158/194, train_loss: 0.7530\n",
      "159/194, train_loss: 0.7249\n",
      "160/194, train_loss: 0.7794\n",
      "161/194, train_loss: 0.8641\n",
      "162/194, train_loss: 0.7752\n",
      "163/194, train_loss: 0.7520\n",
      "164/194, train_loss: 0.8198\n",
      "165/194, train_loss: 0.6755\n",
      "166/194, train_loss: 0.9154\n",
      "167/194, train_loss: 0.7901\n",
      "168/194, train_loss: 0.7160\n",
      "169/194, train_loss: 0.8168\n",
      "170/194, train_loss: 0.8592\n",
      "171/194, train_loss: 0.7039\n",
      "172/194, train_loss: 0.7136\n",
      "173/194, train_loss: 0.8786\n",
      "174/194, train_loss: 0.8183\n",
      "175/194, train_loss: 0.8062\n",
      "176/194, train_loss: 0.6983\n",
      "177/194, train_loss: 0.8890\n",
      "178/194, train_loss: 0.8566\n",
      "179/194, train_loss: 0.8752\n",
      "180/194, train_loss: 0.7730\n",
      "181/194, train_loss: 0.6437\n",
      "182/194, train_loss: 0.6177\n",
      "183/194, train_loss: 0.8739\n",
      "184/194, train_loss: 0.8420\n",
      "185/194, train_loss: 0.9250\n",
      "186/194, train_loss: 0.7736\n",
      "187/194, train_loss: 0.7070\n",
      "188/194, train_loss: 0.7632\n",
      "189/194, train_loss: 0.7864\n",
      "190/194, train_loss: 0.7436\n",
      "191/194, train_loss: 0.8298\n",
      "192/194, train_loss: 0.8304\n",
      "193/194, train_loss: 0.8559\n",
      "194/194, train_loss: 0.7599\n",
      "metric=0.3425747600073616, metric_tc=0.35033497648934525, metric_wt=0.48545671875278157, metric_et=0.19193257414735854\n",
      "metric=0.3425747600073616, metric_tc=0.35033497648934525, metric_wt=0.48545671875278157, metric_et=0.19193257414735854\n",
      "current epoch: 79 current epoch loss: 0.7640\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 79/80 [14:31:32<10:52, 652.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metric=0.3425747600073616, metric_tc=0.35033497648934525, metric_wt=0.48545671875278157, metric_et=0.19193257414735854\n",
      "0.3425747600073616\n",
      "current epoch: 79 current mean dice: 0.3426 tc: 0.3503 wt: 0.4855 et: 0.1919\n",
      "best mean dice: 0.4133 at epoch: 71\n",
      "\n",
      " | Global Training Round : 80 |\n",
      "\n",
      "user 0 selected\n",
      "local epoch 1\n",
      "1/194, train_loss: 0.8688\n",
      "2/194, train_loss: 0.8805\n",
      "3/194, train_loss: 0.7111\n",
      "4/194, train_loss: 0.7474\n",
      "5/194, train_loss: 0.8252\n",
      "6/194, train_loss: 0.7523\n",
      "7/194, train_loss: 0.7516\n",
      "8/194, train_loss: 0.8589\n",
      "9/194, train_loss: 0.7368\n",
      "10/194, train_loss: 0.6267\n",
      "11/194, train_loss: 0.7037\n",
      "12/194, train_loss: 0.7107\n",
      "13/194, train_loss: 0.7876\n",
      "14/194, train_loss: 0.5496\n",
      "15/194, train_loss: 0.6354\n",
      "16/194, train_loss: 0.6522\n",
      "17/194, train_loss: 0.8528\n",
      "18/194, train_loss: 0.7568\n",
      "19/194, train_loss: 0.8099\n",
      "20/194, train_loss: 0.8400\n",
      "21/194, train_loss: 0.7651\n",
      "22/194, train_loss: 0.7311\n",
      "23/194, train_loss: 0.6718\n",
      "24/194, train_loss: 0.7570\n",
      "25/194, train_loss: 0.6214\n",
      "26/194, train_loss: 0.8119\n",
      "27/194, train_loss: 0.8084\n",
      "28/194, train_loss: 0.7692\n",
      "29/194, train_loss: 0.9142\n",
      "30/194, train_loss: 0.6969\n",
      "31/194, train_loss: 0.7520\n",
      "32/194, train_loss: 0.7161\n",
      "33/194, train_loss: 0.7532\n",
      "34/194, train_loss: 0.7856\n",
      "35/194, train_loss: 0.6728\n",
      "36/194, train_loss: 0.8764\n",
      "37/194, train_loss: 0.4965\n",
      "38/194, train_loss: 0.6869\n",
      "39/194, train_loss: 0.5712\n",
      "40/194, train_loss: 0.5109\n",
      "41/194, train_loss: 0.7066\n",
      "42/194, train_loss: 0.7412\n",
      "43/194, train_loss: 0.6598\n",
      "44/194, train_loss: 0.7681\n",
      "45/194, train_loss: 0.5628\n",
      "46/194, train_loss: 0.7829\n",
      "47/194, train_loss: 0.7222\n",
      "48/194, train_loss: 0.7111\n",
      "49/194, train_loss: 0.7378\n",
      "50/194, train_loss: 0.7421\n",
      "51/194, train_loss: 0.7825\n",
      "52/194, train_loss: 0.7475\n",
      "53/194, train_loss: 0.8205\n",
      "54/194, train_loss: 0.9117\n",
      "55/194, train_loss: 0.9258\n",
      "56/194, train_loss: 0.8934\n",
      "57/194, train_loss: 0.8157\n",
      "58/194, train_loss: 0.9132\n",
      "59/194, train_loss: 0.7279\n",
      "60/194, train_loss: 0.9354\n",
      "61/194, train_loss: 0.5965\n",
      "62/194, train_loss: 0.8560\n",
      "63/194, train_loss: 0.6340\n",
      "64/194, train_loss: 0.6516\n",
      "65/194, train_loss: 0.7275\n",
      "66/194, train_loss: 0.8192\n",
      "67/194, train_loss: 0.6067\n",
      "68/194, train_loss: 0.5612\n",
      "69/194, train_loss: 0.6693\n",
      "70/194, train_loss: 0.6817\n",
      "71/194, train_loss: 0.7981\n",
      "72/194, train_loss: 0.7765\n",
      "73/194, train_loss: 0.6512\n",
      "74/194, train_loss: 0.7831\n",
      "75/194, train_loss: 0.7148\n",
      "76/194, train_loss: 0.8416\n",
      "77/194, train_loss: 0.8214\n",
      "78/194, train_loss: 0.5140\n",
      "79/194, train_loss: 0.7742\n",
      "80/194, train_loss: 0.6037\n",
      "81/194, train_loss: 0.8769\n",
      "82/194, train_loss: 0.8640\n",
      "83/194, train_loss: 0.6693\n",
      "84/194, train_loss: 0.8352\n",
      "85/194, train_loss: 0.9186\n",
      "86/194, train_loss: 0.8505\n",
      "87/194, train_loss: 0.8770\n",
      "88/194, train_loss: 0.9582\n",
      "89/194, train_loss: 0.8120\n",
      "90/194, train_loss: 0.7016\n",
      "91/194, train_loss: 0.8440\n",
      "92/194, train_loss: 0.8396\n",
      "93/194, train_loss: 0.7425\n",
      "94/194, train_loss: 0.6906\n",
      "95/194, train_loss: 0.8437\n",
      "96/194, train_loss: 0.6270\n",
      "97/194, train_loss: 0.8557\n",
      "98/194, train_loss: 0.6724\n",
      "99/194, train_loss: 0.7569\n",
      "100/194, train_loss: 0.6616\n",
      "101/194, train_loss: 0.8315\n",
      "102/194, train_loss: 0.8235\n",
      "103/194, train_loss: 0.6306\n",
      "104/194, train_loss: 0.7942\n",
      "105/194, train_loss: 0.8013\n",
      "106/194, train_loss: 0.6406\n",
      "107/194, train_loss: 0.6862\n",
      "108/194, train_loss: 0.7451\n",
      "109/194, train_loss: 0.7791\n",
      "110/194, train_loss: 0.6751\n",
      "111/194, train_loss: 0.7002\n",
      "112/194, train_loss: 0.6485\n",
      "113/194, train_loss: 0.6593\n",
      "114/194, train_loss: 0.7010\n",
      "115/194, train_loss: 0.8781\n",
      "116/194, train_loss: 0.8324\n",
      "117/194, train_loss: 0.7013\n",
      "118/194, train_loss: 0.6723\n",
      "119/194, train_loss: 0.8146\n",
      "120/194, train_loss: 0.7802\n",
      "121/194, train_loss: 0.9004\n",
      "122/194, train_loss: 0.7992\n",
      "123/194, train_loss: 0.7049\n",
      "124/194, train_loss: 0.7871\n",
      "125/194, train_loss: 0.9370\n",
      "126/194, train_loss: 0.7766\n",
      "127/194, train_loss: 0.8386\n",
      "128/194, train_loss: 0.8644\n",
      "129/194, train_loss: 0.7549\n",
      "130/194, train_loss: 0.4574\n",
      "131/194, train_loss: 0.7390\n",
      "132/194, train_loss: 0.7455\n",
      "133/194, train_loss: 0.7819\n",
      "134/194, train_loss: 0.8178\n",
      "135/194, train_loss: 0.6651\n",
      "136/194, train_loss: 0.7808\n",
      "137/194, train_loss: 0.7280\n",
      "138/194, train_loss: 0.9548\n",
      "139/194, train_loss: 0.6226\n",
      "140/194, train_loss: 0.7325\n",
      "141/194, train_loss: 0.8724\n",
      "142/194, train_loss: 0.9620\n",
      "143/194, train_loss: 0.7487\n",
      "144/194, train_loss: 0.7965\n",
      "145/194, train_loss: 0.7117\n",
      "146/194, train_loss: 0.5850\n",
      "147/194, train_loss: 0.6362\n",
      "148/194, train_loss: 0.7076\n",
      "149/194, train_loss: 0.8322\n",
      "150/194, train_loss: 0.7389\n",
      "151/194, train_loss: 0.9062\n",
      "152/194, train_loss: 0.7556\n",
      "153/194, train_loss: 0.6134\n",
      "154/194, train_loss: 0.6923\n",
      "155/194, train_loss: 0.8836\n",
      "156/194, train_loss: 0.9606\n",
      "157/194, train_loss: 0.6894\n",
      "158/194, train_loss: 0.7115\n",
      "159/194, train_loss: 0.8768\n",
      "160/194, train_loss: 0.9061\n",
      "161/194, train_loss: 0.6819\n",
      "162/194, train_loss: 0.8845\n",
      "163/194, train_loss: 0.9240\n",
      "164/194, train_loss: 0.8086\n",
      "165/194, train_loss: 0.7939\n",
      "166/194, train_loss: 0.8374\n",
      "167/194, train_loss: 0.8611\n",
      "168/194, train_loss: 0.8579\n",
      "169/194, train_loss: 0.7166\n",
      "170/194, train_loss: 0.7778\n",
      "171/194, train_loss: 0.7325\n",
      "172/194, train_loss: 0.7260\n",
      "173/194, train_loss: 0.9139\n",
      "174/194, train_loss: 0.8090\n",
      "175/194, train_loss: 0.7059\n",
      "176/194, train_loss: 0.7836\n",
      "177/194, train_loss: 0.7557\n",
      "178/194, train_loss: 0.6088\n",
      "179/194, train_loss: 0.7766\n",
      "180/194, train_loss: 0.6939\n",
      "181/194, train_loss: 0.7036\n",
      "182/194, train_loss: 0.7575\n",
      "183/194, train_loss: 0.6610\n",
      "184/194, train_loss: 0.6823\n",
      "185/194, train_loss: 0.8614\n",
      "186/194, train_loss: 0.8324\n",
      "187/194, train_loss: 0.9378\n",
      "188/194, train_loss: 0.6392\n",
      "189/194, train_loss: 0.7116\n",
      "190/194, train_loss: 0.7024\n",
      "191/194, train_loss: 0.7031\n",
      "192/194, train_loss: 0.7668\n",
      "193/194, train_loss: 0.8671\n",
      "194/194, train_loss: 0.5647\n",
      "metric=0.3758977021401127, metric_tc=0.3842764714111884, metric_wt=0.5274186072250208, metric_et=0.21599802289468548\n",
      "metric=0.3758977021401127, metric_tc=0.3842764714111884, metric_wt=0.5274186072250208, metric_et=0.21599802289468548\n",
      "current epoch: 80 current epoch loss: 0.7568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 80/80 [14:43:19<00:00, 662.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metric=0.3758977021401127, metric_tc=0.3842764714111884, metric_wt=0.5274186072250208, metric_et=0.21599802289468548\n",
      "0.3758977021401127\n",
      "current epoch: 80 current mean dice: 0.3759 tc: 0.3843 wt: 0.5274 et: 0.2160\n",
      "best mean dice: 0.4133 at epoch: 71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "##### global_model.to(device)\n",
    "global_model.train()\n",
    "\n",
    "#print(global_model)\n",
    "\n",
    "# copy weights\n",
    "global_weights = global_model.state_dict()\n",
    "\n",
    "# Training\n",
    "train_loss, train_accuracy = [], []\n",
    "val_acc_list, net_list = [], []\n",
    "cv_loss, cv_acc = [], []\n",
    "print_every = 1\n",
    "val_loss_pre, counter = 0, 0\n",
    "\n",
    "\n",
    "#####\n",
    "best_metric = -1\n",
    "best_metric_epoch = -1\n",
    "#epoch_loss_values = []\n",
    "metric_values = []\n",
    "metric_values_tc = []\n",
    "metric_values_wt = []\n",
    "metric_values_et = []\n",
    "\n",
    "metric, metric_tc, metric_wt, metric_et=0.0,0.0,0.0,0.0\n",
    "\n",
    "for epoch in tqdm.tqdm(range(epochs)):\n",
    "        \n",
    "    local_weights, local_losses = [], []\n",
    "    \n",
    "    print(f'\\n | Global Training Round : {epoch+1} |\\n')\n",
    "\n",
    "    global_model.train()\n",
    "    m = max(int(frac * num_users), 1)\n",
    "    idxs_users = np.random.choice(range(num_users), m, replace=False)\n",
    "\n",
    "    for idx in idxs_users:\n",
    "        \n",
    "        print(f\"user {idx} selected\")\n",
    "        local_model = LocalUpdate(train_dataset=train_dataset, val_dataset=val_dataset,\n",
    "                                  train_idxs=user_groups_train[idx],val_idxs=user_groups_val[idx], logger=logger, local_bs=local_bs, lr=lr, local_ep=local_ep, total_batches)\n",
    "        w, loss = local_model.update_weights(\n",
    "                model=copy.deepcopy(global_model), global_round=epoch)\n",
    "        local_weights.append(copy.deepcopy(w))\n",
    "      #  local_losses.append(copy.deepcopy(loss))\n",
    "        local_losses.append(loss)\n",
    "     #   global_model.load_state_dict(copy.deepcopy(w))\n",
    "    \n",
    "     #   global_model.eval()\n",
    "        \n",
    "     #   local_model.inference(model=global_model)\n",
    "\n",
    "    # update global weights\n",
    "    global_weights = average_weights(local_weights)\n",
    "   ## global_weights = local_weights[0]\n",
    "    \n",
    "    # update global loss\n",
    "    global_model.load_state_dict(global_weights)\n",
    "    \n",
    "    for c in range(num_users):\n",
    "        local_model = LocalUpdate(train_dataset=train_dataset, val_dataset=val_dataset,\n",
    "                                    train_idxs=user_groups_train[c],val_idxs=user_groups_val[c], logger=logger, lr=lr, local_ep=local_ep, local_bs=local_bs)\n",
    "        local_model.inference(model=global_model)\n",
    "    \n",
    "    loss_avg = sum(local_losses) / len(local_losses)\n",
    "    train_loss.append(loss_avg)\n",
    "    print(f\"current epoch: {epoch + 1} current epoch loss: {loss_avg:.4f}\")\n",
    "    # Calculate avg training accuracy over all users at every epoch\n",
    "    \n",
    "   # list_acc, list_loss = [], []\n",
    "    ep_metric_values = []\n",
    "    ep_metric_values_tc = []\n",
    "    ep_metric_values_wt = []\n",
    "    ep_metric_values_et = []\n",
    "\n",
    "    for c in range(num_users):\n",
    "        local_model = LocalUpdate(train_dataset=train_dataset, val_dataset=val_dataset,\n",
    "                                    train_idxs=user_groups_train[c],val_idxs=user_groups_val[c], logger=logger, lr=lr, local_ep=local_ep, local_bs=local_bs)\n",
    "        metric, metric_tc, metric_wt, metric_et=local_model.inference(model=global_model)\n",
    "        \n",
    "        ep_metric_values.append(metric)\n",
    "        ep_metric_values_tc.append(metric_tc)\n",
    "        ep_metric_values_wt.append(metric_wt) \n",
    "        ep_metric_values_et.append(metric_et) \n",
    "\n",
    "    metric = sum(ep_metric_values)/len(ep_metric_values)\n",
    "    metric_tc = sum(ep_metric_values_tc)/len(ep_metric_values_tc)\n",
    "    metric_wt = sum(ep_metric_values_wt)/len(ep_metric_values_wt)\n",
    "    metric_et = sum(ep_metric_values_et)/len(ep_metric_values_et)\n",
    "    metric_values.append(metric)\n",
    "    metric_values_tc.append(metric_tc)\n",
    "    metric_values_wt.append(metric_wt)\n",
    "    metric_values_et.append(metric_et)\n",
    "\n",
    "    global_model.eval()\n",
    "  ###  for c in range(num_users):\n",
    "  ###      local_model = LocalUpdate(train_dataset=train_dataset, val_dataset=val_dataset,\n",
    "  ###                                    train_idxs=user_groups_train[c],val_idxs=user_groups_val[c], logger=logger, lr=lr, local_ep=local_ep, local_bs=local_bs)\n",
    "  ###      metric, metric_tc, metric_wt, metric_et = local_model.inference(model=global_model)\n",
    "         \n",
    "   ##    print(metric)\n",
    "   ##    ep_metric_values.append(metric)\n",
    "   ##     ep_metric_values_tc.append(metric_tc)\n",
    "   ##     ep_metric_values_wt.append(metric_wt) \n",
    "   ##     ep_metric_values_et.append(metric_et) \n",
    "\n",
    "        \n",
    "   # train_accuracy.append(sum(list_acc)/len(list_acc))\n",
    "##    metric = sum(ep_metric_values)/len(ep_metric_values)\n",
    "    print(metric)\n",
    "##    metric_tc = sum(ep_metric_values_tc)/len(ep_metric_values_tc)\n",
    "##    metric_wt = sum(ep_metric_values_wt)/len(ep_metric_values_wt)\n",
    "##    metric_et = sum(ep_metric_values_et)/len(ep_metric_values_et)\n",
    "##    metric_values.append(metric)\n",
    "##    metric_values_tc.append(metric_tc)\n",
    "##    metric_values_wt.append(metric_wt)\n",
    "##    metric_values_et.append(metric_et)\n",
    "    \n",
    "    if metric > best_metric:\n",
    "         \n",
    "        best_metric = metric\n",
    "        best_metric_epoch = epoch + 1\n",
    "        torch.save(\n",
    "                global_model.state_dict(),\n",
    "                os.path.join(root_dir, \"best_metric_model.pth\"),\n",
    "        )\n",
    "        \n",
    "        torch.save({\n",
    "            'epoch': epoch + 1,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'loss': loss,\n",
    "            ...\n",
    "            }, os.path.join(root_dir, \"best_metric_overal_model.pth\"))\n",
    "        \n",
    "        print(\"saved new best metric model\")\n",
    "\n",
    "\n",
    "    # print global training loss after every 'i' rounds\n",
    "    if (epoch+1) % print_every == 0:\n",
    "      #  print(f' \\nAvg Training Stats after {epoch+1} global rounds:')\n",
    "      #  print(f'Training Loss : {np.mean(np.array(train_loss))}')\n",
    "      #  print('Train Accuracy: {:.2f}% \\n'.format(100*train_accuracy[-1]))\n",
    "         print(\n",
    "            f\"current epoch: {epoch + 1} current mean dice: {metric:.4f}\"\n",
    "            f\" tc: {metric_tc:.4f} wt: {metric_wt:.4f} et: {metric_et:.4f}\"\n",
    "            f\"\\nbest mean dice: {best_metric:.4f}\"\n",
    "            f\" at epoch: {best_metric_epoch}\"\n",
    "         )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "harmful-paradise",
   "metadata": {},
   "outputs": [],
   "source": [
    "end = time.time() \n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "sustainable-corruption",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'tuple' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-d0780d3322a6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mglobal_weights\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'model.0.conv.unit0.conv.weight'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m \u001b[0mlocal_weights\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'model.0.conv.unit0.conv.weight'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: 'tuple' object is not callable"
     ]
    }
   ],
   "source": [
    "######i(global_weights['model.0.conv.unit0.conv.weight']== local_weights[0]['model.0.conv.unit0.conv.weight'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ignored-drunk",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'eq'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-c62c63434f62>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#print(local_weights[0])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocal_weights\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglobal_weights\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mnot\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"err\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'eq'"
     ]
    }
   ],
   "source": [
    "#if(global_weights['model.0.conv.unit0.conv.weight']== local_weights[0]['model.0.conv.unit0.conv.weight']):\n",
    "#print(local_weights[0])\n",
    "for i,j in zip(local_weights[0].items(), global_weights.items()):\n",
    "    if(not torch.all(i.eq(j))):\n",
    "        print(\"err\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "attended-webmaster",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.951516932126173, 0.9444546459876385, 0.9369485888284507, 0.9305417934029373, 0.9220035011620865, 0.9144385343359918, 0.9077580964442381, 0.9009163367379572, 0.8920957350853792, 0.8838767839461258, 0.8784263004961702, 0.8732890065797826, 0.8697980931124736, 0.8635182565020532, 0.856944211057781, 0.8518456294364536, 0.8498095636515274, 0.8448240234679782, 0.8439370402970265, 0.8336787844441601, 0.835628092288971, 0.8357607888192246, 0.8208783106091097, 0.828741892404163, 0.8221208142865565, 0.8237798124859014, 0.8236483906962208, 0.8130327174344014, 0.8082682794516849, 0.822904872832839, 0.8147335356658267, 0.8119781880649095, 0.8084260366626621, 0.8093645019629567, 0.8023826910048416, 0.8021150646135979, 0.7996242444232567, 0.8069017299057282, 0.7979499107783603, 0.799815562889748, 0.7967861251732737, 0.7983163930091661, 0.7948083260010198, 0.794691993710921, 0.7947665855442125, 0.7909634140963407, 0.7864561802947644, 0.794921660546175, 0.7931458986911577, 0.7830077283775684, 0.7886057013703376, 0.7897488755970886, 0.7911181775565, 0.7839072733810267, 0.7869193083846692, 0.7772364888301829, 0.7698678272901122, 0.7763043917024258, 0.7803855043711122, 0.7787045255764243, 0.7803620923425734, 0.7752737009648195, 0.7814672395740587, 0.7788568037686888, 0.7781322386461434, 0.7712320984946084, 0.7747516045250844, 0.7696490527428302, 0.7731071437142559, 0.7640041441647047, 0.7706419355476025, 0.7743628943703839, 0.7647483871155178, 0.7607104314356735, 0.759984411529659, 0.7628260052081236, 0.7574785454678781, 0.7622854224185354, 0.7639532602324928, 0.7568326781398242]\n"
     ]
    }
   ],
   "source": [
    "print(train_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "pharmaceutical-walker",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1296x432 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline \n",
    "val_interval=1\n",
    "plt.figure(\"train\", (12, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.title(\"Epoch Average Loss\")\n",
    "x = [i + 1 for i in range(len(train_loss))]\n",
    "y = train_loss\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.plot(x, y, color=\"red\")\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.title(\"Val Mean Dice\")\n",
    "x = [val_interval * (i + 1) for i in range(len(metric_values))]\n",
    "y = metric_values\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.plot(x, y, color=\"green\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure(\"train\", (18, 6))\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.title(\"Val Mean Dice TC\")\n",
    "x = [val_interval * (i + 1) for i in range(len(metric_values_tc))]\n",
    "y = metric_values_tc\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.plot(x, y, color=\"blue\")\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.title(\"Val Mean Dice WT\")\n",
    "x = [val_interval * (i + 1) for i in range(len(metric_values_wt))]\n",
    "y = metric_values_wt\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.plot(x, y, color=\"brown\")\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.title(\"Val Mean Dice ET\")\n",
    "x = [val_interval * (i + 1) for i in range(len(metric_values_et))]\n",
    "y = metric_values_et\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.plot(x, y, color=\"purple\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "designed-browser",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_acc, test_loss = test_inference(args, global_model, test_dataset)\n",
    "    \n",
    "print(f' \\n Results after {epochs} global rounds of training:')\n",
    "print(\"|---- Avg Train Accuracy: {:.2f}%\".format(100*train_accuracy[-1]))\n",
    "print(\"|---- Test Accuracy: {:.2f}%\".format(100*test_acc))\n",
    "\n",
    "    # Saving the objects train_loss and train_accuracy:\n",
    "file_name = '../save/objects/{}_{}_{}_C[{}]_iid[{}]_E[{}]_B[{}].pkl'.\\\n",
    "    format(dataset, model, epochs, frac, iid,\n",
    "            local_ep, local_bs)\n",
    "\n",
    "with open(file_name, 'wb') as f:\n",
    "    pickle.dump([train_loss, train_accuracy], f)\n",
    "\n",
    "print('\\n Total Run Time: {0:0.4f}'.format(time.time()-start_time))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "governmental-ranch",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../save/fed_brats_UNET_1_C[0.1]_iid[1]_E[1]_B[2]_loss.png'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-163-a02ee033f330>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Training loss'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Communication Rounds'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m plt.savefig('../save/fed_{}_{}_{}_C[{}]_iid[{}]_E[{}]_B[{}]_loss.png'.\n\u001b[0m\u001b[1;32m     14\u001b[0m              format(dataset, model, epochs, frac,\n\u001b[1;32m     15\u001b[0m                         iid, local_ep, local_bs))\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36msavefig\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    857\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msavefig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m     \u001b[0mfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgcf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 859\u001b[0;31m     \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msavefig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    860\u001b[0m     \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw_idle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m   \u001b[0;31m# need this if 'transparent=True' to reset colors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/matplotlib/figure.py\u001b[0m in \u001b[0;36msavefig\u001b[0;34m(self, fname, transparent, **kwargs)\u001b[0m\n\u001b[1;32m   2309\u001b[0m                 \u001b[0mpatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_edgecolor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'none'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2310\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2311\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_figure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2313\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtransparent\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/matplotlib/backend_bases.py\u001b[0m in \u001b[0;36mprint_figure\u001b[0;34m(self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, pad_inches, bbox_extra_artists, backend, **kwargs)\u001b[0m\n\u001b[1;32m   2208\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2209\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2210\u001b[0;31m                 result = print_method(\n\u001b[0m\u001b[1;32m   2211\u001b[0m                     \u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2212\u001b[0m                     \u001b[0mdpi\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdpi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/matplotlib/backend_bases.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1637\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1638\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1639\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1640\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1641\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/matplotlib/backends/backend_agg.py\u001b[0m in \u001b[0;36mprint_png\u001b[0;34m(self, filename_or_obj, metadata, pil_kwargs, *args)\u001b[0m\n\u001b[1;32m    508\u001b[0m         \"\"\"\n\u001b[1;32m    509\u001b[0m         \u001b[0mFigureCanvasAgg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 510\u001b[0;31m         mpl.image.imsave(\n\u001b[0m\u001b[1;32m    511\u001b[0m             \u001b[0mfilename_or_obj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuffer_rgba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"png\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morigin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"upper\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    512\u001b[0m             dpi=self.figure.dpi, metadata=metadata, pil_kwargs=pil_kwargs)\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/matplotlib/image.py\u001b[0m in \u001b[0;36mimsave\u001b[0;34m(fname, arr, vmin, vmax, cmap, format, origin, dpi, metadata, pil_kwargs)\u001b[0m\n\u001b[1;32m   1609\u001b[0m         \u001b[0mpil_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetdefault\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"format\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1610\u001b[0m         \u001b[0mpil_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetdefault\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"dpi\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdpi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdpi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1611\u001b[0;31m         \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpil_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1612\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1613\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/PIL/Image.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, fp, format, **params)\u001b[0m\n\u001b[1;32m   2167\u001b[0m                 \u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"r+b\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2168\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2169\u001b[0;31m                 \u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"w+b\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2171\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../save/fed_brats_UNET_1_C[0.1]_iid[1]_E[1]_B[2]_loss.png'"
     ]
    }
   ],
   "source": [
    "#PLOTTING (optional)\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "matplotlib.use('Agg')\n",
    "\n",
    "# Plot Loss curve\n",
    "plt.figure()\n",
    "model = \"UNET\"\n",
    "plt.title('Training Loss vs Communication rounds')\n",
    "plt.plot(range(len(train_loss)), train_loss, color='r')\n",
    "plt.ylabel('Training loss')\n",
    "plt.xlabel('Communication Rounds')\n",
    "plt.savefig('../save/fed_{}_{}_{}_C[{}]_iid[{}]_E[{}]_B[{}]_loss.png'.\n",
    "             format(dataset, model, epochs, frac,\n",
    "                        iid, local_ep, local_bs))\n",
    "    \n",
    "# # Plot Average Accuracy vs Communication rounds\n",
    "plt.figure()\n",
    "plt.title('Average Accuracy vs Communication rounds')\n",
    "plt.plot(range(len(train_accuracy)), train_accuracy, color='k')\n",
    "plt.ylabel('Average Accuracy')\n",
    "plt.xlabel('Communication Rounds')\n",
    "plt.savefig('../save/fed_{}_{}_{}_C[{}]_iid[{}]_E[{}]_B[{}]_acc.png'.\n",
    "             format(dataset, model, epochs, frac,\n",
    "                    iid, local_ep, local_bs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "colored-positive",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
